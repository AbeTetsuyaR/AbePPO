{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbeTetsuyaR/AbePPO/blob/main/AbePPO0807.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qCrwylLHTYPW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import cProfile\n",
        "import sys\n",
        "import copy\n",
        "from torch.distributions.categorical import Categorical\n",
        "import math\n",
        "import os\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.colors as mcolors\n",
        "from tqdm import tqdm  # tqdmをインポート\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats import gamma, uniform\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L6hr_FE6TYPY"
      },
      "outputs": [],
      "source": [
        "class Environment:\n",
        "    def __init__(self, n_units=2):\n",
        "        self.n_units = n_units #number of unit\n",
        "        self.n_states = 5 #number of state\n",
        "        self.inventory = 0\n",
        "        self.demand = 0\n",
        "        self.maintenance_status = [0] * self.n_units\n",
        "        self.interval = 24\n",
        "        self.remain_interval = 24\n",
        "        self.MAX_speed = 10/self.interval\n",
        "        self.MAX_inventory = 0\n",
        "        self.MAX_demand = 15\n",
        "        self.MAX_maintenance_time = 0\n",
        "\n",
        "        self.load_total=1\n",
        "\n",
        "        self.cp = 500#\n",
        "        self.cc = 1800#\n",
        "\n",
        "        self.cps = 0\n",
        "        self.co = 5\n",
        "        self.cs = 500#\n",
        "\n",
        "        self.levels = [0] * self.n_units\n",
        "        self.shape = 3\n",
        "        self.penalty = 1\n",
        "        self.L = 100#\n",
        "        self.P_Cost =[[100,120,140,160,2500],\n",
        "                      [120,140,160,180,2520],\n",
        "                      [140,160,180,200,2540],\n",
        "                      [160,180,200,220,2560],\n",
        "                      [2500,2520,2540,2560,2580]]#一旦\n",
        "\n",
        "        self.failure_keep1 = 0 #1つ故障しているのに保全を選択しなかった回数\n",
        "        self.failure_keep2 = 0 #2つ故障しているのに保全を選択しなかった回数\n",
        "        self.failure_keep3 = 0 #3つ故障しているのに保全を選択しなかった回数\n",
        "        self.replace_chance = 0 #保全を選択できた回数\n",
        "\n",
        "    def init_random(self):\n",
        "        l = range(self.n_states)\n",
        "        m = range(self.MAX_maintenance_time)\n",
        "        flag = True\n",
        "        while flag:\n",
        "            for unit_idx in range(self.n_units):\n",
        "                self.levels[unit_idx] = random.choice(l)\n",
        "                if self.levels[unit_idx] == self.n_states-1:\n",
        "                        flag = False\n",
        "                #if self.levels[unit_idx] == 0:\n",
        "                    #self.maintenance_status[unit_idx] = random.choice(m)\n",
        "\n",
        "        #需要\n",
        "        mean = 10\n",
        "        variance = 2  # 標準偏差\n",
        "        mu = np.log(mean**2 / np.sqrt(variance**2 + mean**2))\n",
        "        sigma = np.sqrt(np.log(1 + (variance**2 / mean**2)))\n",
        "        self.demand = np.random.lognormal(mu, sigma)\n",
        "        if self.demand > 15:\n",
        "            self.demand = 15\n",
        "        self.demand = random.uniform(0,15)\n",
        "        #意思決定時\n",
        "        #self.remain_interval = random.uniform(0, self.interval)\n",
        "        #在庫\n",
        "        self.inventory = random.uniform(0,self.MAX_inventory)\n",
        "\n",
        "        level_ohe= self.one_hot_encode()\n",
        "\n",
        "        return level_ohe, \\\n",
        "               0, self.load_total, 0\n",
        "\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.levels = np.zeros(self.n_units)\n",
        "\n",
        "    def complete_maintenance(self, unit_idx):\n",
        "        self.levels[unit_idx] = 0\n",
        "\n",
        "    def get_ability(self, level): #良品率\n",
        "        if level == 0:\n",
        "            return 1\n",
        "        elif level == 1:\n",
        "            return 0.8\n",
        "        elif level ==2:\n",
        "            return 0.5\n",
        "        elif level == 3:\n",
        "            return 0.1\n",
        "        return (self.n_states - 1 - level) / (self.n_states - 1)\n",
        "\n",
        "    def update_demand(self, speed, ability, time):\n",
        "        if self.demand >= self.inventory:\n",
        "            self.demand -= self.inventory\n",
        "            self.inventory = 0.0\n",
        "        else:\n",
        "            self.inventory -= self.demand\n",
        "            self.demand = 0.0\n",
        "        return max(0, self.demand-self.inventory-ability*speed*time)\n",
        "\n",
        "    def update_inventory(self, speed, ability, time):\n",
        "        if self.demand <= self.inventory + ability * speed * time:\n",
        "            return min(self.MAX_inventory, -self.demand+self.inventory+ability*speed*time), max(0, -self.MAX_inventory-self.demand+self.inventory+ability*speed*time)\n",
        "        else:\n",
        "            return 0.0, 0.0\n",
        "\n",
        "    def get_maintenance_time(self,level):\n",
        "        return 0\n",
        "\n",
        "    def update_maintenance_time(self, unit_idx):\n",
        "        return 0\n",
        "\n",
        "    def one_hot_encode(self):\n",
        "        level_ohe = []\n",
        "        #mstatus_ohe = []\n",
        "        for unit_idx in range(self.n_units):\n",
        "            l = [0] * self.n_states\n",
        "            #m = [0] * (self.MAX_maintenance_time + 1)\n",
        "            l[min(math.floor(self.levels[unit_idx]),self.n_states-1)] = 1\n",
        "            #m[self.maintenance_status[unit_idx]] = 1\n",
        "            level_ohe = level_ohe + l\n",
        "            #mstatus_ohe = mstatus_ohe + m\n",
        "        return level_ohe #mstatus_oheは削除\n",
        "\n",
        "\n",
        "\n",
        "    def operation(self, replacements, load1):\n",
        "        reward = 0\n",
        "\n",
        "        speeds=[load1,0]\n",
        "        #生産速度の調整\n",
        "        if speeds[0] < 0:\n",
        "            speeds[0] = 0\n",
        "        if speeds[0] > 1:\n",
        "            speeds[0] = 1\n",
        "\n",
        "        flag = 0\n",
        "\n",
        "        #保全の意思決定\n",
        "        #print(replacements)\n",
        "\n",
        "        if replacements==[1,1]: #稼働継続\n",
        "          # パラメータの設定\n",
        "          scales=[0,0]\n",
        "          shape1 = 0.69  # ガンマ分布のパラメータ v1 用 0.69\n",
        "          shape2 = 0.69  # ガンマ分布のパラメータ v2 用\n",
        "          tau = 0.5  # ケンドールの順位相関係数\n",
        "\n",
        "          theta = 1 / (1 - tau)\n",
        "          # 一様乱数を生成\n",
        "          u = uniform.rvs(size=1)\n",
        "          v = uniform.rvs(size=1)\n",
        "\n",
        "          # ガンベルコピュラの変換適用\n",
        "          #c = (-np.log(u)) ** theta + (-np.log(v)) ** theta\n",
        "          #u_transformed = np.exp(-c**(1/theta))\n",
        "          #v_transformed = np.exp(-c**(1/theta))\n",
        "\n",
        "          # 一様乱数をガンマ分布の逆関数に通す\n",
        "\n",
        "          #load_totalを考慮した調整\n",
        "          if speeds[0]>self.load_total:\n",
        "            speeds[0]=self.load_total\n",
        "          speeds[1]=self.load_total - speeds[0]\n",
        "          if speeds[1]>self.load_total:\n",
        "            speeds[1]=1\n",
        "            speeds[0]=self.load_total - speeds[1]\n",
        "          #print(speeds, \"speeds\")\n",
        "          #尺度パラメータ計算\n",
        "          for i in range(self.n_units):\n",
        "            scales[i]=6.491*(speeds[i]**2)+0.726\n",
        "\n",
        "\n",
        "          v1 = gamma.ppf(u, shape1, scale=scales[0])\n",
        "          v2 = gamma.ppf(v, shape2, scale=scales[1])\n",
        "\n",
        "          #print(\"稼働継続\")\n",
        "          #print(v1,v2, \"劣化増分\")\n",
        "          self.levels[0]+=v1/25##\n",
        "          self.levels[1]+=v2/25##\n",
        "          #print(self.levels, \"劣化\")\n",
        "\n",
        "          reward -= self.P_Cost[min(math.floor(self.levels[0]),self.n_states-1)][min(math.floor(self.levels[1]),self.n_states-1)]\n",
        "\n",
        "        elif replacements==[0,1]: #1のみ取替\n",
        "          self.levels[0]=0\n",
        "          reward -= self.cs\n",
        "          if self.levels[0]<self.n_states-1:\n",
        "            reward -= self.cp\n",
        "          else:\n",
        "            reward -= self.cc\n",
        "\n",
        "        elif replacements==[1,0]: #2のみ取替\n",
        "          self.levels[1]=0\n",
        "          reward -= self.cs\n",
        "          if self.levels[1]<self.n_states-1:\n",
        "            reward -= self.cp\n",
        "          else:\n",
        "            reward -= self.cc\n",
        "\n",
        "        else: #両方取替\n",
        "          self.levels=[0,0]\n",
        "          reward -= self.cs\n",
        "          if self.levels[0]<self.n_states-1:\n",
        "            reward -= self.cp\n",
        "          else:\n",
        "            reward -= self.cc\n",
        "          if self.levels[1]<self.n_states-1:\n",
        "            reward -= self.cp\n",
        "          else:\n",
        "            reward -= self.cc\n",
        "\n",
        "\n",
        "        #print(self.levels)\n",
        "        #print(reward)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        level_ohe= self.one_hot_encode()\n",
        "\n",
        "        #print(f'状態:{self.levels}, 保全状態:{self.maintenance_status}, 在庫:{self.inventory}, 需要:{self.demand}, 残り時間:{self.remain_interval}, 保全行動:{replacements}, {speeds}')\n",
        "        #print(\"#############\")\n",
        "\n",
        "        flag = 0\n",
        "\n",
        "        return reward, level_ohe, \\\n",
        "               0, self.load_total, 0, flag\n",
        "        #return reward, level_ohe, mstatus_ohe, \\\n",
        "        #       0, (self.demand-mean)/variance, self.remain_interval * 2 / self.interval - 1, flag\n",
        "\n",
        "\n",
        "    #劣化レベル順にすべき可能性"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z_7ruy0iTYPa"
      },
      "outputs": [],
      "source": [
        "class PPOMemory:\n",
        "    def __init__(self,batch_size, interval, beta, GAE_lam):\n",
        "        self.states = []\n",
        "        self.probs = []\n",
        "        self.vals = []\n",
        "        self.acts_dsc = []\n",
        "        self.acts_cnt = []\n",
        "        self.rewards = []\n",
        "        self.time = []\n",
        "        self.batch_size = batch_size\n",
        "        self.interval = interval\n",
        "        self.beta = beta\n",
        "        self.advantage = []\n",
        "        self.lam = GAE_lam\n",
        "\n",
        "    def generate_advantage(self):\n",
        "\n",
        "        \"\"\"\n",
        "        advantage = np.zeros(len(self.rewards),dtype=np.float32)\n",
        "        for t in range(len(self.rewards)-1):\n",
        "            a_t = 0\n",
        "            for k in range(t, len(self.rewards)-1):\n",
        "                a_t += math.exp(-self.beta * self.time[k]) * \\\n",
        "                    (self.rewards[k]+math.exp(-self.beta * (-self.time[k]%self.interval+self.interval))*self.vals[k+1]-self.vals[k])\n",
        "            advantage[t] = a_t\n",
        "        self.advantage = advantage\n",
        "        \"\"\"\n",
        "\n",
        "        advantage = []\n",
        "        gae = 0\n",
        "        for t in reversed(range(len(self.rewards))):\n",
        "            gamma = 1\n",
        "            if t == len(self.rewards) - 1:\n",
        "                delta = self.rewards[t] - self.vals[t]\n",
        "            else:\n",
        "                gamma = math.exp(-self.beta*(self.time[t+1]-self.time[t]))\n",
        "                delta = self.rewards[t] + gamma * self.vals[t+1] - self.vals[t]\n",
        "            gae = delta + gamma * self.lam * gae\n",
        "            advantage.insert(0, gae)\n",
        "        self.advantage = np.array(advantage,dtype=np.float32)\n",
        "\n",
        "\n",
        "\n",
        "    def generate_batches(self):\n",
        "        n_states = len(self.states)\n",
        "        batch_start = np.arange(0, n_states, self.batch_size)\n",
        "        indices = np.arange(n_states, dtype=np.int64)\n",
        "        np.random.shuffle(indices)\n",
        "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
        "\n",
        "        return np.array(self.states),\\\n",
        "               np.array(self.acts_dsc),\\\n",
        "               np.array(self.acts_cnt),\\\n",
        "               np.array(self.probs),\\\n",
        "               np.array(self.vals),\\\n",
        "               np.array(self.rewards),\\\n",
        "               np.array(self.advantage),\\\n",
        "               batches\n",
        "\n",
        "\n",
        "\n",
        "    def store_memory(self, state, act_dsc, act_cnt, probs, vals, reward, time):\n",
        "        self.states.append(state)\n",
        "        self.acts_dsc.append(act_dsc)\n",
        "        self.acts_cnt.append(act_cnt)\n",
        "        self.probs.append(probs)\n",
        "        self.vals.append(vals)\n",
        "        self.rewards.append(reward)\n",
        "        self.time.append(time)\n",
        "\n",
        "    def clear_memory(self):\n",
        "        self.states = []\n",
        "        self.probs = []\n",
        "        self.acts_dsc = []\n",
        "        self.acts_cnt = []\n",
        "        self.rewards = []\n",
        "        self.vals = []\n",
        "        self.time = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MJC8xTojTYPa"
      },
      "outputs": [],
      "source": [
        "class ActorNetwork(nn.Module):\n",
        "    def __init__(self, n_units, n_states, MAX_maintenance_time, input_dims, alpha, fc1_dims=64, fc2_dims=64, fc3_dims=64, chkpt_dir=\"\"):\n",
        "        super(ActorNetwork, self).__init__()\n",
        "        self.n_units = n_units\n",
        "        self.n_states = n_states\n",
        "        self.MAX_maintenance_time = MAX_maintenance_time\n",
        "        self.checkpoint_file = os.path.join(chkpt_dir, \"actor_torch_ppo\")\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dims, fc1_dims)\n",
        "        self.fc2 = nn.Linear(fc1_dims, fc2_dims)\n",
        "        self.fc3 = nn.Linear(fc1_dims, fc3_dims)\n",
        "\n",
        "        self.dsc = nn.Linear(fc2_dims, 2 ** n_units) #離散行動\n",
        "        # 以下に初期化コードを追加\n",
        "        self.init_dsc_weights()\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.Tanh = nn.Tanh()\n",
        "\n",
        "        self.mean = nn.Linear(fc3_dims, n_units-1)\n",
        "        self.log_std = nn.Linear(fc3_dims, n_units-1)\n",
        "\n",
        "        # mean レイヤーの初期化\n",
        "        self.init_mean_weights()\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.to(self.device)\n",
        "\n",
        "        self.scheduler_actor = optim.lr_scheduler.StepLR(self.optimizer, step_size=5, gamma=0.95)\n",
        "\n",
        "    def init_dsc_weights(self):\n",
        "        # ここで特定の出力確率を設定するための重みとバイアスを設定\n",
        "        with torch.no_grad():\n",
        "            # すべての出力がほぼ等しくなるように設定\n",
        "            self.dsc.weight.fill_(0.0)\n",
        "            # 特定の確率分布に調整\n",
        "            self.dsc.bias.data = torch.log(torch.tensor([0.03, 0.03, 0.03, 0.91]))  # logを取るのがポイント\n",
        "\n",
        "    def init_mean_weights(self):\n",
        "        # mean レイヤーの初期化\n",
        "        with torch.no_grad():\n",
        "            self.mean.weight.fill_(0.0)\n",
        "            self.mean.bias.fill_(0.0)  # ここで固定出力0.5を設定#0に変更\n",
        "\n",
        "    #離散行動空間を制限するための関数, 返り値はmaskで制限されるところは-inf,されないところは1。返り値はバッチ数*2\n",
        "    def create_dsc_mask(self, state): #state=[s,m,b,d,t], action=[P(replace), P(keep)]\n",
        "        mask = torch.zeros(state.size(0),2**self.n_units)\n",
        "        #保全を選択できる時点にて、保全中のユニットは保全を選択できない\n",
        "        for unit_idx in range(self.n_units):\n",
        "            for a in range(2 ** self.n_units):\n",
        "                action_list = [int(bit) for bit in format(a, f'0{self.n_units}b')] #action_list=[r1,r2,r3,...]\n",
        "                if action_list[unit_idx] == 0:\n",
        "                    #保全の意思決定時点のとき、保全中の場合は保全を選択できない\n",
        "                    #保全の意思決定時点でないとき、保全を選択できない\n",
        "                    mask[(state[:,(self.n_states*self.n_units-1+(self.MAX_maintenance_time+1)*unit_idx+1)] == 0)\\\n",
        "                        , a] = torch.tensor(1)\n",
        "\n",
        "\n",
        "        mask[(state[:, 4] == 1) & (state[:, 9] == 1) & \\\n",
        "             (state[:,self.n_states*self.n_units-1 + 1] == 1)\n",
        "            ,1:] = torch.tensor(1) #2 ** self.n_units-1\n",
        "            #状態とユニット数により要変更\n",
        "\n",
        "        return mask.bool()\n",
        "\n",
        "    def create_cnt_mask(self, state):\n",
        "        mask= torch.zeros(state.size(0), self.n_units)\n",
        "        for unit_idx in range(self.n_units):\n",
        "            a = 2**(self.n_units)-1 - 2**(self.n_units-1-unit_idx)\n",
        "\n",
        "            #保全の意思決定ができる時\n",
        "            #mask[(state[:,-1] == 1) & \\\n",
        "            #     ((dist_dsc[:,a] <= 0.0001) |\n",
        "            #      (state[:,unit_idx*self.n_states+self.n_states-1] == 1) | \\\n",
        "            #      (state[:,(self.n_states*self.n_units-1+(self.MAX_maintenance_time+1)*unit_idx+1)] == 0)), unit_idx] = torch.tensor(1)\n",
        "            mask[((state[:,unit_idx*self.n_states+self.n_states-1] == 1) | \\\n",
        "                  (state[:,(self.n_states*self.n_units-1+(self.MAX_maintenance_time+1)*unit_idx+1)] == 0)), unit_idx] = torch.tensor(1)\n",
        "\n",
        "\n",
        "        return mask.bool()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x2 = F.relu(self.fc2(x))\n",
        "        x3 = F.relu(self.fc3(x))\n",
        "\n",
        "        first_mask = self.create_dsc_mask(state)\n",
        "\n",
        "        #離散行動の分布\n",
        "        dist_dsc = self.dsc(x2)\n",
        "        dist_dsc = dist_dsc.masked_fill(first_mask,-1e5)\n",
        "\n",
        "        dist_dsc = self.softmax(dist_dsc)\n",
        "        #if (state[0,4]==1 and state[0,9]==1 and state[0,14]==1 and state[0,15]==1 and state[0,19]==1 and state[0,23]==1 and state[0,-1]==1):\n",
        "        #    print(state)\n",
        "        #    print(dist_dsc)\n",
        "        #    print(\"&&&&&&&&\")\n",
        "\n",
        "\n",
        "        second_mask = self.create_cnt_mask(state)\n",
        "        dist_dsc = Categorical(dist_dsc)\n",
        "\n",
        "        #連続行動の分布\n",
        "        mean = self.mean(x3)\n",
        "        mean = self.Tanh(mean)\n",
        "\n",
        "        #mean = mean.masked_fill(second_mask, -1) #セカンドマスクを消す\n",
        "        mean = (mean+1)/2 #これで[0,1]になってほしい\n",
        "\n",
        "        #print(dist_dsc, mean)\n",
        "        #print(state)\n",
        "        #print(dist_dsc)\n",
        "        #mean = torch.clamp(mean,min=-5,max=5)\n",
        "        log_std = self.log_std(x3)\n",
        "        log_std = torch.clamp(log_std,min=-20,max=2)\n",
        "        std = log_std.exp()\n",
        "        #std = std.masked_fill(second_mask, 1e-4) #セカンドマスクを消す\n",
        "        #print(mean)\n",
        "        #print(\"AAAA\")\n",
        "\n",
        "        #print(mean,std)\n",
        "\n",
        "        #dist_cnt = torch.distributions.MultivariateNormal(loc=mean, covariance_matrix = torch.stack([torch.diag(x**2+1e-10) for x in std]))\n",
        "\n",
        "        dist_cnt = torch.distributions.Normal(loc=mean, scale=std) #1次元化のため\n",
        "\n",
        "\n",
        "        return dist_dsc, dist_cnt\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        torch.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        self.load_state_dict(torch.load(self.checkpoint_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "78j9p-tgTYPb"
      },
      "outputs": [],
      "source": [
        "class CriticNetwork(nn.Module):\n",
        "    def __init__(self, input_dims, alpha, fc1_dims=32, fc2_dims=32, fc3_dims=64, chkpt_dir=\"\"):\n",
        "        super(CriticNetwork, self).__init__()\n",
        "\n",
        "        self.checkpoint_file = os.path.join(chkpt_dir, \"critic_torch_ppo\")\n",
        "        self.critic = nn.Sequential(\n",
        "            nn.Linear(input_dims, fc1_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(fc1_dims,fc2_dims),\n",
        "            nn.ReLU(),\n",
        "            #nn.Linear(fc2_dims,fc3_dims),\n",
        "            #nn.ReLU(),\n",
        "            nn.Linear(fc2_dims,1)\n",
        "        )\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.to(self.device)\n",
        "\n",
        "        self.scheduler_critic = optim.lr_scheduler.StepLR(self.optimizer, step_size=5, gamma=0.95)\n",
        "\n",
        "\n",
        "    def forward(self, state):\n",
        "        value = self.critic(state)\n",
        "        return value\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        torch.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        self.load_state_dict(torch.load(self.checkpoint_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jRw3Bjb7TYPb",
        "outputId": "0d31e732-94bc-4de8-c883-69912989f711"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DMZpQl6gTYPc"
      },
      "outputs": [],
      "source": [
        "test_batch = 0\n",
        "class Agent:\n",
        "    def __init__(self, n_units, n_states, MAX_maintenance_time, input_dims, beta=0.0005, GAE_lam=0.95, interval=24,\n",
        "                 alpha_actor=0.03, alpha_critic=0.01,\n",
        "                 policy_clip=0.2, batch_size=512*4, n_epochs=4):\n",
        "        self.beta = beta\n",
        "        self.policy_clip = policy_clip\n",
        "        self.n_epochs = n_epochs\n",
        "\n",
        "        self.loss_history = []\n",
        "        self.loss_history_detail = []\n",
        "\n",
        "        self.actor_loss_history = []\n",
        "        self.actor_loss_history_detail = []\n",
        "        self.critic_loss_history = []\n",
        "        self.critic_loss_history_detail = []\n",
        "        self.entropy_history = []\n",
        "        self.kl_divergence_history = []\n",
        "\n",
        "        self.actor = ActorNetwork(n_units, n_states, MAX_maintenance_time, input_dims, alpha_actor)\n",
        "        self.critic = CriticNetwork(input_dims, alpha_critic)\n",
        "        self.memory = PPOMemory(batch_size, interval=interval, beta=beta, GAE_lam=GAE_lam)\n",
        "\n",
        "    def remember(self,state,action_dsc,action_cnt,probs,vals,reward, time):\n",
        "        self.memory.store_memory(state,action_dsc,action_cnt,probs,vals,reward, time)\n",
        "\n",
        "    def save_models(self):\n",
        "        print(\"... saving models ...\")\n",
        "        self.actor.save_checkpoint()\n",
        "        self.critic.save_checkpoint()\n",
        "\n",
        "    def load_models(self):\n",
        "        print(\"... loading models ...\")\n",
        "        self.actor.load_checkpoint()\n",
        "        self.critic.load_checkpoint()\n",
        "\n",
        "    def choose_action(self,observation):\n",
        "        state = torch.tensor(np.array([observation]),dtype=torch.float).to(self.actor.device)\n",
        "        dist_dsc, dist_cnt = self.actor(state)\n",
        "        print(state, \"dsc:\" ,dist_dsc.probs, \"cnt:\" ,dist_cnt.mean)\n",
        "        value = self.critic(state)\n",
        "        act_dsc = dist_dsc.sample()\n",
        "        act_cnt = dist_cnt.sample()\n",
        "        print(act_cnt)\n",
        "        log_prob_dsc = torch.squeeze(dist_dsc.log_prob(act_dsc)).item()\n",
        "        log_prob_cnt = torch.squeeze(dist_cnt.log_prob(act_cnt)).item()\n",
        "\n",
        "\n",
        "        log_prob = log_prob_dsc + log_prob_cnt\n",
        "\n",
        "        value = torch.squeeze(value).item()\n",
        "\n",
        "        return act_dsc, act_cnt, log_prob, value\n",
        "\n",
        "    def choose_action_max_prob(self,observation):\n",
        "        state = torch.tensor(np.array([observation]),dtype=torch.float).to(self.actor.device)\n",
        "        dist_dsc, dist_cnt = self.actor(state)\n",
        "        print(state, \"dsc\", dist_dsc.probs, \"cnt:\",dist_cnt.mean)\n",
        "        act_dsc = torch.argmax(dist_dsc.probs)\n",
        "        act_cnt = dist_cnt.mean\n",
        "        print(act_dsc, \"act_dsc\")\n",
        "        print(act_cnt, \"act_cnt\")\n",
        "\n",
        "        value = self.critic(state)\n",
        "\n",
        "\n",
        "        log_prob_dsc = torch.squeeze(dist_dsc.log_prob(act_dsc)).item()\n",
        "        log_prob_cnt = torch.squeeze(dist_cnt.log_prob(act_cnt)).item()\n",
        "        log_prob = log_prob_dsc + log_prob_cnt\n",
        "\n",
        "        value = torch.squeeze(value).item()\n",
        "\n",
        "        return act_dsc, act_cnt, log_prob, value\n",
        "\n",
        "    def learn(self):\n",
        "        self.memory.generate_advantage()\n",
        "        actor_loss_sum = 0\n",
        "        critic_loss_sum = 0\n",
        "        entropy_sum = 0\n",
        "        kl_divergence_sum = 0\n",
        "        for _ in range(self.n_epochs):\n",
        "        #for _ in tqdm(range(self.n_epochs), desc=\"Training Progress\"):  # tqdmを用いて進捗表示\n",
        "            \"\"\"\n",
        "            rewards = self.memory.rewards\n",
        "            values = self.memory.vals\n",
        "            times = self.memory.time\n",
        "            advantage = np.zeros(len(reward_arr),dtype=np.float32)\n",
        "            for t in range(len(reward_arr)-1):\n",
        "                a_t = 0\n",
        "                for k in range(t, len(reward_arr)-1):\n",
        "                    a_t += math.exp(-self.beta * times[k]) * \\\n",
        "                        (reward_arr[k]+math.exp(-self.beta * (-times[k]%self.interval+self.interval))*values[k+1]-values[k])\n",
        "                advantage[t] = a_t\n",
        "            advantage = torch.tensor(advantage).to(self.actor.device)\n",
        "            \"\"\"\n",
        "            state_arr, act_dsc_arr, act_cnt_arr, old_probs_arr, vals_arr, reward_arr, advantage, batches=self.memory.generate_batches()\n",
        "            values = vals_arr\n",
        "            \"\"\"\n",
        "            values = vals_arr\n",
        "            times = time_arr\n",
        "            advantage = np.zeros(len(reward_arr),dtype=np.float32)\n",
        "            for t in range(len(reward_arr)-1):\n",
        "                a_t = 0\n",
        "                for k in range(t, len(reward_arr)-1):\n",
        "                    a_t += math.exp(-self.beta * times[k]) * (reward_arr[k]+self.gamma*values[k+1]-values[k])\n",
        "                advantage[t] = a_t\n",
        "            \"\"\"\n",
        "            advantage = torch.tensor(advantage).to(self.actor.device)\n",
        "\n",
        "            values = torch.tensor(values).to(self.actor.device)\n",
        "            start = time.time()\n",
        "            for batch in batches:  # 各バッチの進捗を表示\n",
        "                states = torch.tensor(state_arr[batch], dtype=torch.float).to(self.actor.device)\n",
        "                log_old_probs = torch.tensor(old_probs_arr[batch]).to(self.actor.device)\n",
        "                acts_dsc = torch.tensor(act_dsc_arr[batch]).to(self.actor.device)\n",
        "                acts_cnt = torch.tensor(act_cnt_arr[batch]).to(self.actor.device)\n",
        "\n",
        "                dist_dsc, dist_cnt = self.actor(states)\n",
        "                critic_value = self.critic(states)\n",
        "                critic_value = torch.squeeze(critic_value)\n",
        "\n",
        "                log_new_probs = dist_dsc.log_prob(acts_dsc) + dist_cnt.log_prob(acts_cnt)\n",
        "\n",
        "                prob_ratio = log_new_probs.exp()/log_old_probs.exp()\n",
        "                weighted_probs = advantage[batch]*prob_ratio\n",
        "                weighted_clipped_probs = torch.clamp(prob_ratio, 1-self.policy_clip, 1+self.policy_clip)*advantage[batch]\n",
        "                actor_loss = -torch.min(weighted_probs, weighted_clipped_probs).mean()\n",
        "\n",
        "                returns = advantage[batch] + values[batch]\n",
        "                critic_loss = (returns-critic_value)**2\n",
        "                critic_loss = critic_loss.mean()\n",
        "                #print(actor_loss)\n",
        "                #print(critic_loss)\n",
        "                #print(\"#####\")\n",
        "                entropy = torch.clamp(dist_dsc.entropy().mean(),min=0) + torch.clamp(dist_cnt.entropy().mean(), min=0.0)\n",
        "\n",
        "                total_loss = actor_loss + 0.5*critic_loss + 0.01*entropy\n",
        "                self.actor.optimizer.zero_grad()\n",
        "                self.critic.optimizer.zero_grad()\n",
        "                total_loss.backward()\n",
        "                self.actor.optimizer.step()\n",
        "                self.critic.optimizer.step()\n",
        "                self.loss_history_detail.append(total_loss.item())\n",
        "\n",
        "                actor_loss_sum += actor_loss.item()\n",
        "                critic_loss_sum += critic_loss.item()\n",
        "                entropy_sum += entropy.item()\n",
        "                kl_divergence_sum += torch.distributions.kl_divergence(Categorical(logits=log_old_probs), Categorical(logits=log_new_probs)).mean().item()\n",
        "\n",
        "        print(f'actor loss: {actor_loss_sum}, critic loss: {critic_loss_sum}, entropy: {entropy_sum}, KL divergence: {kl_divergence_sum}')\n",
        "        self.loss_history.append(np.mean(self.loss_history_detail[-self.n_epochs:]))\n",
        "        self.actor_loss_history.append(actor_loss_sum)\n",
        "        self.critic_loss_history.append(critic_loss_sum)\n",
        "        self.entropy_history.append(entropy_sum)\n",
        "        self.kl_divergence_history.append(kl_divergence_sum)\n",
        "            # Update sums\n",
        "        self.actor.scheduler_actor.step()  # 学習率を更新\n",
        "        self.critic.scheduler_critic.step()  # 学習率を更新\n",
        "        self.memory.clear_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l4PW7F3zTYPc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PkbRyHFHTYPc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7JV5KgBxTYPd"
      },
      "outputs": [],
      "source": [
        "#エージェントの初期化\n",
        "n_units = 2\n",
        "n_states = 5\n",
        "MAX_maintenance_time = 0\n",
        "#input_size = n_units * n_states + n_units * (MAX_maintenance_time) + 2 #MDPのため[残り時間]と[保全意思決定時]の2つの入力は入れない\n",
        "input_size = n_units * n_states + 2\n",
        "action_size = 2**n_units  # 行動数は2^3個\n",
        "batch_size = 512*4#512-5120\n",
        "interval = 24\n",
        "alpha_actor = 0.01#ここを変更する\n",
        "alpha_critic = 0.02#ここを変更する\n",
        "n_epochs = 4\n",
        "policy_clip = 0.2\n",
        "beta=0.0005\n",
        "\n",
        "\n",
        "agent = Agent(n_units=n_units,\n",
        "              input_dims=input_size,\n",
        "              n_states=n_states,\n",
        "              MAX_maintenance_time=MAX_maintenance_time,\n",
        "              beta=beta,\n",
        "              interval=interval,\n",
        "              alpha_actor=alpha_actor,\n",
        "              alpha_critic=alpha_critic,\n",
        "              policy_clip=policy_clip,\n",
        "              batch_size=batch_size,\n",
        "              n_epochs=n_epochs)\n",
        "env = Environment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15IhPu1nTYPd",
        "outputId": "007e2279-9d9d-4a53-ed61-aace124abd57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0319, 0.9681]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6719]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0319, 0.9681]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9906]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0319, 0.9681]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0854]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0319, 0.9681]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4738]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0319, 0.9681]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6627]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0319, 0.9681]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1183]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0319, 0.9681]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2003]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0319, 0.9681]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8886]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0319, 0.9681]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2104]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0319, 0.9681]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2911]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0319, 0.9681]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3397]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0319, 0.9681]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1396]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0319, 0.9681]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7611]])"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-8643f87ba5d9>:180: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  reward -= self.P_Cost[min(math.floor(self.levels[0]),self.n_states-1)][min(math.floor(self.levels[1]),self.n_states-1)]\n",
            "<ipython-input-2-8643f87ba5d9>:116: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  l[min(math.floor(self.levels[unit_idx]),self.n_states-1)] = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4117]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0898]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.9541]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0716]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1134]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.6772]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8729]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0249]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4782]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2978]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4294]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6881]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0860]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4994]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5897]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3531]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2719]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3913]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7683]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2395]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5418]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6398]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1448]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2818]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6658]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8234]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6112]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3116]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0266]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0107]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2495]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2700]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1694]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6685]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8123]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6849]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5482]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8832]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1857]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2632]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1058]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3098]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0899]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3785]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2050]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8276]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8185]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2970]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7496]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8914]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5362]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5776]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7126]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9571]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7695]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5634]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0084]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1262]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4425]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4135]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6533]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4728]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4826]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0611]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7840]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3286]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9978]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0897]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1368]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2511]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6806]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7057]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0370]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7022]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2562]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3982]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5327]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5581]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0927]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8034]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3574]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6939]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0845]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3524]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5033]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2600]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0021]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.8165]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4325]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4603]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1223]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3008]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9632]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2914]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5168]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8098]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8794]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9248]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8352]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3691]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3494]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1083]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8746]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2689]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6909]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4236]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4732]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6912]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8384]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8103]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7142]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1823]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4574]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8699]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5790]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2674]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4950]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4726]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5643]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3238]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3553]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1702]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7522]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6523]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7929]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2342]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3808]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5876]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0104]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6491]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5771]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3551]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9687]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6649]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9379]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3578]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0802]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0115]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3480]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1403]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2117]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2825]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1220]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7282]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8384]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9974]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8674]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4162]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4108]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1645]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4254]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5241]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7415]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4487]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9999]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4729]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0194]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7941]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6527]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3126]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0569]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2558]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8771]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1235]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2816]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0369]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0267]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1081]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7566]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2291]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4250]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0938]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9611]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5800]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3999]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5212]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1822]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7247]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4233]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5216]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8654]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2712]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7021]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5431]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1162]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4419]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2502]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7738]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0588]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4235]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5113]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3666]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1204]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8138]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3083]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0778]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1524]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3940]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5104]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7508]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5250]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2490]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4917]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1661]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6811]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0152]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7509]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4526]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1930]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9395]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5255]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3832]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0022]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2080]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9685]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8420]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5338]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7744]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4755]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3077]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0684]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2038]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5235]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8851]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3795]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1206]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1420]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0549]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3947]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7828]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5273]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3699]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6022]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9477]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2907]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4196]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2565]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3905]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8512]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1691]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3952]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7058]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2357]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2537]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3017]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4535]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6973]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4440]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2656]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5699]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4444]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1161]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9513]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8517]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1990]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7481]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2265]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0560]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0717]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8433]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1348]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1074]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9133]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9940]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5427]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0808]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8663]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8044]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3855]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1859]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8197]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7633]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4464]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5045]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3239]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4480]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0065]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4366]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1172]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0543]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4638]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6953]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0601]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6685]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3218]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4112]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6373]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4866]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3782]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3724]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2666]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9943]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6325]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1214]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1357]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3006]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3039]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7214]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6233]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5004]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4653]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3975]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2149]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6268]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4403]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0636]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8070]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3889]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6416]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6211]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0458]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6671]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.1198]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4325]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0955]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1488]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0415]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0008]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7469]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7393]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1450]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3800]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3087]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1420]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1160]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3825]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3437]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5529]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4496]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0271]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7172]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5662]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3617]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1765]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0129]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1198]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8637]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8352]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4764]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6879]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1211]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7181]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5166]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0347]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1206]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1726]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0997]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6479]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1855]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8886]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2193]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9451]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9162]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9422]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0453]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0236]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7722]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8640]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0969]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8739]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8528]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0667]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1716]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5836]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5096]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4663]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3849]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3188]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7971]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1857]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1998]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4537]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6240]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7574]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4860]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0011]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7762]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4572]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7770]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2960]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7606]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0518]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6659]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1702]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5229]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3393]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3747]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.1129]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0915]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5790]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0811]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5031]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3945]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2607]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5656]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6908]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6029]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0512]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8726]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3513]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8702]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2238]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6200]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0090]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2362]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2975]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1666]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1548]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2952]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8251]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6240]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1983]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0798]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7077]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9161]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2839]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1971]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2530]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.8322]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3652]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7710]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6639]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2363]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3693]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5512]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4843]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3236]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2828]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0626]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7460]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0496]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6758]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1730]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1290]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5163]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9505]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3465]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3176]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3921]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7061]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5681]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2654]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9946]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7110]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7057]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1921]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7626]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6674]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4547]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0649]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1866]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6520]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6199]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1952]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0709]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4406]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7285]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0941]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7164]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6733]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3031]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4221]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6371]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4209]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3652]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0614]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2836]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7361]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7769]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0704]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2064]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0748]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7907]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4748]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0977]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2016]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4150]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2559]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2792]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0349]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2891]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6396]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0393]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7317]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0161]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8181]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1818]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1071]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7916]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0834]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7208]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5070]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6406]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3667]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1234]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3686]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5052]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6700]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1078]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6653]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7398]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1645]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8049]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0956]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2671]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5077]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7682]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5055]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6489]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1882]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5708]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1204]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2287]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3780]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1618]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3522]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0162]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8982]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7264]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9446]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3638]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5396]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3221]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3806]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4053]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9983]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3823]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1253]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7573]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5886]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4886]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4477]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4120]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5533]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4157]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7963]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8342]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0251]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5299]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1992]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3205]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2538]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2856]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1978]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6972]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3281]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3534]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7089]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5415]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7731]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3402]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5287]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0983]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6933]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5725]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3692]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7701]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6070]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2254]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3369]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5215]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1538]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3363]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4593]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6681]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5692]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4419]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1009]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9266]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0546]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5408]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0589]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8102]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8739]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9214]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5804]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0369]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4676]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6554]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2172]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7006]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.9006]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2077]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4411]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3638]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1072]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0062]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6213]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7561]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0072]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4325]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4001]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0808]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5280]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0237]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5810]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6454]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3825]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7754]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8559]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6101]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4929]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6677]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9093]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4286]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1482]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3634]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3171]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8337]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3172]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1667]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5842]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4989]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3432]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6259]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2951]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0077]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4102]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0385]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9516]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8134]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8158]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5217]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5388]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4635]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3287]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7296]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1072]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0647]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1005]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6385]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4429]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1829]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7718]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3260]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5357]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0850]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0925]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2515]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2357]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3713]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1286]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6427]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2660]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4195]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0794]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1493]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6260]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1790]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7285]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4278]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8425]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7308]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8217]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3185]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3158]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5765]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5853]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2019]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1344]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4971]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6327]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3425]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2136]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4188]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1788]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3774]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4452]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6643]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5371]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7536]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6000]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3104]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0297]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9877]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7551]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2993]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7171]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5915]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6798]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7016]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3572]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0479]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9717]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2709]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6641]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3340]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1149]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2132]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3898]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7527]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1149]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6910]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5949]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1776]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1440]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3726]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9897]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2652]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7856]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4192]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0891]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7477]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1509]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6486]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3293]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4583]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4264]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7957]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4962]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7748]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6935]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2733]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2953]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3134]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3926]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1930]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3472]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0702]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2998]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2758]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8264]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1979]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4449]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4846]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4342]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9780]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0994]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8696]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5883]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3595]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0893]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5481]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8795]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9684]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2492]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1663]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4959]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3266]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4809]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3064]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9125]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9245]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2228]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7520]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0176]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5401]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4182]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5134]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9491]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4055]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2611]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2050]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8915]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5143]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3492]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6399]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9600]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9407]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7018]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2385]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7235]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4689]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2689]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3833]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0791]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3093]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3377]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1938]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3787]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5667]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5047]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5328]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6729]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2298]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2822]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5978]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3468]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3279]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.9961]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1589]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8579]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2245]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8836]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5969]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4590]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6701]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1893]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7215]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2299]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9271]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3911]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6251]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4908]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2790]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9685]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9676]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3027]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1689]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5141]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1299]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5014]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1310]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6887]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4169]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8740]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1675]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1352]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0075]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2871]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9757]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2737]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0727]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7856]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7994]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8821]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3487]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2869]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6200]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4671]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1932]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9317]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3256]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4762]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2454]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0640]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0735]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3160]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0622]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6260]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1287]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7715]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2870]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7280]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4610]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5834]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9266]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5242]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8575]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3937]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4626]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9360]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9082]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9256]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6671]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2045]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2776]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4962]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1484]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6462]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6251]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8916]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1439]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2439]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4761]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6223]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1291]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9265]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0090]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0812]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7691]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3752]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9808]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4026]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4580]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0437]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1147]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0709]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0778]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2492]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8043]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7585]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9090]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6837]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7934]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1841]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6600]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7890]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4529]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4687]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2961]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1958]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2054]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8804]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5636]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3067]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7722]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7646]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7247]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3915]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4665]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.3356]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0968]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4408]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9288]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0380]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6275]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1555]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1413]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1137]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7788]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5320]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7509]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4517]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4903]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1098]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9633]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2789]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5581]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6091]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9869]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0446]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5695]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6830]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3249]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2067]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7908]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9820]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0787]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3034]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4928]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3829]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1607]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8144]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5219]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1364]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5704]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6684]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0875]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4203]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0148]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5411]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1524]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7364]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7542]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1939]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3384]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1702]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2472]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2924]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3384]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1522]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2269]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4272]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4937]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7091]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6282]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2472]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1675]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0336]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7387]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1710]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5907]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3083]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3409]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5402]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7060]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8282]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0609]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6382]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1962]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8954]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7351]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6153]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1489]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8118]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6650]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6074]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2400]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8846]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4233]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7078]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8845]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0596]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3514]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2661]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0674]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0292]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3419]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8530]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0136]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7080]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2510]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4286]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6614]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2119]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2032]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.3471]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1659]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3100]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5218]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1108]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0127]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5309]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1165]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1849]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0845]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7258]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7528]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3771]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2778]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3493]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7317]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1446]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0034]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9754]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3697]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1252]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2072]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0122]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6740]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2899]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0983]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7943]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6316]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1530]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6162]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2746]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7001]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0619]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5738]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3336]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8238]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5443]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4667]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4934]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5750]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7884]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2207]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8594]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6307]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5171]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3616]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9237]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0293]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5335]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2393]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4671]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3528]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0355]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1075]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3114]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3233]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1571]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3034]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7745]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1944]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3468]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3715]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0702]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6191]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1983]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2060]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2969]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0977]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2093]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9992]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2972]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7013]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8928]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7216]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7741]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0271]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2491]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0624]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1416]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-3.0944]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1887]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2268]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0376]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7463]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1918]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1323]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2907]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5105]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7910]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8011]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1652]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9311]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2891]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1437]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0811]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4718]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0668]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0715]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3578]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1081]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5408]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9328]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6651]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5030]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3052]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4841]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7019]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8498]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6954]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3223]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5995]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4322]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3568]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3726]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1546]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4742]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6567]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5942]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0234]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9792]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9234]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0346]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2977]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6331]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0375]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5373]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1209]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2664]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7713]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4066]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8547]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4409]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9089]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4167]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9086]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3019]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9160]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6802]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5461]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0139]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5528]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1566]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4058]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2700]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3587]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5496]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3586]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7212]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6946]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8867]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0667]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4275]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5369]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2391]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2358]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0860]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8310]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4581]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6518]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8280]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1418]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6772]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2314]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5433]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3963]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4021]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2394]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9922]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4296]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9738]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2758]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3600]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2896]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.9444]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0196]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6141]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7340]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2918]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1394]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1534]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3590]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9472]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8953]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0052]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2496]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0381]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4258]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0294]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8105]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0650]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1722]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6413]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9276]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0068]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3668]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3461]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1146]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0882]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9845]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0183]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1091]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0867]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9097]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7305]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3615]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2263]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4991]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4645]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3164]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9781]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8957]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5468]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2632]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6876]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5837]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8478]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4815]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2219]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7271]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8637]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7792]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2353]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8175]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0214]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.9752]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1853]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5138]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6373]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0006]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7726]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2428]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1313]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6047]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0412]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8412]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7564]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4598]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0681]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4855]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3850]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0235]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0497]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0614]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7079]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8483]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0154]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3844]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6180]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0455]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0287]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6088]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8853]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1889]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5768]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7972]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1772]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7775]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1480]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2220]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8485]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2853]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1457]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6821]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8736]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0314]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2663]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0172]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8065]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1867]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2984]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0370]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0478]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0037]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8276]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0719]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0264]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1341]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2503]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3329]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0094]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2783]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2090]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1054]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4750]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0145]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4513]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6828]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3491]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5132]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5264]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0280]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1936]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6724]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8177]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7608]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4572]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0865]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4108]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3121]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5777]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4257]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6116]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1496]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5719]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4098]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8090]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7712]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5014]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4016]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1180]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9345]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0631]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4253]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5473]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1812]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1605]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3842]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7725]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6756]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1272]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0916]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2991]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6532]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5419]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6084]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0518]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1193]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5087]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0137]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8847]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3602]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0432]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2703]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7907]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2938]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6616]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0223]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3243]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6793]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6939]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5294]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5196]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2744]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4647]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2183]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0186]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6375]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6989]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1070]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1812]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5784]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3285]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2424]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4956]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8522]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7234]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1435]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1493]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3134]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6239]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5084]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1836]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3066]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7126]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1521]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5836]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0395]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1342]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3832]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3202]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2301]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1527]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1653]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8128]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7644]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6335]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6843]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2803]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5069]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6068]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4732]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0799]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5221]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9280]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0589]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1470, 0.8530]], grad_fn=<DivBackward0>) cnt: tensor([[0.4188]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2202]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2904]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1157]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3604]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2373]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9900]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0912]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0257]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0837]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0050]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7823]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0792]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8045]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0798]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7971]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3234]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0709]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9813]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6133]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1179]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4606]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8919]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1914]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7364]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7567]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2036]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8724]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9234]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2532]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2121]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1652]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6966]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6971]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1442]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1057]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4699]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7325]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1721]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2040]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2820]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5799]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0136]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9576]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5388]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.8027]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6847]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3375]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5029]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6304]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0717]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3576]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1613]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3928]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7917]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5357]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7157]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5158]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2178]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0413]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0539]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8675]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2367]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4387]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4390]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3909]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1725]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4277]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2457]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8044]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7534]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4974]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1054]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7850]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0651]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0305]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4923]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2424]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1223]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5728]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9338]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2357]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1938]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7035]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3193]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3990]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9152]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1480]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2447]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3399]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3138]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9439]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5920]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5767]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3862]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2177]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9578]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7033]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7011]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3381]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0960]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7695]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1016]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1707]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1634]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1390]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4884]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0731]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4305]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3022]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6246]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4207]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3152]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7509]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4637]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7526]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8949]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8645]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2001]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8802]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8313]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6810]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.0648]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7467]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4462]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4218]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5777]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9289]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9348]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5983]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6981]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9064]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7552]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4043]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4356]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5040]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4039]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7443]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6568]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4714]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5942]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5487]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1707]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7993]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7517]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0829]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3963]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3814]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4102]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1533]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0437]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7864]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2547]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6754]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1705]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2952]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6432]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4897]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6105]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2766]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3329]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3488]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2595]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2944]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3628]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8563]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7787]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6150]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8926]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1226]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5432]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6244]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2440]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3453]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7146]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4510]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6889]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6578]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5231]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3333]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1862]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9313]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1504]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2831]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4258]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3125]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8236]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6458]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7710]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3257]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2092]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3628]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6780]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3046]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6620]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6652]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6720]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0434]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8463]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1937]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1840]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6561]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6868]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4256]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2133]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6708]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5511]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1735]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5724]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1857]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0246]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7612]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6042]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7650]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9299]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3803]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1341]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5799]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5066]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4573]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7094]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3578]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4313]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4854]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6584]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.8152]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2858]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1750]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8102]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0199]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6391]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3172]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0273]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1120]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1722]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0312]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4406]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8849]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8405]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5074]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0794]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1619]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3876]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5412]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5610]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2389]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9013]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4138]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0783]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0903]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0013]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4117]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0733]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1592]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0429]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6977]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9656]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3627]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4654]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5015]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.1585]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8878]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5153]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2507]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1949]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6747]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8864]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6123]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3085]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4320]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3784]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1526]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0799]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6169]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0748]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0950]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5012]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2221]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3898]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3579]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7529]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1688]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1199]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8043]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6139]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4878]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5139]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0390]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0449]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1347]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4731]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5173]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3849]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3880]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0528]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2269]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2274]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6090]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4236]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4122]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6097]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4628]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7034]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3320]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5116]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8271]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3025]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2114]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1693]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1844]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0701]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4377]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0885]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6924]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2499]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4624]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8024]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0349]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6046]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4153]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2263]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1188]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5092]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0414]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4643]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.1506]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1038]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0219]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7622]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2808]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6878]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9916]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3275]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3306]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3504]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0222]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5761]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3266]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0800]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6003]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4275]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4404]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5603]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9486]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6679]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9997]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3018]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2527]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0680]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3572]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6363]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4856]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2187]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8314]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0761]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9613]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0980]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0956]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7059]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2321]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2764]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0446]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7286]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2196]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4760]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0178]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8217]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4336]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1273]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8171]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4774]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0229]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7968]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3284]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6814]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6011]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4374]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3184]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3052]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8113]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1303]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8653]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1970]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3049]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0825]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0320]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0269]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7044]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3902]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8856]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1405]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0743]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9562]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0557]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3844]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4562]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5864]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8070]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3700]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8949]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6160]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0378]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4696]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1148]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1150]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1283]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9297]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7737]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2150]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5555]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8212]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3440]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1736]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[8.2999e-05]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5375]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5922]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8973]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8631]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5291]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3559]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1235]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1526]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0940]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5414]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1181]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0449]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1802]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8462]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2163]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7509]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9841]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1008]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9936]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5530]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3451]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9359]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3669]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3473]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7345]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5668]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0111]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9800]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5774]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7881]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6057]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2082]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.8924]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4370]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8497]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0379]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2148]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0952]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2955]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4610]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1355]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6380]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2593]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0720]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9051]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9996]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5724]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.0230]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3506]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9093]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4158]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7765]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8676]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1010]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7754]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7317]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6183]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0207]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4805]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4713]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3270]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8988]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7347]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2062]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6792]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5666]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7934]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3390]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9878]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6128]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8921]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3382]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3282]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0981]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0374]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5224]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4276]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5680]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9719]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0291]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6464]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3074]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9472]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7693]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7335]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5371]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0937]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4832]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3474]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1765]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3743]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0025]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0212]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1758]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4229]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0491]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0402]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0892]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2161]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0331]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0038]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2732]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1820]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1417]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6104]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1446]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5963]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3726]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1368]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3432]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5159]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0588]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0889]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0597]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3973]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.0182]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0525]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6584]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0708]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4184]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4603]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2072]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0576]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7087]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5935]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0733]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4129]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5444]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4839]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8210]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8231]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7303]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3518]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3388]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6974]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3281]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3792]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0020]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2137]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4081]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3276]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.7818]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0296]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0265]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6610]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4363]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3661]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1481]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9590]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1998]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1246]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5285]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6919]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6857]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9153]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7937]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9362]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8807]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3028]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7715]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3013]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2134]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7843]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2908]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3044]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7927]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1990]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1981]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9259]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3067]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.2308]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0839]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1964]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9237]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8080]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5773]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1616]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2783]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1337]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0572]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2803]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2688]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0407]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0448]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7154]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3338]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0960]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1127]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0386]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2978]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3256]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3132]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3268]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3740]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1824]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0729]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8455]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0817]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1885]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5716]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2002]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2149]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7102]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7247]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2564]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2002]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5955]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2073]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5973]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0854]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4631]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2728]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2468]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2147]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5701]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0228]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3728]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9356]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7364]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6073]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4854]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5765]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4347]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2728]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2269]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6591]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2164]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0497]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.0638]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0979]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1199]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4821]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4015]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4806]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4433]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2031]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0966]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5270]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0847]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7837]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7539]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4053]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0468]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5884]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.5170]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1662]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1468]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4247]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8363]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2325]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8314]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2017]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6387]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4807]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0817]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8567]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7425]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7023]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2906]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4729]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5873]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5775]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3987]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6659]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1628]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1875]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1695]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1301]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0262]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3766]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5470]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2275]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8673]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1039]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2883]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6945]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2149]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7872]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4148]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0083]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0199]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2177]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2044]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2421]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2423]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4000]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1012]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8779]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7027]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6002]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3864]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0205]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5677]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0333]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3925]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9136]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7260]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1286]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3754]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.0361]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2708]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3918]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5419]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6139]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4138]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4006]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3019]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7674]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9222]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5091]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6035]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0124]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0536]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6134]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9659]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0035]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2768]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9585]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7382]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8251]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0416]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2919]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0274]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8016]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0291]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8634]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2587]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1053]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4489]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5643]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4868]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0649]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2771]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1389]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3310]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7473]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7540]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6535]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4098]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3560]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6289]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6696]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5834]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0578]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4646]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2004]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4263]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0226]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8464]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6521]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3761]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9329]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3225]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5930]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0720]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5992]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1935]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1688]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4834]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9554]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8908]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4099]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5503]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0054]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7906]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9793]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5941]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4225]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3621]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7219]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3671]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9240]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1117]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0830]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9247]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3304]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6157]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6723]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7681]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5007]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1239]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6540]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8764]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2737]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8596]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0652]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1594]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7931]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7335]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2332]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6325]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8887]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1745]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2219]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7263]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6010]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0693]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4505]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2601]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1589]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9136]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2344]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3171]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9262]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7365]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6825]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0605]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4780]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3275]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2693]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5688]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1700]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1289]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0842]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5418]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0584]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0628]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1804]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0843]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6989]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1646]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4850]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9937]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5061]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2449]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9766]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0447]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1200]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3357]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4317]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4111]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5455]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0619]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3113]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1573]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8357]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1183]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2485]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9612]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3514]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6671]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8807]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7850]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3447]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8460]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5853]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6340]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7883]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1718]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4896]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.1214]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2797]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1011]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4226]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3464]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1919]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8977]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6110]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2600]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9583]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5989]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0055]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9985]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9031]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1010]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3080]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0252]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0497]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0491]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2943]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9848]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3909]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2638]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3401]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7130]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9771]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3636]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6172]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5937]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8682]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6493]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2466]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5182]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2333]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5822]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0123]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1620]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2249]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7067]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8800]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6809]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7623]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5178]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3641]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2341]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2763]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6462]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5574]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7062]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8392]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9857]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5039]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5474]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2924]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6447]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9555]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3958]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3932]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2228]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6650]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3498]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4440]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0199]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2739]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1290]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3512]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3206]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6316]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1273]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3769]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4556]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0953]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0853]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0529]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0543]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0405]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9765]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7778]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7639]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5183]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5757]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1159]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2834]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7306]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9101]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6734]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2764]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5833]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0191]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4915]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9920]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6678]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2237]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5874]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.8064]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9245]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6169]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7198]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4253]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0311]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.0934]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1359]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1654]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3066]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0747]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2674]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1166]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1609]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6459]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1490]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7762]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6657]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8747]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0499]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3767]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0014]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1977]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1108]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4595]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5394]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0813]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6887]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2058]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1663]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1924]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9122]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9287]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4975]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8469]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1054, 0.8946]], grad_fn=<DivBackward0>) cnt: tensor([[0.4184]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7967]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2880]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2598]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3332]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7695]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1310]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7260]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2021]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0362]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5453]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4759]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6622]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4706]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3196]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2048]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1726]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8049]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4001]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4122]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8755]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8892]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0645]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2688]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8928]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4975]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2244]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1354]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0868]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5562]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7349]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9221]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4038]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3777]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2964]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0605]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4794]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2904]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5332]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2186]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0439]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4090]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1226]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1097]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2024]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3484]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8045]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2866]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0896]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4875]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2993]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0967]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4325]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1319]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1130]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1629]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1631]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8618]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5472]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4763]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7913]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1499]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2126]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1547]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2275]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4307]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9717]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.1557]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9607]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9739]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6346]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9319]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5251]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5433]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0655]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2018]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2861]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4295]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2691]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5289]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8582]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5294]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4033]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3526]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5773]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9119]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2484]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9509]])\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.0944, 0.9056]], grad_fn=<DivBackward0>) cnt: tensor([[0.4274]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2007]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1097]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3320]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.0099]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1938]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4826]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5005]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8300]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0181]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3386]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7392]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5161]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2387]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7474]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7749]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4702]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3520]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2298]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5453]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2542]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6448]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2172]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6403]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6878]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3161]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3510]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2067]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4017]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4231]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3819]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4443]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7380]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6710]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3204]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5060]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7861]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.8143]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3516]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4348]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0394]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2972]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3889]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2910]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3614]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5282]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc: tensor([[0.0000, 0.0000, 0.1399, 0.8601]], grad_fn=<DivBackward0>) cnt: tensor([[0.4097]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4301]])\n",
            "actor loss: 734106.9089931905, critic loss: 34063298078.8604, entropy: 30.14755403995514, KL divergence: 0.09868292916866588\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1], 離散行動：[1, 1], 連続行動：1.2150577306747437\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "1エピソード目の累積報酬：-230709.26258628914, 一つ保全の回数：7164, 二つ保全の回数：1028, 三つ保全の回数：0, 違反回数：0\n"
          ]
        }
      ],
      "source": [
        "num_episode = 2 #40分？ 2*4*64\n",
        "best_reward = -np.inf\n",
        "episode_reward_history = []\n",
        "avg_cost = 0\n",
        "\n",
        "for episode in range(num_episode):\n",
        "    episode_reward = 0\n",
        "    operation_time = 0\n",
        "    one_action = 0\n",
        "    two_action = 0\n",
        "    three_action = 0\n",
        "    penalty_action = 0\n",
        "    level_ohe, inventory, demand, remain_interval = env.init_random()\n",
        "    if episode % 100 == 0:\n",
        "        interval_time_episode = time.time()\n",
        "    interval_time_episode = time.time()\n",
        "    for _ in range(1024*8):#1024*8\n",
        "        state = level_ohe + list([inventory,demand])\n",
        "        #print(state)\n",
        "        act_dsc, act_cnt, log_prob, val = agent.choose_action(state)\n",
        "        act_dsc_list = [int(bit) for bit in format(act_dsc.item(), f'0{env.n_units}b')]\n",
        "        if sum(act_dsc_list) == 2:\n",
        "            one_action += 1\n",
        "        elif sum(act_dsc_list) == 1:\n",
        "            two_action += 1\n",
        "        elif sum(act_dsc_list) == 0:\n",
        "            three_action += 1\n",
        "        act_cnt_np = act_cnt.squeeze().cpu().numpy().copy()\n",
        "        act_cnt_np = act_cnt_np * 0.5 + 0.5\n",
        "        #print(act_dsc_list,act_cnt_np)\n",
        "        reward, level_ohe_next, inventory_next, demand_next, remain_interval_next, flag = env.operation(act_dsc_list,act_cnt_np)\n",
        "\n",
        "        episode_reward = episode_reward*0.99 + reward\n",
        "        penalty_action += flag\n",
        "        #if remain_interval > remain_interval_next:\n",
        "            #operation_time += (remain_interval+1)/2*interval - (remain_interval_next+1)/2*interval\n",
        "        #else:\n",
        "            #operation_time += (remain_interval_next + 1) / 2 * interval\n",
        "        agent.remember(state, act_dsc.item(), act_cnt.squeeze().cpu().numpy().copy(), log_prob, val, reward, operation_time)\n",
        "        level_ohe = level_ohe_next\n",
        "        #mstatus_ohe = mstatus_ohe_next\n",
        "        inventory = inventory_next\n",
        "        demand = demand_next\n",
        "        remain_interval = remain_interval_next\n",
        "    #print(f'{episode}エピソード目の時間：{time.time()-interval_time_episode}')\n",
        "    interval_time_episode = time.time()\n",
        "    agent.learn()\n",
        "\n",
        "    old_agent = Agent(n_units=n_units,\n",
        "                        input_dims=input_size,\n",
        "                        n_states=n_states,\n",
        "                        MAX_maintenance_time=MAX_maintenance_time,\n",
        "                        beta=beta,\n",
        "                        interval=interval,\n",
        "                        alpha_actor=alpha_actor,\n",
        "                        alpha_critic=alpha_critic,\n",
        "                        policy_clip=policy_clip,\n",
        "                        batch_size=batch_size,\n",
        "                        n_epochs=n_epochs)\n",
        "    if episode != 0:\n",
        "        old_agent.load_models()\n",
        "\n",
        "    #if Check_convergence(agent, old_agent, n_units, n_states, MAX_maintenance_time):\n",
        "    #    break\n",
        "\n",
        "\n",
        "\n",
        "    agent.save_models()\n",
        "    print(f'状態{state}, 離散行動：{act_dsc_list}, 連続行動：{act_cnt_np}')\n",
        "    print(f'[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [{env.replace_chance}, {env.failure_keep1}, {env.failure_keep2}, {env.failure_keep3}]')\n",
        "    env.replace_chance = 0\n",
        "    env.failure_keep1 = 0\n",
        "    env.failure_keep2 = 0\n",
        "    env.failure_keep3 = 0\n",
        "    #print(f'{episode}エピソード目の学習時間：{time.time()-interval_time_episode}')\n",
        "    print(f'{episode}エピソード目の累積報酬：{episode_reward}, 一つ保全の回数：{one_action}, 二つ保全の回数：{two_action}, 三つ保全の回数：{three_action}, 違反回数：{penalty_action}')\n",
        "    episode_reward_history.append(episode_reward)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ncPGOL29TYPd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "857f47d0-8c18-4c46-e488-b04aa137d548"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AHLLAogeTYPe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5e878661-dd85-410d-975f-d88a24f2b2ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2wAAAIjCAYAAAB/FZhcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACI2ElEQVR4nOzdeVxU9f7H8dcMuyDgBoigoKgI7ksuuaCSaJpatmhWllndMk3Tbtni1r3Zoi2mZt1MLVtsdS0VRTCXlFxKUXDDXdwRN7aZ8/vD6/ziqqWGnAHez8djHo/LOd+ZeZ/RW334fOZ7LIZhGIiIiIiIiIjTsZodQERERERERK5MBZuIiIiIiIiTUsEmIiIiIiLipFSwiYiIiIiIOCkVbCIiIiIiIk5KBZuIiIiIiIiTUsEmIiIiIiLipFSwiYiIiIiIOCkVbCIiIiIiIk5KBZuIiMh1mDFjBhaLhT179pgdRURESgEVbCIiUmwdOnSI0aNHs2nTJrOjiIiI3BQq2EREpNg6dOgQY8aMUcEmIiIllgo2ERGR/3Hu3DmzIzgdfSYiIuZQwSYiIkVq7969PPXUU9SuXRsvLy8qVKjAPffcc8XvhGVmZjJ06FDCwsLw8PAgJCSEhx56iOPHj5OYmEizZs0AeOSRR7BYLFgsFmbMmOF4/jfffEOTJk3w8vKiYsWKPPDAAxw8eLDAezz88MP4+Piwa9cubr/9dsqWLUvfvn2v+7qmTJlCdHQ0Hh4eBAcHM3DgQDIzMwus2bFjB7169SIoKAhPT09CQkLo3bs3p0+fdqyJj4+ndevW+Pv74+PjQ+3atXnxxRevKcOsWbO45ZZbKFOmDOXKlaNt27YsWbLEcd5isTB69OjLnhcWFsbDDz/s+PnS9/SSkpJ46qmnCAgIICQkhG+//dZx/H99+OGHWCwWtmzZ4jiWmprK3XffTfny5fH09KRp06bMmzfvmq5FREQucjU7gIiIlC7JycmsXr2a3r17ExISwp49e/jggw+IiYlh69atlClTBoCzZ8/Spk0btm3bRv/+/WncuDHHjx9n3rx5HDhwgDp16jB27FhGjhzJ448/Tps2bQBo1aoVcLHoeOSRR2jWrBnjxo3jyJEjvPfee6xatYqNGzfi7+/vyJSfn09cXBytW7dm/PjxjgzXavTo0YwZM4bY2FiefPJJ0tLS+OCDD0hOTmbVqlW4ubmRm5tLXFwcOTk5DBo0iKCgIA4ePMiCBQvIzMzEz8+PlJQUunXrRv369Rk7diweHh7s3LmTVatW/WWGMWPGMHr0aFq1asXYsWNxd3dn7dq1JCQk0KlTp+u6nkueeuopKlWqxMiRIzl37hxdu3bFx8eHr7/+mnbt2hVYO3v2bKKjo6lbty4AKSkp3HrrrVSpUoUXXngBb29vvv76a3r27Ml3333HnXfeeUOZRERKHUNERKQInT9//rJja9asMQDj008/dRwbOXKkARjff//9ZevtdrthGIaRnJxsAMb06dMLnM/NzTUCAgKMunXrGhcuXHAcX7BggQEYI0eOdBzr16+fARgvvPDCNeWfPn26ARjp6emGYRjG0aNHDXd3d6NTp06GzWZzrJs0aZIBGJ988olhGIaxceNGAzC++eabq772O++8YwDGsWPHrinLJTt27DCsVqtx5513FshgGP//WRmGYQDGqFGjLnt+tWrVjH79+l12ja1btzby8/MLrO3Tp48REBBQ4Pjhw4cNq9VqjB071nGsY8eORr169Yzs7OwCWVq1amXUrFnzuq5PRKQ000ikiIgUKS8vL8f/zsvL48SJE0RERODv78+GDRsc57777jsaNGhwxU6MxWL50/f49ddfOXr0KE899RSenp6O4127diUyMpKFCxde9pwnn3zyRi6HpUuXkpuby5AhQ7Ba//9fq4899hi+vr6O9/Lz8wNg8eLFnD9//oqvdanrN3fuXOx2+zVnmDNnDna7nZEjRxbIAH/9Wf2Zxx57DBcXlwLH7rvvPo4ePUpiYqLj2Lfffovdbue+++4D4OTJkyQkJHDvvfdy5swZjh8/zvHjxzlx4gRxcXHs2LHjstFUERG5MhVsIiJSpC5cuMDIkSMJDQ3Fw8ODihUrUqlSJTIzMwt8l2vXrl2O8brrtXfvXgBq16592bnIyEjH+UtcXV0JCQkp1Pdyd3enevXqjvPh4eE8++yzfPzxx1SsWJG4uDgmT55c4Jrvu+8+br31VgYMGEBgYCC9e/fm66+//svibdeuXVitVqKiom7oGq4mPDz8smOdO3fGz8+P2bNnO47Nnj2bhg0bUqtWLQB27tyJYRi88sorVKpUqcBj1KhRABw9erRQs4qIlFT6DpuIiBSpQYMGMX36dIYMGULLli3x8/PDYrHQu3fv6+oqFSYPD4/LOlM3w4QJE3j44YeZO3cuS5YsYfDgwYwbN45ffvmFkJAQvLy8WLFiBcuXL2fhwoUsWrSI2bNn06FDB5YsWXJZt6uw2Gy2Kx7/Yzf0Eg8PD3r27MkPP/zAlClTOHLkCKtWreK1115zrLn05zh8+HDi4uKu+NoRERGFkFxEpORTwSYiIkXq22+/pV+/fkyYMMFxLDs7+7IdFWvUqFFgx8Erudq4X7Vq1QBIS0ujQ4cOBc6lpaU5zheGP75X9erVHcdzc3NJT08nNja2wPp69epRr149Xn75ZVavXs2tt97K1KlT+de//gWA1WqlY8eOdOzYkbfffpvXXnuNl156ieXLl1/2WpfUqFEDu93O1q1badiw4VWzlitX7rLPOTc3l8OHD1/XNd93333MnDmTZcuWsW3bNgzDcIxDAo7Pwc3N7aqZRUTk2mgkUkREipSLiwuGYRQ49v7771/W5enVqxe//fYbP/zww2Wvcen53t7eAJcVIU2bNiUgIICpU6eSk5PjOP7TTz+xbds2unbtWhiXAkBsbCzu7u5MnDixwHVNmzaN06dPO94rKyuL/Pz8As+tV68eVqvVkfHkyZOXvf6lAuyP1/G/evbsidVqZezYsZd1Kf+YqUaNGqxYsaLA+Y8++uiqHbariY2NpXz58syePZvZs2dzyy23FBifDAgIICYmhg8//PCKxeCxY8eu6/1EREozddhERKRIdevWjc8++ww/Pz+ioqJYs2YNS5cupUKFCgXWPffcc3z77bfcc8899O/fnyZNmnDy5EnmzZvH1KlTadCgATVq1MDf35+pU6dStmxZvL29ad68OeHh4bzxxhs88sgjtGvXjj59+ji29Q8LC2Po0KGFdj2VKlVixIgRjBkzhs6dO9O9e3fS0tKYMmUKzZo144EHHgAgISGBp59+mnvuuYdatWqRn5/PZ599houLC7169QJg7NixrFixgq5du1KtWjWOHj3KlClTCAkJoXXr1lfNEBERwUsvvcSrr75KmzZtuOuuu/Dw8CA5OZng4GDGjRsHwIABA/jHP/5Br169uO222/jtt99YvHgxFStWvK5rdnNz46677uKrr77i3LlzjB8//rI1kydPpnXr1tSrV4/HHnuM6tWrc+TIEdasWcOBAwf47bffrus9RURKLTO3qBQRkdLn1KlTxiOPPGJUrFjR8PHxMeLi4ozU1NTLtpY3DMM4ceKE8fTTTxtVqlQx3N3djZCQEKNfv37G8ePHHWvmzp1rREVFGa6urpdt8T979myjUaNGhoeHh1G+fHmjb9++xoEDBwq8R79+/Qxvb+9rzv+/2/pfMmnSJCMyMtJwc3MzAgMDjSeffNI4deqU4/zu3buN/v37GzVq1DA8PT2N8uXLG+3btzeWLl3qWLNs2TKjR48eRnBwsOHu7m4EBwcbffr0MbZv335N2T755BPH9ZYrV85o166dER8f7zhvs9mM559/3qhYsaJRpkwZIy4uzti5c+dVt/VPTk6+6nvFx8cbgGGxWIz9+/dfcc2uXbuMhx56yAgKCjLc3NyMKlWqGN26dTO+/fbba7oeERExDIth/M9cioiIiIiIiDgFfYdNRERERETESalgExERERERcVIq2ERERERERJyUCjYREREREREnpYJNRERERETESalgExERERERcVK6cXYRstvtHDp0iLJly2KxWMyOIyIiIiIiJjEMgzNnzhAcHIzVevU+mgq2InTo0CFCQ0PNjiEiIiIiIk5i//79hISEXPW8CrYiVLZsWeDiH4qvr6/JaURERERExCxZWVmEhoY6aoSrMbVgCwsLY+/evZcdf+qpp5g8eTK7du1i+PDhrFy5kpycHDp37sz7779PYGCgY+3JkycZNGgQ8+fPx2q10qtXL9577z18fHwca37//XcGDhxIcnIylSpVYtCgQfzzn/8s8J7ffPMNr7zyCnv27KFmzZq88cYb3H777Y7zhmEwatQo/vOf/5CZmcmtt97KBx98QM2aNa/5ei+NQfr6+qpgExERERGRv/yqlKmbjiQnJ3P48GHHIz4+HoB77rmHc+fO0alTJywWCwkJCaxatYrc3FzuuOMO7Ha74zX69u1LSkoK8fHxLFiwgBUrVvD44487zmdlZdGpUyeqVavG+vXreeuttxg9ejQfffSRY83q1avp06cPjz76KBs3bqRnz5707NmTLVu2ONa8+eabTJw4kalTp7J27Vq8vb2Ji4sjOzu7CD4pEREREREpjSyGYRhmh7hkyJAhLFiwgB07dhAfH0+XLl04deqUoxt1+vRpypUrx5IlS4iNjWXbtm1ERUWRnJxM06ZNAVi0aBG33347Bw4cIDg4mA8++ICXXnqJjIwM3N3dAXjhhReYM2cOqampANx3332cO3eOBQsWOLK0aNGChg0bMnXqVAzDIDg4mGHDhjF8+HBHlsDAQGbMmEHv3r2v6fqysrLw8/Pj9OnT6rCJiIiIiJRi11obOM22/rm5ucyaNYv+/ftjsVjIycnBYrHg4eHhWOPp6YnVamXlypUArFmzBn9/f0exBhAbG4vVamXt2rWONW3btnUUawBxcXGkpaVx6tQpx5rY2NgCeeLi4lizZg0A6enpZGRkFFjj5+dH8+bNHWuuJCcnh6ysrAIPERERERGRa+U0m47MmTOHzMxMHn74YeBih8vb25vnn3+e1157DcMweOGFF7DZbBw+fBiAjIwMAgICCryOq6sr5cuXJyMjw7EmPDy8wJpL34HLyMigXLlyZGRkFPhe3KU1f3yNPz7vSmuuZNy4cYwZM+Z6PgYRERERKWSGYZCfn4/NZjM7ipQiLi4uuLq6/u3beTlNwTZt2jS6dOlCcHAwAJUqVeKbb77hySefZOLEiVitVvr06UPjxo3/9D4FzmTEiBE8++yzjp8v7QQjIiIiIkUjNzeXw4cPc/78ebOjSClUpkwZKleuXGDa73o5RcG2d+9eli5dyvfff1/geKdOndi1axfHjx/H1dUVf39/goKCqF69OgBBQUEcPXq0wHPy8/M5efIkQUFBjjVHjhwpsObSz3+15o/nLx2rXLlygTUNGza86nV5eHgUGOkUERERkaJjt9tJT0/HxcWF4OBg3N3d/3a3Q+RaGIZBbm4ux44dIz09nZo1a95w08kpCrbp06cTEBBA165dr3i+YsWKACQkJHD06FG6d+8OQMuWLcnMzGT9+vU0adLEscZut9O8eXPHmpdeeom8vDzc3NwAiI+Pp3bt2pQrV86xZtmyZQwZMsTxnvHx8bRs2RKA8PBwgoKCWLZsmaNAy8rKYu3atTz55JOF+2GIiIiISKHIzc3FbrcTGhpKmTJlzI4jpYyXlxdubm7s3buX3NxcPD09b+h1TJ8ttNvtTJ8+nX79+uHqWrB+nD59Or/88gu7du1i1qxZ3HPPPQwdOpTatWsDUKdOHTp37sxjjz3GunXrWLVqFU8//TS9e/d2jFbef//9uLu78+ijj5KSksLs2bN57733CowqPvPMMyxatIgJEyaQmprK6NGj+fXXX3n66aeBi/dGGDJkCP/617+YN28emzdv5qGHHiI4OJiePXsWzQclIiIiIjekuHydRkqewvi7Z3qHbenSpezbt4/+/ftfdi4tLY0RI0Zw8uRJwsLCeOmllxg6dGiBNZ9//jlPP/00HTt2dNw4e+LEiY7zfn5+LFmyhIEDB9KkSRMqVqzIyJEjC9yrrVWrVnzxxRe8/PLLvPjii9SsWZM5c+ZQt25dx5p//vOfnDt3jscff5zMzExat27NokWLbrhSFhERERER+StOdR+2kk73YRMREREpOtnZ2aSnpxMeHq5fsosp/uzvYLG7D5uIiIiIiBSePXv2YLFY2LRp0017j4cffrjUf0UoLCyMd99996a9vgo2EREREREn8/DDD2OxWC57dO7c+ZpfIzQ0lMOHDxf4mo8ziomJcVyfp6cntWrVYty4cWgQ8CLTv8MmIiIiIiKX69y5M9OnTy9w7HpuGeXi4uK4PZWze+yxxxg7diw5OTkkJCTw+OOP4+/v7zQ7sttsNiwWiykb2KjDJiIiIiKlhmEYnM/NN+VxvR0jDw8PgoKCCjwu3ZYKLu5k/sEHH9ClSxe8vLyoXr063377reP8/45Enjp1ir59+1KpUiW8vLyoWbNmgYJw8+bNdOjQAS8vLypUqMDjjz/O2bNnHedtNhvPPvss/v7+VKhQgX/+85+XXZPdbmfcuHGEh4fj5eVFgwYNCmS6mjJlyhAUFES1atV45JFHqF+/PvHx8Y7zOTk5DB8+nCpVquDt7U3z5s1JTEx0/JlWqlSpwPs0bNiwwP2TV65ciYeHh+MG6m+//Tb16tXD29ub0NBQnnrqqQLXOmPGDPz9/Zk3bx5RUVF4eHiwb98+jh49yh133IGXlxfh4eF8/vnnf3ltf5c6bCIiIiJSalzIsxE1crEp7711bBxl3Av3P79feeUVXn/9dd577z0+++wzevfuzebNm6lTp84V127dupWffvqJihUrsnPnTi5cuADAuXPniIuLo2XLliQnJ3P06FEGDBjA008/zYwZMwCYMGECM2bM4JNPPqFOnTpMmDCBH374gQ4dOjjeY9y4ccyaNYupU6dSs2ZNVqxYwQMPPEClSpVo167dX16PYRisXLmS1NRUatas6Tj+9NNPs3XrVr766iuCg4P54Ycf6Ny5M5s3b6ZmzZq0bduWxMRE7r77bk6dOsW2bdvw8vIiNTWVyMhIkpKSaNasmeN+fFarlYkTJxIeHs7u3bt56qmn+Oc//8mUKVMc73n+/HneeOMNPv74YypUqEBAQAB33303hw4dYvny5bi5uTF48GCOHj16Q39210oFm4iIiIiIE1qwYAE+Pj4Fjr344ou8+OKLjp/vueceBgwYAMCrr75KfHw877//foHC45J9+/bRqFEjmjZtClzcLOOSL774guzsbD799FO8vb0BmDRpEnfccQdvvPEGgYGBvPvuu4wYMYK77roLgKlTp7J48f8Xvzk5Obz22mssXbqUli1bAlC9enVWrlzJhx9++KcF25QpU/j444/Jzc0lLy8PT09PBg8e7Mg9ffp09u3b57jX8vDhw1m0aBHTp0/ntddeIyYmhg8//BCAFStW0KhRI4KCgkhMTCQyMpLExMQC7z9kyBDH/w4LC+Nf//oX//jHPwp8bnl5eUyZMoUGDRoAsH37dn766SfWrVtHs2bNAJg2bdoVi+PCpIKtlFq27QhuLlba1qpkdhQRERGRIuPl5sLWsXGmvff1aN++PR988EGBY+XLly/w86XC6I8/X21XyCeffJJevXqxYcMGOnXqRM+ePWnVqhUA27Zto0GDBo5iDeDWW2/FbreTlpaGp6cnhw8fpnnz5o7zrq6uNG3a1DEWuXPnTs6fP89tt91W4H1zc3Np1KjRn15r3759eemllzh16hSjRo2iVatWjmybN2/GZrNRq1atAs/JycmhQoUKALRr145nnnmGY8eOkZSURExMjKNge/TRR1m9ejX//Oc/Hc9dunQp48aNIzU1laysLPLz88nOzub8+fOOLpy7uzv169d3PGfbtm24urrSpEkTx7HIyEj8/f3/9Nr+LhVspdCZ7Dxe+H4zx87k0Dk6iJe71SGkXBmzY4mIiIjcdBaLpdDHEm8Wb29vIiIiCu31unTpwt69e/nxxx+Jj4+nY8eODBw4kPHjxxfK61/6DtjChQupUqVKgXN/tVmKn5+f41q//vprIiIiaNGiBbGxsZw9exYXFxfWr1+Pi0vBovdSB7JevXqUL1+epKQkkpKS+Pe//01QUBBvvPEGycnJ5OXlOQrAPXv20K1bN5588kn+/e9/U758eVauXMmjjz5Kbm6uo2Dz8vLCYrH8/Q/mb9KmI6WQxWLhjvrBuFgtLErJIPbtJN5ftoPsPJvZ0URERETkOvzyyy+X/fxnI3qVKlWiX79+zJo1i3fffZePPvoIgDp16vDbb79x7tw5x9pVq1ZhtVqpXbs2fn5+VK5cmbVr1zrO5+fns379esfPf9ycIyIiosAjNDT0mq/Jx8eHZ555huHDh2MYBo0aNcJms3H06NHLXvfSLpgWi4U2bdowd+5cUlJSaN26NfXr1ycnJ4cPP/yQpk2bOrqH69evx263M2HCBFq0aEGtWrU4dOjQX+aKjIy87JrT0tLIzMy85mu7ESrYSiEfD1dG3hHFj4Pb0Dy8PNl5dibEbyfu3RUkpB4xO56IiIiIcHHkLyMjo8Dj+PHjBdZ88803fPLJJ2zfvp1Ro0axbt06nn766Su+3siRI5k7dy47d+4kJSWFBQsWOIq7vn374unpSb9+/diyZQvLly9n0KBBPPjggwQGBgLwzDPP8PrrrzNnzhxSU1N56qmnChQrZcuWZfjw4QwdOpSZM2eya9cuNmzYwPvvv8/MmTOv69qfeOIJtm/fznfffUetWrXo27cvDz30EN9//z3p6emsW7eOcePGsXDhQsdzYmJi+PLLL2nYsCE+Pj5YrVbatm3L559/XuD7axEREeTl5fH++++ze/duPvvsM6ZOnfqXmWrXrk3nzp154oknWLt2LevXr2fAgAF4eXld17VdLxVspVjtoLJ89XgLJvZpRKCvB3tPnKf/jF8ZMDOZfSfOmx1PREREpFRbtGgRlStXLvBo3bp1gTVjxozhq6++on79+nz66ad8+eWXREVFXfH13N3dGTFiBPXr16dt27a4uLjw1VdfARe31V+8eDEnT56kWbNm3H333XTs2JFJkyY5nj9s2DAefPBB+vXrR8uWLSlbtix33nlngfd49dVXeeWVVxg3bhx16tShc+fOLFy4kPDw8Ou69vLly/PQQw8xevRo7HY706dP56GHHmLYsGHUrl2bnj17kpycTNWqVR3PadeuHTabjZiYGMexmJiYy441aNCAt99+mzfeeIO6devy+eefM27cuGvKNX36dIKDg2nXrh133XUXjz/+OAEBAdd1bdfLYugW4kUmKysLPz8/Tp8+ja+vr9lxCjibk8/7y3YwbWU6+XYDd1cr/2hXg6diauB5nV+QFREREXEG2dnZpKenEx4ejqenp9lxCp3FYuGHH36gZ8+eZkeRq/izv4PXWhuowybAxTHJEbfXYdGQtrSOqEhuvp2Jy3YQ+3YSi1MyrvtGjyIiIiIi8vepYJMCIgJ8+OzRW5jStzHBfp4cOHWBJz5bz8PTk9l97Oxfv4CIiIiIiBSa4rGnqRQpi8XC7fUqE1O7EpOX7+Q/K9JJ2n6Mzu/+zIA24TzdIaLYbIcrIiIiUlJpAqp0UIdNrqqMuyvPxUWyeGhbYmpXItdmZ0riLjpOSGLh74f1DwkRERERkZtMBZv8pfCK3kx/uBkfPdiEkHJeHD6dzcAvNvDAtLXsPHrG7HgiIiIif0q/ZBazFMbfPRVsck0sFgudooNY+mw7nulYE3dXK6t2nqDzuz/z2o/bOJuTb3ZEERERkQLc3NwAOH9etysSc1z6u3fp7+KN0Lb+RciZt/W/XvtOnGfsgq0s3XbxRtsBZT14qWsdujcIxmKxmJxORERE5KLDhw+TmZlJQEAAZcqU0X+nSJEwDIPz589z9OhR/P39qVy58mVrrrU2UMFWhEpSwXbJ8tSjjJ6fwt7/3mj7lvDyjO0RTWRQybg+ERERKd4MwyAjI4PMzEyzo0gp5O/vT1BQ0BV/UaCCzQmVxIINIDvPxsc/72bS8p1k59lxsVp4qGU1ht5WC1/PG2//ioiIiBQWm81GXl6e2TGkFHFzc8PFxeWq51WwOaGSWrBdcuDUef69cBs/bckAoKKPOy90qcNdjapgtWr8QERERETkEhVsTqikF2yXrNh+jNHzU9h97BwATaqVY0z3aOpW8TM5mYiIiIiIc1DB5oRKS8EGkJtv55NV6UxctoPzuTasFujbvBrDOtXCv4y72fFEREREREx1rbWBtvWXm8Ld1co/2tVg2bB23NEgGLsBn/2ylw4Tkvhq3T7sdv2eQERERETkr6jDVoRKU4ftf63edZxRc1PYcfQsAA1C/Xm1RzT1Q/zNDSYiIiIiYgKNRDqh0lywAeTZ7MxcvYd3l+7gbE4+Fgv0bhbKc3GRlPfWmKSIiIiIlB4aiRSn4+ZiZUCb6iQMb8ddjapgGPDluv20H5/IZ7/sxaYxSRERERGRAtRhK0KlvcP2v5L3nOSVOVtIzTgDQN0qvozpXpcm1cqZnExERERE5ObSSKQTUsF2uXybnc/X7mP8kjTOZOcDcHeTEF7oEklFHw+T04mIiIiI3BwaiZRiwdXFSr9WYSwfHsO9TUMA+Hb9AdqPT2T6qnTybXaTE4qIiIiImEcdtiKkDttf27DvFCPnbmHLwSwAIoPKMqZ7NM2rVzA5mYiIiIhI4dFIpBNSwXZtbHaDr5L38dbiNDLP5wHQs2EwL95ehwBfT5PTiYiIiIj8fRqJlGLLxWqhb/NqLB8Ww/3Nq2KxwJxNh2g/PpH/rNhNnsYkRURERKSUUIetCKnDdmN+P5DJyLkpbNqfCUDNAB/G9IimVY2K5gYTEREREblBGol0QirYbpzdbvDt+gO8viiVk+dyAehavzIvd61DZT8vk9OJiIiIiFwfjURKiWK1Wri3WSjLh8XQr2U1rBZY+PthOoxPYkriTnLzNSYpIiIiIiWPOmxFSB22wpNy6DSj5qbw695TAFSv6M3o7tG0rVXJ5GQiIiIiIn9NI5FOSAVb4TIMgx82HuS1H1M5fjYHgLjoQF7pFkVIuTImpxMRERERuTqNREqJZ7FYuKtxCAnD29H/1nBcrBYWpxwh9u0kJi7bQXaezeyIIiIiIiJ/izpsRUgdtpsrLeMMI+duYW36SQCqVSjDqDui6BAZaHIyEREREZGCNBLphFSw3XyGYTD/98P8e+FWjmRdHJPsGBnAqDuiqVpBY5IiIiIi4hw0EimlksVioXuDYJYNi+GJdtVxtVpYlnqU2HeSeDt+OxdyNSYpIiIiIsWHOmxFSB22orfz6FlGz0th5c7jAFTx92LkHVF0igrEYrGYnE5ERERESiuNRDohFWzmMAyDRVsyeHXBVg6dzgagXa1KjLojiuqVfExOJyIiIiKlkQo2J6SCzVznc/OZsnwXH63YTa7NjpuLhQFtqjOoQwRl3F3NjiciIiIipYgKNiekgs05pB8/x5j5KSSmHQOgsp8nL3eN4vZ6QRqTFBEREZEioYLNCalgcx6GYbB021HGzE/hwKkLANwaUYEx3aOJCChrcjoRERERKelUsDkhFWzOJzvPxgeJu/ggaRe5+XZcrRb6tw5ncMea+HhoTFJEREREbg5t6y9yDTzdXBh6Wy2WDm1HbJ1A8u0GH63YTYfxiczddBD9PkNEREREzKQOWxFSh835LU+9OCa558R5AG4JL8/YHtFEBunPS0REREQKj0YinZAKtuIhO8/Gxz/vZtLynWTn2XGxWnioZTWGxNbCz8vN7HgiIiIiUgJoJFLkBnm6ufB0h5osGxZDl7pB2OwG01ftoeOERL5dfwC7Xb/jEBEREZGioQ5bEVKHrXj6eccxRs1LYfexcwA0qVaOMd2jqVvFz+RkIiIiIlJcaSTSCalgK75y8+18siqdict2cD7XhtUCfZtXY1inWviXcTc7noiIiIgUMxqJFClE7q5W/tGuBgnDYrijQTB2Az77ZS8dJiTx1bp9GpMUERERkZtCHbYipA5bybFm1wlGzdvC9iNnAWgQ4sfYHnVpEOpvbjARERERKRY0EumEVLCVLHk2OzNX7+HdpTs4m5OPxQK9m4XyXFwk5b01JikiIiIiV6eRSJGbzM3FyoA21UkY3o67GlXBMODLdftpPz6Rz37Zi01jkiIiIiLyN6nDVoTUYSvZkvec5JU5W0jNOANAdLAvY3vUpUm1ciYnExERERFno5FIJ6SCreTLt9n5fO0+xi9J40x2PgB3Nwnh+c6RVCrrYXI6EREREXEWGokUMYGri5V+rcJYPjyGe5uGAPDt+gN0mJDI9FXp5NvsJicUERERkeJEHbYipA5b6bNh3ylGzt3CloNZAEQGlWVM92iaV69gcjIRERERMZNGIp2QCrbSyWY3+Cp5H28tTiPzfB4APRsGM+L2OgT6epqcTkRERETMoJFIESfhYrXQt3k1lg+L4f7mVbFYYM6mQ3QYn8h/VuwmT2OSIiIiInIV6rAVIXXYBOD3A5mMnJvCpv2ZAEQE+DC2ezStIiqaG0xEREREioxGIp2QCja5xG43+Hb9AV5flMrJc7kAdK1fmZe71qGyn5fJ6URERETkZisWI5FhYWFYLJbLHgMHDgQgIyODBx98kKCgILy9vWncuDHfffddgdc4efIkffv2xdfXF39/fx599FHOnj1bYM3vv/9OmzZt8PT0JDQ0lDfffPOyLN988w2RkZF4enpSr149fvzxxwLnDcNg5MiRVK5cGS8vL2JjY9mxY0chfyJSWlitFu5tFsryYTH0a1kNqwUW/n6YDuOTmJK4k5x8m9kRRURERMQJmFqwJScnc/jwYccjPj4egHvuuQeAhx56iLS0NObNm8fmzZu56667uPfee9m4caPjNfr27UtKSgrx8fEsWLCAFStW8PjjjzvOZ2Vl0alTJ6pVq8b69et56623GD16NB999JFjzerVq+nTpw+PPvooGzdupGfPnvTs2ZMtW7Y41rz55ptMnDiRqVOnsnbtWry9vYmLiyM7O/tmf0xSgvmVcWNMj7rMH9SaptXKcSHPxpuL0ujy7s8kbT9mdjwRERERMZlTjUQOGTKEBQsWsGPHDiwWCz4+PnzwwQc8+OCDjjUVKlTgjTfeYMCAAWzbto2oqCiSk5Np2rQpAIsWLeL222/nwIEDBAcH88EHH/DSSy+RkZGBu7s7AC+88AJz5swhNTUVgPvuu49z586xYMECx/u0aNGChg0bMnXqVAzDIDg4mGHDhjF8+HAATp8+TWBgIDNmzKB3797XdH0aiZQ/YxgGP2w8yGs/pnL8bA4AcdGBvNw1itDyZUxOJyIiIiKFqViMRP5Rbm4us2bNon///lgsFgBatWrF7NmzOXnyJHa7na+++ors7GxiYmIAWLNmDf7+/o5iDSA2Nhar1cratWsda9q2beso1gDi4uJIS0vj1KlTjjWxsbEF8sTFxbFmzRoA0tPTycjIKLDGz8+P5s2bO9ZcSU5ODllZWQUeIldjsVi4q3EICcPb8WjrcFysFhanHCH27SQmLttBdp7GJEVERERKG6cp2ObMmUNmZiYPP/yw49jXX39NXl4eFSpUwMPDgyeeeIIffviBiIgI4OJ33AICAgq8jqurK+XLlycjI8OxJjAwsMCaSz//1Zo/nv/j86605krGjRuHn5+f4xEaGnpNn4WUbr6ebrzSLYofB7eheXh5cvLtvB2/nU7vrGDZtiNmxxMRERGRIuQ0Bdu0adPo0qULwcHBjmOvvPIKmZmZLF26lF9//ZVnn32We++9l82bN5uY9NqNGDGC06dPOx779+83O5IUI7WDyvLV4y2Y2KcRgb4e7Dt5nkdn/sqjM5LZe+Kc2fFEREREpAi4mh0AYO/evSxdupTvv//ecWzXrl1MmjSJLVu2EB0dDUCDBg34+eefmTx5MlOnTiUoKIijR48WeK38/HxOnjxJUFAQAEFBQRw5UrArcennv1rzx/OXjlWuXLnAmoYNG171ujw8PPDw8Ljmz0Hkf1ksFro3CKZjZAATE3Yw7ed0lqUe5eedx/lH2+o8GROBl7uL2TFFRERE5CZxig7b9OnTCQgIoGvXro5j58+fB8BqLRjRxcUFu90OQMuWLcnMzGT9+vWO8wkJCdjtdpo3b+5Ys2LFCvLy8hxr4uPjqV27NuXKlXOsWbZsWYH3iY+Pp2XLlgCEh4cTFBRUYE1WVhZr1651rBG5mbw9XBnRpQ6LhrSldURFcvPtTEzYSezbSSxOycCJ9g4SERERkUJkesFmt9uZPn06/fr1w9X1/xt+kZGRRERE8MQTT7Bu3Tp27drFhAkTiI+Pp2fPngDUqVOHzp0789hjj7Fu3TpWrVrF008/Te/evR2jlffffz/u7u48+uijpKSkMHv2bN577z2effZZx3s988wzLFq0iAkTJpCamsro0aP59ddfefrpp4GLXY4hQ4bwr3/9y3GLgYceeojg4GBHFpGiEBHgw2eP3sIHfRsT7OfJwcwLPPHZevpNT2b3sbN//QIiIiIiUqyYvq3/kiVLHLs21qpVq8C5HTt28MILL7By5UrOnj1LREQEw4cPL7DN/8mTJ3n66aeZP38+VquVXr16MXHiRHx8fBxrfv/9dwYOHEhycjIVK1Zk0KBBPP/88wXe65tvvuHll19mz5491KxZkzfffJPbb7/dcd4wDEaNGsVHH31EZmYmrVu3ZsqUKZdl/jPa1l8K0/ncfKYs38VHK3aTa7Pj5mJhQJvqDOoQQRl3p5h2FhEREZGruNbawPSCrTRRwSY3Q/rxc4yZn0Ji2sUbbVf28+SlrnXoWq+y4xYZIiIiIuJcVLA5IRVscrMYhsHSbUcZMz+FA6cuAHBrRAVG3xFNzcCyJqcTERERkf+lgs0JqWCTmy07z8bUpF18kLiLnHw7rlYLj9waxjOxtfDx0JikiIiIiLO41trA9E1HRKTweLq5MCS2FkufbUdsnUDy7Qb/+TmdDuMTmbPxoHaTFBERESlm1GErQuqwSVFbnnpxTHLPiYu3ybglvDxje0QTGaS/fyIiIiJm0kikE1LBJmbIybfx8c/pvJ+wg+w8Oy5WCw+2qMbQ22rh5+VmdjwRERGRUkkjkSICgIerCwPbR7BsWAxd6gZhsxvMWL2HjhMS+Xb9Aex2/c5GRERExFmpw1aE1GETZ/DzjmOMmpfC7mPnAGhc1Z+xPepSt4qfyclERERESg+NRDohFWziLHLz7Uxflc57y3ZwPteG1QL3N6/K8E618S/jbnY8ERERkRJPI5EiclXurlaeaFeDhGExdG8QjN2AWb/so/34RL5ct09jkiIiIiJOQh22IqQOmzirNbtOMGreFrYfOQtAgxA/xvaoS4NQf3ODiYiIiJRQGol0QirYxJnl2ex8umYv78Zv50xOPhYL3Nc0lH92jqS8t8YkRURERAqTRiJF5Lq4uVh5tHU4y4a3465GVTAM+Cp5P+3HJ/LZL3uxaUxSREREpMipw1aE1GGT4iR5z0lGzk1h2+EsAKKDfRnboy5NqpUzOZmIiIhI8aeRSCekgk2Km3ybnS/W7WP84jSysvMB6NU4hBe6RFKprIfJ6URERESKL41Eisjf5upi5aGWYSQMj+HepiEAfLfhAB0mJDJ9VTr5NrvJCUVERERKNnXYipA6bFLcbdx3ipFzU9h88DQAkUFlGdM9mubVK5icTERERKR40UikE1LBJiWBzW7wVfI+3lqcRub5PAB6NgxmxO11CPT1NDmdiIiISPGgkUgRuSlcrBb6Nq/G8mEx3N+8KhYLzNl0iA7jE/nPit3kaUxSREREpNCow1aE1GGTkmjzgdO8MncLm/ZnAhAR4MOY7tHcGlHR3GAiIiIiTkwjkU5IBZuUVHa7wbfrD/D6olROnssFoGu9yrzUtQ7B/l4mpxMRERFxPhqJFJEiY7VauLdZKMuHxdCvZTWsFli4+TAdJyQxJXEnOfk2syOKiIiIFEvqsBUhddiktNh6KItR87aQvOcUANUrejOqezTtalUyOZmIiIiIc9BIpBNSwSaliWEY/LDxIK/9mMrxszkAdIoK5JVuUYSWL2NyOhERERFzaSRSRExlsVi4q3EIy4e349HW4bhYLSzZeoTYt5OYuGwH2XkakxQRERH5K+qwFSF12KQ0237kDCPnbuGX3ScBqFq+DKPuiKJjnUCTk4mIiIgUPY1EOiEVbFLaGYbB/N8P8++FWzmSdXFMsmNkACPviKJaBW+T04mIiIgUHY1EiojTsVgsdG8QTMKwGJ5oVx03FwvLUo9y2zsreHtJGhdyNSYpIiIi8kfqsBUhddhECtp59Cxj5qfw847jAFTx9+KVblHERQdisVhMTiciIiJy82gk0gmpYBO5nGEYLNqSwasLtnLodDYAbWpWZEz3aKpX8jE5nYiIiMjNoYLNCalgE7m687n5TFm+i49W7CbXZsfNxcKANtUZ1CGCMu6uZscTERERKVQq2JyQCjaRv5Z+/Bxj5qeQmHYMgMp+nrzUtQ5d61XWmKSIiIiUGCrYnJAKNpFrYxgGS7cdZeyCFPafvABAqxoVGNM9mpqBZU1OJyIiIvL3qWBzQirYRK5Pdp6NqUm7+CBxFzn5dlytFh65NYzBHWtS1tPN7HgiIiIiN0zb+otIsefp5sKQ2FosfbYdt0UFkm83+M/P6XSckMScjQfR75tERESkpFOHrQipwyby9yxPO8qYeSnsOXEegFvCyjOmRzR1Kuv/TyIiIlK8aCTSCalgE/n7cvJtfPxzOu8n7CA7z46L1cKDLaox9LZa+HlpTFJERESKB41EikiJ5OHqwsD2ESwbFsPt9YKw2Q1mrN5DxwmJfPPrfux2/Q5KRERESg512IqQOmwihe/nHccYNS+F3cfOAdC4qj9je9SlbhU/k5OJiIiIXJ1GIp2QCjaRmyM33870Vem8t2wH53NtWCzQt3lVhneqjX8Zd7PjiYiIiFxGI5EiUmq4u1p5ol0NEobF0L1BMIYBs37ZR/vxiXy5bp/GJEVERKTYUoetCKnDJlI01uw6wah5W9h+5CwADUL8GNOjLg1D/c0NJiIiIvJfGol0QirYRIpOns3Op2v28m78ds7k5GOxwH1NQ/ln50jKe2tMUkRERMylkUgRKdXcXKw82jqcZcPbcVfjKhgGfJW8n/bjE/lszR5sGpMUERGRYkAdtiKkDpuIeX7dc5JX5qaw7XAWAFGVfXm1ZzRNqpU3OZmIiIiURhqJdEIq2ETMlW+z88W6fYxfnEZWdj4AvRqH8EKXSCqV9TA5nYiIiJQmGokUEfkfri5WHmoZRsLwGO5rGgrAdxsO0GF8Ip+sTCffZjc5oYiIiEhB6rAVIXXYRJzLxn2nGDk3hc0HTwMQGVSWMd2jaV69gsnJREREpKTTSKQTUsEm4nxsdoPZyft5c3EqmefzAOjRMJgXb69DoK+nyelERESkpNJIpIjINXCxWri/eVWWD4uhb/OqWCwwd9MhOoxP5KMVu8jTmKSIiIiYSB22IqQOm4jz23zgNK/M3cKm/ZkARAT4MKZ7NLdGVDQ3mIiIiJQoGol0QirYRIoHu93g2w0HeOOnVE6cywWga73KvNS1DsH+XianExERkZJAI5EiIjfIarVwb9NQEobF0K9lNawWWLj5MB0nJDF5+U5y8m1mRxQREZFSQh22IqQOm0jxtPVQFqPmbSF5zykAwit6M7p7NO1qVTI5mYiIiBRXGol0QirYRIovwzCYs+kgr/2YyrEzOQB0igrklW5RhJYvY3I6ERERKW40EikiUogsFgt3NgohYVg7BrQOx8VqYcnWI8S+ncR7S3eQnacxSRERESl86rAVIXXYREqO7UfOMHLuFn7ZfRKAquXLMOqOKDrWCTQ5mYiIiBQHGol0QirYREoWwzBY8Pth/r1wGxlZ2QB0iAxg1B1RVKvgbXI6ERERcWYaiRQRucksFgt3NAhm2bB2PNGuOm4uFhJSj3LbOyt4e0kaF3I1JikiIiJ/jzpsRUgdNpGSbefRs4yZn8LPO44DUMXfi1e6RREXHYjFYjE5nYiIiDgTjUQ6IRVsIiWfYRgsTsng1QXbOJh5AYA2NSsyuns0NSr5mJxOREREnIUKNiekgk2k9LiQa2Py8p18tGI3uTY7bi4WHm1dnUEdIvD2cDU7noiIiJhM32ETETGRl7sLw+Nqs2RoW9rXrkSezWBq0i5i305iwe+H0O/KRERE5Fqow1aE1GETKZ0Mw2DZtqOMWZDC/pMXxyRb1ajAmO7R1Awsa3I6ERERMYNGIp2QCjaR0i07z8bUpF18kLiLnHw7rlYLD7cK45nYmpT1dDM7noiIiBQhjUSKiDgZTzcXhsTWYumz7bgtKpB8u8HHK9PpOCGJORsPakxSRERELqMOWxFSh01E/mh52lHGzEthz4nzANwSVp4xPaKpU1n/fBARESnpNBLphFSwicj/ysm38fHP6byfsIPsPDsuVgsPtqjG0Ntq4eelMUkREZGSqliMRIaFhWGxWC57DBw4kD179lzxnMVi4ZtvvnG8xr59++jatStlypQhICCA5557jvz8/ALvk5iYSOPGjfHw8CAiIoIZM2ZclmXy5MmEhYXh6elJ8+bNWbduXYHz2dnZDBw4kAoVKuDj40OvXr04cuTITflcRKT08HB1YWD7CJYNi+H2ekHY7AYzVu+h44REvvl1P3a7fqcmIiJSmplasCUnJ3P48GHHIz4+HoB77rmH0NDQAucOHz7MmDFj8PHxoUuXLgDYbDa6du1Kbm4uq1evZubMmcyYMYORI0c63iM9PZ2uXbvSvn17Nm3axJAhQxgwYACLFy92rJk9ezbPPvsso0aNYsOGDTRo0IC4uDiOHj3qWDN06FDmz5/PN998Q1JSEocOHeKuu+4qok9KREq6Kv5eTOnbhM8evYUalbw5fjaX5779nbunrmbLwdNmxxMRERGTONVI5JAhQ1iwYAE7duzAYrFcdr5Ro0Y0btyYadOmAfDTTz/RrVs3Dh06RGBgIABTp07l+eef59ixY7i7u/P888+zcOFCtmzZ4nid3r17k5mZyaJFiwBo3rw5zZo1Y9KkSQDY7XZCQ0MZNGgQL7zwAqdPn6ZSpUp88cUX3H333QCkpqZSp04d1qxZQ4sWLa7p+jQSKSLXIjffzvRV6by3bAfnc21YLNC3eVWGd6qNfxl3s+OJiIhIISgWI5F/lJuby6xZs+jfv/8Vi7X169ezadMmHn30UcexNWvWUK9ePUexBhAXF0dWVhYpKSmONbGxsQVeKy4ujjVr1jjed/369QXWWK1WYmNjHWvWr19PXl5egTWRkZFUrVrVseZKcnJyyMrKKvAQEfkr7q5WnmhXg4RhMXRvEIxhwKxf9tF+fCJfrtunMUkREZFSxGkKtjlz5pCZmcnDDz98xfPTpk2jTp06tGrVynEsIyOjQLEGOH7OyMj40zVZWVlcuHCB48ePY7PZrrjmj6/h7u6Ov7//Vddcybhx4/Dz83M8QkNDr/4BiIj8jyA/Tyb2acSXj7WgVqAPp87nMeL7zdw5ZRWb9meaHU9ERESKgNMUbNOmTaNLly4EBwdfdu7ChQt88cUXBbprxcGIESM4ffq047F//36zI4lIMdSyRgUWDm7DK92iKOvhym8HTnPnlFW88N3vnDibY3Y8ERERuYmcomDbu3cvS5cuZcCAAVc8/+2333L+/HkeeuihAseDgoIu26nx0s9BQUF/usbX1xcvLy8qVqyIi4vLFdf88TVyc3PJzMy86por8fDwwNfXt8BDRORGuLlYebR1OMuGt+OuxlUwDPgqeT8dJiTx2Zo92DQmKSIiUiI5RcE2ffp0AgIC6Nq16xXPT5s2je7du1OpUqUCx1u2bMnmzZsL7OYYHx+Pr68vUVFRjjXLli0r8Lz4+HhatmwJgLu7O02aNCmwxm63s2zZMseaJk2a4ObmVmBNWloa+/btc6wRESkKAWU9efvehnz7j5bUqezL6Qt5vDI3hTveX8n6vSfNjiciIiKFzPRdIu12O+Hh4fTp04fXX3/9svM7d+6kVq1a/Pjjj3Tu3LnAOZvNRsOGDQkODubNN98kIyODBx98kAEDBvDaa68BF7f1r1u3LgMHDqR///4kJCQwePBgFi5cSFxcHHBxW/9+/frx4Ycfcsstt/Duu+/y9ddfk5qa6vhu25NPPsmPP/7IjBkz8PX1ZdCgQQCsXr36mq9Vu0SKSGHKt9n5Yt0+xi9OIyv74v0nezUO4YUukVQq62FyOhEREfkz11obmF6wLVmyhLi4ONLS0qhVq9Zl51988UVmzZrFnj17sFovbwju3buXJ598ksTERLy9venXrx+vv/46rq6ujjWJiYkMHTqUrVu3EhISwiuvvHLZ5iaTJk3irbfeIiMjg4YNGzJx4kSaN2/uOJ+dnc2wYcP48ssvycnJIS4ujilTpvzpSOT/UsEmIjfDibM5vLkojdm/XvyebFkPV4beVouHWlbD1cUpBilERETkfxSbgq00UcEmIjfTxn2nGDk3hc3/vdF27cCyjO0RTfPqFUxOJiIiIv9LBZsTUsEmIjebzW4wO3k/by5OJfN8HgA9Ggbz4u11CPT1NDmdiIiIXFLsbpwtIiJ/n4vVwv3Nq7J8WAx9m1fFYoG5mw7RYXwiH63YRZ7NbnZEERERuQ7qsBUhddhEpKhtPnCaV+ZucdxoOyLAhzHdo7k1oqK5wUREREo5jUQ6IRVsImIGu93g2w0HeOOnVE6cywWga73KvNS1DsH+XianExERKZ00EikiIgBYrRbubRpKwvAYHm4VhtUCCzcfpuOEJCYv30lOvs3siCIiInIV6rAVIXXYRMQZbD2Uxah5W0jecwqA8IrejLojipjaASYnExERKT00EumEVLCJiLMwDIM5mw7y2o+pHDuTA0CnqEBe6RZFaPkyJqcTEREp+TQSKSIiV2WxWLizUQgJw9oxoHU4LlYLS7YeIfbtJN5buoPsPI1JioiIOAN12IqQOmwi4qy2HznDqLkprNl9AoCq5cswslsUsVGBJicTEREpmTQS6YRUsImIMzMMgwW/H+bfC7eRkZUNQIfIAEbdEUW1Ct4mpxMRESlZVLA5IRVsIlIcnMvJ5/2EnUxbuZs8m4G7i5Un2lXnqZgIvNxdzI4nIiJSIqhgc0Iq2ESkONl17Cyj56Xw847jAFTx9+KVbnWIiw7CYrGYnE5ERKR4U8HmhFSwiUhxYxgGi1MyeHXBNg5mXgCgTc2KjO4eTY1KPianExERKb5UsDkhFWwiUlxdyLUxJXEnHybtJtdmx83FwqOtqzOoQwTeHq5mxxMRESl2tK2/iIgUGi93F4Z1qs2SoW1pX7sSeTaDqUm76Dghifm/HUK/+xMREbk51GErQuqwiUhJYBgGy7YdZcyCFPafvDgm2apGBcZ0j6ZmYFmT04mIiBQPGol0QirYRKQkyc6z8WHSbqYk7iQn346r1cLDrcJ4JrYmZT3dzI4nIiLi1DQSKSIiN5WnmwvPxNZk6bPt6BQVSL7d4OOV6XSYkMQPGw9oTFJERKQQqMNWhNRhE5GSLDHtKKPnpbDnxHkAbgkrz5ge0dSprH/eiYiI/C+NRDohFWwiUtLl5Nv4+Od03k/YQXaeHasFHmoZxtDbauHnpTFJERGRSzQSKSIiRc7D1YWB7SNYNiyG2+sFYTdgxuo9dBifyNe/7sdu1+8IRUREroc6bEVIHTYRKW1W7jjOqHlb2HXsHACNqvrzao+61K3iZ3IyERERc2kk0gmpYBOR0ig3386M1em8t3QH53JtWCxw/y1VeS6uNv5l3M2OJyIiYgqNRIqIiFNwd7XyeNsaLBsWQ/cGwRgGfL52H+3HJ/Llun3YNCYpIiJyVeqwFSF12ERE4JfdJxg1N4W0I2cAqB/ix9gedWkY6m9uMBERkSKkkUgnpIJNROSiPJudz9bs5Z347ZzJycdigfuahvJcXG0q+HiYHU9EROSm00ikiIg4LTcXK/1bh7NseDt6NQ7BMOCr5P20H5/Ip2v2aExSRETkv9RhK0LqsImIXNmve04ycm4KWw9nARBV2ZdXe0bTpFp5k5OJiIjcHBqJdEIq2ERErs5mN/h87V7GL04jKzsfgLsaV2FElzpUKqsxSRERKVk0EikiIsWKi9XCQy3DWD48hvuahgLw/YaDdBifyCcr08m32U1OKCIiUvT+dsGWlZXFnDlz2LZtW2HkERGRUq6Cjwdv3F2fOQNvpX6IH2dy8hm7YCtdJ67kl90nzI4nIiJSpK67YLv33nuZNGkSABcuXKBp06bce++91K9fn++++67QA4qISOnUMNSfH566ldfurId/GTfSjpyh90e/MPjLjRzJyjY7noiISJG47oJtxYoVtGnTBoAffvgBwzDIzMxk4sSJ/Otf/yr0gCIiUnq5WC3c37wqy4fF0Ld5VSwWmPfbITqMT+SjFbvIzdeYpIiIlGzXXbCdPn2a8uUv7tq1aNEievXqRZkyZejatSs7duwo9IAiIiLlvN359531mP90axpV9edcro3Xfkyly3srWLXzuNnxREREbprrLthCQ0NZs2YN586dY9GiRXTq1AmAU6dO4enpWegBRURELqlbxY/v/tGKN++uTwVvd3YdO0ffj9cy8PMNHMq8YHY8ERGRQnfdBduQIUPo27cvISEhBAcHExMTA1wclaxXr15h5xMRESnAarVwb9NQEobH8HCrMKwWWLj5MB0nJDF5+U5y8m1mRxQRESk0N3Qftl9//ZX9+/dz22234ePjA8DChQvx9/fn1ltvLfSQJYXuwyYiUvi2Hspi1LwtJO85BUB4RW9G3RFFTO0Ak5OJiIhcXZHdONtms7F582aqVatGuXLl/s5LlXgq2EREbg7DMJiz6SCv/ZjKsTM5ANwWFcjIblGEli9jcjoREZHL3bQbZw8ZMoRp06YBF4u1du3a0bhxY0JDQ0lMTLzhwCIiIjfKYrFwZ6MQEoa1Y0DrcFysFuK3HiH27STeW7qD7DyNSYqISPF03QXbt99+S4MGDQCYP38+6enppKamMnToUF566aVCDygiInKtynq68XK3KH56pg0tq1cgJ9/OO0u3c9s7SSzdesTseCIiItftugu248ePExQUBMCPP/7IPffcQ61atejfvz+bN28u9IAiIiLXq1ZgWb54rDnv92lEkK8n+09eYMCnv9J/RjJ7jp8zO56IiMg1u+6CLTAwkK1bt2Kz2Vi0aBG33XYbAOfPn8fFxaXQA4qIiNwIi8XCHQ2CWTasHf9oVwM3FwsJqUfp9M4KJixJ40KuxiRFRMT5XXfB9sgjj3DvvfdSt25dLBYLsbGxAKxdu5bIyMhCDygiIvJ3eHu48kKXSBYNaUubmhXJtdl5P2EnsW8nsWjLYf7m3lsiIiI31Q3tEvntt9+yf/9+7rnnHkJCQgCYOXMm/v7+9OjRo9BDlhTaJVJExFyGYbA4JYNXF2zj4H9vtN2mZkVGd4+mRiUfk9OJiEhpUmTb+su1U8EmIuIcLuTamJK4kw+TdpNrs+PmYuHR1tUZ1CECbw9Xs+OJiEgpcNO29QdISkrijjvuICIigoiICLp3787PP/98w2FFRESKkpe7C8M61WbJ0La0r12JPJvB1KRddJyQxPzfDmlMUkREnMZ1F2yzZs0iNjaWMmXKMHjwYAYPHoyXlxcdO3bkiy++uBkZRUREboqwit5Mf+QWPn6oKaHlvcjIymbQlxu5/z9r2X7kjNnxRERErn8ksk6dOjz++OMMHTq0wPG3336b//znP2zbtq1QA5YkGokUEXFe2Xk2PkzazZTEneTk23G1Wni4VRjPxNakrKeb2fFERKSEuWnfYfPw8CAlJYWIiIgCx3fu3EndunXJzs6+scSlgAo2ERHnt//keV5dsJUl/73RdqWyHrx4eyQ9G1bBYrGYnE5EREqKm/YdttDQUJYtW3bZ8aVLlxIaGnq9LyciIuJUQsuX4aOHmjLjkWaEV/Tm2Jkchs7+jXs/XMPWQ1lmxxMRkVLmurfCGjZsGIMHD2bTpk20atUKgFWrVjFjxgzee++9Qg8oIiJihpjaAbSsUYGPf05nUsJOkvecotv7P/NQyzCG3lYLPy+NSYqIyM13Q9v6//DDD0yYMMHxfbU6derw3HPP6R5sf0EjkSIixdPBzAv8e+FWftycAUAFb3ee7xLJ3Y1DsFo1JikiItdP92FzQirYRESKt5U7jjNq3hZ2HTsHQKOq/oztXpd6IX4mJxMRkeJGBZsTUsEmIlL85ebbmbE6nfeW7uBcrg2LBe6/pSrPxdXGv4y72fFERKSYKNSCrVy5cte8M9bJkyevPWUpo4JNRKTkyDidzbiftjF30yEAypVx47m4SO5rFoqLxiRFROQvFGrBNnPmzGt+4379+l3z2tJGBZuISMnzy+4TjJqbQtp/b7RdP8SPMd2jaVS1nMnJRETEmWkk0gmpYBMRKZnybHY+W7OXd+K3cyYnH4D7mobyz861qeDjYXI6ERFxRjftPmwiIiJSkJuLlf6tw1k2vB29GocAMPvX/bQfn8ina/Zgs+t3oyIicmPUYStC6rCJiJQOv+45yci5KWw9fPFG21GVfRnbI5qmYeVNTiYiIs5CI5FOSAWbiEjpYbMbfLF2L28tTiMr++KY5F2Nq/BCl0gCynqanE5ERMymkUgRERETuVgtPNgyjOXDY7ivaSgA3284SMfxSUxbmU6+zW5yQhERKQ6uq2DLy8vD1dWVLVu23Kw8IiIiJUoFHw/euLs+cwbeSv0QP87k5PPqgq10nbiSX3afMDueiIg4uesq2Nzc3KhatSo2m+1m5RERESmRGob688NTtzLurnqUK+NG2pEz9P7oFwZ/uZEjWdlmxxMRESd13SORL730Ei+++KJukC0iInKdXKwW+txSlYRhMTzQoioWC8z77RAdxifyYdIucvM1JikiIgVd96YjjRo1YufOneTl5VGtWjW8vb0LnN+wYUOhBixJtOmIiIj80ZaDp3ll7hY27ssEoEYlb8Z0r0vrmhXNDSYiIjfdtdYGrtf7wj179vw7uUREROS/6lbx47t/tOK7DQd4/adUdh07xwPT1nJ7vSBe7hpFsL+X2RFFRMRk2ta/CKnDJiIiV3P6Qh7vxG/n0zV7sBvg5ebC0x0iGNAmHA9XF7PjiYhIIbvp2/qvX7+eWbNmMWvWLDZu3HhDrxEWFobFYrnsMXDgQMeaNWvW0KFDB7y9vfH19aVt27ZcuHDBcf7kyZP07dsXX19f/P39efTRRzl79myB9/n9999p06YNnp6ehIaG8uabb16W5ZtvviEyMhJPT0/q1avHjz/+WOC8YRiMHDmSypUr4+XlRWxsLDt27Lih6xYREflffl5ujO4ezcLBbWgWVo4LeTbeWpxG53d/JjHtqNnxRETEJNddsB09epQOHTrQrFkzBg8ezODBg2nSpAkdO3bk2LFj1/VaycnJHD582PGIj48H4J577gEuFmudO3emU6dOrFu3juTkZJ5++mms1v+P3bdvX1JSUoiPj2fBggWsWLGCxx9/3HE+KyuLTp06Ua1aNdavX89bb73F6NGj+eijjxxrVq9eTZ8+fXj00UfZuHEjPXv2pGfPngVuX/Dmm28yceJEpk6dytq1a/H29iYuLo7sbO3sJSIihadOZV++fqIl797XkEplPUg/fo6Hpyfz2Ke/sv/kebPjiYhIEbvukcj77ruP3bt38+mnn1KnTh0Atm7dSr9+/YiIiODLL7+84TBDhgxhwYIF7NixA4vFQosWLbjtttt49dVXr7h+27ZtREVFkZycTNOmTQFYtGgRt99+OwcOHCA4OJgPPviAl156iYyMDNzd3QF44YUXmDNnDqmpqY5rOnfuHAsWLHC8dosWLWjYsCFTp07FMAyCg4MZNmwYw4cPB+D06dMEBgYyY8YMevfufU3Xp5FIERG5Hmey83hv6Q6mr96DzW7g4WrlyZga/KNdDTzdNCYpIlKc3bSRyEWLFjFlyhRHsQYQFRXF5MmT+emnn24sLZCbm8usWbPo378/FouFo0ePsnbtWgICAmjVqhWBgYG0a9eOlStXOp6zZs0a/P39HcUaQGxsLFarlbVr1zrWtG3b1lGsAcTFxZGWlsapU6cca2JjYwvkiYuLY82aNQCkp6eTkZFRYI2fnx/Nmzd3rLmSnJwcsrKyCjxERESuVVlPN17uFsVPz7ShZfUK5OTbeXfpDm57J4n4rUfQ19BFREq+6y7Y7HY7bm5ulx13c3PDbr/x+8fMmTOHzMxMHn74YQB2794NwOjRo3nsscdYtGgRjRs3pmPHjo7vjmVkZBAQEFDgdVxdXSlfvjwZGRmONYGBgQXWXPr5r9b88fwfn3elNVcybtw4/Pz8HI/Q0NBr+zBERET+oFZgWb54rDmT7m9EkK8n+09e4LFPf6X/jGT2HD9ndjwREbmJrrtg69ChA8888wyHDh1yHDt48CBDhw6lY8eONxxk2rRpdOnSheDgYABH8ffEE0/wyCOP0KhRI9555x1q167NJ598csPvU5RGjBjB6dOnHY/9+/ebHUlERIopi8VCt/rBLBvWjidjauDmYmF52jE6vbOC8YvTuJBrMzuiiIjcBNddsE2aNImsrCzCwsKoUaMGNWrUIDw8nKysLN5///0bCrF3716WLl3KgAEDHMcqV64MXBy3/KM6deqwb98+AIKCgjh6tODOWfn5+Zw8eZKgoCDHmiNHjhRYc+nnv1rzx/N/fN6V1lyJh4cHvr6+BR4iIiJ/h7eHK893jmTRkLa0qVmRXJudSct3Evt2Eou2HNaYpIhICXPdBVtoaCgbNmxg4cKFDBkyhCFDhvDjjz+yYcMGQkJCbijE9OnTCQgIoGvXro5jYWFhBAcHk5aWVmDt9u3bqVatGgAtW7YkMzOT9evXO84nJCRgt9tp3ry5Y82KFSvIy8tzrImPj6d27dqUK1fOsWbZsmUF3ic+Pp6WLVsCEB4eTlBQUIE1WVlZrF271rFGRESkKNWo5MOn/W9h6gONqeLvxcHMC/xj1gYe+mQdu46d/esXEBGR4sG4TjNnzjSys7MvO56Tk2PMnDnzel/OsNlsRtWqVY3nn3/+snPvvPOO4evra3zzzTfGjh07jJdfftnw9PQ0du7c6VjTuXNno1GjRsbatWuNlStXGjVr1jT69OnjOJ+ZmWkEBgYaDz74oLFlyxbjq6++MsqUKWN8+OGHjjWrVq0yXF1djfHjxxvbtm0zRo0aZbi5uRmbN292rHn99dcNf39/Y+7cucbvv/9u9OjRwwgPDzcuXLhwzdd6+vRpAzBOnz59vR+TiIjIVZ3PyTfGL041ar74o1Ht+QVGxIsLjXE/bjPOZueZHU1ERK7iWmuD697W38XFhcOHD1+22ceJEycICAjAZru+GfolS5Y4dm2sVavWZedff/11Jk+ezMmTJ2nQoAFvvvkmrVu3dpw/efIkTz/9NPPnz8dqtdKrVy8mTpyIj4+PY83vv//OwIEDSU5OpmLFigwaNIjnn3++wPt88803vPzyy+zZs4eaNWvy5ptvcvvttzvOG4bBqFGj+Oijj8jMzKR169ZMmTLlipmvRtv6i4jIzbTn+DnGLthKQurFrwsE+XryUtc6dKtfGYvFYnI6ERH5o2utDa67YLNarRw5coRKlSoVOP7bb7/Rvn17Tp48eWOJSwEVbCIiUhSWbj3CmAUp7D95AYCW1Sswpkc0tQLLmpxMREQuudbawPVaX7BRo0ZYLBYsFgsdO3bE1fX/n2qz2UhPT6dz585/L7WIiIj8bbFRgbSuWZEPk3YzJXEna3afoMt7P/NwqzCGxNakrOflt+cRERHndM0FW8+ePQHYtGkTcXFxBUYO3d3dCQsLo1evXoUeUERERK6fp5sLz8TW5K7GVXh1wVaWbD3CtJXpzPvtEC/eHknPhlU0JikiUgxc90jkzJkz6d27Nx4eHjcrU4mlkUgRETFLYtpRxszfSvp/b7TdLKwcY7rXJSpY/z4SETHDtdYG172tf1RUFJs2bbrs+Nq1a/n111+v9+VERESkCMTUDmDRkDY8F1cbLzcXkvecotv7PzN6XgqnL+T99QuIiIgprrtgGzhwIPv377/s+MGDBxk4cGChhBIREZHC5+HqwsD2ESwb1o6u9SpjN2DG6j10GJ/I17/ux27XTbdFRJzNdY9E+vj48Pvvv1O9evUCx9PT06lfvz5nzpwp1IAliUYiRUTEmazccZxR87aw69jFMclGVf0Z270u9UL8TE4mIlLy3bSRSA8PD44cOXLZ8cOHDxfYOVJEREScW+uaFfnpmba8eHsk3u4ubNyXSffJK3nph82cOpdrdjwREeEGCrZOnToxYsQITp8+7TiWmZnJiy++yG233Vao4UREROTmcne18njbGiQMj6FHw2AMAz5fu4/2ExL5Yu0+bBqTFBEx1XWPRB48eJC2bdty4sQJGjVqBFzc6j8wMJD4+HhCQ0NvStCSQCORIiLi7H7ZfYJRc1NIO3LxKw71Q/wY0z2aRlXLmZxMRKRkudba4LoLNoBz587x+eef89tvv+Hl5UX9+vXp06cPbm66EeefUcEmIiLFQb7Nzqdr9vJO/HbO5OQDcG/TEJ7vHEkFH93WR0SkMNzUgk1ujAo2EREpTo6dyeH1n1L5bsMBAHw9XRkeV5u+zavhYtVNt0VE/o6bXrBt3bqVffv2kZtb8EvJ3bt3v5GXKxVUsImISHG0fu9JXpmTwtbDWQBEVfZlbI9omoaVNzmZiEjxddMKtt27d3PnnXeyefNmLBYLl55usVz8TZvNZvsbsUs2FWwiIlJc2ewGX6zdy1uL08jKvjgmeVfjKrzQJZKAsp4mpxMRKX5u2rb+zzzzDOHh4Rw9epQyZcqQkpLCihUraNq0KYmJiX8ns4iIiDgpF6uFB1uGsXx4DL2bhWKxwPcbDtJxfBLTVqaTZ7ObHVFEpES67g5bxYoVSUhIoH79+vj5+bFu3Tpq165NQkICw4YNY+PGjTcra7GnDpuIiJQUm/ZnMnLuFn4/cPE2P7UDyzKmRzQtqlcwOZmISPFw0zpsNpuNsmXLAheLt0OHDgFQrVo10tLSbjCuiIiIFCcNQ/354albGXdXPcqVcSPtyBl6f/QLg7/cSMbpbLPjiYiUGNddsNWtW5fffvsNgObNm/Pmm2+yatUqxo4dS/Xq1Qs9oIiIiDgnF6uFPrdUZfnwGB5oURWLBeb9doiOExL5MGkXufkakxQR+buueyRy8eLFnDt3jrvuuoudO3fSrVs3tm/fToUKFZg9ezYdOnS4WVmLPY1EiohISbbl4GlembuFjfsyAahRyZsx3evSumZFc4OJiDihIr0P28mTJylXrpxjp0i5MhVsIiJS0tntBt9tOMDrP6Vy4tzFW//cXi+Il7pGUcXfy+R0IiLOQzfOdkIq2EREpLQ4fSGPd+K38+maPdgN8HJz4ekOEQxoE46Hq4vZ8URETKeCzQmpYBMRkdJm2+EsRs1NYd2ekwCEVSjDqO7RtK8dYHIyERFzqWBzQirYRESkNDIMg7mbDvHvH7dx7EwOALdFBTKyWxSh5cuYnE5ExBw3bVt/ERERkethsVjo2agKCcPa8VibcFytFuK3HiH27STeXbqd7Dyb2RFFRJyWOmxFSB02ERER2HHkDCPnprBm9wkAQst7MbJbNLF1ArSBmYiUGhqJdEIq2ERERC4yDIOFmw/zrwXbyMi6eKPt9rUrMeqOaMIqepucTkTk5lPB5oRUsImIiBR0LiefSct38vHPu8mzGbi7WHm8bXUGto/Ay127SYpIyaWCzQmpYBMREbmyXcfOMnpeCj/vOA5AFX8vXu5ah851gzQmKSIlkgo2J6SCTURE5OoMw2BxyhFeXbCVg5kXAGhTsyKju0dTo5KPyelERAqXCjYnpIJNRETkr13ItTElcScfJu0m12bHzcVC/9bhDO5QE28PV7PjiYgUChVsTkgFm4iIyLXbc/wcYxdsJSH1KABBvp682LUOd9SvrDFJESn2VLA5IRVsIiIi12/ZtiOMmb+VfSfPA9CyegXG9IimVmBZk5OJiNw4FWxOSAWbiIjIjcnOs/HRit1MXr6TnHw7LlYLD7cKY0hsTcp6upkdT0Tkul1rbWAtwkwiIiIiN8TTzYXBHWuy9Nl2dIoKxGY3mLYynfbjk/h+wwH0+2cRKanUYStC6rCJiIgUjsS0o4yZv5X04+cAaBZWjjHd6xIVrH+/ikjxoJFIJ6SCTUREpPDk5NuYtjKd95ft5EKeDasFHmxRjWc71cbPS2OSIuLcNBIpIiIiJZqHqwtPxUSwbFg7utarjN2AmWv20mF8Il8n78du1++kRaT4U4etCKnDJiIicvOs2nmcUfNS2Hn0LACNqvoztntd6oX4mZxMRORyGol0QirYREREbq7cfDszVqfz3tIdnMu1YbFAn1uq8lyn2pTzdjc7noiIg0YiRUREpNRxd7XyeNsaJAyPoUfDYAwDvli7j/YTEvl87V5sGpMUkWJGHbYipA6biIhI0Vq7+wSj5qWQmnEGgHpV/BjbI5pGVcuZnExESjuNRDohFWwiIiJFL99m57Nf9vL2ku2cyckH4N6mITzfOZIKPh4mpxOR0kojkSIiIiKAq4uVR24NJ2F4DL0ahwDw9a8HaD8+kZmr95Bvs5ucUETk6tRhK0LqsImIiJhv/d6TjJybQsqhLADqVPbl1R7RNA0rb3IyESlNNBLphFSwiYiIOAeb3eCLtXt5a3EaWdkXxyTvalyFF7pEElDW0+R0IlIaaCRSRERE5CpcrBYebBnG8uEx9G4WisUC3284SMfxSUxbmU6exiRFxEmow1aE1GETERFxTpv2ZzJy7hZ+P3AagNqBZRndPZqWNSqYnExESiqNRDohFWwiIiLOy243mP3rft5clMqp83kA3NEgmJdur0OQn8YkRaRwaSRSRERE5DpYrRb63FKV5cNjeKBFVSwWmP/bITpOSOTDpF3k5mtMUkSKnjpsRUgdNhERkeJjy8HTjJy7hQ37MgGoUcmbMd3r0rpmRXODiUiJoJFIJ6SCTUREpHix2w2+23CANxalcvxsLgBd6gbxcrcoqvh7mZxORIozjUSKiIiI/E1Wq4V7moaybFgMD7cKw2qBn7Zk0HFCIpMSdpCTbzM7ooiUcOqwFSF12ERERIq3bYezGDU3hXV7TgIQVqEMo7pH0752gMnJRKS40UikE1LBJiIiUvwZhsHcTYf494/bOHYmB4DbogIZ2S2K0PJlTE4nIsWFRiJFREREbgKLxULPRlVIGNaOx9qE42q1EL/1CLFvJ/Hu0u1k52lMUkQKjzpsRUgdNhERkZJnx5EzjJqXwupdJwAILe/FyG7RxNYJwGKxmJxORJyVRiKdkAo2ERGRkskwDBZuPsy/FmwjIysbgJjalRh9RzRhFb1NTicizkgFmxNSwSYiIlKyncvJZ9LynXz8827ybAbuLlYeb1udp9rXoIy7q9nxRMSJqGBzQirYRERESoddx84yel4KP+84DkCwnyevdIuic90gjUmKCKCCzSmpYBMRESk9DMNgccoRXl2wlYOZFwBoU7Mio+6IJiLAx+R0ImI2FWxOSAWbiIhI6XMh18YHiTuZumI3ufl23Fws9G8dzqAONfHx0JikSGmlbf1FREREnICXuwvPdqpN/NC2dIgMIM9m8GHSbjpOSGTeb4fQ785F5M+ow1aE1GETERGRZduOMGb+VvadPA9Ai+rlGdO9LrWDypqcTESKkkYinZAKNhEREQHIzrPx0YrdTF6+k5x8Oy5WCw+3CuOZ2Jr4erqZHU9EioBGIkVERESclKebC4M71mTps+2Iiw7EZjeYtjKdDuOT+H7DAY1JioiDOmxFSB02ERERuZKk7ccYPS+F9OPnAGharRxje9QlKlj/vSBSUmkk0gmpYBMREZGrycm3MW1lOu8v28mFPBtWCzzYohrP3lYbvzIakxQpaYrFSGRYWBgWi+Wyx8CBAwGIiYm57Nw//vGPAq+xb98+unbtSpkyZQgICOC5554jPz+/wJrExEQaN26Mh4cHERERzJgx47IskydPJiwsDE9PT5o3b866desKnM/OzmbgwIFUqFABHx8fevXqxZEjRwr3AxEREZFSy8PVhadiIlg2rB1d61fGbsDMNXvpMCGRr5P3Y7frd+wipZGpBVtycjKHDx92POLj4wG45557HGsee+yxAmvefPNNxzmbzUbXrl3Jzc1l9erVzJw5kxkzZjBy5EjHmvT0dLp27Ur79u3ZtGkTQ4YMYcCAASxevNixZvbs2Tz77LOMGjWKDRs20KBBA+Li4jh69KhjzdChQ5k/fz7ffPMNSUlJHDp0iLvuuutmfjwiIiJSCgX7ezH5/sZ8PqA5EQE+nDiXyz+/+527PljN5gOnzY4nIkXMqUYihwwZwoIFC9ixYwcWi4WYmBgaNmzIu+++e8X1P/30E926dePQoUMEBgYCMHXqVJ5//nmOHTuGu7s7zz//PAsXLmTLli2O5/Xu3ZvMzEwWLVoEQPPmzWnWrBmTJk0CwG63ExoayqBBg3jhhRc4ffo0lSpV4osvvuDuu+8GIDU1lTp16rBmzRpatGhxTdenkUgRERG5Hrn5dmau3sO7S7dzLteGxQJ9bqnKc51qU87b3ex4IvI3FIuRyD/Kzc1l1qxZ9O/fH4vF4jj++eefU7FiRerWrcuIESM4f/6849yaNWuoV6+eo1gDiIuLIysri5SUFMea2NjYAu8VFxfHmjVrHO+7fv36AmusViuxsbGONevXrycvL6/AmsjISKpWrepYcyU5OTlkZWUVeIiIiIhcK3dXK4+1rU7C8Bh6NAzGMOCLtftoPyGRz9fuxaYxSZESz2kKtjlz5pCZmcnDDz/sOHb//fcza9Ysli9fzogRI/jss8944IEHHOczMjIKFGuA4+eMjIw/XZOVlcWFCxc4fvw4Npvtimv++Bru7u74+/tfdc2VjBs3Dj8/P8cjNDT02j4MERERkT8I9PXkvd6NmP14CyKDypJ5Po+XfthCz8mr2LDvlNnxROQmcjU7wCXTpk2jS5cuBAcHO449/vjjjv9dr149KleuTMeOHdm1axc1atQwI+Z1GTFiBM8++6zj56ysLBVtIiIicsOaV6/AgkGt+eyXvby9ZDubD57mrimrubdpCM93jqSCj4fZEUWkkDlFh23v3r0sXbqUAQMG/Om65s2bA7Bz504AgoKCLtup8dLPQUFBf7rG19cXLy8vKlasiIuLyxXX/PE1cnNzyczMvOqaK/Hw8MDX17fAQ0REROTvcHWx8sit4SQMj+HuJiEAfP3rAdqPT2Tm6j3k2+wmJxSRwuQUBdv06dMJCAiga9euf7pu06ZNAFSuXBmAli1bsnnz5gK7OcbHx+Pr60tUVJRjzbJlywq8Tnx8PC1btgTA3d2dJk2aFFhjt9tZtmyZY02TJk1wc3MrsCYtLY19+/Y51oiIiIgUpUplPRh/TwO+e7Il0cG+ZGXnM2peCndMWkXynpNmxxORQmL6LpF2u53w8HD69OnD66+/7ji+a9cuvvjiC26//XYqVKjA77//ztChQwkJCSEpKQm4uK1/w4YNCQ4O5s033yQjI4MHH3yQAQMG8NprrwEXt/WvW7cuAwcOpH///iQkJDB48GAWLlxIXFwccHFb/379+vHhhx9yyy238O677/L111+Tmprq+G7bk08+yY8//siMGTPw9fVl0KBBAKxevfqar1W7RIqIiMjNYLMbfLF2L28tTiMr++L9aO9qVIUXbo8koKynyelE5EqutTYwvWBbsmQJcXFxpKWlUatWLcfx/fv388ADD7BlyxbOnTtHaGgod955Jy+//HKBC9q7dy9PPvkkiYmJeHt7069fP15//XVcXf//63mJiYkMHTqUrVu3EhISwiuvvFJgcxOASZMm8dZbb5GRkUHDhg2ZOHGiYwQTLt44e9iwYXz55Zfk5OQQFxfHlClT/nQk8n+pYBMREZGb6cTZHMYvSeOr5P0YBvh4uDIktib9WoXh5uIUg1Ui8l/FpmArTVSwiYiISFHYtD+TUXO38Nt/b7RdK9CHMd3r0rJGBZOTicglKtickAo2ERERKSp2u8HXv+7njUWpnDqfB8AdDYJ56fY6BPlpTFLEbMXuxtkiIiIiUnisVgu9b6nK8uExPNCiKhYLzP/tEB0mJDI1aRe5+dpNUqQ4UIetCKnDJiIiImbZcvA0I+duYcO+TACqV/JmTPdo2tSsZG4wkVJKI5FOSAWbiIiImMluN/h+40Fe/2kbx8/mAtClbhAvd4uiir+XyelESheNRIqIiIhIAVarhbubhLBsWAyP3BqGi9XCT1sy6DghkUkJO8jJt5kdUUT+hzpsRUgdNhEREXEm2w5nMWpuCuv+e6PtsAplGHVHNO0jA0xOJlLyaSTSCalgExEREWdjGAZzNx3i3z9u49iZHABi6wQy6o4oQsuXMTmdSMmlkUgRERER+UsWi4WejaqQMKwdj7UJx9VqYem2I8S+ncQ78dvJztOYpIiZ1GErQuqwiYiIiLPbceQMo+alsHrXCQBCy3sxsls0sXUCsFgsJqcTKTk0EumEVLCJiIhIcWAYBj9uzuBfC7dy+HQ2ADG1KzHqjmjCK3qbnE6kZFDB5oRUsImIiEhxci4nn0nLd/Lxz7vJsxm4u1h5rG04A9tHUMbd1ex4IsWaCjYnpIJNREREiqPdx84yev5WVmw/BkCwnyevdIuic90gjUmK3CBtOiIiIiIihaJ6JR9mPtKMDx9sQhV/Lw6dzubJzzfw4LR17Dx61ux4IiWaOmxFSB02ERERKe4u5Nr4IHEnU1fsJjffjqvVwqOtwxnUsSY+HhqTFLlW6rCJiIiISKHzcnfh2U61iR/alo6RAeTbDT5csZuOExKZ99sh1AsQKVzqsBUhddhERESkpFm27Qhj5m9l38nzALSoXp4x3etSO6isyclEnJs2HXFCKthERESkJMrOs/HRit1MXr6TnHw7LlYLD7cK45nYmvh6upkdT8QpaSRSRERERIqEp5sLgzvWZOmz7YiLDsRmN5i2Mp0O45P4fsMBjUmK/A3qsBUhddhERESkNEjafozR81JIP34OgKbVyjGmRzTRwX4mJxNxHhqJdEIq2ERERKS0yMm3MW1lOu8v28mFPBtWCzzQohrDbquNXxmNSYpoJFJERERETOPh6sJTMREsG9aOrvUrYzfg0zV76TAhka+T92O3q2cgci3UYStC6rCJiIhIabVq53FGzUtx3Gi7Yag/Y3tEUz/E39xgIibRSKQTUsEmIiIipVmezc6MVXt4d+l2zuXasFigzy1Vea5Tbcp5u5sdT6RIaSRSRERERJyKm4uVx9pWJ2F4DD0bBmMY8MXafbSfkMjna/di05ikyGXUYStC6rCJiIiI/L+1u08wal4KqRlnAKhXxY8xPaJpXLWcyclEbj6NRDohFWwiIiIiBeXb7Hz2y17eXrKdMzn5ANzbNIR/do6koo+HyelEbh6NRIqIiIiI03N1sfLIreEkDI/h7iYhAHz96wE6jE9k5uo95NvsJicUMZc6bEVIHTYRERGRP7d+70lGzk0h5VAWAHUq+zK2RzTNwsqbnEykcGkk0gmpYBMRERH5aza7wRfr9jF+cRqnL+QBcGejKozoEkmAr6fJ6UQKh0YiRURERKRYcrFaeLBFNZYPj6HPLaFYLPDDxoN0mJDExz/vJk9jklKKqMNWhNRhExEREbl+m/ZnMmruFn47cBqAWoE+jOlel5Y1KpicTOTGaSTSCalgExEREbkxdrvB17/u541FqZw6f3FM8o4Gwbx0ex2C/DQmKcWPRiJFREREpMSwWi30vqUqy4fH8GCLalgtMP+3Q3SYkMjUpF3k5mtMUkomddiKkDpsIiIiIoVjy8HTjJy7hQ37MgGoXsmbMd2jaVOzkrnBRK6RRiKdkAo2ERERkcJjtxt8v/Egr/+0jeNncwHoUjeIl7tFUcXfy+R0In9OI5EiIiIiUqJZrRbubhLCsmExPHJrGC5WCz9tyaDjhEQmJewgJ99mdkSRv00dtiKkDpuIiIjIzbPtcBaj5qawbs9JAMIqlGHUHdG0jwwwOZnI5TQS6YRUsImIiIjcXIZhMO+3Q/x74TaOnskBILZOACO7RVO1QhmT04n8P41EioiIiEipY7FY6NGwCsuGteOxNuG4Wi0s3XaU2HeSeCd+O9l5GpOU4kUdtiKkDpuIiIhI0dpx5Ayj5qWwetcJAELKeTGyWxS3RQVisVhMTielmUYinZAKNhEREZGiZxgGP27O4F8Lt3L4dDYAMbUrMeqOaMIrepucTkorFWxOSAWbiIiIiHnO5eQzeflO/vPzbvJsBu4uVh5rG87A9hGUcXc1O56UMirYnJAKNhERERHz7T52ltHzt7Ji+zEAgv08eblbFF3qBmlMUoqMCjYnpIJNRERExDkYhsGSrUcYO38rBzMvANA6oiKju0cREVDW5HRSGqhgc0Iq2EREREScy4VcGx8k7WJq0i5y8+24Wi082jqcQR1r4uOhMUm5ebStv4iIiIjIX/Byd+HZ22oRP7QtHSMDyLcbfLhiNx0nJDJ300HU2xCzqcNWhNRhExEREXFuy7YdYcz8rew7eR6AFtXLM6Z7XWoHaUxSCpdGIp2QCjYRERER55edZ+OjFbuZvHwnOfl2XKwW+rUMY8htNfH1dDM7npQQGokUEREREbkBnm4uDO5Yk6XPtiMuOhCb3eCTVel0GJ/Ed+sPaExSipQ6bEVIHTYRERGR4idp+zHGzEth9/FzADStVo4xPaKJDvYzOZkUZxqJdEIq2ERERESKp5x8G5+s3MP7CTs4n2vDaoEHWlRj2G218SujMUm5fhqJFBEREREpJB6uLjwZU4Nlw9rRtX5l7AZ8umYv7SckMjt5H3a7eiByc6jDVoTUYRMREREpGVbtPM6oeSnsPHoWgAah/rzaI5r6If7mBpNiQyORTkgFm4iIiEjJkWezM2PVHt5dup1zuTYsFujdrCr/jKtNOW93s+OJk9NIpIiIiIjITeTmYuWxttVZPjyGng2DMQz4ct0+2k9IZNYve7FpTFIKgTpsRUgdNhEREZGSa+3uE4yal0JqxhkA6lXxY0yPaBpXLWdyMnFGGol0QirYREREREq2fJudz37Zy9tLtnMmJx+Ae5qE8HyXSCr6eJicTpyJRiJFRERERIqYq4uVR24NJ2F4DHc3CQHgm/UH6DA+kZmr95Bvs5ucUIobddiKkDpsIiIiIqXL+r2nGDl3CymHsgCIDCrLqz3r0iysvMnJxGwaiXRCKthERERESh+b3eCLdfsYvziN0xfyALizURVGdIkkwNfT5HRiFo1EioiIiIg4ARerhQdbVGP58Bj63BKKxQI/bDxIhwlJfPzzbvI0Jil/Qh22IqQOm4iIiIj8tj+TkXO38NuB0wDUCvRhdPdoWtWoaHIyKUoaiXRCKthEREREBMBuN/j61/28sSiVU+cvjkl2q1+Zl7rWobKfl8nppChoJFJERERExElZrRZ631KV5cNjeLBFNawWWPD7YTpOSGJq0i5y8zUmKRepw1aE1GETERERkSvZcvA0I+duYcO+TACqV/JmTPdo2tSsZG4wuWk0EumEVLCJiIiIyNXY7QbfbzzI6z9t4/jZXAA6Rwfxyh1RVPHXmGRJo5FIEREREZFixGq1cHeTEBKGx/DIrWG4WC0sSsmg44REJiXsIDvPZnZEMYGpBVtYWBgWi+Wyx8CBAwusMwyDLl26YLFYmDNnToFz+/bto2vXrpQpU4aAgACee+458vPzC6xJTEykcePGeHh4EBERwYwZMy7LMnnyZMLCwvD09KR58+asW7euwPns7GwGDhxIhQoV8PHxoVevXhw5cqRQPgcRERERkUt8Pd0YdUc0Cwe35pbw8mTn2Rm/ZDtx765geepRs+NJETO1YEtOTubw4cOOR3x8PAD33HNPgXXvvvsuFovlsufbbDa6du1Kbm4uq1evZubMmcyYMYORI0c61qSnp9O1a1fat2/Ppk2bGDJkCAMGDGDx4sWONbNnz+bZZ59l1KhRbNiwgQYNGhAXF8fRo///f4ihQ4cyf/58vvnmG5KSkjh06BB33XVXYX8kIiIiIiIARAb5MvvxFrzXuyEBZT3Ye+I8j8xIZsDMZPadOG92PCkiTvUdtiFDhrBgwQJ27NjhKNA2bdpEt27d+PXXX6lcuTI//PADPXv2BOCnn36iW7duHDp0iMDAQACmTp3K888/z7Fjx3B3d+f5559n4cKFbNmyxfE+vXv3JjMzk0WLFgHQvHlzmjVrxqRJkwCw2+2EhoYyaNAgXnjhBU6fPk2lSpX44osvuPvuuwFITU2lTp06rFmzhhYtWlzT9ek7bCIiIiJyI85k5/F+wk4+WZlOvt3A3dXKP9rV4KmYGni6uZgdT25AsfsOW25uLrNmzaJ///6OYu38+fPcf//9TJ48maCgoMues2bNGurVq+co1gDi4uLIysoiJSXFsSY2NrbA8+Li4lizZo3jfdevX19gjdVqJTY21rFm/fr15OXlFVgTGRlJ1apVHWuuJCcnh6ysrAIPEREREZHrVdbTjRdvr8NPz7ShVY0K5ObbmbhsB7FvJ7EkJQMn6sFIIXOagm3OnDlkZmby8MMPO44NHTqUVq1a0aNHjys+JyMjo0CxBjh+zsjI+NM1WVlZXLhwgePHj2Oz2a645o+v4e7ujr+//1XXXMm4cePw8/NzPEJDQ6/+AYiIiIiI/IWagWX5fEBzJt/fmMp+nhw4dYHHP1vPIzOSST9+zux4chM4TcE2bdo0unTpQnBwMADz5s0jISGBd99919xgf8OIESM4ffq047F//36zI4mIiIhIMWexWOhavzLLhrXjqZgauLlYSEw7Rtw7K3hrcSrnc/P/+kWk2HCKgm3v3r0sXbqUAQMGOI4lJCSwa9cu/P39cXV1xdXVFYBevXoRExMDQFBQ0GU7NV76+dII5dXW+Pr64uXlRcWKFXFxcbnimj++Rm5uLpmZmVddcyUeHh74+voWeIiIiIiIFIYy7q78s3Mki4e0pW2tSuTa7ExevovYCUn8uPmwxiRLCKco2KZPn05AQABdu3Z1HHvhhRf4/fff2bRpk+MB8M477zB9+nQAWrZsyebNmwvs5hgfH4+vry9RUVGONcuWLSvwfvHx8bRs2RIAd3d3mjRpUmCN3W5n2bJljjVNmjTBzc2twJq0tDT27dvnWCMiIiIiYobqlXyY+UgzPnywCVX8vTh0OpunPt/Ag9PWsfPoGbPjyd9k+i6Rdrud8PBw+vTpw+uvv/6nay0WS4FdIm02Gw0bNiQ4OJg333yTjIwMHnzwQQYMGMBrr70GXNzWv27dugwcOJD+/fuTkJDA4MGDWbhwIXFxccDFbf379evHhx9+yC233MK7777L119/TWpqquO7bU8++SQ//vgjM2bMwNfXl0GDBgGwevXqa75W7RIpIiIiIjfThVwbHyTtYmrSLnLz7bhaLTzaOpxBHWvi4+Fqdjz5g2utDUz/U1u6dCn79u2jf//+1/1cFxcXFixYwJNPPknLli3x9vamX79+jB071rEmPDychQsXMnToUN577z1CQkL4+OOPHcUawH333cexY8cYOXIkGRkZNGzYkEWLFhXYiOSdd97BarXSq1cvcnJyiIuLY8qUKX/v4kVERERECpGXuwvP3laLXo2r8OqCrSzddpQPV+xmzqaDvHh7Hbo3CL7i/Y3FeZneYStN1GETERERkaKUkHqE0fO2su/kxRttNw8vz9gedakdVNbkZHKttYEKtiKkgk1EREREilp2no3/rNjN5MSdZOfZcbFaeKhlNYbeVgtfTzez45Vaxe7G2SIiIiIiUvg83VwY1LEmS59tR1x0IDa7wfRVe+gwPonv1h/QbpJOTh22IqQOm4iIiIiYLWn7McbMS2H3f2+03bRaOcb0iCY62M/kZKWLRiKdkAo2EREREXEGufl2pq1M5/2EHZzPtWG1wAMtqjHsttr4ldGYZFHQSKSIiIiIiFyRu6uVJ2NqsGxYO7rVr4zdgE/X7KX9hERmJ+/DbldPx1mow1aE1GETEREREWe0eudxRs1LYcfRswA0CPXn1R7R1A/xNzdYCaaRSCekgk1EREREnFWezc7M1Xt4d+kOzubkY7FA72ZVeS6uNuW93c2OV+JoJFJERERERK6Zm4uVAW2qkzCsHXc2qoJhwJfr9tFhQiKzftmLTWOSplCHrQipwyYiIiIixcW69JOMnLuF1IwzANSt4svYHnVpXLWcyclKBo1EOiEVbCIiIiJSnOTb7Mz6ZS8T4rdzJjsfgHuahPB8l0gq+niYnK5400ikiIiIiIj8La4uVh6+NZyEYTHc3SQEgG/WH6D9+ERmrEon32Y3OWHJpw5bEVKHTURERESKs/V7TzFq3ha2HMwCIDKoLGN71OWW8PImJyt+NBLphFSwiYiIiEhxZ7MbfLluH28tTuP0hTwA7mxUhRFdIgnw9TQ5XfGhkUgRERERESl0LlYLD7SoxvLhMfS5JRSLBX7YeJAOE5L4+Ofd5GlMslCpw1aE1GETERERkZLmt/2ZjJyXwm/7MwGoGeDDmB7RtKpR0dxgTk4jkU5IBZuIiIiIlER2u8HXv+7njUWpnDp/cUyyW/3KvNS1DpX9vExO55w0EikiIiIiIkXCarXQ+5aqLB8ew4MtqmG1wILfD9NxQhIfJO4iN19jkjdKHbYipA6biIiIiJQGWw6eZtS8FNbvPQVA9YrejO4eTdtalUxO5jw0EumEVLCJiIiISGlhtxv8sPEg435K5fjZHAA6Rwfxcrc6hJQrY3I682kkUkRERERETGO1WujVJISE4e145NYwXKwWFqVkEPt2Eu8v20F2ns3siMWCOmxFSB02ERERESmtUjOyGDk3hXXpJwGoVqEMo+6IokNkoMnJzKGRSCekgk1ERERESjPDMJj32yH+vXAbR89cHJOMrRPAyG7RVK1QusYkNRIpIiIiIiJOxWKx0KNhFRKGx/B42+q4Wi0s3XaU2HeSeDt+u8Ykr0AdtiKkDpuIiIiIyP/befQMo+alsGrnCQBCynnxSrcoOkUFYrFYTE53c2kk0gmpYBMRERERKcgwDH7cnMG/Fm7l8OlsANrVqsTo7tGEV/Q2Od3No4LNCalgExERERG5svO5+UxK2Ml/ft5Nns3A3cXKY23DGdg+gjLurmbHK3Qq2JyQCjYRERERkT+3+9hZxszfStL2YwAE+3nycrcoutQNKlFjkirYnJAKNhERERGRv2YYBvFbjzB2wVYOnLoAQOuIiozuHkVEQFmT0xUOFWxOSAWbiIiIiMi1y86zMSVxF1OTdpGbb8fVaqF/63AGd6yJj0fxHpPUtv4iIiIiIlKsebq58OxttYgf2pbYOgHk2w0+WrGbjhMSmbvpIKWh96QOWxFSh01ERERE5MYlpB5hzPyt7D1xHoDm4eUZ26MutYOK35ikRiKdkAo2EREREZG/JzvPxn9W7GZy4k6y8+y4WC081LIaQ2+rha+nm9nxrplGIkVEREREpMTxdHNhUMeaLH22HZ2jg7DZDaav2kOH8Yl8u/4AdnvJ6kepw1aE1GETERERESlcK7YfY/S8FHYfPwdAk2rlGNsjmuj/a+fuY6qu/z6Ovw4gB3SgKMqNnUq8vwsT0/BmXpqK5qXR3DQjhktnJjbD+3R2LPsFa+bl1hQneVMzxXThmpKmpjXvsik4S6SMUJdgubwhKBHO5/rLc4VidbjknC/wfGxn63zP53vO67D3jufV93u+0S19nOzvcUqkBVHYAAAAgAevssql9Yd/0ntf/KCKymr52aQXnnxEc0d2Vcvm1jxNklMiAQAAADQJgQF+evm/OurA3KH678ei5DLSh8cuaNi7h7Ttm4sN+jRJjrB5EUfYAAAAgPp39PxVOT/9Tj/88rskKdbRSsuf6anHHmrl22B/wSmRFkRhAwAAALzjdrVLHxwt1qr9P+j3W1Wy2aTnnnBofkI3tW4R6Ot4nBIJAAAAoOlq5u+naUNi9MXcoXr28fYyRtp64pISVx9RVbXL1/H+NQobAAAAgEarXWiQ/mdSH338Ury6RYZo6uAOCvBvODUowNcBAAAAAKC+9e/QWrteGSybzebrKB6hsAEAAABoEhrSkbU7Gl5iAAAAAGgiKGwAAAAAYFEUNgAAAACwKAobAAAAAFgUhQ0AAAAALIrCBgAAAAAWRWEDAAAAAIuisAEAAACARVHYAAAAAMCiKGwAAAAAYFEUNgAAAACwKAobAAAAAFgUhQ0AAAAALIrCBgAAAAAWRWEDAAAAAIuisAEAAACARVHYAAAAAMCiAnwdoCkxxkiSbt686eMkAAAAAHzpTie40xHuh8LmRWVlZZIkh8Ph4yQAAAAArKCsrEwtW7a87+M280+VDg+My+XS5cuXFRISIpvN5tMsN2/elMPh0KVLlxQaGurTLGgYmBl4ipmBp5gZeIqZgaesNDPGGJWVlSk6Olp+fvf/pRpH2LzIz89PDz30kK9j1BAaGurzYUXDwszAU8wMPMXMwFPMDDxllZn5uyNrd3DREQAAAACwKAobAAAAAFgUha2Jstvtcjqdstvtvo6CBoKZgaeYGXiKmYGnmBl4qiHODBcdAQAAAACL4ggbAAAAAFgUhQ0AAAAALIrCBgAAAAAWRWEDAAAAAIuisDViq1ev1qOPPqqgoCANGDBAJ06c+Nv127dvV7du3RQUFKTevXsrNzfXS0lhFZ7MTFZWloYMGaKwsDCFhYVpxIgR/zhjaHw8/Zy5Izs7WzabTYmJifUbEJbj6cxcv35dqampioqKkt1uV5cuXfj3qYnxdGZWrVqlrl27Kjg4WA6HQ2lpafrzzz+9lBa+9NVXX2ncuHGKjo6WzWbTzp07/3GfQ4cOqW/fvrLb7erUqZM2bdpU7zk9RWFrpLZt26Y5c+bI6XTq1KlTio2NVUJCgn755Zda1x89elSTJ0/W1KlTlZeXp8TERCUmJurbb7/1cnL4iqczc+jQIU2ePFkHDx7UsWPH5HA4NGrUKP38889eTg5f8XRm7iguLta8efM0ZMgQLyWFVXg6M5WVlRo5cqSKi4u1Y8cOFRYWKisrS+3bt/dycviKpzOzZcsWLVq0SE6nUwUFBVq/fr22bdumxYsXezk5fKG8vFyxsbFavXr1v1r/008/aezYsRo2bJjy8/P16quvatq0adq7d289J/WQQaPUv39/k5qa6r5fXV1toqOjTXp6eq3rJ06caMaOHVtj24ABA8xLL71UrzlhHZ7OzN2qqqpMSEiI+eCDD+orIiymLjNTVVVlBg4caN5//32TkpJinnnmGS8khVV4OjOZmZkmJibGVFZWeisiLMbTmUlNTTXDhw+vsW3OnDlm0KBB9ZoT1iPJ5OTk/O2aBQsWmJ49e9bYNmnSJJOQkFCPyTzHEbZGqLKyUidPntSIESPc2/z8/DRixAgdO3as1n2OHTtWY70kJSQk3Hc9Gpe6zMzdKioqdPv2bbVu3bq+YsJC6jozb775ptq1a6epU6d6IyYspC4z8+mnnyo+Pl6pqamKiIhQr1699Pbbb6u6utpbseFDdZmZgQMH6uTJk+7TJouKipSbm6unn37aK5nRsDSU778Bvg6AB+/q1auqrq5WREREje0RERE6d+5crfuUlpbWur60tLTecsI66jIzd1u4cKGio6Pv+eBD41SXmTl8+LDWr1+v/Px8LySE1dRlZoqKivTFF18oKSlJubm5On/+vGbOnKnbt2/L6XR6IzZ8qC4z8/zzz+vq1asaPHiwjDGqqqrSjBkzOCUStbrf99+bN2/qjz/+UHBwsI+S1cQRNgD/bxkZGcrOzlZOTo6CgoJ8HQcWVFZWpuTkZGVlZSk8PNzXcdBAuFwutWvXTuvWrVNcXJwmTZqkJUuWaO3atb6OBos6dOiQ3n77ba1Zs0anTp3SJ598ot27d2v58uW+jgbUGUfYGqHw8HD5+/vrypUrNbZfuXJFkZGRte4TGRnp0Xo0LnWZmTtWrFihjIwM7d+/X4899lh9xoSFeDozP/74o4qLizVu3Dj3NpfLJUkKCAhQYWGhOnbsWL+h4VN1+ZyJiopSs2bN5O/v797WvXt3lZaWqrKyUoGBgfWaGb5Vl5lZunSpkpOTNW3aNElS7969VV5erunTp2vJkiXy8+NYBf7P/b7/hoaGWubomsQRtkYpMDBQcXFxOnDggHuby+XSgQMHFB8fX+s+8fHxNdZL0r59++67Ho1LXWZGkt555x0tX75ce/bsUb9+/bwRFRbh6cx069ZNZ86cUX5+vvs2fvx495W5HA6HN+PDB+ryOTNo0CCdP3/eXe4l6fvvv1dUVBRlrQmoy8xUVFTcU8ruFH5jTP2FRYPUYL7/+vqqJ6gf2dnZxm63m02bNpmzZ8+a6dOnm1atWpnS0lJjjDHJyclm0aJF7vVHjhwxAQEBZsWKFaagoMA4nU7TrFkzc+bMGV+9BXiZpzOTkZFhAgMDzY4dO0xJSYn7VlZW5qu3AC/zdGbuxlUimx5PZ+bixYsmJCTEzJo1yxQWFppdu3aZdu3ambfeestXbwFe5unMOJ1OExISYrZu3WqKiorM559/bjp27GgmTpzoq7cALyorKzN5eXkmLy/PSDIrV640eXl55sKFC8YYYxYtWmSSk5Pd64uKikzz5s3N/PnzTUFBgVm9erXx9/c3e/bs8dVbqBWFrRF77733zMMPP2wCAwNN//79zfHjx92PDR061KSkpNRY//HHH5suXbqYwMBA07NnT7N7924vJ4aveTIzjzzyiJF0z83pdHo/OHzG08+Zv6KwNU2ezszRo0fNgAEDjN1uNzExMeY///mPqaqq8nJq+JInM3P79m2zbNky07FjRxMUFGQcDoeZOXOmuXbtmveDw+sOHjxY63eTOzOSkpJihg4des8+ffr0MYGBgSYmJsZs3LjR67n/ic0Yjg8DAAAAgBXxGzYAAAAAsCgKGwAAAABYFIUNAAAAACyKwgYAAAAAFkVhAwAAAACLorABAAAAgEVR2AAAAADAoihsAAAAAGBRFDYAAB6g4uJi2Ww25efn19trTJkyRYmJifX2/AAA66CwAQDwF1OmTJHNZrvnNnr06H+1v8PhUElJiXr16lXPSQEATUGArwMAAGA1o0eP1saNG2tss9vt/2pff39/RUZG1kcsAEATxBE2AADuYrfbFRkZWeMWFhYmSbLZbMrMzNSYMWMUHBysmJgY7dixw73v3adEXrt2TUlJSWrbtq2Cg4PVuXPnGmXwzJkzGj58uIKDg9WmTRtNnz5dv//+u/vx6upqzZkzR61atVKbNm20YMECGWNq5HW5XEpPT1eHDh0UHBys2NjYGpkAAA0XhQ0AAA8tXbpUEyZM0OnTp5WUlKTnnntOBQUF91179uxZffbZZyooKFBmZqbCw8MlSeXl5UpISFBYWJi++eYbbd++Xfv379esWbPc+7/77rvatGmTNmzYoMOHD+u3335TTk5OjddIT0/Xhx9+qLVr1+q7775TWlqaXnjhBX355Zf190cAAHiFzdz9v+kAAGjCpkyZos2bNysoKKjG9sWLF2vx4sWy2WyaMWOGMjMz3Y89+eST6tu3r9asWaPi4mJ16NBBeXl56tOnj8aPH6/w8HBt2LDhntfKysrSwoULdenSJbVo0UKSlJubq3Hjxuny5cuKiIhQdHS00tLSNH/+fElSVVWVOnTooLi4OO3cuVO3bt1S69attX//fsXHx7ufe9q0aaqoqNCWLVvq488EAPASfsMGAMBdhg0bVqOQSVLr1q3d//3XYnTn/v2uCvnyyy9rwoQJOnXqlEaNGqXExEQNHDhQklRQUKDY2Fh3WZOkQYMGyeVyqbCwUEFBQSopKdGAAQPcjwcEBKhfv37u0yLPnz+viooKjRw5ssbrVlZW6vHHH/f8zQMALIXCBgDAXVq0aKFOnTo9kOcaM2aMLly4oNzcXO3bt09PPfWUUlNTtWLFigfy/Hd+77Z79261b9++xmP/9kIpAADr4jdsAAB46Pjx4/fc7969+33Xt23bVikpKdq8ebNWrVqldevWSZK6d++u06dPq7y83L32yJEj8vPzU9euXdWyZUtFRUXp66+/dj9eVVWlkydPuu/36NFDdrtdFy9eVKdOnWrcHA7Hg3rLAAAf4QgbAAB3uXXrlkpLS2tsCwgIcF8sZPv27erXr58GDx6sjz76SCdOnND69etrfa7XX39dcXFx6tmzp27duqVdu3a5y11SUpKcTqdSUlK0bNky/frrr3rllVeUnJysiIgISdLs2bOVkZGhzp07q1u3blq5cqWuX7/ufv6QkBDNmzdPaWlpcrlcGjx4sG7cuKEjR44oNDRUKSkp9fAXAgB4C4UNAIC77NmzR1FRUTW2de3aVefOnZMkvfHGG8rOztbMmTMVFRWlrVu3qkePHrU+V2BgoF577TUVFxcrODhYQ4YMUXZ2tiSpefPm2rt3r2bPnq0nnnhCzZs314QJE7Ry5Ur3/nPnzlVJSYlSUlLk5+enF198Uc8++6xu3LjhXrN8+XK1bdtW6enpKioqUqtWrdS3b18tXrz4Qf9pAABexlUiAQDwgM1mU05OjhITE30dBQDQBPAbNgAAAACwKAobAAAAAFgUv2EDAMAD/JIAAOBNHGEDAAAAAIuisAEAAACARVHYAAAAAMCiKGwAAAAAYFEUNgAAAACwKAobAAAAAFgUhQ0AAAAALIrCBgAAAAAW9b+poy03i8DncQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def plot_learning_curve(rewards, title=\"Learning Curve\", label=\"Total reward\"):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(rewards, label='Episode Reward')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel(label)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# エージェントの学習\n",
        "# (agent.train()の呼び出しなど)\n",
        "\n",
        "# 学習後のエージェントの評価\n",
        "#evaluate_agent(agent, env, num_episodes=10)\n",
        "\n",
        "# 学習曲線のプロット\n",
        "plot_learning_curve(episode_reward_history, title=\"PPO Learning Curve\", label=\"Total reward\")\n",
        "plot_learning_curve(agent.loss_history_detail, title=\"loss curve\", label=\"Total loss (actor loss +  critic loss) \")\n",
        "plot_learning_curve(agent.actor_loss_history, title=\"actor loss curve\", label=\"actor loss\")\n",
        "plot_learning_curve(agent.critic_loss_history, title=\"critic loss curve\", label=\"critic loss\")\n",
        "plot_learning_curve(agent.entropy_history, title=\"entropy curve\", label=\"entropy\")\n",
        "plot_learning_curve(agent.kl_divergence_history, title=\"kl divergence curve\", label=\"kl divergence\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "U3bLWs2RTYPe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0bf8212b-1d50-4293-8dae-55861547c95f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.4063, 0.5937]], grad_fn=<DivBackward0>) cnt: tensor([[0.4156]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4156]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.4155535 <class 'numpy.ndarray'>\n",
            "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.1821, 0.8179]], grad_fn=<DivBackward0>) cnt: tensor([[0.4473]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4473]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.44728732 <class 'numpy.ndarray'>\n",
            "[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.2174, 0.7826]], grad_fn=<DivBackward0>) cnt: tensor([[0.4322]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4322]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.43219405 <class 'numpy.ndarray'>\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.2398, 0.7602]], grad_fn=<DivBackward0>) cnt: tensor([[0.4345]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4345]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.43450162 <class 'numpy.ndarray'>\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.1545, 0.8455]], grad_fn=<DivBackward0>) cnt: tensor([[0.4393]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4393]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.4392995 <class 'numpy.ndarray'>\n",
            "[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.3778, 0.6222]], grad_fn=<DivBackward0>) cnt: tensor([[0.4185]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4185]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.4185486 <class 'numpy.ndarray'>\n",
            "[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.1322, 0.8678]], grad_fn=<DivBackward0>) cnt: tensor([[0.4457]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4457]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.44570565 <class 'numpy.ndarray'>\n",
            "[0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.1696, 0.8304]], grad_fn=<DivBackward0>) cnt: tensor([[0.4330]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4330]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.43304402 <class 'numpy.ndarray'>\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.1976, 0.8024]], grad_fn=<DivBackward0>) cnt: tensor([[0.4350]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4350]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.43499723 <class 'numpy.ndarray'>\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.0901, 0.9099]], grad_fn=<DivBackward0>) cnt: tensor([[0.4356]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4356]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.4355554 <class 'numpy.ndarray'>\n",
            "[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.6303, 0.3697]], grad_fn=<DivBackward0>) cnt: tensor([[0.4083]], grad_fn=<DivBackward0>)\n",
            "tensor(2) act_dsc\n",
            "tensor([[0.4083]], grad_fn=<DivBackward0>) act_cnt\n",
            "[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.2672, 0.7328]], grad_fn=<DivBackward0>) cnt: tensor([[0.4390]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4390]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.4390499 <class 'numpy.ndarray'>\n",
            "[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.3480, 0.6520]], grad_fn=<DivBackward0>) cnt: tensor([[0.4242]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4242]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.42421204 <class 'numpy.ndarray'>\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.3526, 0.6474]], grad_fn=<DivBackward0>) cnt: tensor([[0.4180]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4180]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.41799298 <class 'numpy.ndarray'>\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.2366, 0.7634]], grad_fn=<DivBackward0>) cnt: tensor([[0.4220]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4220]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.42204154 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1]\n",
            "tensor([[0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.5949, 0.4051]], grad_fn=<DivBackward0>) cnt: tensor([[0.4325]], grad_fn=<DivBackward0>)\n",
            "tensor(2) act_dsc\n",
            "tensor([[0.4325]], grad_fn=<DivBackward0>) act_cnt\n",
            "[0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1]\n",
            "tensor([[0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.3003, 0.6997]], grad_fn=<DivBackward0>) cnt: tensor([[0.4480]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4480]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.44796583 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "tensor([[0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.3513, 0.6487]], grad_fn=<DivBackward0>) cnt: tensor([[0.4408]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4408]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.44082224 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n",
            "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.2966, 0.7034]], grad_fn=<DivBackward0>) cnt: tensor([[0.4453]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4453]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.44529712 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
            "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.2181, 0.7819]], grad_fn=<DivBackward0>) cnt: tensor([[0.4457]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4457]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.44571477 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1]\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.3329, 0.6671]], grad_fn=<DivBackward0>) cnt: tensor([[0.4055]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4055]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.40550673 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1]\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.1064, 0.8936]], grad_fn=<DivBackward0>) cnt: tensor([[0.4305]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4305]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.43053037 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.1817, 0.8183]], grad_fn=<DivBackward0>) cnt: tensor([[0.4235]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4235]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.42350936 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.1885, 0.8115]], grad_fn=<DivBackward0>) cnt: tensor([[0.4204]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4204]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.42039952 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1]\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.]]) dsc tensor([[0.0000, 0.0000, 0.0963, 0.9037]], grad_fn=<DivBackward0>) cnt: tensor([[0.4281]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4281]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.42813778 <class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def one_hot_encoding(levels, n_units=2,n_states=5, MAX_maintenance_time=0):\n",
        "    level_ohe = []\n",
        "    #mstatus_ohe = []\n",
        "    for unit_idx in range(n_units):\n",
        "        l = [0] * n_states\n",
        "        #m = [0] * (MAX_maintenance_time + 1)\n",
        "        l[levels[unit_idx]] = 1\n",
        "        #m[maintenance_status[unit_idx]] = 1\n",
        "        level_ohe = level_ohe + l\n",
        "        #mstatus_ohe = mstatus_ohe + m\n",
        "    return level_ohe #, mstatus_ohe\n",
        "\n",
        "\n",
        "def get_color(action):\n",
        "    if action < 0:\n",
        "        print(action)\n",
        "        return \"white\"\n",
        "    #cmap = [\"red\",\"sandybrown\",\"orange\",\"lawngreen\",\"darkorange\",\"lightgreen\",\"green\",\"lightblue\"]\n",
        "    cmap = [\"red\",\"orange\",\"orange\",\"lightgreen\",\"orange\",\"lightgreen\",\"lightgreen\",\"lightblue\"]\n",
        "    return cmap[action]\n",
        "\n",
        "def plot_action(ax, center_x, center_y, act_dsc, act_cnt):\n",
        "    size = 1\n",
        "    opt_action = patches.Rectangle(\n",
        "        (center_x-size/2, center_y-size/2),\n",
        "        1,\n",
        "        1,\n",
        "        linewidth = 0,\n",
        "        facecolor = get_color(act_dsc)\n",
        "    )\n",
        "    ax.add_patch(opt_action)\n",
        "    #print(act_dsc)\n",
        "    if act_dsc==0:\n",
        "        ax.text(center_x,center_y,f'M12',ha='center', va='center')\n",
        "    elif act_dsc==1:\n",
        "        ax.text(center_x,center_y,f'M1',ha='center', va='center')\n",
        "    elif act_dsc==2:\n",
        "        ax.text(center_x,center_y,f'M2',ha='center', va='center')\n",
        "    else: #稼働継続\n",
        "        print(act_cnt, type(act_cnt))\n",
        "        #ax.text(center_x, center_y,f'{(round(act_cnt[0],2),round(1-act_cnt[0],2))}',ha='center', va='center',fontsize=5)\n",
        "        ax.text(center_x, center_y, f'{(round(float(act_cnt), 2), round(1 - float(act_cnt), 2))}', ha='center', va='center', fontsize=5)\n",
        "\n",
        "\n",
        "\n",
        "def optimal_policy(s1,b,d,t):\n",
        "    fig, ax = plt.subplots()\n",
        "    x = 5\n",
        "    for s2 in range(x):\n",
        "        for s3 in range(x):\n",
        "            level_ohe = one_hot_encoding(levels=[s2,s3])\n",
        "            state = level_ohe + list([b,d])\n",
        "            print(state)\n",
        "            act_dsc, act_cnt, log_prob, val = agent.choose_action_max_prob(state)\n",
        "            act_dsc = act_dsc.item()\n",
        "            act_cnt = act_cnt.squeeze().cpu().detach().numpy().copy()\n",
        "            #print(act_dsc,act_cnt)\n",
        "            plot_action(ax, s2, s3, act_dsc, act_cnt)\n",
        "    ax.set_xlim(-0.5,x+0.5)\n",
        "    ax.set_ylim(-0.5,x+0.5)\n",
        "    #cbar = plt.colorbar(scatter, cax=cax, ticks=np.arange(0.5, 8.5, 1))\n",
        "    #cbar.ax.set_yticklabels([f'{i:b}' for i in range(8)])\n",
        "    ax.set_aspect('equal', adjustable='box')  # アスペクト比を保持\n",
        "    ax.set_xlabel(\"s1\") #変更\n",
        "    ax.set_ylabel(\"s2\") #変更\n",
        "    # グラフを表示\n",
        "    ax.set_title(\"(s1=\"+str(s1)+\", s2, s3, b=\"+str(b)+\", d=\"+str(d)+\", t=\"+str(t)+\")\")\n",
        "    plt.show()\n",
        "optimal_policy(s1=0,b=0,d=1,t=1)\n",
        "#optimal_policy(s1=0,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=1,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=2,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=3,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=4,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=4,m1=0,m2=0,m3=0,b=0,d=0,t=1)\n",
        "#optimal_policy(s1=0,m1=1,m2=1,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=0,m1=0,m2=0,m3=0,b=1,d=0,t=0.5)\n",
        "#optimal_policy(s1=0,m1=0,m2=0,m3=0,b=-1,d=0,t=1)\n",
        "#optimal_policy(s1=1,m1=0,m2=0,m3=0,b=-1,d=0,t=1)\n",
        "#optimal_policy(s1=2,m1=0,m2=0,m3=0,b=-1,d=0,t=1)\n",
        "#optimal_policy(s1=3,m1=0,m2=0,m3=0,b=-1,d=0,t=1)\n",
        "#optimal_policy(s1=4,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=0,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=1,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=2,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=3,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=4,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "s1 = 4\n",
        "s2 = 4\n",
        "s3 = 4\n",
        "m1 = 0\n",
        "m2 = 0\n",
        "m3 = 0\n",
        "inventory = 0\n",
        "#demand = 0\n",
        "remain_interval = 1\n",
        "#level_ohe, mstatus_ohe = one_hot_encoding(levels=[s1,s2,s3],maintenance_status=[m1,m2,m3])\n",
        "#state = level_ohe + mstatus_ohe + list([inventory,demand,remain_interval])\n",
        "#act_dsc, act_cnt, log_prob, val = agent.choose_action_max_prob(state)\n",
        "#act_dsc = act_dsc.item()\n",
        "#act_dsc"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DRL",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.1.undefined"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}