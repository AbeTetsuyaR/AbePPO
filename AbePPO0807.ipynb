{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbeTetsuyaR/AbePPO/blob/main/AbePPO0807.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qCrwylLHTYPW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import cProfile\n",
        "import sys\n",
        "import copy\n",
        "from torch.distributions.categorical import Categorical\n",
        "import math\n",
        "import os\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.colors as mcolors\n",
        "from tqdm import tqdm  # tqdmをインポート\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats import gamma, uniform\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L6hr_FE6TYPY"
      },
      "outputs": [],
      "source": [
        "class Environment:\n",
        "    def __init__(self, n_units=2):\n",
        "        self.n_units = n_units #number of unit\n",
        "        self.n_states = 5 #number of state\n",
        "        self.inventory = 0\n",
        "        self.demand = 0\n",
        "        self.maintenance_status = [0] * self.n_units\n",
        "        self.interval = 24\n",
        "        self.remain_interval = 24\n",
        "        self.MAX_speed = 10/self.interval\n",
        "        self.MAX_inventory = 0\n",
        "        self.MAX_demand = 15\n",
        "        self.MAX_maintenance_time = 0\n",
        "\n",
        "        self.load_total=1\n",
        "\n",
        "        self.cp = 500#\n",
        "        self.cc = 1800#\n",
        "\n",
        "        self.cps = 0\n",
        "        self.co = 5\n",
        "        self.cs = 500#\n",
        "\n",
        "        self.levels = [0] * self.n_units\n",
        "        self.shape = 3\n",
        "        self.penalty = 1\n",
        "        self.L = 100#\n",
        "        self.P_Cost =[[100,120,140,160,2500],\n",
        "                      [120,140,160,180,2520],\n",
        "                      [140,160,180,200,2540],\n",
        "                      [160,180,200,220,2560],\n",
        "                      [2500,2520,2540,2560,2580]]#一旦\n",
        "\n",
        "        self.failure_keep1 = 0 #1つ故障しているのに保全を選択しなかった回数\n",
        "        self.failure_keep2 = 0 #2つ故障しているのに保全を選択しなかった回数\n",
        "        self.failure_keep3 = 0 #3つ故障しているのに保全を選択しなかった回数\n",
        "        self.replace_chance = 0 #保全を選択できた回数\n",
        "\n",
        "    def init_random(self):\n",
        "        l = range(self.n_states)\n",
        "        m = range(self.MAX_maintenance_time)\n",
        "        flag = True\n",
        "        while flag:\n",
        "            for unit_idx in range(self.n_units):\n",
        "                self.levels[unit_idx] = random.choice(l)\n",
        "                if self.levels[unit_idx] == self.n_states-1:\n",
        "                        flag = False\n",
        "                #if self.levels[unit_idx] == 0:\n",
        "                    #self.maintenance_status[unit_idx] = random.choice(m)\n",
        "\n",
        "        #需要\n",
        "        mean = 10\n",
        "        variance = 2  # 標準偏差\n",
        "        mu = np.log(mean**2 / np.sqrt(variance**2 + mean**2))\n",
        "        sigma = np.sqrt(np.log(1 + (variance**2 / mean**2)))\n",
        "        self.demand = np.random.lognormal(mu, sigma)\n",
        "        if self.demand > 15:\n",
        "            self.demand = 15\n",
        "        self.demand = random.uniform(0,15)\n",
        "        #意思決定時\n",
        "        #self.remain_interval = random.uniform(0, self.interval)\n",
        "        #在庫\n",
        "        self.inventory = random.uniform(0,self.MAX_inventory)\n",
        "\n",
        "        level_ohe, mstatus_ohe = self.one_hot_encode()\n",
        "\n",
        "        return level_ohe, mstatus_ohe, \\\n",
        "               0, self.load_total, 0\n",
        "\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.levels = np.zeros(self.n_units)\n",
        "\n",
        "    def complete_maintenance(self, unit_idx):\n",
        "        self.levels[unit_idx] = 0\n",
        "\n",
        "    def get_ability(self, level): #良品率\n",
        "        if level == 0:\n",
        "            return 1\n",
        "        elif level == 1:\n",
        "            return 0.8\n",
        "        elif level ==2:\n",
        "            return 0.5\n",
        "        elif level == 3:\n",
        "            return 0.1\n",
        "        return (self.n_states - 1 - level) / (self.n_states - 1)\n",
        "\n",
        "    def update_demand(self, speed, ability, time):\n",
        "        if self.demand >= self.inventory:\n",
        "            self.demand -= self.inventory\n",
        "            self.inventory = 0.0\n",
        "        else:\n",
        "            self.inventory -= self.demand\n",
        "            self.demand = 0.0\n",
        "        return max(0, self.demand-self.inventory-ability*speed*time)\n",
        "\n",
        "    def update_inventory(self, speed, ability, time):\n",
        "        if self.demand <= self.inventory + ability * speed * time:\n",
        "            return min(self.MAX_inventory, -self.demand+self.inventory+ability*speed*time), max(0, -self.MAX_inventory-self.demand+self.inventory+ability*speed*time)\n",
        "        else:\n",
        "            return 0.0, 0.0\n",
        "\n",
        "    def get_maintenance_time(self,level):\n",
        "        return 0\n",
        "\n",
        "    def update_maintenance_time(self, unit_idx):\n",
        "        return 0\n",
        "\n",
        "    def one_hot_encode(self):\n",
        "        level_ohe = []\n",
        "        mstatus_ohe = []\n",
        "        for unit_idx in range(self.n_units):\n",
        "            l = [0] * self.n_states\n",
        "            m = [0] * (self.MAX_maintenance_time + 1)\n",
        "            l[min(math.floor(self.levels[unit_idx]),self.n_states-1)] = 1\n",
        "            m[self.maintenance_status[unit_idx]] = 1\n",
        "            level_ohe = level_ohe + l\n",
        "            mstatus_ohe = mstatus_ohe + m\n",
        "        return level_ohe, mstatus_ohe\n",
        "\n",
        "\n",
        "\n",
        "    def operation(self, replacements, load1):\n",
        "        reward = 0\n",
        "\n",
        "        speeds=[load1,0]\n",
        "        #生産速度の調整\n",
        "        if speeds[0] < 0:\n",
        "            speeds[0] = 0\n",
        "        if speeds[0] > 1:\n",
        "            speeds[0] = 1\n",
        "\n",
        "        flag = 0\n",
        "\n",
        "        #保全の意思決定\n",
        "        #print(replacements)\n",
        "\n",
        "        if replacements==[1,1]: #稼働継続\n",
        "          # パラメータの設定\n",
        "          scales=[0,0]\n",
        "          shape1 = 0.69  # ガンマ分布のパラメータ v1 用 0.69\n",
        "          shape2 = 0.69  # ガンマ分布のパラメータ v2 用\n",
        "          tau = 0.5  # ケンドールの順位相関係数\n",
        "\n",
        "          theta = 1 / (1 - tau)\n",
        "          # 一様乱数を生成\n",
        "          u = uniform.rvs(size=1)\n",
        "          v = uniform.rvs(size=1)\n",
        "\n",
        "          # ガンベルコピュラの変換適用\n",
        "          #c = (-np.log(u)) ** theta + (-np.log(v)) ** theta\n",
        "          #u_transformed = np.exp(-c**(1/theta))\n",
        "          #v_transformed = np.exp(-c**(1/theta))\n",
        "\n",
        "          # 一様乱数をガンマ分布の逆関数に通す\n",
        "\n",
        "          #load_totalを考慮した調整\n",
        "          if speeds[0]>self.load_total:\n",
        "            speeds[0]=self.load_total\n",
        "          speeds[1]=self.load_total - speeds[0]\n",
        "          if speeds[1]>self.load_total:\n",
        "            speeds[1]=1\n",
        "            speeds[0]=self.load_total - speeds[1]\n",
        "          #print(speeds, \"speeds\")\n",
        "          #尺度パラメータ計算\n",
        "          for i in range(self.n_units):\n",
        "            scales[i]=6.491*(speeds[i]**2)+0.726\n",
        "\n",
        "\n",
        "          v1 = gamma.ppf(u, shape1, scale=scales[0])\n",
        "          v2 = gamma.ppf(v, shape2, scale=scales[1])\n",
        "\n",
        "          #print(\"稼働継続\")\n",
        "          #print(v1,v2, \"劣化増分\")\n",
        "          self.levels[0]+=v1/25##\n",
        "          self.levels[1]+=v2/25##\n",
        "          #print(self.levels, \"劣化\")\n",
        "\n",
        "          reward -= self.P_Cost[min(math.floor(self.levels[0]),self.n_states-1)][min(math.floor(self.levels[1]),self.n_states-1)]\n",
        "\n",
        "        elif replacements==[0,1]: #1のみ取替\n",
        "          self.levels[0]=0\n",
        "          reward -= self.cs\n",
        "          if self.levels[0]<self.n_states-1:\n",
        "            reward -= self.cp\n",
        "          else:\n",
        "            reward -= self.cc\n",
        "\n",
        "        elif replacements==[1,0]: #2のみ取替\n",
        "          self.levels[1]=0\n",
        "          reward -= self.cs\n",
        "          if self.levels[1]<self.n_states-1:\n",
        "            reward -= self.cp\n",
        "          else:\n",
        "            reward -= self.cc\n",
        "\n",
        "        else: #両方取替\n",
        "          self.levels=[0,0]\n",
        "          reward -= self.cs\n",
        "          if self.levels[0]<self.n_states-1:\n",
        "            reward -= self.cp\n",
        "          else:\n",
        "            reward -= self.cc\n",
        "          if self.levels[1]<self.n_states-1:\n",
        "            reward -= self.cp\n",
        "          else:\n",
        "            reward -= self.cc\n",
        "\n",
        "\n",
        "        #print(self.levels)\n",
        "        #print(reward)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        level_ohe, mstatus_ohe = self.one_hot_encode()\n",
        "\n",
        "        #print(f'状態:{self.levels}, 保全状態:{self.maintenance_status}, 在庫:{self.inventory}, 需要:{self.demand}, 残り時間:{self.remain_interval}, 保全行動:{replacements}, {speeds}')\n",
        "        #print(\"#############\")\n",
        "\n",
        "        flag = 0\n",
        "\n",
        "        return reward, level_ohe, mstatus_ohe, \\\n",
        "               0, self.load_total, 0, flag\n",
        "        #return reward, level_ohe, mstatus_ohe, \\\n",
        "        #       0, (self.demand-mean)/variance, self.remain_interval * 2 / self.interval - 1, flag\n",
        "\n",
        "\n",
        "    #劣化レベル順にすべき可能性"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z_7ruy0iTYPa"
      },
      "outputs": [],
      "source": [
        "class PPOMemory:\n",
        "    def __init__(self,batch_size, interval, beta, GAE_lam):\n",
        "        self.states = []\n",
        "        self.probs = []\n",
        "        self.vals = []\n",
        "        self.acts_dsc = []\n",
        "        self.acts_cnt = []\n",
        "        self.rewards = []\n",
        "        self.time = []\n",
        "        self.batch_size = batch_size\n",
        "        self.interval = interval\n",
        "        self.beta = beta\n",
        "        self.advantage = []\n",
        "        self.lam = GAE_lam\n",
        "\n",
        "    def generate_advantage(self):\n",
        "\n",
        "        \"\"\"\n",
        "        advantage = np.zeros(len(self.rewards),dtype=np.float32)\n",
        "        for t in range(len(self.rewards)-1):\n",
        "            a_t = 0\n",
        "            for k in range(t, len(self.rewards)-1):\n",
        "                a_t += math.exp(-self.beta * self.time[k]) * \\\n",
        "                    (self.rewards[k]+math.exp(-self.beta * (-self.time[k]%self.interval+self.interval))*self.vals[k+1]-self.vals[k])\n",
        "            advantage[t] = a_t\n",
        "        self.advantage = advantage\n",
        "        \"\"\"\n",
        "\n",
        "        advantage = []\n",
        "        gae = 0\n",
        "        for t in reversed(range(len(self.rewards))):\n",
        "            gamma = 1\n",
        "            if t == len(self.rewards) - 1:\n",
        "                delta = self.rewards[t] - self.vals[t]\n",
        "            else:\n",
        "                gamma = math.exp(-self.beta*(self.time[t+1]-self.time[t]))\n",
        "                delta = self.rewards[t] + gamma * self.vals[t+1] - self.vals[t]\n",
        "            gae = delta + gamma * self.lam * gae\n",
        "            advantage.insert(0, gae)\n",
        "        self.advantage = np.array(advantage,dtype=np.float32)\n",
        "\n",
        "\n",
        "\n",
        "    def generate_batches(self):\n",
        "        n_states = len(self.states)\n",
        "        batch_start = np.arange(0, n_states, self.batch_size)\n",
        "        indices = np.arange(n_states, dtype=np.int64)\n",
        "        np.random.shuffle(indices)\n",
        "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
        "\n",
        "        return np.array(self.states),\\\n",
        "               np.array(self.acts_dsc),\\\n",
        "               np.array(self.acts_cnt),\\\n",
        "               np.array(self.probs),\\\n",
        "               np.array(self.vals),\\\n",
        "               np.array(self.rewards),\\\n",
        "               np.array(self.advantage),\\\n",
        "               batches\n",
        "\n",
        "\n",
        "\n",
        "    def store_memory(self, state, act_dsc, act_cnt, probs, vals, reward, time):\n",
        "        self.states.append(state)\n",
        "        self.acts_dsc.append(act_dsc)\n",
        "        self.acts_cnt.append(act_cnt)\n",
        "        self.probs.append(probs)\n",
        "        self.vals.append(vals)\n",
        "        self.rewards.append(reward)\n",
        "        self.time.append(time)\n",
        "\n",
        "    def clear_memory(self):\n",
        "        self.states = []\n",
        "        self.probs = []\n",
        "        self.acts_dsc = []\n",
        "        self.acts_cnt = []\n",
        "        self.rewards = []\n",
        "        self.vals = []\n",
        "        self.time = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MJC8xTojTYPa"
      },
      "outputs": [],
      "source": [
        "class ActorNetwork(nn.Module):\n",
        "    def __init__(self, n_units, n_states, MAX_maintenance_time, input_dims, alpha, fc1_dims=64, fc2_dims=64, fc3_dims=64, chkpt_dir=\"\"):\n",
        "        super(ActorNetwork, self).__init__()\n",
        "        self.n_units = n_units\n",
        "        self.n_states = n_states\n",
        "        self.MAX_maintenance_time = MAX_maintenance_time\n",
        "        self.checkpoint_file = os.path.join(chkpt_dir, \"actor_torch_ppo\")\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dims, fc1_dims)\n",
        "        self.fc2 = nn.Linear(fc1_dims, fc2_dims)\n",
        "        self.fc3 = nn.Linear(fc1_dims, fc3_dims)\n",
        "\n",
        "        self.dsc = nn.Linear(fc2_dims, 2 ** n_units) #離散行動\n",
        "        # 以下に初期化コードを追加\n",
        "        self.init_dsc_weights()\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.Tanh = nn.Tanh()\n",
        "\n",
        "        self.mean = nn.Linear(fc3_dims, n_units-1)\n",
        "        self.log_std = nn.Linear(fc3_dims, n_units-1)\n",
        "\n",
        "        # mean レイヤーの初期化\n",
        "        self.init_mean_weights()\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.to(self.device)\n",
        "\n",
        "        self.scheduler_actor = optim.lr_scheduler.StepLR(self.optimizer, step_size=5, gamma=0.95)\n",
        "\n",
        "    def init_dsc_weights(self):\n",
        "        # ここで特定の出力確率を設定するための重みとバイアスを設定\n",
        "        with torch.no_grad():\n",
        "            # すべての出力がほぼ等しくなるように設定\n",
        "            self.dsc.weight.fill_(0.0)\n",
        "            # 特定の確率分布に調整\n",
        "            self.dsc.bias.data = torch.log(torch.tensor([0.03, 0.03, 0.03, 0.91]))  # logを取るのがポイント\n",
        "\n",
        "    def init_mean_weights(self):\n",
        "        # mean レイヤーの初期化\n",
        "        with torch.no_grad():\n",
        "            self.mean.weight.fill_(0.0)\n",
        "            self.mean.bias.fill_(0.0)  # ここで固定出力0.5を設定#0に変更\n",
        "\n",
        "    #離散行動空間を制限するための関数, 返り値はmaskで制限されるところは-inf,されないところは1。返り値はバッチ数*2\n",
        "    def create_dsc_mask(self, state): #state=[s,m,b,d,t], action=[P(replace), P(keep)]\n",
        "        mask = torch.zeros(state.size(0),2**self.n_units)\n",
        "        #保全を選択できる時点にて、保全中のユニットは保全を選択できない\n",
        "        for unit_idx in range(self.n_units):\n",
        "            for a in range(2 ** self.n_units):\n",
        "                action_list = [int(bit) for bit in format(a, f'0{self.n_units}b')] #action_list=[r1,r2,r3,...]\n",
        "                if action_list[unit_idx] == 0:\n",
        "                    #保全の意思決定時点のとき、保全中の場合は保全を選択できない\n",
        "                    #保全の意思決定時点でないとき、保全を選択できない\n",
        "                    mask[(state[:,(self.n_states*self.n_units-1+(self.MAX_maintenance_time+1)*unit_idx+1)] == 0)\\\n",
        "                        , a] = torch.tensor(1)\n",
        "\n",
        "\n",
        "        mask[(state[:, 4] == 1) & (state[:, 9] == 1) & \\\n",
        "             (state[:,self.n_states*self.n_units-1 + 1] == 1) & (state[:,self.n_states*self.n_units-1 + (self.MAX_maintenance_time+1) * 1 + 1] == 1) & (state[:,self.n_states*self.n_units-1 + (self.MAX_maintenance_time+1) * 2 + 1] == 1)\n",
        "            ,1:] = torch.tensor(1) #2 ** self.n_units-1\n",
        "            #状態とユニット数により要変更\n",
        "\n",
        "        return mask.bool()\n",
        "\n",
        "    def create_cnt_mask(self, state):\n",
        "        mask= torch.zeros(state.size(0), self.n_units)\n",
        "        for unit_idx in range(self.n_units):\n",
        "            a = 2**(self.n_units)-1 - 2**(self.n_units-1-unit_idx)\n",
        "\n",
        "            #保全の意思決定ができる時\n",
        "            #mask[(state[:,-1] == 1) & \\\n",
        "            #     ((dist_dsc[:,a] <= 0.0001) |\n",
        "            #      (state[:,unit_idx*self.n_states+self.n_states-1] == 1) | \\\n",
        "            #      (state[:,(self.n_states*self.n_units-1+(self.MAX_maintenance_time+1)*unit_idx+1)] == 0)), unit_idx] = torch.tensor(1)\n",
        "            mask[((state[:,unit_idx*self.n_states+self.n_states-1] == 1) | \\\n",
        "                  (state[:,(self.n_states*self.n_units-1+(self.MAX_maintenance_time+1)*unit_idx+1)] == 0)), unit_idx] = torch.tensor(1)\n",
        "\n",
        "\n",
        "        return mask.bool()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x2 = F.relu(self.fc2(x))\n",
        "        x3 = F.relu(self.fc3(x))\n",
        "\n",
        "        first_mask = self.create_dsc_mask(state)\n",
        "\n",
        "        #離散行動の分布\n",
        "        dist_dsc = self.dsc(x2)\n",
        "        dist_dsc = dist_dsc.masked_fill(first_mask,-1e5)\n",
        "\n",
        "        dist_dsc = self.softmax(dist_dsc)\n",
        "        #if (state[0,4]==1 and state[0,9]==1 and state[0,14]==1 and state[0,15]==1 and state[0,19]==1 and state[0,23]==1 and state[0,-1]==1):\n",
        "        #    print(state)\n",
        "        #    print(dist_dsc)\n",
        "        #    print(\"&&&&&&&&\")\n",
        "\n",
        "\n",
        "        second_mask = self.create_cnt_mask(state)\n",
        "        dist_dsc = Categorical(dist_dsc)\n",
        "\n",
        "        #連続行動の分布\n",
        "        mean = self.mean(x3)\n",
        "        mean = self.Tanh(mean)\n",
        "\n",
        "        #mean = mean.masked_fill(second_mask, -1) #セカンドマスクを消す\n",
        "        mean = (mean+1)/2 #これで[0,1]になってほしい\n",
        "\n",
        "        #print(dist_dsc, mean)\n",
        "        #print(state)\n",
        "        #print(dist_dsc)\n",
        "        #mean = torch.clamp(mean,min=-5,max=5)\n",
        "        log_std = self.log_std(x3)\n",
        "        log_std = torch.clamp(log_std,min=-20,max=2)\n",
        "        std = log_std.exp()\n",
        "        #std = std.masked_fill(second_mask, 1e-4) #セカンドマスクを消す\n",
        "        #print(mean)\n",
        "        #print(\"AAAA\")\n",
        "\n",
        "        #print(mean,std)\n",
        "\n",
        "        #dist_cnt = torch.distributions.MultivariateNormal(loc=mean, covariance_matrix = torch.stack([torch.diag(x**2+1e-10) for x in std]))\n",
        "\n",
        "        dist_cnt = torch.distributions.Normal(loc=mean, scale=std) #1次元化のため\n",
        "\n",
        "\n",
        "        return dist_dsc, dist_cnt\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        torch.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        self.load_state_dict(torch.load(self.checkpoint_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "78j9p-tgTYPb"
      },
      "outputs": [],
      "source": [
        "class CriticNetwork(nn.Module):\n",
        "    def __init__(self, input_dims, alpha, fc1_dims=32, fc2_dims=32, fc3_dims=64, chkpt_dir=\"\"):\n",
        "        super(CriticNetwork, self).__init__()\n",
        "\n",
        "        self.checkpoint_file = os.path.join(chkpt_dir, \"critic_torch_ppo\")\n",
        "        self.critic = nn.Sequential(\n",
        "            nn.Linear(input_dims, fc1_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(fc1_dims,fc2_dims),\n",
        "            nn.ReLU(),\n",
        "            #nn.Linear(fc2_dims,fc3_dims),\n",
        "            #nn.ReLU(),\n",
        "            nn.Linear(fc2_dims,1)\n",
        "        )\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.to(self.device)\n",
        "\n",
        "        self.scheduler_critic = optim.lr_scheduler.StepLR(self.optimizer, step_size=5, gamma=0.95)\n",
        "\n",
        "\n",
        "    def forward(self, state):\n",
        "        value = self.critic(state)\n",
        "        return value\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        torch.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        self.load_state_dict(torch.load(self.checkpoint_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jRw3Bjb7TYPb",
        "outputId": "d7780ef5-8c79-4dc4-9276-3a837cbdbe69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DMZpQl6gTYPc"
      },
      "outputs": [],
      "source": [
        "test_batch = 0\n",
        "class Agent:\n",
        "    def __init__(self, n_units, n_states, MAX_maintenance_time, input_dims, beta=0.0005, GAE_lam=0.95, interval=24,\n",
        "                 alpha_actor=0.03, alpha_critic=0.01,\n",
        "                 policy_clip=0.2, batch_size=512*4, n_epochs=4):\n",
        "        self.beta = beta\n",
        "        self.policy_clip = policy_clip\n",
        "        self.n_epochs = n_epochs\n",
        "\n",
        "        self.loss_history = []\n",
        "        self.loss_history_detail = []\n",
        "\n",
        "        self.actor_loss_history = []\n",
        "        self.actor_loss_history_detail = []\n",
        "        self.critic_loss_history = []\n",
        "        self.critic_loss_history_detail = []\n",
        "        self.entropy_history = []\n",
        "        self.kl_divergence_history = []\n",
        "\n",
        "        self.actor = ActorNetwork(n_units, n_states, MAX_maintenance_time, input_dims, alpha_actor)\n",
        "        self.critic = CriticNetwork(input_dims, alpha_critic)\n",
        "        self.memory = PPOMemory(batch_size, interval=interval, beta=beta, GAE_lam=GAE_lam)\n",
        "\n",
        "    def remember(self,state,action_dsc,action_cnt,probs,vals,reward, time):\n",
        "        self.memory.store_memory(state,action_dsc,action_cnt,probs,vals,reward, time)\n",
        "\n",
        "    def save_models(self):\n",
        "        print(\"... saving models ...\")\n",
        "        self.actor.save_checkpoint()\n",
        "        self.critic.save_checkpoint()\n",
        "\n",
        "    def load_models(self):\n",
        "        print(\"... loading models ...\")\n",
        "        self.actor.load_checkpoint()\n",
        "        self.critic.load_checkpoint()\n",
        "\n",
        "    def choose_action(self,observation):\n",
        "        state = torch.tensor(np.array([observation]),dtype=torch.float).to(self.actor.device)\n",
        "        dist_dsc, dist_cnt = self.actor(state)\n",
        "        print(state, \"dsc:\" ,dist_dsc.probs, \"cnt:\" ,dist_cnt.mean)\n",
        "        value = self.critic(state)\n",
        "        act_dsc = dist_dsc.sample()\n",
        "        act_cnt = dist_cnt.sample()\n",
        "        print(act_cnt)\n",
        "        log_prob_dsc = torch.squeeze(dist_dsc.log_prob(act_dsc)).item()\n",
        "        log_prob_cnt = torch.squeeze(dist_cnt.log_prob(act_cnt)).item()\n",
        "\n",
        "\n",
        "        log_prob = log_prob_dsc + log_prob_cnt\n",
        "\n",
        "        value = torch.squeeze(value).item()\n",
        "\n",
        "        return act_dsc, act_cnt, log_prob, value\n",
        "\n",
        "    def choose_action_max_prob(self,observation):\n",
        "        state = torch.tensor(np.array([observation]),dtype=torch.float).to(self.actor.device)\n",
        "        dist_dsc, dist_cnt = self.actor(state)\n",
        "        print(state, \"dsc\", dist_dsc.probs, \"cnt:\",dist_cnt.mean)\n",
        "        act_dsc = torch.argmax(dist_dsc.probs)\n",
        "        act_cnt = dist_cnt.mean\n",
        "        print(act_dsc, \"act_dsc\")\n",
        "        print(act_cnt, \"act_cnt\")\n",
        "\n",
        "        value = self.critic(state)\n",
        "\n",
        "\n",
        "        log_prob_dsc = torch.squeeze(dist_dsc.log_prob(act_dsc)).item()\n",
        "        log_prob_cnt = torch.squeeze(dist_cnt.log_prob(act_cnt)).item()\n",
        "        log_prob = log_prob_dsc + log_prob_cnt\n",
        "\n",
        "        value = torch.squeeze(value).item()\n",
        "\n",
        "        return act_dsc, act_cnt, log_prob, value\n",
        "\n",
        "    def learn(self):\n",
        "        self.memory.generate_advantage()\n",
        "        actor_loss_sum = 0\n",
        "        critic_loss_sum = 0\n",
        "        entropy_sum = 0\n",
        "        kl_divergence_sum = 0\n",
        "        for _ in range(self.n_epochs):\n",
        "        #for _ in tqdm(range(self.n_epochs), desc=\"Training Progress\"):  # tqdmを用いて進捗表示\n",
        "            \"\"\"\n",
        "            rewards = self.memory.rewards\n",
        "            values = self.memory.vals\n",
        "            times = self.memory.time\n",
        "            advantage = np.zeros(len(reward_arr),dtype=np.float32)\n",
        "            for t in range(len(reward_arr)-1):\n",
        "                a_t = 0\n",
        "                for k in range(t, len(reward_arr)-1):\n",
        "                    a_t += math.exp(-self.beta * times[k]) * \\\n",
        "                        (reward_arr[k]+math.exp(-self.beta * (-times[k]%self.interval+self.interval))*values[k+1]-values[k])\n",
        "                advantage[t] = a_t\n",
        "            advantage = torch.tensor(advantage).to(self.actor.device)\n",
        "            \"\"\"\n",
        "            state_arr, act_dsc_arr, act_cnt_arr, old_probs_arr, vals_arr, reward_arr, advantage, batches=self.memory.generate_batches()\n",
        "            values = vals_arr\n",
        "            \"\"\"\n",
        "            values = vals_arr\n",
        "            times = time_arr\n",
        "            advantage = np.zeros(len(reward_arr),dtype=np.float32)\n",
        "            for t in range(len(reward_arr)-1):\n",
        "                a_t = 0\n",
        "                for k in range(t, len(reward_arr)-1):\n",
        "                    a_t += math.exp(-self.beta * times[k]) * (reward_arr[k]+self.gamma*values[k+1]-values[k])\n",
        "                advantage[t] = a_t\n",
        "            \"\"\"\n",
        "            advantage = torch.tensor(advantage).to(self.actor.device)\n",
        "\n",
        "            values = torch.tensor(values).to(self.actor.device)\n",
        "            start = time.time()\n",
        "            for batch in batches:  # 各バッチの進捗を表示\n",
        "                states = torch.tensor(state_arr[batch], dtype=torch.float).to(self.actor.device)\n",
        "                log_old_probs = torch.tensor(old_probs_arr[batch]).to(self.actor.device)\n",
        "                acts_dsc = torch.tensor(act_dsc_arr[batch]).to(self.actor.device)\n",
        "                acts_cnt = torch.tensor(act_cnt_arr[batch]).to(self.actor.device)\n",
        "\n",
        "                dist_dsc, dist_cnt = self.actor(states)\n",
        "                critic_value = self.critic(states)\n",
        "                critic_value = torch.squeeze(critic_value)\n",
        "\n",
        "                log_new_probs = dist_dsc.log_prob(acts_dsc) + dist_cnt.log_prob(acts_cnt)\n",
        "\n",
        "                prob_ratio = log_new_probs.exp()/log_old_probs.exp()\n",
        "                weighted_probs = advantage[batch]*prob_ratio\n",
        "                weighted_clipped_probs = torch.clamp(prob_ratio, 1-self.policy_clip, 1+self.policy_clip)*advantage[batch]\n",
        "                actor_loss = -torch.min(weighted_probs, weighted_clipped_probs).mean()\n",
        "\n",
        "                returns = advantage[batch] + values[batch]\n",
        "                critic_loss = (returns-critic_value)**2\n",
        "                critic_loss = critic_loss.mean()\n",
        "                #print(actor_loss)\n",
        "                #print(critic_loss)\n",
        "                #print(\"#####\")\n",
        "                entropy = torch.clamp(dist_dsc.entropy().mean(),min=0) + torch.clamp(dist_cnt.entropy().mean(), min=0.0)\n",
        "\n",
        "                total_loss = actor_loss + 0.5*critic_loss + 0.01*entropy\n",
        "                self.actor.optimizer.zero_grad()\n",
        "                self.critic.optimizer.zero_grad()\n",
        "                total_loss.backward()\n",
        "                self.actor.optimizer.step()\n",
        "                self.critic.optimizer.step()\n",
        "                self.loss_history_detail.append(total_loss.item())\n",
        "\n",
        "                actor_loss_sum += actor_loss.item()\n",
        "                critic_loss_sum += critic_loss.item()\n",
        "                entropy_sum += entropy.item()\n",
        "                kl_divergence_sum += torch.distributions.kl_divergence(Categorical(logits=log_old_probs), Categorical(logits=log_new_probs)).mean().item()\n",
        "\n",
        "        print(f'actor loss: {actor_loss_sum}, critic loss: {critic_loss_sum}, entropy: {entropy_sum}, KL divergence: {kl_divergence_sum}')\n",
        "        self.loss_history.append(np.mean(self.loss_history_detail[-self.n_epochs:]))\n",
        "        self.actor_loss_history.append(actor_loss_sum)\n",
        "        self.critic_loss_history.append(critic_loss_sum)\n",
        "        self.entropy_history.append(entropy_sum)\n",
        "        self.kl_divergence_history.append(kl_divergence_sum)\n",
        "            # Update sums\n",
        "        self.actor.scheduler_actor.step()  # 学習率を更新\n",
        "        self.critic.scheduler_critic.step()  # 学習率を更新\n",
        "        self.memory.clear_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l4PW7F3zTYPc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PkbRyHFHTYPc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7JV5KgBxTYPd"
      },
      "outputs": [],
      "source": [
        "#エージェントの初期化\n",
        "n_units = 2\n",
        "n_states = 5\n",
        "MAX_maintenance_time = 0\n",
        "input_size = n_units * n_states + n_units * (MAX_maintenance_time+1) + 2 #MDPのため[残り時間]と[保全意思決定時]の2つの入力は入れない\n",
        "action_size = 2**n_units  # 行動数は2^3個\n",
        "batch_size = 512*4#512-5120\n",
        "interval = 24\n",
        "alpha_actor = 0.01#ここを変更する\n",
        "alpha_critic = 0.02#ここを変更する\n",
        "n_epochs = 4\n",
        "policy_clip = 0.2\n",
        "beta=0.0005\n",
        "\n",
        "\n",
        "agent = Agent(n_units=n_units,\n",
        "              input_dims=input_size,\n",
        "              n_states=n_states,\n",
        "              MAX_maintenance_time=MAX_maintenance_time,\n",
        "              beta=beta,\n",
        "              interval=interval,\n",
        "              alpha_actor=alpha_actor,\n",
        "              alpha_critic=alpha_critic,\n",
        "              policy_clip=policy_clip,\n",
        "              batch_size=batch_size,\n",
        "              n_epochs=n_epochs)\n",
        "env = Environment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15IhPu1nTYPd",
        "outputId": "0410b541-3579-439e-ee8f-01781f1cf987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3830]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2404]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0563]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6438]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3912]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1765]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3722]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6376]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2119]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9797]])\n",
            "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5947]])\n",
            "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9388]])\n",
            "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2156]])\n",
            "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc: tensor([[0.0300, 0.0300, 0.0300, 0.9100]], grad_fn=<DivBackward0>) cnt: tensor([[0.5000]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2290]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-8a6e3b87a748>:180: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  reward -= self.P_Cost[min(math.floor(self.levels[0]),self.n_states-1)][min(math.floor(self.levels[1]),self.n_states-1)]\n",
            "<ipython-input-2-8a6e3b87a748>:116: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  l[min(math.floor(self.levels[unit_idx]),self.n_states-1)] = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6819]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2119]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0653]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3988]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4523]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2751]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0375]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1973]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6214]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6476]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4546]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1531]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1257]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9520]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5910]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6212]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2346]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0158]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7611]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0597]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9095]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.2257]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6305]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6210]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2060]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6575]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7410]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5809]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3663]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3358]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2413]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3140]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1078]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2409]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5388]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5562]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4460]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2491]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4498]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6077]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4851]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1139]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0509]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1849]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8223]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2270]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7893]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6198]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0939]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6904]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8671]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1909]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7100]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5572]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2965]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0071]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1913]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4170]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3564]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9591]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3581]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2874]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3028]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6339]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1198]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1553, 0.1190, 0.0287, 0.6970]], grad_fn=<DivBackward0>) cnt: tensor([[0.5069]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8850]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7319]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7048]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4588]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6731]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3996]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9550]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2612]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0504]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9984]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3171]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2984]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4494]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8609]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4150]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5087]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0237]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2261]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1164]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5975]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7143]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1968]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4116]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7887]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2264]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4647]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8105]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5098]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2938]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1562]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6187]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4535]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6571]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6393]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7325]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0414]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0155]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1967]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3786]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2355]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6491]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0131]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7227]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1673]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7973]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1348]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1122]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7957]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3089]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3361]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9887]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3483]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9956]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2721]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7760]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4239]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8737]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8110]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2280]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5368]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7126]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6655]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1016]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4651]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2178]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8723]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0719]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0186]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2716]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9638]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7594]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1243]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4722]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6258]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3815]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4154]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8710]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3500]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.5294]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3660]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0552]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6034]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9394]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5209]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2419]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7548]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0938]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3389]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5696]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5809]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1561]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6671]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0743]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6407]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3840]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0165]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9302]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.0167]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3673]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8493]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1292]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0461]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7945]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7086]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6406]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7100]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4001]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4581]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4143]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2238]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2973]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1098]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.1843]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7084]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5591]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1427]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6730]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3323]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8622]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9053]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3273]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4382]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6229]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9714]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8937]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7704]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7877]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9136]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2999]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4928]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7176]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7038]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5100]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1704]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4438]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6493]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3654]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2400]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5140]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3559]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9820]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4580]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1726]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0918]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5134]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4685]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7514]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2190]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1081]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1097]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1056]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5420]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4373]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.8210]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0954]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0881]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2622]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3521]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7160]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5997]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2776]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1084]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6493]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4677]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3337]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6228]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7653]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5256]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1585]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1784]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9713]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1470]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8473]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9733]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1252]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1465]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6716]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4276]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6275]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4974]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0976]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1144]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0334]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3540]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7876]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1143]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2756]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6805]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0614]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5944]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1587]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7350]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9460]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0311]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3397]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9106]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7176]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0657]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4003]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3390]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.2121]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3273]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1825]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6161]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1002]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5570]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3730]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6187]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2063]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6014]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0867]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6230]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3569]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2839]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5751]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9478]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3238]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3299]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7310]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1408]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1356]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9909]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1590]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1441]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9661]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3187]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5750]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1599]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1232]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0383]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2215]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2248]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3009]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6428]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4220]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9966]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0245]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6376]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6347]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3416]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1741]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8505]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.1273]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5087]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5788]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6818]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2507]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8298]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2738]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6509]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0585]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2094]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0679]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3114]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8887]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5765]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3407]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8115]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4469]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5016]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7761]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8313]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5146]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0765]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1118]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4707]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6275]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4419]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1845]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5548]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2571]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8199]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4214]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7565]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1476]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1740]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6689]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3771]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1986]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8019]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7634]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5042]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0603]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4709]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5061]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0354]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9713]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5747]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8842]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6177]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1275]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1299]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8436]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1810]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9802]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7096]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9364]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6584]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8410]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0296]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0396]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2002]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8493]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7336]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9197]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6795]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0371]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5763]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0731]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3875]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9818]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9542]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2146]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3571]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3297]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.2825]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5077]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2633]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3454]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4351]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1385]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2321]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0718]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0304]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4144]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8236]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0086]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7373]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3737]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0267]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7477]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0195]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2698]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1119]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3974]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4129]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7018]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2249]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0153]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2173]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1151]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1226]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3291]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0780]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0439]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1583]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4682]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1257]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4057]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1899]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0511]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6304]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7934]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2842]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3276]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.1155]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6979]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3966]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9807]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0890]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4533]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1740]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9557]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5725]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1168]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3250]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0593]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0922]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4728]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2695]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6577]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3206]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8115]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2402]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6399]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0008]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6568]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4497]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6501]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7289]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5685]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5846]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5763]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7288]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7409]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3557]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6496]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7553]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5140]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3807]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6336]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5758]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7970]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8900]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4643]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2599]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2669]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4760]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0197]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1931]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2512]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.9529]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9881]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7160]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1445]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6291]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7009]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5208]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0465]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9119]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8272]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5380]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6334]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1351]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7855]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3068]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3293]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6404]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1769]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6975]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1941]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5736]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7566]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3938]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1880]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4607]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4146]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2970]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4512]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7227]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6388]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9126]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3677]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3916]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9478]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1848]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8437]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1828]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4954]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0715]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.3749]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6141]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7784]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0700]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5818]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3092]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2665]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8997]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9476]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.1640]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1114, 0.0911, 0.0308, 0.7667]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3823]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6218]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0518]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0031]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4575]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9645]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7275]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1889]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3284]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.9386]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1863]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8407]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7893]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2423]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0463]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1489]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7402]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0101]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6218]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7754]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7211]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3704]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6157]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0661]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4052]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4359]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6136]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7092]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8035]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0771]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1099]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5337]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4972]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9576]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3430]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0911]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0240]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0782]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5616]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0174]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4120]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1775]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8238]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6618]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0956]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6536]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0675]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2222]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7890]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2473]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4125]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4899]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2970]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.9076]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7659]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1893]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2868]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6089]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5696]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3954]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8684]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2247]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2600]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6480]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8161]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4134]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0813]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8128]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2121]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1477]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7046]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7640]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2219]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0501]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8453]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.1789]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4552]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7498]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6835]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7502]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4891]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4267]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0053]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0532]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6908]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5495]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6366]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1812]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5998]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2170]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6229]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4349]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3019]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1607]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6849]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6639]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8790]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0697]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5772]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3074]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1230]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1494]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8636]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0588]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1278]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0485]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.9022]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0616]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7592]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0862]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7437]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4254]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0129]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1644]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8622]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7163]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1171]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1003]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0355]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2130]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0862]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1623]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6224]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9954]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7966]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8955]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.7376]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3100]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2482]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0421]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8554]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0802]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3832]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6098]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6617]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0159]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4347]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0623]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5219]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1691]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7140]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0725]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8414]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9259]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8952]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6314]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9929]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9635]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4348]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2001]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1475]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4779]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3647]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7201]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5929]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9384]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4916]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.1179]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7138]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6887]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5780]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0857]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7095]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1313]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3093]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6163]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8449]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9440]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.3614]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3254]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.5595]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2163]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1120]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1508]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6741]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3674]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0960]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1960]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1419]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0650]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.9782]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4159]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0436]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7637]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3458]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1451]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4929]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6413]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8526]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0868]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7624]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1009]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7152]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5001]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0539]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9819]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4811]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.9666]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2930]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.1437]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1107]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7626]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5911]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6269]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3638]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0296]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3016]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4231]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3552]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.3615]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7938]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4602]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0934]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3360]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1425]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7376]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4889]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1529]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4545]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3458]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8474]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9220]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6586]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5584]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1855]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1776]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5578]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4075]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3098]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8470]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2131]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7324]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5710]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7569]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2378]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9692]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4846]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0912]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3951]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5650]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7666]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5545]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3714]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7645]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5511]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1872]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5368]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3295]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1381]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9703]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6015]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1553, 0.1190, 0.0287, 0.6970]], grad_fn=<DivBackward0>) cnt: tensor([[0.5069]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7107]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1553, 0.1190, 0.0287, 0.6970]], grad_fn=<DivBackward0>) cnt: tensor([[0.5069]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0139]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8224]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4533]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2822]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2284]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7861]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4052]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3680]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8173]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.9736]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9161]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2970]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8907]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0831]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9761]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4499]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0317]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3802]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1484]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1848]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5840]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0093]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1181]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0768]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8934]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1018]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3411]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8413]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1735]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1842]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2716]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4405]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2843]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2923]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7381]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7771]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9557]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5100]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2870]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9689]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2628]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4220]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8168]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7349]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0758]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1838]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3810]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2463]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3077]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4950]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4834]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4916]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2682]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0154]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1114, 0.0911, 0.0308, 0.7667]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7798]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1553, 0.1190, 0.0287, 0.6970]], grad_fn=<DivBackward0>) cnt: tensor([[0.5069]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4691]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1553, 0.1190, 0.0287, 0.6970]], grad_fn=<DivBackward0>) cnt: tensor([[0.5069]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1845]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1553, 0.1190, 0.0287, 0.6970]], grad_fn=<DivBackward0>) cnt: tensor([[0.5069]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5176]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1114, 0.0911, 0.0308, 0.7667]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5737]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1114, 0.0911, 0.0308, 0.7667]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0370]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1114, 0.0911, 0.0308, 0.7667]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6200]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1114, 0.0911, 0.0308, 0.7667]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5099]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1114, 0.0911, 0.0308, 0.7667]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8758]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1114, 0.0911, 0.0308, 0.7667]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3479]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9433]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7525]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0282]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4977]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4587]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0289]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2910]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1347]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3904]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4931]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8713]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8573]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0546]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3333]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3007]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5117]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4782]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1727]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9565]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2339]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5147]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0968]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2028]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0684]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7146]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5242]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8264]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9645]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0007]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6202]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2926]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3525]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2512]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1891]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2482]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3956]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3642]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4870]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1591]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8191]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8425]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5938]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0661]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9215]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9699]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1285]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1432]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7671]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2954]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7264]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6994]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3048]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5667]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3238]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.2159]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5289]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7226]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4835]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9673]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7308]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4663]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7774]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9520]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8173]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2489]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4875]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.0747]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2775]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6310]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7008]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2966]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4810]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7519]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4267]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0351]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0141]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4382]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3975]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5090]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7891]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.0208]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6265]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8457]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3024]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8899]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9750]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1339]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7069]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4180]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5850]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8226]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1562]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7226]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1003]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5501]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1081]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0286]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4554]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0096]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1079]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9650]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6954]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5682]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4653]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9032]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7438]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2449]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6542]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3786]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7040]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7776]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1484]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8899]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0884]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0815]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5157]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2342]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2492]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7321]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.3089]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2264]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6478]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7363]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5731]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0300]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0874]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5560]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.8453]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3399]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3424]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1284]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8714]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1197]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0481]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9898]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3672]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0084]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4401]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8627]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9530]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2155]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7932]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2247]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0151]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1248]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1077]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0936]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8088]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6816]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6068]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5535]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2491]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6116]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5425]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0571]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0173]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9647]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6529]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4209]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1903]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3444]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2517]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4621]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2816]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2040]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2330]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9409]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5423]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1392]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2707]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0462]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3415]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0554]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8924]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0774]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5729]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0678]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0968]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6015]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1236]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4632]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7031]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4478]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7776]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4678]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9639]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5998]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0559]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5125]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2997]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9724]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6764]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2187]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2322]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7050]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0968]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6341]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4863]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1964]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7929]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6479]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6865]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0001]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1226]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2426]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6323]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1640]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0648]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5791]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0132]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5332]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1426]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4627]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4792]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7226]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1077]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9766]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5555]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9707]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4949]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8239]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8730]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5054]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5224]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1407]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5583]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0339]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3444]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0563]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4536]])\n",
            "tensor([[0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1338, 0.1086, 0.0291, 0.7285]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7939]])\n",
            "tensor([[0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1338, 0.1086, 0.0291, 0.7285]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4967]])\n",
            "tensor([[0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1338, 0.1086, 0.0291, 0.7285]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0397]])\n",
            "tensor([[0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1338, 0.1086, 0.0291, 0.7285]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6665]])\n",
            "tensor([[0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1338, 0.1086, 0.0291, 0.7285]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9312]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9879]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0277]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1804]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5367]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6376]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6802]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5912]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2106]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7563]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0050]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6607]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1184]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7912]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1289]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4961]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5422]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4621]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1421]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5550]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1366]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3294]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1328]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9300]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2150]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7756]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8647]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0663]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2429]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2666]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0787]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2084]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3342]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9176]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5423]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.3467]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4575]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3216]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4662]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7650]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3592]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2704]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3938]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.9046]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8878]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4075]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6172]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1270]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4944]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1070]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4909]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5090]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1214]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3820]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3376]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0120]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1689]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5032]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0547]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6838]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1781]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1587]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6419]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5834]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1258]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2815]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8677]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6174]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2196]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9032]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1051]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0745]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0892]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3839]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1137]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0891]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2134]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1081]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2435]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0378]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5055]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1176]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0467]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5781]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2399]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4801]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8449]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5536]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0284]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4134]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1767]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1627]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7692]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3060]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1221]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9459]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6693]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2396]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6889]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3380]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0140]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0588]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0494]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1691]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4883]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3458]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7080]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2355]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6381]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4149]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.3732]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1880]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2832]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0057]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5576]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5303]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0035]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9624]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5373]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7341]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1182]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6685]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4483]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8510]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1228]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1374]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3240]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8076]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7881]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4846]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2866]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5914]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6474]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4255]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6258]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9696]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8423]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3945]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0086]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2014]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3000]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2950]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8527]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9668]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2036]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2360]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2805]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0022]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3076]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7463]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3990]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5700]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6932]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5492]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.2045]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5426]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9472]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8837]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1931]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5798]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8921]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3941]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1058]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6386]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4663]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5341]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4557]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6959]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4466]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.9586]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6382]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2090]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2881]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5342]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6323]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1249]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5993]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7887]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2378]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0849]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6562]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6597]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0674]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4283]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3676]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5829]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4696]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8140]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8374]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2509]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2176]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5439]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4574]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6258]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7917]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0286]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1985]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5426]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6604]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1910]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2638]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6694]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6561]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1852]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4898]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5242]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9707]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4229]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7571]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1759]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4180]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7716]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5101]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3748]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5298]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1299]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4816]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7847]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0776]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1408]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7935]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0648]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9361]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0607]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3855]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3717]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9956]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7288]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0097]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.3486]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2771]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2485]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7587]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9527]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4716]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0547]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2678]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2294]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7602]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5309]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8850]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8060]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8755]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1871]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2189]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1990]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8193]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7894]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3777]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2348]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3038]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4773]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9023]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1900]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3986]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9957]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5542]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1439]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3578]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9349]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2739]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.9913]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1716]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3702]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4740]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4044]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1555]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5113]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4136]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6333]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6180]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7683]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5032]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9368]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3242]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8829]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2343]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6103]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5882]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7892]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4774]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1558]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8730]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0977]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3141]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1375]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5089]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0757]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.9501]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9565]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1466]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0933]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4359]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5551]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4423]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8519]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3517]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2442]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5376]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1863]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6573]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6719]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5537]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2898]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3935]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8726]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2974]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5931]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.4819]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.9173]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4431]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4491]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8599]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1018]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0132]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2215]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0084]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2966]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5732]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[4.1490]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1047]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5717]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2700]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1958]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0505]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6996]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2470]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8546]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5254]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2117]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2529]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6931]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7239]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1100]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7586]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8996]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9154]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2890]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.0412]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1427]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1869]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3359]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4621]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5890]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4049]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6852]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5262]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7646]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0269]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3232]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1635]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1609]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1071]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1817]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5671]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5376]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3503]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5960]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1014]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0128]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2732]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6815]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1360]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7901]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6317]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1801]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4058]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1909]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7363]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1964]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0531]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9213]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2714]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5391]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1850]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1321]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1940]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7302]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0307]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8429]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8544]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2571]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1945]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2968]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2699]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9248]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1543]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5277]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7874]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9850]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2414]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3970]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0768]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7514]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9469]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1198]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0482]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2567]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8770]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7816]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5469]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7094]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4497]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1191]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0949]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7583]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3778]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2467]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1308]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9205]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4948]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8364]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0504]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7038]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5185]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9579]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3907]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3107]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4187]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1235]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1962]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5535]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2016]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3239]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0981]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5250]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4213]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0786]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3685]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6282]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3110]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7768]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3789]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2792]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2841]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3324]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3553]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2411]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0045]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9092]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4713]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8273]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7510]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6936]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9625]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1798]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0397]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9772]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1539]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1340]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1910]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8727]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6362]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6772]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3310]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5467]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1921]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1493]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4615]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0482]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6126]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4257]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6900]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7548]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7280]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5669]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4723]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1572]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6590]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7097]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9937]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0953]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4927]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0011]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0869]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2327]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3559]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5389]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5719]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3659]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1923]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9661]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8248]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0771]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2108]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5783]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5281]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2851]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3352]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2379]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3495]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6177]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6099]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0826]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1223]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1782]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2682]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9464]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7212]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1452]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9586]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9767]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8306]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0387]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4430]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3750]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9986]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3606]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6250]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7616]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8417]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0871]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1280]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6015]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6837]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5539]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0568]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3812]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6519]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5741]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1118]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2176]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5367]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8639]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0740]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2615]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9399]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7676]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5536]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2813]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2302]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1918]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1191]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2198]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9189]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5625]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5850]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7566]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1533]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5056]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0398]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3841]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4225]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9817]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1393]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4872]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9232]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8764]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6281]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3537]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4933]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1122]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2738]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2116]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6087]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0453]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1473]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8650]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7217]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5301]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5244]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6343]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1517]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7643]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4614]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1299]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2509]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2472]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6683]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6133]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4823]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7010]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5830]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0576]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3514]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3537]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2692]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7139]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2172]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7243]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8731]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3218]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4711]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4086]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3211]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2994]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2449]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2704]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1028]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4527]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1733]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1136]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3202]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6649]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1499]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1721]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1142]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3159]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8178]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6073]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2262]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7768]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9643]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3335]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4238]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4861]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3030]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4819]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4678]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0696]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4021]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0858]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8752]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.7332]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5130]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1328]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0795]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1114, 0.0911, 0.0308, 0.7667]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0765]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4427]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4207]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6753]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0196]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1232]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4238]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9500]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0156]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7984]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8315]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6783]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3317]])\n",
            "tensor([[0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1338, 0.1086, 0.0291, 0.7285]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1953]])\n",
            "tensor([[0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1338, 0.1086, 0.0291, 0.7285]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3723]])\n",
            "tensor([[0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1338, 0.1086, 0.0291, 0.7285]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7529]])\n",
            "tensor([[0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1338, 0.1086, 0.0291, 0.7285]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2410]])\n",
            "tensor([[0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1338, 0.1086, 0.0291, 0.7285]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5198]])\n",
            "tensor([[0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1338, 0.1086, 0.0291, 0.7285]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7631]])\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1621, 0.1305, 0.0271, 0.6803]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1552]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4121]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7477]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4113]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3161]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3796]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3208]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6387]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3302]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3639]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1278]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8640]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8888]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5393]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3053]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6309]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1272]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0110]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3693]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0189]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6396]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6366]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5107]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8289]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4075]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6288]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1728]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9287]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.3406]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2152]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2292]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9973]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8234]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2079]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7447]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0364]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9754]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4002]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6504]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5218]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3938]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5303]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2207]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8229]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2123]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4694]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3156]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7124]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1688]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1914]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8379]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7610]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0663]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4787]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.9892]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5420]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5282]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.0800]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4933]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0377]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2797]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0291]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4401]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5393]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0439]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6536]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.3536]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5190]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4542]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8410]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8777]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9065]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0438]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2972]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9710]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0927]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4788]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4749]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7245]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8654]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2561]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8681]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4274]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3861]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2951]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5922]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9532]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3363]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9650]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6688]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4467]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1304]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0372]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3893]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.9057]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6712]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1936]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1477]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7922]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1410]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0433]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8341]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2212]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1108]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7512]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9308]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0902]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0607]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1170]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9810]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5549]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3861]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1740]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1656]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1230]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0555]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6399]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4601]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3157]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7610]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0279]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6083]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6511]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1592]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3652]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3720]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3473]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1730]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2190]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8550]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0556]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0822]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4612]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7496]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0239]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3078]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2177]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3314]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1007]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3031]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1148]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1911]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1290]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5358]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3626]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0270]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0975]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5045]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6203]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8822]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6291]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8256]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9838]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2763]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2299]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1982]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4985]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2700]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2921]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8908]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3430]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2358]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0514]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.6648]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1802]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5830]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0238]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7127]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3282]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9856]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4834]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2476]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0196]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2407]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1548]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9538]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5284]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8321]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3099]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1967]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4197]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4585]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7220]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5341]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8443]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8412]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0384]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.0678]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4334]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0664]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3770]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0842]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0892]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4132]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5411]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7481]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5155]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7868]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2021]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6165]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8119]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8225]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2080]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5889]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3164]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3149]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9559]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0326]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2009]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8635]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5070]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9544]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5476]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8359]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1763]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2783]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1513]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0773]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5343]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3064]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2190]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2240]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7399]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3449]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2505]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2227]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2081]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8238]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0599]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5910]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3232]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2685]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2540]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4700]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4631]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1155]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0960]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7183]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9611]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2468]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2190]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4067]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5817]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5670]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3089]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.9475]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9024]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3082]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8694]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9626]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8472]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2575]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0873]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1396]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1292]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4801]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8372]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2702]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8344]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8750]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0106]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4611]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7577]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0094]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3370]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4815]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2109]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2603]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5206]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5921]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0470]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2921]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7427]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0165]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3399]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4863]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0097]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4751]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9685]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4921]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6314]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5312]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1717]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5870]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0587]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2662]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7085]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4700]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6328]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1961]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0650]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0144]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4075]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0438]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3531]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7223]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6683]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9986]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1717]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0916]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3871]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4136]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3533]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7758]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6934]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3245]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4444]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9751]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0770]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3134]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0920]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5125]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7450]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9362]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1686]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5774]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.1252]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5327]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7882]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1047]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6130]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9709]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3802]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1845]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0469]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4036]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6706]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3944]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9529]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2334]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.2154]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0455]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6215]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3134]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6682]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4292]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0253]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9655]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3104]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0681]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5881]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1819]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4777]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9009]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6641]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4002]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6844]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9458]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6319]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8777]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.3019]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6822]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0005]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5965]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3166]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8849]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4552]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9747]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4588]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3603]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8699]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8898]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3628]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3421]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7695]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5777]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0788]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0652]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3626]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7570]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4512]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6375]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3655]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1442]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2252]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1826]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6417]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5150]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2863]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2736]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6747]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2891]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1363]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9072]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9685]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1632]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7205]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3205]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4957]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4062]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4914]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1452]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0756]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0795]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9181]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4964]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9482]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7832]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9785]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1306]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[3.1864]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4035]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6226]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8955]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0904]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5986]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4405]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2558]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2551]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3801]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5833]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5456]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4368]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0844]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7736]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8264]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5198]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0103]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1048]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8411]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0771]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1744]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2813]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1243]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0168]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3926]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8056]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9989]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9479]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8391]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8615]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2701]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2085]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7059]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4895]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0000]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8286]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5078]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9403]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8934]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7655]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7511]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6506]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5961]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3300]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2493]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4922]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6008]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6282]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3878]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4060]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8187]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2073]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2521]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1072]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1425]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2290]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0064]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3010]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.7510]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3846]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0339]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1016]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3162]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1574]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2354]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0138]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6026]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3726]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9600]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3025]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2525]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8814]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3432]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0959]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9481]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2877]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6490]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1399]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.2470]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2787]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6032]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6397]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4894]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1050]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8180]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0538]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.5402]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5555]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8155]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9319]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.4486]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6119]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6069]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2669]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0818]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3720]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8193]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5314]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5012]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3514]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0235]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6128]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1718]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4078]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2408]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0678]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8563]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4812]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0241]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6178]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1791]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8526]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7420]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4736]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2977]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0454]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0130]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0279]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2532]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.8066]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0030]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0225]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1699]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2184]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0919]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0656]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0176]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5811]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2671]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3402]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2984]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2239]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.1409]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8899]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3080]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6347]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7918]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1842]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7437]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4949]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5068]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4714]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2404]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8525]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3369]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3165]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3579]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4641]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6767]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7746]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.6759]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2184]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2890]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5485]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2813]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3500]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2257]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2880]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.9694]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6998]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6655]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7014]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.0322]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7008]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2638]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9057]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8415]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5926]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0475]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2318]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7688]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3100]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4544]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3463]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9736]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1493]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1696]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.3217]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.0916]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1165]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3486]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0583]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8012]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2060]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7487]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4763]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4006]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0892]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7287]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2689]])\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1470, 0.1151, 0.0281, 0.7098]], grad_fn=<DivBackward0>) cnt: tensor([[0.5067]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0617]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5605]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7376]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5892]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5358]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4973]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1306]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3093]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0086]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5900]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7832]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0977]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2210]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8571]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0195]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2728]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2698]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.8853]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3580]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3179]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2947]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6661]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1841]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7204]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7403]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7725]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8159]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4102]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.3158]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9738]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6346]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6815]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1337]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2525]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3461]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6599]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6796]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5326]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4825]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3978]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3712]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2946]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7378]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7314]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0635]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3381]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3710]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8970]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5351]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3368]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0030]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6646]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7078]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5886]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2149]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0395]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5422]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2980]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4582]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6298]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3321]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2733]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8765]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0909]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1381]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7138]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0843]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7296]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2046]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0564]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7989]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0965, 0.0823, 0.0305, 0.7907]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9909]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1112]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1592]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7705]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1850]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4535]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9738]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1542, 0.1190, 0.0285, 0.6983]], grad_fn=<DivBackward0>) cnt: tensor([[0.5056]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9014]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3248]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6542]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1719, 0.1293, 0.0276, 0.6712]], grad_fn=<DivBackward0>) cnt: tensor([[0.5064]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2530]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1938, 0.1426, 0.0270, 0.6366]], grad_fn=<DivBackward0>) cnt: tensor([[0.5073]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4099]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1938, 0.1426, 0.0270, 0.6366]], grad_fn=<DivBackward0>) cnt: tensor([[0.5073]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1006]])\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1938, 0.1426, 0.0270, 0.6366]], grad_fn=<DivBackward0>) cnt: tensor([[0.5073]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0294]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1114, 0.0911, 0.0308, 0.7667]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5859]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1114, 0.0911, 0.0308, 0.7667]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7484]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.1114, 0.0911, 0.0308, 0.7667]], grad_fn=<DivBackward0>) cnt: tensor([[0.5063]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1852]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5431]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8241]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6049]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0338]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1964]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9206]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.0048]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0922]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8168]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.4511]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2838]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9695]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9152]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0284]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6915]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1397]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6235]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5355]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0772]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0423]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.4001]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4084]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3866]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.9073]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4500]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8412]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.2861]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.5563]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7942]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5177]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6030]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1858]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1757]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2601]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0398]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5669]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1435]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2339]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.2319]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5122]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3744]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1940]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3138]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5867]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5624]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.6243]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1561]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4382]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.6515]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5171]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.7308]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5012]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7498]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1108]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0415]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5018]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5341]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1582]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3975]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8000]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3426]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2390]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.1840]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5360]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5117]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3714]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.9987]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1049]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.1789]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.1556]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3335]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.5145]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0995]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3909]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4418]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2591]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.2992]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.0538]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.9663]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.3568]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1006]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.5911]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.8986]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4000]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9752]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-2.0768]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8390]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.2348]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3669]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7009]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.8638]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4861]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6299]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7860]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.2847]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-1.3407]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.4625]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.5698]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6960]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.1358]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.4287]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9468]])\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0916, 0.0783, 0.0306, 0.7996]], grad_fn=<DivBackward0>) cnt: tensor([[0.5066]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3005]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.3468]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6309]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7045]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.6813]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.3623]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.7845]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8698]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[1.1239]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.0008]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.8308]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.7678]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[0.6327]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[2.4103]])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc: tensor([[0.0726, 0.0648, 0.0310, 0.8317]], grad_fn=<DivBackward0>) cnt: tensor([[0.5060]], grad_fn=<DivBackward0>)\n",
            "tensor([[-0.9566]])\n",
            "actor loss: 101551.32044048348, critic loss: 634258589.5921865, entropy: 33.022116899490356, KL divergence: 0.015150248829961108\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1], 離散行動：[0, 0], 連続行動：0.021710872650146484\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "1エピソード目の累積報酬：-34623.502669628586, 一つ保全の回数：6658, 二つ保全の回数：871, 三つ保全の回数：663, 違反回数：0\n"
          ]
        }
      ],
      "source": [
        "num_episode = 2 #40分？ 2*4*64\n",
        "best_reward = -np.inf\n",
        "episode_reward_history = []\n",
        "avg_cost = 0\n",
        "\n",
        "for episode in range(num_episode):\n",
        "    episode_reward = 0\n",
        "    operation_time = 0\n",
        "    one_action = 0\n",
        "    two_action = 0\n",
        "    three_action = 0\n",
        "    penalty_action = 0\n",
        "    level_ohe, mstatus_ohe, inventory, demand, remain_interval = env.init_random()\n",
        "    if episode % 100 == 0:\n",
        "        interval_time_episode = time.time()\n",
        "    interval_time_episode = time.time()\n",
        "    for _ in range(1024*8):#1024*8\n",
        "        state = level_ohe + mstatus_ohe + list([inventory,demand])\n",
        "        #print(state)\n",
        "        act_dsc, act_cnt, log_prob, val = agent.choose_action(state)\n",
        "        act_dsc_list = [int(bit) for bit in format(act_dsc.item(), f'0{env.n_units}b')]\n",
        "        if sum(act_dsc_list) == 2:\n",
        "            one_action += 1\n",
        "        elif sum(act_dsc_list) == 1:\n",
        "            two_action += 1\n",
        "        elif sum(act_dsc_list) == 0:\n",
        "            three_action += 1\n",
        "        act_cnt_np = act_cnt.squeeze().cpu().numpy().copy()\n",
        "        act_cnt_np = act_cnt_np * 0.5 + 0.5\n",
        "        #print(act_dsc_list,act_cnt_np)\n",
        "        reward, level_ohe_next, mstatus_ohe_next, inventory_next, demand_next, remain_interval_next, flag = env.operation(act_dsc_list,act_cnt_np)\n",
        "\n",
        "        episode_reward = episode_reward*0.99 + reward\n",
        "        penalty_action += flag\n",
        "        #if remain_interval > remain_interval_next:\n",
        "            #operation_time += (remain_interval+1)/2*interval - (remain_interval_next+1)/2*interval\n",
        "        #else:\n",
        "            #operation_time += (remain_interval_next + 1) / 2 * interval\n",
        "        agent.remember(state, act_dsc.item(), act_cnt.squeeze().cpu().numpy().copy(), log_prob, val, reward, operation_time)\n",
        "        level_ohe = level_ohe_next\n",
        "        mstatus_ohe = mstatus_ohe_next\n",
        "        inventory = inventory_next\n",
        "        demand = demand_next\n",
        "        remain_interval = remain_interval_next\n",
        "    #print(f'{episode}エピソード目の時間：{time.time()-interval_time_episode}')\n",
        "    interval_time_episode = time.time()\n",
        "    agent.learn()\n",
        "\n",
        "    old_agent = Agent(n_units=n_units,\n",
        "                        input_dims=input_size,\n",
        "                        n_states=n_states,\n",
        "                        MAX_maintenance_time=MAX_maintenance_time,\n",
        "                        beta=beta,\n",
        "                        interval=interval,\n",
        "                        alpha_actor=alpha_actor,\n",
        "                        alpha_critic=alpha_critic,\n",
        "                        policy_clip=policy_clip,\n",
        "                        batch_size=batch_size,\n",
        "                        n_epochs=n_epochs)\n",
        "    if episode != 0:\n",
        "        old_agent.load_models()\n",
        "\n",
        "    #if Check_convergence(agent, old_agent, n_units, n_states, MAX_maintenance_time):\n",
        "    #    break\n",
        "\n",
        "\n",
        "\n",
        "    agent.save_models()\n",
        "    print(f'状態{state}, 離散行動：{act_dsc_list}, 連続行動：{act_cnt_np}')\n",
        "    print(f'[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [{env.replace_chance}, {env.failure_keep1}, {env.failure_keep2}, {env.failure_keep3}]')\n",
        "    env.replace_chance = 0\n",
        "    env.failure_keep1 = 0\n",
        "    env.failure_keep2 = 0\n",
        "    env.failure_keep3 = 0\n",
        "    #print(f'{episode}エピソード目の学習時間：{time.time()-interval_time_episode}')\n",
        "    print(f'{episode}エピソード目の累積報酬：{episode_reward}, 一つ保全の回数：{one_action}, 二つ保全の回数：{two_action}, 三つ保全の回数：{three_action}, 違反回数：{penalty_action}')\n",
        "    episode_reward_history.append(episode_reward)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ncPGOL29TYPd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2eaf5715-a8a8-4bc7-cd36-821187012fac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AHLLAogeTYPe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26c32a82-938d-437d-d1f4-7389448aea5a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAIjCAYAAACQ1/NiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACOr0lEQVR4nOzdd3hUddrG8e9MOgkkhJCEQIDQ0qgCUqQTCdIVCy4rqKhrAZWi2AhlXVEEC9JkLdhFXOkKhpJEivQICSRSQie0kAQCaTPn/YOXWbOgEgyZSXJ/rmuua+ec35y5z8iKzzzPnGMyDMNAREREREREHJLZ3gFERERERETk96loExERERERcWAq2kRERERERByYijYREREREREHpqJNRERERETEgaloExERERERcWAq2kRERERERByYijYREREREREHpqJNRERERETEgaloExERKYZ58+ZhMpk4ePCgvaOIiEgFoaJNRETKrOPHjzNhwgQSExPtHUVEROSmUdEmIiJl1vHjx5k4caKKNhERKddUtImIiPyPnJwce0dwOPpMRETsR0WbiIiUqkOHDvHkk08SGhqKh4cH1apV45577rnmb8QyMzMZOXIkdevWxc3NjVq1ajFkyBDOnDlDXFwcrVu3BuChhx7CZDJhMpmYN2+e7fULFiygZcuWeHh44Ofnx9///neOHTtW5D0efPBBvLy82L9/P7169aJy5coMHjy42Oc1a9YsIiMjcXNzIygoiKeeeorMzMwia/bu3cvAgQMJDAzE3d2dWrVqMWjQILKysmxrYmNj6dChAz4+Pnh5eREaGspLL710XRk+//xzbr31VipVqkTVqlXp1KkTP/74o22/yWRiwoQJV72ubt26PPjgg7bnV363Fx8fz5NPPom/vz+1atXi22+/tW3/X++//z4mk4mkpCTbtpSUFO6++258fX1xd3enVatWLFmy5LrORURE/svZ3gFERKRi2bJlCxs2bGDQoEHUqlWLgwcPMnv2bLp06cLu3bupVKkSABcuXKBjx47s2bOHhx9+mFtuuYUzZ86wZMkSjh49Snh4OJMmTSImJobHHnuMjh07AtC+fXvgcuHx0EMP0bp1ayZPnszJkyd59913Wb9+PTt27MDHx8eWqbCwkOjoaDp06MDUqVNtGa7XhAkTmDhxIlFRUTzxxBOkpqYye/ZstmzZwvr163FxcSE/P5/o6Gjy8vIYMWIEgYGBHDt2jGXLlpGZmYm3tzfJycn06dOHpk2bMmnSJNzc3Ni3bx/r16//0wwTJ05kwoQJtG/fnkmTJuHq6sqmTZtYs2YNPXr0KNb5XPHkk09SvXp1YmJiyMnJoXfv3nh5efHNN9/QuXPnImvnz59PZGQkjRs3BiA5OZnbbruNmjVr8sILL+Dp6ck333zDgAED+M9//sOdd955Q5lERCokQ0REpBRdvHjxqm0bN240AOPTTz+1bYuJiTEA47vvvrtqvdVqNQzDMLZs2WIAxscff1xkf35+vuHv7280btzYuHTpkm37smXLDMCIiYmxbRs6dKgBGC+88MJ15f/4448NwEhLSzMMwzBOnTpluLq6Gj169DAsFott3YwZMwzA+OijjwzDMIwdO3YYgLFgwYLfPfbbb79tAMbp06evK8sVe/fuNcxms3HnnXcWyWAY//2sDMMwAGP8+PFXvb5OnTrG0KFDrzrHDh06GIWFhUXW3n///Ya/v3+R7SdOnDDMZrMxadIk27bu3bsbTZo0MXJzc4tkad++vdGwYcNinZ+ISEWn8UgRESlVHh4etv9dUFDA2bNnadCgAT4+Pmzfvt227z//+Q/NmjW7ZkfGZDL94Xts3bqVU6dO8eSTT+Lu7m7b3rt3b8LCwli+fPlVr3niiSdu5HRYtWoV+fn5PPvss5jN//1r9dFHH6VKlSq29/L29gZg5cqVXLx48ZrHutL9W7x4MVar9bozLFq0CKvVSkxMTJEM8Oef1R959NFHcXJyKrLtvvvu49SpU8TFxdm2ffvtt1itVu677z4AMjIyWLNmDffeey/nz5/nzJkznDlzhrNnzxIdHc3evXuvGlMVEZHfp6JNRERK1aVLl4iJiSE4OBg3Nzf8/PyoXr06mZmZRX7btX//ftuoXXEdOnQIgNDQ0Kv2hYWF2fZf4ezsTK1atUr0vVxdXalXr55tf0hICKNGjeKDDz7Az8+P6OhoZs6cWeSc77vvPm677TYeeeQRAgICGDRoEN98882fFnD79+/HbDYTERFxQ+fwe0JCQq7a1rNnT7y9vZk/f75t2/z582nevDmNGjUCYN++fRiGwbhx46hevXqRx/jx4wE4depUiWYVESnP9Js2EREpVSNGjODjjz/m2WefpV27dnh7e2MymRg0aFCxukslyc3N7aoO1c0wbdo0HnzwQRYvXsyPP/7I008/zeTJk/n555+pVasWHh4eJCQksHbtWpYvX86KFSuYP38+3bp148cff7yq61VSLBbLNbf/tit6hZubGwMGDGDhwoXMmjWLkydPsn79el577TXbmiv/HMeMGUN0dPQ1j92gQYMSSC4iUjGoaBMRkVL17bffMnToUKZNm2bblpube9WVFuvXr1/kSoTX8nujf3Xq1AEgNTWVbt26FdmXmppq218Sfvte9erVs23Pz88nLS2NqKioIuubNGlCkyZNeOWVV9iwYQO33XYbc+bM4dVXXwXAbDbTvXt3unfvzltvvcVrr73Gyy+/zNq1a6861hX169fHarWye/dumjdv/rtZq1atetXnnJ+fz4kTJ4p1zvfddx+ffPIJq1evZs+ePRiGYRuNBGyfg4uLy+9mFhGR66fxSBERKVVOTk4YhlFk23vvvXdVt2fgwIH88ssvLFy48KpjXHm9p6cnwFWFSKtWrfD392fOnDnk5eXZtv/www/s2bOH3r17l8SpABAVFYWrqyvTp08vcl4ffvghWVlZtvfKzs6msLCwyGubNGmC2Wy2ZczIyLjq+FeKsN+ex/8aMGAAZrOZSZMmXdWt/G2m+vXrk5CQUGT/3Llzf7fT9nuioqLw9fVl/vz5zJ8/n1tvvbXIKKW/vz9dunTh/fffv2ZBePr06WK9n4hIRadOm4iIlKo+ffrw2Wef4e3tTUREBBs3bmTVqlVUq1atyLrnnnuOb7/9lnvuuYeHH36Yli1bkpGRwZIlS5gzZw7NmjWjfv36+Pj4MGfOHCpXroynpydt2rQhJCSEN954g4ceeojOnTtz//332y75X7duXUaOHFli51O9enVefPFFJk6cSM+ePenXrx+pqanMmjWL1q1b8/e//x2ANWvWMHz4cO655x4aNWpEYWEhn332GU5OTgwcOBCASZMmkZCQQO/evalTpw6nTp1i1qxZ1KpViw4dOvxuhgYNGvDyyy/zz3/+k44dO3LXXXfh5ubGli1bCAoKYvLkyQA88sgjPP744wwcOJDbb7+dX375hZUrV+Ln51esc3ZxceGuu+7i66+/Jicnh6lTp161ZubMmXTo0IEmTZrw6KOPUq9ePU6ePMnGjRs5evQov/zyS7HeU0SkQrPnpStFRKTiOXfunPHQQw8Zfn5+hpeXlxEdHW2kpKRcddl5wzCMs2fPGsOHDzdq1qxpuLq6GrVq1TKGDh1qnDlzxrZm8eLFRkREhOHs7HzV5f/nz59vtGjRwnBzczN8fX2NwYMHG0ePHi3yHkOHDjU8PT2vO///XvL/ihkzZhhhYWGGi4uLERAQYDzxxBPGuXPnbPsPHDhgPPzww0b9+vUNd3d3w9fX1+jatauxatUq25rVq1cb/fv3N4KCggxXV1cjKCjIuP/++41ff/31urJ99NFHtvOtWrWq0blzZyM2Nta232KxGGPHjjX8/PyMSpUqGdHR0ca+fft+95L/W7Zs+d33io2NNQDDZDIZR44cueaa/fv3G0OGDDECAwMNFxcXo2bNmkafPn2Mb7/99rrOR0RELjMZxv/MqIiIiIiIiIjD0G/aREREREREHJiKNhEREREREQemok1ERERERMSBqWgTERERERFxYCraREREREREHJiKNhEREREREQemm2uXIqvVyvHjx6lcuTImk8necURERERExE4Mw+D8+fMEBQVhNv9xL01FWyk6fvw4wcHB9o4hIiIiIiIO4siRI9SqVesP16hoK0WVK1cGLv+DqVKlip3TiIiIiIiIvWRnZxMcHGyrEf6IirZSdGUkskqVKiraRERERETkun42pQuRiIiIiIiIODAVbSIiIiIiIg5MRZuIiIiIiIgD02/aRERERKRcMwyDwsJCLBaLvaNIBeLk5ISzs3OJ3OpLRZuIiIiIlFv5+fmcOHGCixcv2juKVECVKlWiRo0auLq6/qXjqGgTERERkXLJarWSlpaGk5MTQUFBuLq6lkjXQ+TPGIZBfn4+p0+fJi0tjYYNG/7pDbT/iIo2ERERESmX8vPzsVqtBAcHU6lSJXvHkQrGw8MDFxcXDh06RH5+Pu7u7jd8LF2IRERERETKtb/S4RD5K0rqz57+BIuIiIiIiDgwFW0iIiIiIiIOTEWbiIiIiEg5dPDgQUwmE4mJiTftPR588EEGDBhw045fFtStW5d33nnnpr6HijYREREREQfz4IMPYjKZrnr07Nnzuo8RHBzMiRMnaNy48U1M+td16dLFdn7u7u40atSIyZMnYxiGvaM5DF09UkRERETEAfXs2ZOPP/64yDY3N7frfr2TkxOBgYElHeumePTRR5k0aRJ5eXmsWbOGxx57DB8fH5544gl7RwPAYrFgMpnsdlEbddpEREREpMIwDIOL+YV2eRS3c+Tm5kZgYGCRR9WqVW37TSYTs2fP5o477sDDw4N69erx7bff2vb/73jkuXPnGDx4MNWrV8fDw4OGDRsWKQp37dpFt27d8PDwoFq1ajz22GNcuHDBtt9isTBq1Ch8fHyoVq0azz///FXnZLVamTx5MiEhIXh4eNCsWbMimX5PpUqVCAwMpE6dOjz00EM0bdqU2NhY2/68vDzGjBlDzZo18fT0pE2bNsTFxdn+mVavXr3I+zRv3pwaNWrYnq9btw43NzfbTdbfeustmjRpgqenJ8HBwTz55JNFznXevHn4+PiwZMkSIiIicHNz4/Dhw5w6dYq+ffvi4eFBSEgIX3zxxZ+eW0lQp01EREREKoxLBRYiYlba5b13T4qmkmvJ/uf3uHHjeP3113n33Xf57LPPGDRoELt27SI8PPyaa3fv3s0PP/yAn58f+/bt49KlSwDk5OQQHR1Nu3bt2LJlC6dOneKRRx5h+PDhzJs3D4Bp06Yxb948PvroI8LDw5k2bRoLFy6kW7dutveYPHkyn3/+OXPmzKFhw4YkJCTw97//nerVq9O5c+c/PR/DMFi3bh0pKSk0bNjQtn348OHs3r2br7/+mqCgIBYuXEjPnj3ZtWsXDRs2pFOnTsTFxXH33Xdz7tw59uzZg4eHBykpKYSFhREfH0/r1q1t9+szm81Mnz6dkJAQDhw4wJNPPsnzzz/PrFmzbO958eJF3njjDT744AOqVauGv78/d999N8ePH2ft2rW4uLjw9NNPc+rUqRv6Z1ccKtpERERERBzQsmXL8PLyKrLtpZde4qWXXrI9v+eee3jkkUcA+Oc//0lsbCzvvfdekeLjisOHD9OiRQtatWoFXL6AxhVffvklubm5fPrpp3h6egIwY8YM+vbtyxtvvEFAQADvvPMOL774InfddRcAc+bMYeXK/xbAeXl5vPbaa6xatYp27doBUK9ePdatW8f777//h0XbrFmz+OCDD8jPz6egoAB3d3eefvppW+6PP/6Yw4cPExQUBMCYMWNYsWIFH3/8Ma+99hpdunTh/fffByAhIYEWLVoQGBhIXFwcYWFhxMXFFXn/Z5991va/69aty6uvvsrjjz9e5HMrKChg1qxZNGvWDIBff/2VH374gc2bN9O6dWsAPvzww2sWyCVNRVsFte3QOY6eu0i/ZkGYTCZ7xxEREREpFR4uTuyeFG239y6Orl27Mnv27CLbfH19izy/Uhz99vnvXS3yiSeeYODAgWzfvp0ePXowYMAA2rdvD8CePXto1qyZrWADuO2227BaraSmpuLu7s6JEydo06aNbb+zszOtWrWyjUju27ePixcvcvvttxd53/z8fFq0aPGH5zp48GBefvllzp07x/jx42nfvr0t265du7BYLDRq1KjIa/Ly8qhWrRoAnTt35plnnuH06dPEx8fTpUsXW9E2bNgwNmzYwPPPP2977apVq5g8eTIpKSlkZ2dTWFhIbm4uFy9etHXjXF1dadq0qe01e/bswdnZmZYtW9q2hYWF4ePj84fnVhJUtFVAhRYrLy/cRUr6eb7cdJhJ/RsTGljZ3rFEREREbjqTyVTiI4o3i6enJw0aNCix491xxx0cOnSI77//ntjYWLp3785TTz3F1KlTS+T4V34Ttnz5cmrWrFlk359dQMXb29t2rt988w0NGjSgbdu2REVFceHCBZycnNi2bRtOTkUL3yudyCZNmuDr60t8fDzx8fH861//IjAwkDfeeIMtW7ZQUFBgKwIPHjxInz59eOKJJ/jXv/6Fr68v69atY9iwYeTn59uKNg8PD4dpbuhCJBWQ1YA+TWvg7mJmU1oGvab/xMSlyWTnFtg7moiIiIgUw88//3zV8z8a16tevTpDhw7l888/55133mHu3LkAhIeH88svv5CTk2Nbu379esxmM6GhoXh7e1OjRg02bdpk219YWMi2bdtsz397wY4GDRoUeQQHB1/3OXl5efHMM88wZswYDMOgRYsWWCwWTp06ddVxr1wd02Qy0bFjRxYvXkxycjIdOnSgadOm5OXl8f7779OqVStbF3Hbtm1YrVamTZtG27ZtadSoEcePH//TXGFhYVedc2pqKpmZmdd9bjdKRVsF5OpsZni3hqwa1ZmekYFYrAYfrz9It6nx/GfbUd0TQ0RERMQB5OXlkZ6eXuRx5syZImsWLFjARx99xK+//sr48ePZvHkzw4cPv+bxYmJiWLx4Mfv27SM5OZlly5bZCrzBgwfj7u7O0KFDSUpKYu3atYwYMYIHHniAgIAAAJ555hlef/11Fi1aREpKCk8++WSRgqVy5cqMGTOGkSNH8sknn7B//362b9/Oe++9xyeffFKsc//HP/7Br7/+yn/+8x8aNWrE4MGDGTJkCN999x1paWls3ryZyZMns3z5cttrunTpwldffUXz5s3x8vLCbDbTqVMnvvjiiyK/Z2vQoAEFBQW89957HDhwgM8++4w5c+b8aabQ0FB69uzJP/7xDzZt2sS2bdt45JFH8PDwKNa53QgVbRVYraqVmPNASz59+FbqVffkzIU8Ri/4hXvmbCT5eJa944mIiIhUaCtWrKBGjRpFHh06dCiyZuLEiXz99dc0bdqUTz/9lK+++oqIiIhrHs/V1ZUXX3yRpk2b0qlTJ5ycnPj666+By5fcX7lyJRkZGbRu3Zq7776b7t27M2PGDNvrR48ezQMPPMDQoUNp164dlStX5s477yzyHv/85z8ZN24ckydPJjw8nJ49e7J8+XJCQkKKde6+vr4MGTKECRMmYLVa+fjjjxkyZAijR48mNDSUAQMGsGXLFmrXrm17TefOnbFYLHTp0sW2rUuXLldta9asGW+99RZvvPEGjRs35osvvmDy5MnXlevjjz8mKCiIzp07c9ddd/HYY4/h7+9frHO7ESZDbZVSk52djbe3N1lZWVSpUsXecYrIL7Ty4bo03luzl4v5Fswm+HvbOoy+PRTvSi72jiciIiJSbLm5uaSlpRESEoK7u7u945Q4k8nEwoULGTBggL2jyO/4oz+DxakN7NppS0hIoG/fvgQFXb6C4aJFi4rsN5lM13y8+eabtjUZGRkMHjyYKlWq4OPjw7Bhw4rcGA9g586ddOzYEXd3d4KDg5kyZcpVWRYsWEBYWBju7u40adKE77//vsh+wzCIiYmhRo0aeHh4EBUVxd69e0vuw7AzV2czT3Spz+rRnenTtAZWAz7deIiu0+KYv+UwVqtqexERERERe7Br0ZaTk0OzZs2YOXPmNfefOHGiyOOjjz7CZDIxcOBA25rBgweTnJxMbGwsy5YtIyEhgccee8y2Pzs7mx49elCnTh22bdvGm2++yYQJE2w/ugTYsGED999/P8OGDWPHjh0MGDCAAQMGkJSUZFszZcoUpk+fzpw5c9i0aROenp5ER0eTm5t7Ez4Z+6nh7cGMv93Cl4+0oaG/Fxk5+Yz9zy7unL2BnUcz7R1PRERERKTCcZjxyOtp7w4YMIDz58+zevVq4PK9EiIiItiyZYvtJoErVqygV69eHD16lKCgIGbPns3LL79Meno6rq6uALzwwgu2H1AC3HfffeTk5LBs2TLbe7Vt25bmzZszZ84cDMMgKCiI0aNHM2bMGACysrIICAhg3rx5DBo06LrO0ZHHI6+lwGLlkw0HeWfVXi7kFWIywaDWtXkuOhRfT1d7xxMRERH5Q+V9PFIcX7kYjyyOkydPsnz5coYNG2bbtnHjRnx8fGwFG0BUVBRms9l2OdKNGzfSqVMnW8EGEB0dTWpqKufOnbOtiYqKKvJ+0dHRbNy4EYC0tDTS09OLrPH29qZNmza2NdeSl5dHdnZ2kUdZ4uJk5pGO9VgzujN3tqiJYcBXmw/TbVocn/98CItGJkVEREREbroyU7R98sknVK5cmbvuusu2LT09/aqrtTg7O+Pr60t6erptzZXLlF5x5fmfrfnt/t++7lprrmXy5Ml4e3vbHsW5P4Uj8a/iztv3Neebf7QjLLAymRcLeGVREv1nrmPboXP2jiciIiLyhxxksEwqoJL6s1dmiraPPvrIdv+IsuLFF18kKyvL9jhy5Ii9I/0lt4b4smxEByb0jaCyuzNJx7IZOHsDzy34hTMX8uwdT0RERKQIF5fLV8C+ePGinZNIRXXlz96VP4s3yrkkwtxsP/30E6mpqcyfP7/I9sDAQE6dOlVkW2FhIRkZGba7owcGBnLy5Mkia648/7M1v91/ZVuNGjWKrGnevPnv5nZzc8PNze16T7NMcHYy8+BtIfRpFsQbP6SwYNtRFmw7yorkdEbf3oi/t62Ds1OZ+S5AREREyjEnJyd8fHxs/71YqVIlTCaTnVNJRWAYBhcvXuTUqVP4+Pjg5OT0l45XJoq2Dz/8kJYtW9KsWbMi29u1a0dmZibbtm2jZcuWAKxZswar1UqbNm1sa15++WUKCgpsFW5sbCyhoaFUrVrVtmb16tU8++yztmPHxsbSrl07AEJCQggMDGT16tW2Ii07O5tNmzbxxBNP3MxTd1h+Xm68eU8z7m9Tm5jFSSQdy2bC0t18veUIk/o35tYQX3tHFBEREbF9+f6/X/SLlAYfHx/bn8G/wq5Xj7xw4QL79u0DoEWLFrz11lt07doVX19f293Ns7OzqVGjBtOmTePxxx+/6hh33HEHJ0+eZM6cORQUFPDQQw/RqlUrvvzyS+DyVR5DQ0Pp0aMHY8eOJSkpiYcffpi3337bdmuADRs20LlzZ15//XV69+7N119/zWuvvcb27dtp3LgxAG+88Qavv/46n3zyCSEhIYwbN46dO3eye/fu6x7ZLGtXj7xeFqvBV5sP8+bKVLIuFQBwZ4uavHhHGP5Vys44q4iIiJRfFouFgoICe8eQCsTFxeUPO2zFqQ3sWrTFxcXRtWvXq7YPHTqUefPmATB37lyeffZZTpw4gbe391VrMzIyGD58OEuXLsVsNjNw4ECmT5+Ol5eXbc3OnTt56qmn2LJlC35+fowYMYKxY8cWOc6CBQt45ZVXOHjwIA0bNmTKlCn06tXLtt8wDMaPH8/cuXPJzMykQ4cOzJo1i0aNGl33+ZbXou2KjJx83lyZytdbDmMY4OXmzLNRDRnavi4uGpkUEREREbEpM0VbRVPei7YrfjmSScySZH45kglAQ38vJvaPpH19P/sGExERERFxECraHFRFKdoArFaDBduO8MaKVDJy8gHo07QGL/cOp4a3h53TiYiIiIjYV7m8ubaULWazifta12bN6M4MaVcHswmW7TxB92nxzI7bT36h1d4RRURERETKBHXaSlFF6rT9r+TjWcQsTrbdjLuenycT+kXSqVF1OycTERERESl9Go90UBW5aIPLF3P5bvsxJv+QYrsZd8/IQF7pE06tqpXsnE5EREREpPRoPFIckslkYmDLWqwZ05mHbwvByWxiRXI6UW/F897qveQWWOwdUURERETE4ajTVooqeqftf6WkZxOzOJnNaRkA1KlWifF9I+gWFmDnZCIiIiIiN5fGIx2UirarGYbBkl+O89r3eziZfXlkMircn5g+kdSuppFJERERESmfNB4pZYbJZKJ/85qsHt2Ff3Sqh7PZxKo9p4h6O563Yn/VyKSIiIiIVHjqtJUiddr+3L5T5xm/JJn1+84CUKuqB+P6RNAjIgCTyWTndCIiIiIiJUPjkQ5KRdv1MQyDH5LSeXXZbo5n5QLQuVF1JvSLJMTP087pRERERET+OhVtDkpFW/FczC9k5tp9/DshjXyLFVcnM490DGF4twZUcnW2dzwRERERkRumos1BqWi7MWlncpiwJJn4X08DEOTtzit9IrijcaBGJkVERESkTFLR5qBUtN04wzCI3X2SSct2c/TcJQA6NPBjQr8IGvhXtnM6EREREZHiUdHmoFS0/XW5BRZmx+1ndvx+8gutOJtNPNwhhKe7N8TLTSOTIiIiIlI26JL/Um65uzgx8vZGrBrZmahwfwqtBnMTDtB9WhyLE4+h7yBEREREpLxRp60UqdNW8taknGTi0t0cOnsRgDYhvkzq35jQQI1MioiIiIjj0nikg1LRdnPkFlj44KcDzFi7j9wCK05mE0Pa1WHk7Y2o4u5i73giIiIiIlfReKRUKO4uTgzv1pBVozpzR+NALFaDj9cfpNvUOL7ddhSrVd9LiIiIiEjZpU5bKVKnrXQk/HqaCUuTOXA6B4CWdaoyqX8kkUHedk4mIiIiInKZxiMdlIq20pNfaOWj9WlMX72Xi/kWzCb4e9s6jL49FO9KGpkUEREREfvSeKRUeK7OZh7vXJ/VozvTp2kNrAZ8uvEQXafFMX/LYY1MioiIiEiZoU5bKVKnzX427D/D+MXJ7D11AYBmwT78s38kTWv52DeYiIiIiFRIGo90UCra7KvAYuWTDQd5Z9VeLuQVYjLBoNbBPBcdhq+nq73jiYiIiEgFovFIkWtwcTLzSMd6rBndmTtb1MQw4KvNR+g2LY7Pfz6ERSOTIiIiIuKA1GkrReq0OZbNaRnELE4iJf08AI1rVmFiv8a0rFPVzslEREREpLzTeKSDUtHmeAotVr7YdJipP6ZyPrcQgHta1mLsHWH4ebnZOZ2IiIiIlFcajxS5Ts5OZoa2r8vaMV24t1UtABZsO0rXqXHMW59GocVq54QiIiIiUtGp01aK1GlzfNsPnyNmcRJJx7IBCAuszKT+jbk1xNfOyURERESkPNF4pINS0VY2WKwGX20+zJsrU8m6VADAnS1q8uIdYfhXcbdzOhEREREpDzQeKfIXOJlN/L1tHdaO6cL9t9bGZIKFO47RbVo8H/x0gAKNTIqIiIhIKVKnrRSp01Y27TyaybjFyfxyJBOAhv5eTOwfSfv6fvYNJiIiIiJllsYjHZSKtrLLajVYsO0Ib6xIJSMnH4DeTWvwSu9wanh72DmdiIiIiJQ1Go8UKWFms4n7Wtdm7eguDGlXB7MJlu88Qfdp8cyO209+oUYmRUREROTmUKetFKnTVn4kH89i/OJkth46B0A9P08m9IukU6Pqdk4mIiIiImWBxiMdlIq28sUwDL7bfozJP6Rw5kIeAD0jA3mlTzi1qlayczoRERERcWQajxQpBSaTiYEta7FmTGcevi0EJ7OJFcnpRL0Vz3ur95JbYLF3RBEREREpB9RpK0XqtJVvKenZjF+czKa0DADqVKvE+L4RdAsLsHMyEREREXE0Go90UCrayj/DMFjyy3Fe+34PJ7Mvj0xGhfsT0yeS2tU0MikiIiIil2k8UsROTCYT/ZvXZPXoLvyjUz2czSZW7TlF1NvxvBX7q0YmRURERKTY1GkrReq0VTz7Tl1gwpJk1u07A0Ctqh6M6xNBj4gATCaTndOJiIiIiL1oPNJBqWirmAzD4IekdF5dtpvjWbkAdG5UnfF9I6hX3cvO6URERETEHlS0OSgVbRXbxfxCZq7dx78T0si3WHF1MvNIxxCGd2tAJVdne8cTERERkVKkos1BqWgTgLQzOUxcmkxc6mkAani780rvCHo1CdTIpIiIiEgFoaLNQalokysMwyB290kmLdvN0XOXALitQTUm9oukgX9lO6cTERERkZtNRZuDUtEm/yu3wMLsuP3Mjt9PfqEVZ7OJhzuE8HT3hni5aWRSREREpLzSJf9Fygh3FydG3t6IVSM7ExUeQKHVYG7CAbpNjWNx4jH0nYqIiIiIqNNWitRpkz+zNuUUE5Ymc+jsRQBuDfFlUv9IwgL150VERESkPNF4pINS0SbXI7fAwgc/HWDG2n3kFlhxMpsY0q4OI29vRBV3F3vHExEREZESoPFIkTLM3cWJ4d0asmpUZ+5oHIjFavDx+oN0mxrHt9uOYrXqexYRERGRisSuRVtCQgJ9+/YlKCgIk8nEokWLrlqzZ88e+vXrh7e3N56enrRu3ZrDhw/b9ufm5vLUU09RrVo1vLy8GDhwICdPnixyjMOHD9O7d28qVaqEv78/zz33HIWFhUXWxMXFccstt+Dm5kaDBg2YN2/eVVlmzpxJ3bp1cXd3p02bNmzevLlEPgeRa6lVtRKz/96STx++lXrVPTlzIZ8xC37hnvc3knQsy97xRERERKSU2LVoy8nJoVmzZsycOfOa+/fv30+HDh0ICwsjLi6OnTt3Mm7cONzd3W1rRo4cydKlS1mwYAHx8fEcP36cu+66y7bfYrHQu3dv8vPz2bBhA5988gnz5s0jJibGtiYtLY3evXvTtWtXEhMTefbZZ3nkkUdYuXKlbc38+fMZNWoU48ePZ/v27TRr1ozo6GhOnTp1Ez4Zkf/q1Kg6K57pxAt3hFHJ1Ylth87Rb8Y6xi1KIutigb3jiYiIiMhN5jC/aTOZTCxcuJABAwbYtg0aNAgXFxc+++yza74mKyuL6tWr8+WXX3L33XcDkJKSQnh4OBs3bqRt27b88MMP9OnTh+PHjxMQEADAnDlzGDt2LKdPn8bV1ZWxY8eyfPlykpKSirx3ZmYmK1asAKBNmza0bt2aGTNmAGC1WgkODmbEiBG88MIL13WO+k2b/FUnsi7xr+V7WLbzBAC+nq48Hx3Kva2CMZt1Y24RERGRsqJc/KbNarWyfPlyGjVqRHR0NP7+/rRp06bICOW2bdsoKCggKirKti0sLIzatWuzceNGADZu3EiTJk1sBRtAdHQ02dnZJCcn29b89hhX1lw5Rn5+Ptu2bSuyxmw2ExUVZVtzLXl5eWRnZxd5iPwVNbw9mPG3W/jy0TY09PciIyefF77bxZ2zN7DzaKa944mIiIjITeCwRdupU6e4cOECr7/+Oj179uTHH3/kzjvv5K677iI+Ph6A9PR0XF1d8fHxKfLagIAA0tPTbWt+W7Bd2X9l3x+tyc7O5tKlS5w5cwaLxXLNNVeOcS2TJ0/G29vb9ggODi7+ByFyDe3r+/H9Mx15pXc4Xm7O/HIkk/4z1/PidzvJyMm3dzwRERERKUEOW7RZrVYA+vfvz8iRI2nevDkvvPACffr0Yc6cOXZOd31efPFFsrKybI8jR47YO5KUIy5OZh7pWI81oztzV4uaGAZ8tfkIXafG8dnPh7DoKpMiIiIi5YLDFm1+fn44OzsTERFRZHt4eLjt6pGBgYHk5+eTmZlZZM3JkycJDAy0rfnfq0leef5na6pUqYKHhwd+fn44OTldc82VY1yLm5sbVapUKfIQKWn+Vdx5677mLHi8HWGBlcm6VMC4RUn0n7mObYfO2TueiIiIiPxFDlu0ubq60rp1a1JTU4ts//XXX6lTpw4ALVu2xMXFhdWrV9v2p6amcvjwYdq1awdAu3bt2LVrV5GrPMbGxlKlShVbQdiuXbsix7iy5soxXF1dadmyZZE1VquV1atX29aI2Fvrur4sG9GBif0iqezuTNKxbAbO3sCYBb9w5kKeveOJiIiIyA1ytuebX7hwgX379tmep6WlkZiYiK+vL7Vr1+a5557jvvvuo1OnTnTt2pUVK1awdOlS4uLiAPD29mbYsGGMGjUKX19fqlSpwogRI2jXrh1t27YFoEePHkRERPDAAw8wZcoU0tPTeeWVV3jqqadwc3MD4PHHH2fGjBk8//zzPPzww6xZs4ZvvvmG5cuX27KNGjWKoUOH0qpVK2699VbeeecdcnJyeOihh0rvAxP5E85OZoa2r0vvpjWYsiKFb7Ye5dttR1mZnM6o2xvxQNs6ODs57Hc1IiIiInINdr3kf1xcHF27dr1q+9ChQ203t/7oo4+YPHkyR48eJTQ0lIkTJ9K/f3/b2tzcXEaPHs1XX31FXl4e0dHRzJo1q8jY4qFDh3jiiSeIi4vD09OToUOH8vrrr+Ps/N+aNS4ujpEjR7J7925q1arFuHHjePDBB4vkmjFjBm+++Sbp6ek0b96c6dOn06ZNm+s+X13yX0rb9sPniFmcRNKxy1cuDQuszMR+kbSpV83OyUREREQqtuLUBg5zn7aKQEWb2IPFavD1lsO8uTKVzP+/GfeA5kG81Csc/yruf/JqEREREbkZysV92kSkZDiZTQxuU4e1o7tw/621MZlgUeJxuk2L54OfDlBgsdo7ooiIiIj8AXXaSpE6beIIdh7NJGZxMolHMgFo6O/FxP6RtK/vZ99gIiIiIhWIxiMdlIo2cRRWq8G3247y+ooU2824ezetwSu9w6nh7WHndCIiIiLln8YjReQPmc0m7m0dzNrRXRjarg5mEyzfeYJuU+OZFbeP/EKNTIqIiIg4CnXaSpE6beKoko9nMX5xMlv//2bc9fw8mdAvkk6Nqts5mYiIiEj5pPFIB6WiTRyZYRgs3HGM175Psd2MOzoygHF9IqhVtZKd04mIiIiULxqPFJFiM5lM3HVLLdaM6czDt4XgZDaxMvkkUW/F897qveQWWOwdUURERKRCUqetFKnTJmVJavp5YhYnsSktA4A61Soxvm8E3cIC7JxMREREpOzTeKSDUtEmZY1hGCzdeYJ/Ld/NyezLI5Pdw/wZ3zeS2tU0MikiIiJyozQeKSIlwmQy0a9ZEKtHd+EfnerhbDaxOuUUUW/H81bsr1zK18ikiIiIyM2mTlspUqdNyrp9py4wYUky6/adAaCmjwcxfSPoERGAyWSyczoRERGRskPjkQ5KRZuUB4ZhsCIpnX8u283xrFwAOjeqzvi+EdSr7mXndCIiIiJlg4o2B6WiTcqTi/mFzFq7n7kJB8i3WHFxMvFIx3qM6NaASq7O9o4nIiIi4tBUtDkoFW1SHqWdyWHi0mTiUk8DUMPbnVd6R9CrSaBGJkVERER+h4o2B6WiTcorwzCI3X2SSct2c/TcJQBua1CNif0iaeBf2c7pRERERByPijYHpaJNyrvcAguz4/YzO34/+YVWnM0mHu4QwtPdG+LlppFJERERkSt0yX8RsQt3FydG3t6IVSM7ExUeQKHVYG7CAbpNjWNx4jH0HZGIiIhI8anTVorUaZOKZm3KKSYsTebQ2YsA3Briy6T+kYQF6s+/iIiIVGwaj3RQKtqkIsotsPDBTweYsXYfuQVWnMwmhrSrw7NRjfD2cLF3PBERERG70HikiDgMdxcnhndryOrRXbijcSAWq8HH6w/SfVoc3247itWq741ERERE/og6baVInTYR+GnvacYvSebA6RwAWtapysR+kTSu6W3nZCIiIiKlR+ORDkpFm8hl+YVWPlqfxvTVe7mYb8FsgsFt6jC6RyN8KrnaO56IiIjITafxSBFxaK7OZh7vXJ81o7vQt1kQVgM++/kQ3abF8/XmwxqZFBEREfkNddpKkTptIte2Yf8Zxi9OZu+pCwA0q+XNpP6NaRbsY99gIiIiIjeJxiMdlIo2kd9XYLHyyYaDvLNqLxfyCjGZYFDrYJ6LDsPXUyOTIiIiUr5oPFJEyhwXJzOPdKzHmjGduatFTQwDvtp8hK5T4/js50NYNDIpIiIiFZQ6baVInTaR67flYAbjFiWRkn4egMigKkzq35iWdaraOZmIiIjIX6fxSAelok2keAotVr7YdJipP6ZyPrcQgLtb1mJszzCqV3azczoRERGRG6fxSBEpF5ydzAxtX5e1Y7pwb6taAHy77SjdpsXx8fo0Ci1WOycUERERufnUaStF6rSJ/DXbD58jZnESSceyAQgLrMzEfpG0qVfNzslEREREikfjkQ5KRZvIX2exGny95TBvrkwl82IBAAOaB/Fir3ACqrjbOZ2IiIjI9dF4pIiUW05mE4Pb1GHt6C78rU1tTCZYlHicblPj+HfCAQo0MikiIiLljDptpUidNpGSt/NoJjGLk0k8kglAA38vJvWLpH0DP/sGExEREfkDGo90UCraRG4Oq9Xg221HeX1FChk5+QD0blqDV3qHU8Pbw87pRERERK6m8UgRqVDMZhP3tg5m7eguDG1XB7MJlu88Qbep8cyK20deocXeEUVERERumDptpUidNpHSkXw8i/GLk9l66BwA9fw8Gd8vks6Nqts5mYiIiMhlGo90UCraREqPYRgs3HGM175P4cyFPACiIwN4pXcEwb6V7JxOREREKjqNR4pIhWcymbjrllqsGdOZYR1CcDKbWJl8kqi34pm+ei+5BRqZFBERkbJBnbZSpE6biP2kpp8nZnESm9IyAKjtW4nxfSPoHh5g52QiIiJSEWk80kGpaBOxL8MwWLrzBP9avpuT2ZdHJruH+RPTN4I61TztnE5EREQqEo1Hiohcg8lkol+zIFaP7sI/OtfD2Wxidcopbn87gbd+TOVSvkYmRURExPGo01aK1GkTcSz7Tl1gwpJk1u07A0BNHw9i+kbQIyIAk8lk53QiIiJSnqnTJiJyHRr4e/HZsFuZPfgWgrzdOZZ5iX98to2hH2/hwOkL9o4nIiIiAqjTVqrUaRNxXBfzC5m1dj9zEw6Qb7Hi4mTikY71GNGtAZVcne0dT0RERMoZXYjEQaloE3F8aWdymLg0mbjU0wDU8Hbn5d7h9G5SQyOTIiIiUmJUtDkoFW0iZYNhGKzac4qJS5M5eu4SALc1qMaEvpE0DKhs53QiIiJSHqhoc1Aq2kTKltwCC7Pj9jM7fj/5hVaczSYeuq0uz0Q1wstNI5MiIiJy43QhEhGREuDu4sTI2xuxamRnosIDKLQa/PunNLpNjWNx4jH0nZeIiIiUBnXaSpE6bSJl29qUyyOTB89eBODWEF8m9Y8kLFD/fxYREZHi0Xikg1LRJlL25RZY+HBdGu+t2UtugRUns4kH2tZh5O2N8PZwsXc8ERERKSPKzHhkQkICffv2JSgoCJPJxKJFi4rsf/DBBzGZTEUePXv2LLImIyODwYMHU6VKFXx8fBg2bBgXLhS9v9LOnTvp2LEj7u7uBAcHM2XKlKuyLFiwgLCwMNzd3WnSpAnff/99kf2GYRATE0ONGjXw8PAgKiqKvXv3lswHISJlhruLE091bcDq0V24o3EgFqvBvA0H6T4tjm+3HcVq1fdgIiIiUrLsWrTl5OTQrFkzZs6c+btrevbsyYkTJ2yPr776qsj+wYMHk5ycTGxsLMuWLSMhIYHHHnvMtj87O5sePXpQp04dtm3bxptvvsmECROYO3eubc2GDRu4//77GTZsGDt27GDAgAEMGDCApKQk25opU6Ywffp05syZw6ZNm/D09CQ6Oprc3NwS/EREpKyo6ePB7L+35LNht1KvuidnLuQzZsEv3D1nA0nHsuwdT0RERMoRhxmPNJlMLFy4kAEDBti2Pfjgg2RmZl7Vgbtiz549REREsGXLFlq1agXAihUr6NWrF0ePHiUoKIjZs2fz8ssvk56ejqurKwAvvPACixYtIiUlBYD77ruPnJwcli1bZjt227Ztad68OXPmzMEwDIKCghg9ejRjxowBICsri4CAAObNm8egQYOumS8vL4+8vDzb8+zsbIKDgzUeKVLO5Bda+Xh9Gu+u3svFfAtmE/ytTW3G9AjFp5KrveOJiIiIAyoz45HXIy4uDn9/f0JDQ3niiSc4e/asbd/GjRvx8fGxFWwAUVFRmM1mNm3aZFvTqVMnW8EGEB0dTWpqKufOnbOtiYqKKvK+0dHRbNy4EYC0tDTS09OLrPH29qZNmza2NdcyefJkvL29bY/g4OC/8EmIiKNydTbzj871WTO6C32bBWE14POfD9N1ahxfbT6skUkRERH5Sxy6aOvZsyeffvopq1ev5o033iA+Pp477rgDi8UCQHp6Ov7+/kVe4+zsjK+vL+np6bY1AQEBRdZcef5na367/7evu9aaa3nxxRfJysqyPY4cOVKs8xeRsiXQ25337m/BV4+2pVGAF+cuFvDid7u4c9Z6fjmSae94IiIiUkY59N1hfzt22KRJE5o2bUr9+vWJi4uje/fudkx2fdzc3HBzc7N3DBEpZe3qV2P50x35ZMNB3lm1l1+OZjFg1nruaxXM8z3D8PXUyKSIiIhcP4futP2vevXq4efnx759+wAIDAzk1KlTRdYUFhaSkZFBYGCgbc3JkyeLrLny/M/W/Hb/b193rTUiIr/l4mTmkY71WDOmM3e1qIlhwNdbjtB1ahyf/XwIi0YmRURE5DqVqaLt6NGjnD17lho1agDQrl07MjMz2bZtm23NmjVrsFqttGnTxrYmISGBgoIC25rY2FhCQ0OpWrWqbc3q1auLvFdsbCzt2rUDICQkhMDAwCJrsrOz2bRpk22NiMi1+Fd25637mrPg8XaE16hC1qUCxi1Kot+MdWw7dM7e8URERKQMsGvRduHCBRITE0lMTAQuX/AjMTGRw4cPc+HCBZ577jl+/vlnDh48yOrVq+nfvz8NGjQgOjoagPDwcHr27Mmjjz7K5s2bWb9+PcOHD2fQoEEEBQUB8Le//Q1XV1eGDRtGcnIy8+fP591332XUqFG2HM888wwrVqxg2rRppKSkMGHCBLZu3crw4cOBy1e2fPbZZ3n11VdZsmQJu3btYsiQIQQFBRW52qWIyO9pXdeXpcNvY1L/SKq4O5N8PJuBszcw+ptfOH0+788PICIiIhWWXS/5HxcXR9euXa/aPnToUGbPns2AAQPYsWMHmZmZBAUF0aNHD/75z38WuSBIRkYGw4cPZ+nSpZjNZgYOHMj06dPx8vKyrdm5cydPPfUUW7Zswc/PjxEjRjB27Ngi77lgwQJeeeUVDh48SMOGDZkyZQq9evWy7TcMg/HjxzN37lwyMzPp0KEDs2bNolGjRtd9vsW5rKeIlF9nLuQxZUUK32w9CkBld2dG3d6IB9rWwdmpTA1AiIiIyA0qTm3gMPdpqwhUtInIb+04fI6Yxcns+v+bcYcFVmZiv0ja1Ktm52QiIiJys6loc1Aq2kTkf1msBl9vOcybK1PJvHj5t7cDmgfxYq9wAqq42zmdiIiI3Czl6ubaIiLlmZPZxOA2dVg7ugt/a1MbkwkWJR6n29Q4/p1wgAKL1d4RRURExM7UaStF6rSJyJ/ZeTSTmMXJJP7/zbgb+HsxqV8k7Rv42TeYiIiIlCiNRzooFW0icj2sVoNvtx3l9RUpZOTkA9C7aQ1e7hVOkI+HndOJiIhISdB4pIhIGWY2m7i3dTBrR3dhaLs6mE2wfOcJuk+LZ1bcPvIKLfaOKCIiIqVInbZSpE6biNyI3cezGb8kiS0HL9+Mu56fJ+P7RdK5UXU7JxMREZEbpfFIB6WiTURulGEYLNxxjNe+T+HMhcs34+4REcC4PhEE+1ayczoREREpLo1HioiUMyaTibtuqcXaMZ0Z1iEEJ7OJH3efJOqteKav3ktugUYmRUREyit12kqROm0iUlJS088TsziJTWkZANT2rcT4vhF0Dw+wczIRERG5HhqPdFAq2kSkJBmGwdKdJ/jX8t2czL48Mtk9zJ+YvhHUqeZp53QiIiLyRzQeKSJSAZhMJvo1C2LN6C78o3M9nM0mVqec4va3E3jrx1Qu5WtkUkREpDxQp60UqdMmIjfTvlMXmLAkmXX7zgBQ08eDcX0iiI4MwGQy2TmdiIiI/JY6bSIiFVADfy8+G3YrswffQpC3O8cyL/H459sY+vEWDpy+YO94IiIicoPUaStF6rSJSGm5mF/IrLX7mZtwgHyLFRcnE490rMeIbg2o5Ops73giIiIVni5E4qBUtIlIaUs7k8PEpcnEpZ4GoIa3Oy/3Dqd3kxoamRQREbEjFW0OSkWbiNiDYRis2nOKScuSOZJxCYD29asxsV8kDQMq2zmdiIhIxaSizUGpaBMRe8otsDAnfj+z4/aTV2jF2Wziodvq8nT3hlR2d7F3PBERkQpFFyIREZGruLs48WxUI1aN6kxUeACFVoN//5RG92nxLNpxDH2HJyIi4pjUaStF6rSJiCNZm3KKiUuTOXj2IgC3hvgyqX8kYYH695OIiMjNpvFIB6WiTUQcTV6hhQ9+SuO9NXvJLbDiZDbxQNs6jLy9Ed4eGpkUERG5WTQeKSIi18XN2YmnujZg9egu9GoSiMVqMG/DQbpPi2PB1iNYrfpeT0RExN7UaStF6rSJiKP7ae9pxi9J5sDpHABuqe3DpP6NaVzT287JREREyheNRzooFW0iUhbkF1r5eH0a767ey8V8CyYTDG5TmzE9QvGp5GrveCIiIuWCxiNFROSGuTqb+Ufn+qwZ3YV+zYIwDPj858N0nRrHV5sPa2RSRESklKnTVorUaRORsmjj/rOMX5LErycvANCsljcT+zemebCPfYOJiIiUYRqPdFAq2kSkrCqwWPl04yHeif2V83mFmExwX6tgnu8Zhq+nRiZFRESKS+ORIiJSolyczAzrEMLqMZ25q0VNDAO+3nKErlPj+GzjQSwamRQREblp1GkrReq0iUh5seVgBjGLk9lzIhuAyKAqTOrfmJZ1qto5mYiISNmg8UgHpaJNRMqTQouVLzcfZurKVLJzCwEYeEstXrgjjOqV3eycTkRExLFpPFJERG46ZyczQ9rVZc2YLtzXKhiA/2w/SrepcXy0Lo1Ci9XOCUVERMoHddpKkTptIlKe7Th8jpjFyew6lgVAWGBlJvaLpE29anZOJiIi4ng0HumgVLSJSHlnsRp8veUwb65MJfNiAQD9mwfxUq9wAqq42zmdiIiI49B4pIiI2IWT2cTgNnVYO7oLf2tTG5MJFicep9vUOOYm7KdAI5MiIiLFpk5bKVKnTUQqml1Hsxi3OInEI5kANPD3YmK/SG5r4GffYCIiInam8UgHpaJNRCoiq9Xg2+1HeeOHFM7m5APQu0kNXu4dTpCPh53TiYiI2IfGI0VExGGYzSbubRXMmtFdGNquDmYTLN91gu7T4pkVt4+8Qou9I4qIiDg0ddpKkTptIiKw+3g245ckseXgOQBC/DyZ0C+Szo2q2zmZiIhI6dF4pINS0SYicplhGCxKPMZr36dw+nweAD0iAhjXJ4Jg30p2TiciInLzaTxSREQcmslk4s4WtVgzujOPdAjByWzix90niXornndX7SW3QCOTIiIiV6jTVorUaRMRubZfT54nZnESPx/IAKC2byXG942ge3iAnZOJiIjcHBqPdFAq2kREfp9hGCzdeYJ/Ld/NyezLI5PdwvwZ3zeCOtU87ZxORESkZGk8UkREyhyTyUS/ZkGsGd2Ff3Suh4uTiTUpp7j97QTe+jGVS/kamRQRkYrpLxdt2dnZLFq0iD179pREHhERqeA83Zx58Y5wfnimEx0b+pFfaGX6mn1EvRXPiqR0NCAiIiIVTbGLtnvvvZcZM2YAcOnSJVq1asW9995L06ZN+c9//lPiAUVEpGJq4O/Fpw/fypy/30JNHw+OZV7i8c+3MeSjzRw4fcHe8UREREpNsYu2hIQEOnbsCMDChQsxDIPMzEymT5/Oq6++WuIBRUSk4jKZTPRsXINVozozvGsDXJ3M/LT3DNHvJPDGihRy8grtHVFEROSmK3bRlpWVha+vLwArVqxg4MCBVKpUid69e7N3794SDygiIuLh6sSY6FB+HNmJrqHVKbAYzI7bT9Rb8SzbeVwjkyIiUq4Vu2gLDg5m48aN5OTksGLFCnr06AHAuXPncHd3L/GAIiIiV9T18+SjB1vzwZBWBPt6cCIrl+Ff7mDwB5vYe/K8veOJiIjcFMUu2p599lkGDx5MrVq1CAoKokuXLsDlsckmTZqUdD4REZEiTCYTUREBxI7szLNRDXFzNrNh/1nuePcnXl22m/O5BfaOKCIiUqJu6D5tW7du5ciRI9x+++14eXkBsHz5cnx8fLjttttKPGR5ofu0iYiUvCMZF5m0bDexu08C4F/ZjZd6hdO/eRAmk8nO6URERK7tpt+nrVWrVtx55514eXlhsVhITEykffv2xS7YEhIS6Nu3L0FBl/9iXbRo0e+uffzxxzGZTLzzzjtFtmdkZDB48GCqVKmCj48Pw4YN48KFolcV27lzJx07dsTd3Z3g4GCmTJly1fEXLFhAWFgY7u7uNGnShO+//77IfsMwiImJoUaNGnh4eBAVFaXf8ImIOIBg30r8e0grPn6oNXWrVeLU+TyenZ/Ife//zJ4T2faOJyIi8pfd0Hjkhx9+CIDFYqFz587ccsstBAcHExcXV6xj5eTk0KxZM2bOnPmH6xYuXMjPP/9MUFDQVfsGDx5McnIysbGxLFu2jISEBB577DHb/uzsbHr06EGdOnXYtm0bb775JhMmTGDu3Lm2NRs2bOD+++9n2LBh7NixgwEDBjBgwACSkpJsa6ZMmcL06dOZM2cOmzZtwtPTk+joaHJzc4t1ziIicnN0DfVn5chOPBcdiruLmc0HM+jz3jomLEkm65JGJkVEpAwziqlmzZrGli1bDMMwjIULFxpBQUFGamqq8corrxjt27cv7uFsAGPhwoVXbT969KhRs2ZNIykpyahTp47x9ttv2/bt3r3bAGx5DMMwfvjhB8NkMhnHjh0zDMMwZs2aZVStWtXIy8uzrRk7dqwRGhpqe37vvfcavXv3LvK+bdq0Mf7xj38YhmEYVqvVCAwMNN58803b/szMTMPNzc346quvrvscs7KyDMDIysq67teIiEjxHT130Xji861GnbHLjDpjlxkt//mj8c2Ww4bFYrV3NBEREcMwilcbFLvTdubMGQIDAwH4/vvvueeee2jUqBEPP/wwu3btKtGC0mq18sADD/Dcc88RGRl51f6NGzfi4+NDq1atbNuioqIwm81s2rTJtqZTp064urra1kRHR5Oamsq5c+dsa6KiooocOzo6mo0bNwKQlpZGenp6kTXe3t60adPGtuZa8vLyyM7OLvIQEZGbr6aPB7MGt+SzYbdSv7onZy7k89y3O7l7zgaSjmXZO56IiEixFLtoCwgIYPfu3VgsFlasWMHtt98OwMWLF3FycirRcG+88QbOzs48/fTT19yfnp6Ov79/kW3Ozs74+vqSnp5uWxMQEHDVOVzZ90drfrv/t6+71pprmTx5Mt7e3rZHcHDwH56viIiUrI4Nq/PDM5148Y4wKrk6sf1wJn1nrOOVRbvIvJhv73giIiLXpdhF20MPPcS9995L48aNL192+f+7T5s2bSIsLKzEgm3bto13332XefPmldmrf7344otkZWXZHkeOHLF3JBGRCsfV2cw/Otdnzegu9GsWhGHA5z8fpuvUOL7afBirVTfmFhERx1bsom3ChAl88MEHPPbYY6xfvx43NzcAnJyceOGFF0os2E8//cSpU6eoXbs2zs7OODs7c+jQIUaPHk3dunUBCAwM5NSpU0VeV1hYSEZGhm2EMzAwkJMnTxZZc+X5n6357f7fvu5aa67Fzc2NKlWqFHmIiIh9BHq7M/3+Fnz1aFsaBXhx7mIBL363iztnrSfxSKa944mIiPyuG7rk/913383IkSOpVauWbdvQoUPp379/iQV74IEH2LlzJ4mJibZHUFAQzz33HCtXrgSgXbt2ZGZmsm3bNtvr1qxZg9VqpU2bNrY1CQkJFBT898phsbGxhIaGUrVqVdua1atXF3n/2NhY2rVrB0BISAiBgYFF1mRnZ7Np0ybbGhERKRva1a/G8qc7Mq5PBJXdnPnlaBZ3zlrPC//ZydkLefaOJyIicpUbKtri4+Pp27cvDRo0oEGDBvTr14+ffvqp2Me5cOGCrSCDyxf8SExM5PDhw1SrVo3GjRsXebi4uBAYGEhoaCgA4eHh9OzZk0cffZTNmzezfv16hg8fzqBBg2y3B/jb3/6Gq6srw4YNIzk5mfnz5/Puu+8yatQoW45nnnmGFStWMG3aNFJSUpgwYQJbt25l+PDhAJhMJp599lleffVVlixZwq5duxgyZAhBQUEMGDDgRj5CERGxIxcnM8M6hLB6TGfuuqUmhgFfbzlCt2nxfLbxIBaNTIqIiAMpdtH2+eefExUVRaVKlXj66ad5+umn8fDwoHv37nz55ZfFOtbWrVtp0aIFLVq0AGDUqFG0aNGCmJiY6z7GF198QVhYGN27d6dXr1506NChyD3YvL29+fHHH0lLS6Nly5aMHj2amJiYIvdya9++PV9++SVz586lWbNmfPvttyxatIjGjRvb1jz//POMGDGCxx57jNatW3PhwgVWrFiBu7t7sc5ZREQch39ld966tznfPt6O8BpVyLpUwLjFyfR9bx3bDmXYO56IiAgAJsMwivV1Ynh4OI899hgjR44ssv2tt97i3//+N3v27CnRgOVJdnY23t7eZGVl6fdtIiIOptBi5cvNh5m6MpXs3EIABt5SixfuCKN6ZTc7pxMRkfKmOLVBsYs2Nzc3kpOTadCgQZHt+/bto3HjxuTm5hY/cQWhok1ExPGdvZDHlBWpzN96+Yq/ld2cGXl7I4a0q4Oz0w39qkBEROQqxakNiv23T3Bw8FUX7QBYtWqV7kMmIiJlXjUvN964uykLn2xPk5renM8rZNKy3fSevo5NB87aO56IiFRAzsV9wejRo3n66adJTEykffv2AKxfv5558+bx7rvvlnhAERERe2hRuyqLnrqN+VuOMGVlCqknz3Pf3J/p3zyIl3qFE1BFv2kWEZHSUezxSICFCxcybdo02+/XwsPDee6550r0kv/lkcYjRUTKpnM5+Uz9MZUvNx/GMMDT1Ylnohry0G0huGhkUkREbsBN/U2b3DgVbSIiZduuo1mMW5xkuxl3A38vJvaL5LYGfvYNJiIiZY6KNgelok1EpOyzWg2+3X6UN35I4WxOPgC9m9Tg5d7hBPl42DmdiIiUFSVetFWtWhWTyXRdb56Rofva/B4VbSIi5UfWxQLeXvUrn248iNUADxcnhndrwCMdQ3BzdrJ3PBERcXAlXrR98skn1/3mQ4cOve61FY2KNhGR8mf38WzGL0liy8FzAIT4eTK+bwRdQv3tnExERByZxiMdlIo2EZHyyTAMFiUe47XvUzh9Pg+AHhEBjOsTQbBvJTunExERR3RT79MmIiIiRZlMJu5sUYs1ozvzSIcQnMwmftx9kqi34nl31V5yCyz2jigiImWYOm2lSJ02EZGK4deT54lZnMTPBy7/zru2byVi+kQQFRFg52QiIuIoNB7poFS0iYhUHIZhsGznCf61fA/p2bkAdAvzZ3zfCOpU87RzOhERsTeNR4qIiNiZyWSib7MgVo/uzD8618PFycSalFPc/lYC035M5VK+RiZFROT6FKtoKygowNnZmaSkpJuVR0REpFzxdHPmxTvC+eGZTnRs6Ee+xcp7a/YR9VY8K5JOoIEXERH5M8Uq2lxcXKhduzYWi74dFBERKY4G/l58+vCtzPn7LdT08eBY5iUe/3w7Qz7azP7TF+wdT0REHFixxyNffvllXnrpJd1EW0REpJhMJhM9G9dg1ajOjOjWAFcnMz/tPUPPdxJ4/YcUcvIK7R1RREQcULEvRNKiRQv27dtHQUEBderUwdOz6I+pt2/fXqIByxNdiERERH7r4JkcJi5NZm3qaQBqeLvzcu9wejepgclksnM6ERG5mYpTGzgX9+ADBgy40VwiIiLyG3X9PPnowdas3nOKicuSOZJxieFf7uDL+oeZ2C+ShgGV7R1RREQcgC75X4rUaRMRkd+TW2Dh/fgDzIrbR16hFWeziQfb1+WZqIZUdnexdzwRESlhpXKftm3btrFnzx4AIiMjadGixY0cpkJR0SYiIn/mSMZFJi3bTezukwBUr+zGS73CGNC8pkYmRUTKkZtatJ06dYpBgwYRFxeHj48PAJmZmXTt2pWvv/6a6tWr33Dw8k5Fm4iIXK+1qaeYuCSZg2cvAnBrXV8m9o8kvIb+/hARKQ9u6s21R4wYwfnz50lOTiYjI4OMjAySkpLIzs7m6aefvuHQIiIi8l9dQ/1ZObITz0WH4u5iZvPBDHpP/4kJS5LJulRg73giIlKKit1p8/b2ZtWqVbRu3brI9s2bN9OjRw8yMzNLMl+5ok6biIjciGOZl/jX8t18vysdgGqeroy9I4y7b6mF2ayRSRGRsuimdtqsVisuLlf/INrFxQWr1Vrcw4mIiMifqOnjwazBLfl8WBvqV/fkbE4+z3+7k4FzNpB0LMve8URE5CYrdtHWrVs3nnnmGY4fP27bduzYMUaOHEn37t1LNJyIiIj8V4eGfvzwTCde6hWGp6sTOw5n0nfGOl5euIvMi/n2jiciIjdJsccjjxw5Qr9+/UhOTiY4ONi2rXHjxixZsoRatWrdlKDlgcYjRUSkpKRn5fLa93tY8svlL1GrVnLh+Z5h3NsqGCeNTIqIOLybfsl/wzBYtWoVKSkpAISHhxMVFXVjaSsQFW0iIlLSNu4/y/glSfx68gIATWt5M6l/Y5oH+9g3mIiI/KGbWrR9+umn3Hfffbi5uRXZnp+fz9dff82QIUOKn7iCUNEmIiI3Q4HFyqcbD/FO7K+czyvEZIL7WgXzXHQo1bzc/vwAIiJS6m5q0ebk5MSJEyfw9/cvsv3s2bP4+/tjsViKn7iCUNEmIiI306nzubz+QwrfbT8GQBV3Z8ZEhzK4TR2NTIqIOJibevVIwzAwma7+F//Ro0fx9vYu7uFERESkhPhXduete5vz7ePtiKhRhezcQmIWJ9P3vXVsO5Rh73giInKDnK93YYsWLTCZTJhMJrp3746z839farFYSEtLo2fPnjclpIiIiFy/VnV9WTqiA19sOsTUlansPpHNwNkbueuWmrx4RzjVK2tkUkSkLLnuom3AgAEAJCYmEh0djZeXl22fq6srdevWZeDAgSUeUERERIrPyWxiSLu69G5SgykrUpm/9QjfbT9GbPJJRt7eiCHt6uDsVOyBGxERsYNi/6btk08+YdCgQVddiET+nH7TJiIi9pJ4JJOYxUnsPHr5ZtyhAZWZ2D+StvWq2TmZiEjFdFN/0xYREUFiYuJV2zdt2sTWrVuLezgREREpBc2DfVj45G28dmcTfCq5kHryPIPm/szTX+3gZHauveOJiMgfKHbR9tRTT3HkyJGrth87doynnnqqREKJiIhIyXMym/hbm9qsHd2FwW1qYzLBkl+O021qHHMT9pNfaLV3RBERuYZij0d6eXmxc+dO6tWrV2R7WloaTZs25fz58yUasDzReKSIiDiSXUezGLc4icQjmQDUr+7JpP6Nua2Bn32DiYhUADd1PNLNzY2TJ09etf3EiRNFrigpIiIijq1JLW++e6I9U+5uSjVPV/afzmHwB5t46ovtHM+8ZO94IiLy/4pdtPXo0YMXX3yRrKws27bMzExeeuklbr/99hINJyIiIjeX2Wzi3lbBrBnThQfb18VsguW7TtB9Wjwz1+4jr9Bi74giIhVesccjjx07RqdOnTh79iwtWrQALt8GICAggNjYWIKDg29K0PJA45EiIuLodh/PZvySJLYcPAdAiJ8n4/tG0CXU387JRETKl+LUBsUu2gBycnL44osv+OWXX/Dw8KBp06bcf//9uLi43HDoikBFm4iIlAWGYbAo8RivfZ/C6fN5ANweEUBMnwiCfSvZOZ2ISPlw04s2uTEq2kREpCw5n1vAu6v28vGGg1isBm7OZp7s0oB/dK6Hu4uTveOJiJRppVK07d69m8OHD5Ofn19ke79+/W7kcBWCijYRESmLfj15nvGLk9l44CwAtX0rEdMngqiIADsnExEpu25q0XbgwAHuvPNOdu3ahclk4srLTSYTABaLfrD8e1S0iYhIWWUYBst2nuBfy/eQ/v834+4W5k9Mnwjq+nnaOZ2ISNlzUy/5/8wzzxASEsKpU6eoVKkSycnJJCQk0KpVK+Li4m40s4iIiDgwk8lE32ZBrB7dmcc718fFycSalFP0eDuBaT+mcilfX9qKiNwsxe60+fn5sWbNGpo2bYq3tzebN28mNDSUNWvWMHr0aHbs2HGzspZ56rSJiEh5sf/0BSYsSeanvWcAqOnjwbg+4URHBtqmb0RE5Pfd1E6bxWKhcuXKwOUC7vjx4wDUqVOH1NTUG4grIiIiZU396l58+vCtzPn7LdT08eBY5iUe/3w7Qz7azP7TF+wdT0SkXCl20da4cWN++eUXANq0acOUKVNYv349kyZNol69eiUeUERERByTyWSiZ+MarBrVmRHdGuDqZOanvWfo+U4Cr/+QQk5eob0jioiUC8Uej1y5ciU5OTncdddd7Nu3jz59+vDrr79SrVo15s+fT7du3W5W1jJP45EiIlKeHTyTw8SlyaxNPQ1AYBV3Xu4dTp+mNTQyKSLyP0r9Pm0ZGRlUrVpV/0L+EyraRESkIli1+yQTlyVzJOMSAO3qVWNi/0gaBVS2czIREcdxU3/Tdi2+vr43VLAlJCTQt29fgoKCMJlMLFq0qMj+CRMmEBYWhqenJ1WrViUqKopNmzYVWZORkcHgwYOpUqUKPj4+DBs2jAsXis7S79y5k44dO+Lu7k5wcDBTpky5KsuCBQsICwvD3d2dJk2a8P333xfZbxgGMTEx1KhRAw8PD6Kioti7d2+xz1lERKS8i4oIIHZkZ0ZGNcLN2czGA2fp9e5PvLpsN+dzC+wdT0SkzCmRou1G5eTk0KxZM2bOnHnN/Y0aNWLGjBns2rWLdevWUbduXXr06MHp06dtawYPHkxycjKxsbEsW7aMhIQEHnvsMdv+7OxsevToQZ06ddi2bRtvvvkmEyZMYO7cubY1GzZs4P7772fYsGHs2LGDAQMGMGDAAJKSkmxrpkyZwvTp05kzZw6bNm3C09OT6OhocnNzb8InIyIiUra5uzjxTFRDVo3qTI+IAAqtBh+sS6PbtHgW7jhKCQz6iIhUGCUyHlkSTCYTCxcuZMCAAb+75koLcdWqVXTv3p09e/YQERHBli1baNWqFQArVqygV69eHD16lKCgIGbPns3LL79Meno6rq6uALzwwgssWrSIlJQUAO677z5ycnJYtmyZ7b3atm1L8+bNmTNnDoZhEBQUxOjRoxkzZgwAWVlZBAQEMG/ePAYNGnRd56jxSBERqajiUk8xYUkyB89eBKB13apM7NeYiCD9fSgiFVOpj0eWhvz8fObOnYu3tzfNmjUDYOPGjfj4+NgKNoCoqCjMZrNtjHLjxo106tTJVrABREdHk5qayrlz52xroqKiirxfdHQ0GzduBCAtLY309PQia7y9vWnTpo1tzbXk5eWRnZ1d5CEiIlIRdQn1Z+XITjwXHYqHixNbDp6jz3s/MWFJMlmXNDIpIvJHHL5oW7ZsGV5eXri7u/P2228TGxuLn58fAOnp6fj7+xdZ7+zsjK+vL+np6bY1AQEBRdZcef5na367/7evu9aaa5k8eTLe3t62R3BwcLHOXUREpDxxc3biqa4NWDW6M72aBGI1YN6Gg3SbGsc3W49gtTrE8I+IiMNx+KKta9euJCYmsmHDBnr27Mm9997LqVOn7B3rurz44otkZWXZHkeOHLF3JBEREbur6ePBrMEt+XxYG+pX9+RsTj7Pf7uTgXM2sOtolr3jiYg4HIcv2jw9PWnQoAFt27blww8/xNnZmQ8//BCAwMDAqwq4wsJCMjIyCAwMtK05efJkkTVXnv/Zmt/u/+3rrrXmWtzc3KhSpUqRh4iIiFzWoaEfPzzTiZd6heHp6sSOw5n0m7mOlxfuIvNivr3jiYg4DIcv2v6X1WolLy8PgHbt2pGZmcm2bdts+9esWYPVaqVNmza2NQkJCRQU/HdePjY2ltDQUKpWrWpbs3r16iLvExsbS7t27QAICQkhMDCwyJrs7Gw2bdpkWyMiIiLF5+ps5rFO9Vk9ugv9mwdhGPDFpsN0nRrHl5sOY9HIpIiIfYu2CxcukJiYSGJiInD5gh+JiYkcPnyYnJwcXnrpJX7++WcOHTrEtm3bePjhhzl27Bj33HMPAOHh4fTs2ZNHH32UzZs3s379eoYPH86gQYMICgoC4G9/+xuurq4MGzaM5ORk5s+fz7vvvsuoUaNsOZ555hlWrFjBtGnTSElJYcKECWzdupXhw4cDl69s+eyzz/Lqq6+yZMkSdu3axZAhQwgKCvrDq12KiIjI9Qn0dufdQS34+rG2hAZU5tzFAl5auIs7Z60n8UimveOJiNiVXS/5HxcXR9euXa/aPnToUObMmcPf/vY3Nm3axJkzZ6hWrRqtW7fmlVdeoXXr1ra1GRkZDB8+nKVLl2I2mxk4cCDTp0/Hy8vLtmbnzp089dRTbNmyBT8/P0aMGMHYsWOLvOeCBQt45ZVXOHjwIA0bNmTKlCn06tXLtt8wDMaPH8/cuXPJzMykQ4cOzJo1i0aNGl33+eqS/yIiIn+uwGLls42HeDv2V87nFQJwX6tgnu8ZSjUvNzunExEpGcWpDRzmPm0VgYo2ERGR63fqfC5v/JDKf7YfBaCKuzNjokMZ3KYOTmaTndOJiPw1KtoclIo2ERGR4tt6MIOYxcnsPnH5fqcRNaowqX8krer62jmZiMiNU9HmoFS0iYiI3BiL1eDLTYd4c2Uq2bmXRybvuqUmL9wRhn9ldzunExEpvuLUBmXu6pEiIiJS8TiZTTzQri5rx3ThvlbBAHy3/Rjdp8bz4bo0Ci1WOycUEbl51GkrReq0iYiIlIzEI5nELE5i5//fjDs0oDIT+0fStl41OycTEbk+Go90UCraRERESo7FavDN1iNMWZHCuYuX78far1kQL/cOJ6CKRiZFxLFpPFJERETKPSeziftvrc2a0V0Y3KY2JhMs+eU43abG8X78fvILNTIpIuWDOm2lSJ02ERGRmyfpWBbjFiex43AmAPWrezKxX2M6NPSzbzARkWvQeKSDUtEmIiJyc1mtBt9uP8obP6RwNicfgF5NAnmldwRBPh52Tici8l8ajxQREZEKyWw2cW+rYNaM6cKD7etiNsH3u9LpPi2emWv3kVdosXdEEZFiU6etFKnTJiIiUrr2nMgmZnESWw6eAyDEz5PxfSPoEupv52QiUtFpPNJBqWgTEREpfYZhsDjxOP/6fg+nz+cBcHtEADF9Igj2rWTndCJSUWk8UkREROT/mUwmBrSoyZrRnXmkQwhOZhOxu08S9VY876z6ldwCjUyKiGNTp60UqdMmIiJif7+ePM/4xclsPHAWgGBfD8b3iSQqIsDOyUSkItF4pINS0SYiIuIYDMNg+a4TvLpsD+nZuQB0C/Mnpk8Edf087ZxORCoCFW0OSkWbiIiIY8nJK+S9Nfv4cN0BCiwGrk5mHutUj6e6NsDD1cne8USkHFPR5qBUtImIiDim/acvMGFJMj/tPQNATR8PxvUJJzoyEJPJZOd0IlIeqWhzUCraREREHJdhGKxMTuefy/ZwLPMSAB0b+jGhXyT1q3vZOZ2IlDcq2hyUijYRERHHdynfwqy4fbwff4B8ixUXJxPDOtRjRLcGeLo52zueiJQTKtoclIo2ERGRsuPgmRwmLdvNmpRTAARWcefl3uH0aVpDI5Mi8pepaHNQKtpERETKnlW7TzJxWTJHMi6PTLarV42J/SNpFFDZzslEpCxT0eagVLSJiIiUTbkFFt6PP8CsuH3kFVpxMpt4sH1dno1qSGV3F3vHE5EyqDi1gbmUMomIiIiUWe4uTjwT1ZBVozrTIyIAi9Xgw3VpdJsWz8IdR9F34CJyM6nTVorUaRMRESkf4lJPMXHpbtLO5ADQum5VJvZrTESQ/n4Xkeuj8UgHpaJNRESk/MgrtPDBT2nMWLOPSwUWzCYY0q4uI29vhLeHRiZF5I9pPFJERETkJnNzduKprg1YNbozvZvUwGrAvA0H6TY1jm+2HsFq1ffiIlIy1GkrReq0iYiIlF/r9p5h/JIk9p++PDLZorYPk/o1pkktbzsnExFHpPFIB6WiTUREpHzLL7Qyb0Ma767aS06+BZMJ/nZrbcb0CKWqp6u944mIA9F4pIiIiIgduDqbeaxTfdaM6UL/5kEYBnyx6TBdp8Xx5abDWDQyKSI3QJ22UqROm4iISMXy84GzjF+cTOrJ8wA0reXNxH6RtKhd1c7JRMTeNB7poFS0iYiIVDwFFiufbTzE27G/cj6vEID7WgXzfM9Qqnm52TmdiNiLxiNFREREHISLk5mHO4SwekxnBt5SC4D5W4/QdWocn248qJFJEflT6rSVInXaREREZOvBDGIWJ7P7RDYAETWqMKl/JK3q+to5mYiUJo1HOigVbSIiIgJgsRp8uekQb65MJTv38sjkXbfU5IU7wvCv7G7ndCJSGjQeKSIiIuLAnMwmHmhXl7VjujCodTAmE3y3/Rjdp8bz4bo0CixWe0cUEQeiTlspUqdNREREriXxSCYxi5PYeTQLgNCAykzsH0nbetXsnExEbhaNRzooFW0iIiLyeyxWg2+2HmHKihTOXSwAoF+zIF7qFU6gt0YmRcobjUeKiIiIlDFOZhP331qbtWO68Pe2tTGZYMkvx+k+LY734/eTX6iRSZGKSp22UqROm4iIiFyvpGNZjFucxI7DmQDUr+7JxH6N6dDQz77BRKREaDzSQaloExERkeKwWg3+s/0or/+QwtmcfAB6NQnk5d4R1PTxsHM6EfkrNB4pIiIiUg6YzSbuaRXMmjFdeLB9Xcwm+H5XOlHT4pm5dh95hRZ7RxSRUqBOWylSp01ERET+ij0nshm/OJnNBzMAqFutEuP7RdI11N/OyUSkuDQe6aBUtImIiMhfZRgGixOP86/v93D6fB4At0cEENMngmDfSnZOJyLXS+ORIiIiIuWUyWRiQIuarBndmUc7huBsNhG7+yRRb8XzzqpfyS3QyKRIeaNOWylSp01ERERK2t6T54lZnMzGA2cBCPb1IKZPJFHh/phMJjunE5Hfo/FIB6WiTURERG4GwzBYvusEry7bQ3p2LgBdQ6szvm8kdf087ZxORK5FRZuDUtEmIiIiN1NOXiEz1u7jg58OUGAxcHUy81inejzVtQEerk72jiciv6GizUGpaBMREZHSsP/0BSYsSeanvWcAqOnjwSu9w+nZOFAjkyIOQkWbg1LRJiIiIqXFMAxWJp/kn8t2cyzzEgAdG/oxoV8k9at72TmdiKhoc1Aq2kRERKS0Xcq3MCtuH+/HHyDfYsXFycTDHUJ4ultDPN2c7R1PpMIqM5f8T0hIoG/fvgQFBWEymVi0aJFtX0FBAWPHjqVJkyZ4enoSFBTEkCFDOH78eJFjZGRkMHjwYKpUqYKPjw/Dhg3jwoULRdbs3LmTjh074u7uTnBwMFOmTLkqy4IFCwgLC8Pd3Z0mTZrw/fffF9lvGAYxMTHUqFEDDw8PoqKi2Lt3b8l9GCIiIiI3gYerE6N7hPLjyE50C/OnwGLwfvwBuk+LZ8kvx9H39yKOz65FW05ODs2aNWPmzJlX7bt48SLbt29n3LhxbN++ne+++47U1FT69etXZN3gwYNJTk4mNjaWZcuWkZCQwGOPPWbbn52dTY8ePahTpw7btm3jzTffZMKECcydO9e2ZsOGDdx///0MGzaMHTt2MGDAAAYMGEBSUpJtzZQpU5g+fTpz5sxh06ZNeHp6Eh0dTW5u7k34ZERERERKVl0/Tz56sDUfDm1Fbd9KpGfn8vRXO/jbvzfx68nz9o4nIn/AYcYjTSYTCxcuZMCAAb+7ZsuWLdx6660cOnSI2rVrs2fPHiIiItiyZQutWrUCYMWKFfTq1YujR48SFBTE7Nmzefnll0lPT8fV1RWAF154gUWLFpGSkgLAfffdR05ODsuWLbO9V9u2bWnevDlz5szBMAyCgoIYPXo0Y8aMASArK4uAgADmzZvHoEGDruscNR4pIiIijiC3wMLchAPMXLuPvEIrTmYTD7avy7NRDans7mLveCIVQpkZjyyurKwsTCYTPj4+AGzcuBEfHx9bwQYQFRWF2Wxm06ZNtjWdOnWyFWwA0dHRpKamcu7cOduaqKioIu8VHR3Nxo0bAUhLSyM9Pb3IGm9vb9q0aWNbcy15eXlkZ2cXeYiIiIjYm7uLE093b8iqUZ3pERGAxWrw4bo0uk6N57vtRzUyKeJgykzRlpuby9ixY7n//vttlWh6ejr+/v5F1jk7O+Pr60t6erptTUBAQJE1V57/2Zrf7v/t66615lomT56Mt7e37REcHFyscxYRERG5mYJ9KzF3SCvmPdSaED9PzlzIY9Q3v3Dv+xvZfVxfNos4ijJRtBUUFHDvvfdiGAazZ8+2d5zr9uKLL5KVlWV7HDlyxN6RRERERK7SJdSfFc925LnoUDxcnNhy8Bx93vuJ8YuTyLpUYO94IhWewxdtVwq2Q4cOERsbW2TeMzAwkFOnThVZX1hYSEZGBoGBgbY1J0+eLLLmyvM/W/Pb/b993bXWXIubmxtVqlQp8hARERFxRG7OTjzVtQGrR3emd5MaWA34ZOMhuk2N45stR7BaNTIpYi8OXbRdKdj27t3LqlWrqFatWpH97dq1IzMzk23bttm2rVmzBqvVSps2bWxrEhISKCj477dEsbGxhIaGUrVqVdua1atXFzl2bGws7dq1AyAkJITAwMAia7Kzs9m0aZNtjYiIiEh5EOTjwczBt/DFI21o4O/F2Zx8nv/PTgbO2cCuo1n2jidSIdm1aLtw4QKJiYkkJiYCly/4kZiYyOHDhykoKODuu+9m69atfPHFF1gsFtLT00lPTyc/Px+A8PBwevbsyaOPPsrmzZtZv349w4cPZ9CgQQQFBQHwt7/9DVdXV4YNG0ZycjLz58/n3XffZdSoUbYczzzzDCtWrGDatGmkpKQwYcIEtm7dyvDhw4HLV7Z89tlnefXVV1myZAm7du1iyJAhBAUF/eHVLkVERETKqtsa+PH90x15qVcYnq5O7DicSb+Z63hp4S7O5eTbO55IhWLXS/7HxcXRtWvXq7YPHTqUCRMmEBIScs3XrV27li5dugCXb649fPhwli5ditlsZuDAgUyfPh0vLy/b+p07d/LUU0+xZcsW/Pz8GDFiBGPHji1yzAULFvDKK69w8OBBGjZsyJQpU+jVq5dtv2EYjB8/nrlz55KZmUmHDh2YNWsWjRo1uu7z1SX/RUREpCw6mZ3La9/vYXHicQB8KrnwXHQog1rXxslssnM6kbKpOLWBw9ynrSJQ0SYiIiJl2aYDZxm/JJmU9Ms3425S05tJ/SNpUbuqnZOJlD0q2hyUijYREREp6wotVj7deIi3Y3/lfF4hAPe2qsXYnmFU83KzczqRsqPc3lxbREREROzL2cnMwx1CWDOmCwNvqQXAN1uP0nVqHJ9uPEihxWrnhCLljzptpUidNhERESlvth3KYNyiZHafuHwz7vAaVfhn/0ha1fW1czIRx6bxSAelok1ERETKI4vV4MtNh3hzZSrZuZdHJu+6pSYv3BGGf2V3O6cTcUwajxQRERGRUuNkNvFAu7qsHdOFQa2DMZngu+3H6D41ng/XpVGgkUmRv0SdtlKkTpuIiIhUBIlHMolZnMTO/78Zd2hAZSb0i6Rd/Wp2TibiODQe6aBUtImIiEhFYbUazN96hCkrUjh3sQCAvs2CeLlXOIHeGpkU0XikiIiIiNiV2Wzi/ltrs3ZMF/7etjYmEyz95Tjdp8Xxfvx+8gs1MilyvdRpK0XqtImIiEhFlXQsi3GLk9hxOBOA+tU9mdivMR0a+tk3mIidaDzSQaloExERkYrMajX4z/ajvP5DCmdz8gG4o3Egr/SJoKaPh53TiZQujUeKiIiIiMMxm03c0yqYNWO68GD7uphN8ENSOlHT4pm5dh95hRZ7RxRxSOq0lSJ12kRERET+a8+JbMYvTmbzwQwA6larxPh+kXQN9bdzMpGbT+ORDkpFm4iIiEhRhmGwOPE4//p+D6fP5wFwe0QAMX0iCPatZOd0IjePxiNFREREpEwwmUwMaFGTNaM782jHEJzNJmJ3nyTqrXjeWfUruQUamRRRp60UqdMmIiIi8sf2njzP+CXJbNh/FoBgXw9i+kQSFe6PyWSyczqRkqPxSAelok1ERETkzxmGwfJdJ3h12R7Ss3MB6BJanQl9I6nr52nndCIlQ+ORIiIiIlJmmUwm+jQNYvXozjzRpT4uTibiUk/T4+0Epq5M5VK+RialYlGnrRSp0yYiIiJSfPtPX2DCkmR+2nsGgJo+HrzSO5yejQM1MilllsYjHZSKNhEREZEbYxgGK5NP8s9luzmWeQmAjg39GN83kgb+XnZOJ1J8KtoclIo2ERERkb/mUr6F2XH7mJNwgPxCKy5OJh7uEMKIbg3xcnO2dzyR66bftImIiIhIueTh6sSoHqHEjuxEtzB/CiwG78cfoPu0OJb8chz1I6Q8UqetFKnTJiIiIlKyVu85ycSluzmccRGAtvV8mdivMaGBle2cTOSPaTzSQaloExERESl5uQUW5iYcYObafeQVWnEym3iwfV2eiWpIFXcXe8cTuSaNR4qIiIhIheHu4sTT3RuyalRnekQEYLEafLgujW5T4/lu+1GNTEqZp05bKVKnTUREROTmi0s9xcSlu0k7kwNAqzpVmdS/MRFB+u8vcRwaj3RQKtpERERESkdeoYUP16Xx3up9XCqwYDbBA23rMKpHKN4eGpkU+9N4pIiIiIhUaG7OTjzZpQGrR3emd9MaWA34ZOMhuk2N45stR7Ba1beQskOdtlKkTpuIiIiIfazfd4bxS5LZd+oCAM2Dffhn/8Y0qeVt52RSUWk80kGpaBMRERGxn/xCK59sOMg7q34lJ9+CyQT331qb53qEUtXT1d7xpILReKSIiIiIyP9wdTbzaKd6rBnThf7NgzAM+HLTYbpOi+OLTYewaGRSHJQ6baVInTYRERERx7HpwFnGL0kmJf08AE1qejOxfyS31K5q52RSEWg80kGpaBMRERFxLIUWK5/9fIi3fvyV83mFANzbqhZje4ZRzcvNzumkPNN4pIiIiIjIdXB2MvPQbSGsGdOFgbfUAuCbrUfpOjWOTzYcpNBitXNCEXXaSpU6bSIiIiKObduhDGIWJ5N8PBuA8BpV+Gf/SFrV9bVzMilvNB7poFS0iYiIiDg+i9Xgy02HeHNlKtm5l0cm72pRkxd6heFf2d3O6aS80HikiIiIiMgNcjKbeKBdXdaO6cL9twZjMsF3O47RbWo8H/x0gAKNTEopU6etFKnTJiIiIlL2JB7JZPziJH45mgVAowAvJvZrTLv61eycTMoyjUc6KBVtIiIiImWT1WrwzdYjvLEihXMXCwDo2yyIl3uFE+itkUkpPo1HioiIiIiUILPZxKBba7N2TBf+3rY2JhMs/eU43abFMSd+P/mFGpmUm0edtlKkTpuIiIhI+ZB0LIuYxUlsP5wJQL3qnkzsF0nHhtXtG0zKDI1HOigVbSIiIiLlh9Vq8J/tR3ljRQpnLuQDcEfjQF7pE0FNHw87pxNHp/FIEREREZGbzGw2cU+rYFaP7sKD7etiNsEPSel0nxbHjDV7ySu02DuilBPqtJUiddpEREREyq89J7IZvziZzQczAKhbrRLj+0XSNdTfzsnEEWk80kGpaBMREREp3wzDYHHicf71/R5On88DICo8gPF9Iwj2rWTndOJINB4pIiIiImIHJpOJAS1qsmZ0Zx7tGIKz2cSqPSeJeiuet2N/JbdAI5NSfOq0lSJ12kREREQqlr0nzzN+STIb9p8FINjXg5g+kUSF+2MymeycTuxJ45EOSkWbiIiISMVjGAbLd53g1WV7SM/OBaBLaHXG940kxM/TzunEXlS0OSgVbSIiIiIVV05eITPW7uODnw5QYDFwdTLzaKcQnuragEquzvaOJ6VMRZuDUtEmIiIiIvtPX2DCkmR+2nsGgCBvd8b1iaBn40CNTFYgZeZCJAkJCfTt25egoCBMJhOLFi0qsv+7776jR48eVKtWDZPJRGJi4lXHyM3N5amnnqJatWp4eXkxcOBATp48WWTN4cOH6d27N5UqVcLf35/nnnuOwsLCImvi4uK45ZZbcHNzo0GDBsybN++q95o5cyZ169bF3d2dNm3asHnz5r/6EYiIiIhIBVO/uhefPnwrc/7ekpo+HhzPyuWJL7bzwIeb2Xfqgr3jiQOya9GWk5NDs2bNmDlz5u/u79ChA2+88cbvHmPkyJEsXbqUBQsWEB8fz/Hjx7nrrrts+y0WC7179yY/P58NGzbwySefMG/ePGJiYmxr0tLS6N27N127diUxMZFnn32WRx55hJUrV9rWzJ8/n1GjRjF+/Hi2b99Os2bNiI6O5tSpUyXwSYiIiIhIRWIymejZOJBVozrzdLcGuDqbWbfvDD3fSWDy93u4kFf45weRCsNhxiNNJhMLFy5kwIABV+07ePAgISEh7Nixg+bNm9u2Z2VlUb16db788kvuvvtuAFJSUggPD2fjxo20bduWH374gT59+nD8+HECAgIAmDNnDmPHjuX06dO4uroyduxYli9fTlJSku3YgwYNIjMzkxUrVgDQpk0bWrduzYwZMwCwWq0EBwczYsQIXnjhhes6R41HioiIiMi1HDqbw6Slu1mdcrkhEFDFjZd7R9C3aQ2NTJZTZWY88q/atm0bBQUFREVF2baFhYVRu3ZtNm7cCMDGjRtp0qSJrWADiI6OJjs7m+TkZNua3x7jyporx8jPz2fbtm1F1pjNZqKiomxrriUvL4/s7OwiDxERERGR/1WnmicfPtiaD4e2orZvJU5m5/H0Vzu4/98/k5p+3t7xxM7KdNGWnp6Oq6srPj4+RbYHBASQnp5uW/Pbgu3K/iv7/mhNdnY2ly5d4syZM1gslmuuuXKMa5k8eTLe3t62R3Bw8A2dp4iIiIhUDN3DA/hxZCdG3d4IN2czPx/IoNf0n/jnst1k5xbYO57YSZku2hzdiy++SFZWlu1x5MgRe0cSEREREQfn7uLE090bsmpUZ6IjA7BYDT5cl0a3qfF8t/0oDvLrJilFZbpoCwwMJD8/n8zMzCLbT548SWBgoG3N/15N8srzP1tTpUoVPDw88PPzw8nJ6ZprrhzjWtzc3KhSpUqRh4iIiIjI9Qj2rcT7D7Tik4dvJcTPkzMX8hj1zS/cM2cjycez7B1PSlGZLtpatmyJi4sLq1evtm1LTU3l8OHDtGvXDoB27dqxa9euIld5jI2NpUqVKkRERNjW/PYYV9ZcOYarqystW7YsssZqtbJ69WrbGhERERGRm6Fzo+qseLYjz/cMxcPFia2HztH3vXXELE4i66JGJisCu956/cKFC+zbt8/2PC0tjcTERHx9falduzYZGRkcPnyY48ePA5cLMrjcGQsMDMTb25thw4YxatQofH19qVKlCiNGjKBdu3a0bdsWgB49ehAREcEDDzzAlClTSE9P55VXXuGpp57Czc0NgMcff5wZM2bw/PPP8/DDD7NmzRq++eYbli9fbss2atQohg4dSqtWrbj11lt55513yMnJ4aGHHiqtj0tEREREKig3Zyee7NKAAc1r8q/v97B85wk+3XiI5TtPMLZnGHe3rIXZrKtMlld2veR/XFwcXbt2vWr70KFDmTdvHvPmzbtmUTR+/HgmTJgAXL659ujRo/nqq6/Iy8sjOjqaWbNmFRlbPHToEE888QRxcXF4enoydOhQXn/9dZyd/1uzxsXFMXLkSHbv3k2tWrUYN24cDz74YJH3nTFjBm+++Sbp6ek0b96c6dOn06ZNm+s+X13yX0RERERKwvp9Zxi/JNl2M+7mwT5M6h9J01o+9g0m1604tYHD3KetIlDRJiIiIiIlpcBiZd76g7yz6ldy8i2YTHD/rbV5rkcoVT1d7R1P/kSFuU+biIiIiEhF5eJk5tFO9VgzpgsDmgdhGPDlpsN0nRbHF5sOYbGqN1NeqNNWitRpExEREZGbZdOBs4xfkkzK/9+Mu0lNbyb2j+SW2lXtnEyuReORDkpFm4iIiIjcTIUWK5/9fIi3fvyV83mFANzbqhbP9wzDz8vNzunktzQeKSIiIiJSATk7mXnothDWjOnC3S1rAfDN1qN0mxrHJxsOUmix2jmh3Ah12kqROm0iIiIiUpq2HcogZnEyycezAQivUYVJ/SNpXdfXzslE45EOSkWbiIiIiJQ2i9Xgy82HmboylaxLl2/GfWeLmrx4Rxj+VdztnK7i0nikiIiIiIgA4GQ28UDbOqwd04X7bw3GZIKFO47RbVo8H/x0gAKNTDo8ddpKkTptIiIiImJviUcyGb84iV+OZgHQKMCLif0a065+NTsnq1g0HumgVLSJiIiIiCOwWg2+2XqEN1akcO7i5ZHJvs2CeLlXOIHeGpksDRqPFBERERGR32U2mxh0a23WjunCA23rYDbB0l+O021aHHPi95NfqJFJR6JOWylSp01EREREHFHSsSxiFiex/XAmAPWqezKxXyQdG1a3b7ByTOORDkpFm4iIiIg4KqvV4Lsdx3j9hz2cuZAPwB2NA3mlTwQ1fTzsnK780XikiIiIiIgUi9ls4u6WtVg9ugsP3VYXJ7OJH5LS6T4tjhlr9pJXaLF3xApLnbZSpE6biIiIiJQVe05kM35xMpsPZgBQt1olxveNpGuYv52TlQ8aj3RQKtpEREREpCwxDIMlvxznX8v3cOp8HgBR4QHE9ImgdrVKdk5Xtmk8UkRERERE/jKTyUT/5jVZPbozj3YMwdlsYtWek0S9Hc/bsb+SW6CRydKgTlspUqdNRERERMqyvSfPM35JMhv2nwWgVlUPYvpEcHtEACaTyc7pyhaNRzooFW0iIiIiUtYZhsH3u9J5dfluTmTlAtAltDrj+0YS4udp53Rlh4o2B6WiTURERETKi5y8Qmas3ccHPx2gwGLg6mTm0U4hPNW1AZVcne0dz+GpaHNQKtpEREREpLw5cPoCE5buJuHX0wAEebvzSp8I7mgcqJHJP6CizUGpaBMRERGR8sgwDH7cfZJJS3dzLPMSAB0a+DGhXwQN/CvbOZ1jUtHmoFS0iYiIiEh5dinfwuz4/cyJ309+oRVns4lhHUIY0b0hXm4amfwtXfJfRERERERKnYerE6Nub0TsyE50D/On0GrwfsIBuk+LY3HiMdQvujHqtJUiddpEREREpCJZveckE5fu5nDGRQDa1vNlYr/GhAZqZFLjkQ5KRZuIiIiIVDS5BRbmJhxg5tp95BVacTKbGNquLs/e3pAq7i72jmc3Go8UERERERGH4O7ixNPdG7JqVGeiIwOwWA0+Wp9Gt6nx/GfbUY1MXgd12kqROm0iIiIiUtHF/3qaCUuSSTuTA0CrOlWZ2D+SyCBvOycrXRqPdFAq2kREREREIK/Qwofr0nhv9T4uFVgwm+Dvbesw+vZQvCtVjJFJjUeKiIiIiIjDcnN24skuDVj9f+3de3AUZb7G8WeSkEnA3BDIBUfkIgQCBgEJ4aKCkYAWGIs9AmazwQVZF9hCLipCQVBc4bDAcXcLoUAUPa6CUIblQIwCghwhgIaEBQxxMQZQCC4CSQhKSOY9f2wxh4GgmUhmmvD9VHWV0/129zOpXw3z8+3umXKfHr4rWk4jvZVzRP0XbtPqz47K6WRe6XLMtHkRM20AAADA1XYcPqWM9Qd1+LtzkqSujnC9+Eic7rot3LfB6hGXR1oUTRsAAABQs4vVTq3cUaxXNn+pispq2WzSiHtu17PJHRTRJNDX8a47Lo8EAAAAcENp5O+nJ+9to61T71dK1xgZI72756j6L9ymt3cdUfVNfMkkM21exEwbAAAAUDu7i75XxvqDOlRSLknq0jJMLzwSp263R/g42fXB5ZEWRdMGAAAA1F5VtVP/veuIFn30pcovVEmS/qP7bXpucKya3WL3cbpfhssjAQAAANzwAvz99ESf1vp46v36VffbJElrcr/RgAXb9ObOYlVVO32c0DuYafMiZtoAAACAuss9clqz/n5QB4+XSZJio0I0J6Wz7rmjqY+TeY7LIy2Kpg0AAAD4ZaqdRu/sOaoFHxaq9IeLkqRH726p5wfHqkVokI/T1R6XRwIAAABokPz9bErr1Upbp96vkT0dstmkzLxvNWDhJ3rtf4t0sQFeMslMmxcx0wYAAABcX/uOndWsvx/Qvm9KJUntI2/RC0M7K7HtrT5O9tO4PNKiaNoAAACA68/pNHrv82P6z+xDOnP+35dMDomP0fSHYhUdFuzjdDXj8kgAAAAANw0/P5tG9LxdW6fer7RereRnk/5n33E9sPATLf3kK1VW3diXTDLT5kXMtAEAAAD178C3pZr19wPae/SsJKlN8yZ6YWic+t3Z3LfBLsPlkRZF0wYAAAB4h9Np9H7et5r3QYFOnauUJA2Ki9LMIZ3UMtz3l0xyeSQAAACAm5qfn02/6n6btky5X0/0uUP+fjZlHyzRoP/a7vqpgBtFgK8DAAAAAEB9CQtupIwhcXqsh0MZ6w8q/rYwhQU38nUsj9C0AQAAAGjwOkaHavXYXrpYfePdHUbTBgAAAOCmYLPZFBhg83UMj3FPGwAAAABYGE0bAAAAAFiYT5u27du3a8iQIYqJiZHNZtO6devcthtjNGvWLEVHRys4OFhJSUn65z//6Tbm9OnTSk1NVWhoqMLDwzV69GidO3fObcw//vEP9evXT0FBQXI4HJo/f/5VWdasWaPY2FgFBQWpS5cuysrK8jgLAAAAAFxvPm3aKioqFB8fr8WLF9e4ff78+frLX/6ipUuXavfu3WrSpImSk5P1448/usakpqbq4MGD2rRpkzZs2KDt27dr7Nixru1lZWUaOHCgWrVqpdzcXP3pT3/S7NmztWzZMteYnTt3auTIkRo9erTy8vKUkpKilJQUHThwwKMsAAAAAHC9WebHtW02mzIzM5WSkiLp3zNbMTExmjJliqZOnSpJKi0tVWRkpFauXKkRI0aooKBAnTp10meffaYePXpIkrKzs/XQQw/pm2++UUxMjJYsWaIZM2aopKREgYGBkqRp06Zp3bp1OnTokCRp+PDhqqio0IYNG1x5evXqpa5du2rp0qW1ylIb/Lg2AAAAAKmB/Lj2119/rZKSEiUlJbnWhYWFKSEhQTk5OZKknJwchYeHuxo2SUpKSpKfn592797tGnPvvfe6GjZJSk5OVmFhoc6cOeMac/l5Lo25dJ7aZKnJhQsXVFZW5rYAAAAAgCcs27SVlJRIkiIjI93WR0ZGuraVlJSoRYsWbtsDAgLUtGlTtzE1HePyc1xrzOXbfy5LTebOnauwsDDX4nA4fuZdAwAAAIA7yzZtDcHzzz+v0tJS13Ls2DFfRwIAAABwg7Fs0xYVFSVJOnnypNv6kydPurZFRUXpu+++c9teVVWl06dPu42p6RiXn+NaYy7f/nNZamK32xUaGuq2AAAAAIAnLNu0tW7dWlFRUdqyZYtrXVlZmXbv3q3ExERJUmJios6ePavc3FzXmI8//lhOp1MJCQmuMdu3b9fFixddYzZt2qQOHTooIiLCNeby81wac+k8tckCAAAAAPXBp03buXPnlJ+fr/z8fEn/fuBHfn6+jh49KpvNpqefflovvfSS1q9fr/379+s3v/mNYmJiXE+Y7NixowYNGqQnn3xSe/bs0Y4dOzRhwgSNGDFCMTExkqTHH39cgYGBGj16tA4ePKjVq1frz3/+syZPnuzKMXHiRGVnZ2vhwoU6dOiQZs+erc8//1wTJkyQpFplAQAAAIB6YXxo69atRtJVS3p6ujHGGKfTaWbOnGkiIyON3W43DzzwgCksLHQ7xvfff29GjhxpbrnlFhMaGmqeeOIJU15e7jZm3759pm/fvsZut5uWLVuaefPmXZXlvffeM+3btzeBgYEmLi7ObNy40W17bbL8nNLSUiPJlJaWerQfAAAAgIbFk97AMr/TdjPgd9oAAAAASA3kd9oAAAAAADRtAAAAAGBpNG0AAAAAYGE0bQAAAABgYQG+DnAzufTMl7KyMh8nAQAAAOBLl3qC2jwXkqbNi8rLyyVJDofDx0kAAAAAWEF5ebnCwsJ+cgyP/Pcip9Op48ePKyQkRDabzadZysrK5HA4dOzYMX5+ALVCzcBT1Aw8Rc3AU9QMPGWlmjHGqLy8XDExMfLz++m71php8yI/Pz/ddtttvo7hJjQ01OcFixsLNQNPUTPwFDUDT1Ez8JRVaubnZtgu4UEkAAAAAGBhNG0AAAAAYGE0bTcpu92ujIwM2e12X0fBDYKagaeoGXiKmoGnqBl46katGR5EAgAAAAAWxkwbAAAAAFgYTRsAAAAAWBhNGwAAAABYGE0bAAAAAFgYTVsDtnjxYt1xxx0KCgpSQkKC9uzZ85Pj16xZo9jYWAUFBalLly7KysryUlJYhSc1s3z5cvXr108RERGKiIhQUlLSz9YYGh5PP2cuWbVqlWw2m1JSUuo3ICzH05o5e/asxo8fr+joaNntdrVv355/n24yntbMK6+8og4dOig4OFgOh0OTJk3Sjz/+6KW08KXt27dryJAhiomJkc1m07p16352n23btqlbt26y2+1q166dVq5cWe8564KmrYFavXq1Jk+erIyMDO3du1fx8fFKTk7Wd999V+P4nTt3auTIkRo9erTy8vKUkpKilJQUHThwwMvJ4Sue1sy2bds0cuRIbd26VTk5OXI4HBo4cKC+/fZbLyeHr3haM5cUFxdr6tSp6tevn5eSwio8rZnKyko9+OCDKi4u1tq1a1VYWKjly5erZcuWXk4OX/G0Zt555x1NmzZNGRkZKigo0IoVK7R69WpNnz7dy8nhCxUVFYqPj9fixYtrNf7rr7/Www8/rP79+ys/P19PP/20xowZow8//LCek9aBQYPUs2dPM378eNfr6upqExMTY+bOnVvj+Mcee8w8/PDDbusSEhLM7373u3rNCevwtGauVFVVZUJCQsybb75ZXxFhMXWpmaqqKtO7d2/z2muvmfT0dPPII494ISmswtOaWbJkiWnTpo2prKz0VkRYjKc1M378eDNgwAC3dZMnTzZ9+vSp15ywHkkmMzPzJ8c8++yzJi4uzm3d8OHDTXJycj0mqxtm2hqgyspK5ebmKikpybXOz89PSUlJysnJqXGfnJwct/GSlJycfM3xaFjqUjNXOn/+vC5evKimTZvWV0xYSF1r5sUXX1SLFi00evRob8SEhdSlZtavX6/ExESNHz9ekZGR6ty5s15++WVVV1d7KzZ8qC4107t3b+Xm5rouoSwqKlJWVpYeeughr2TGjeVG+v4b4OsAuP5OnTql6upqRUZGuq2PjIzUoUOHatynpKSkxvElJSX1lhPWUZeaudJzzz2nmJiYqz780DDVpWY+/fRTrVixQvn5+V5ICKupS80UFRXp448/VmpqqrKysnT48GGNGzdOFy9eVEZGhjdiw4fqUjOPP/64Tp06pb59+8oYo6qqKj311FNcHokaXev7b1lZmX744QcFBwf7KNnVmGkD8IvNmzdPq1atUmZmpoKCgnwdBxZUXl6utLQ0LV++XM2aNfN1HNwgnE6nWrRooWXLlql79+4aPny4ZsyYoaVLl/o6Gixq27Ztevnll/Xqq69q7969ev/997Vx40bNmTPH19GAX4SZtgaoWbNm8vf318mTJ93Wnzx5UlFRUTXuExUV5dF4NCx1qZlLFixYoHnz5mnz5s2666676jMmLMTTmvnqq69UXFysIUOGuNY5nU5JUkBAgAoLC9W2bdv6DQ2fqsvnTHR0tBo1aiR/f3/Xuo4dO6qkpESVlZUKDAys18zwrbrUzMyZM5WWlqYxY8ZIkrp06aKKigqNHTtWM2bMkJ8f8xX4f9f6/hsaGmqpWTaJmbYGKTAwUN27d9eWLVtc65xOp7Zs2aLExMQa90lMTHQbL0mbNm265ng0LHWpGUmaP3++5syZo+zsbPXo0cMbUWERntZMbGys9u/fr/z8fNcydOhQ1xO7HA6HN+PDB+ryOdOnTx8dPnzY1eBL0pdffqno6GgatptAXWrm/PnzVzVml5p+Y0z9hcUN6Yb6/uvrJ6GgfqxatcrY7XazcuVK88UXX5ixY8ea8PBwU1JSYowxJi0tzUybNs01fseOHSYgIMAsWLDAFBQUmIyMDNOoUSOzf/9+X70FeJmnNTNv3jwTGBho1q5da06cOOFaysvLffUW4GWe1syVeHrkzcfTmjl69KgJCQkxEyZMMIWFhWbDhg2mRYsW5qWXXvLVW4CXeVozGRkZJiQkxLz77rumqKjIfPTRR6Zt27bmscce89VbgBeVl5ebvLw8k5eXZySZRYsWmby8PHPkyBFjjDHTpk0zaWlprvFFRUWmcePG5plnnjEFBQVm8eLFxt/f32RnZ/vqLVwTTVsD9te//tXcfvvtJjAw0PTs2dPs2rXLte2+++4z6enpbuPfe+890759exMYGGji4uLMxo0bvZwYvuZJzbRq1cpIumrJyMjwfnD4jKefM5ejabs5eVozO3fuNAkJCcZut5s2bdqYP/7xj6aqqsrLqeFLntTMxYsXzezZs03btm1NUFCQcTgcZty4cebMmTPeDw6v27p1a43fTS7VSHp6urnvvvuu2qdr164mMDDQtGnTxrzxxhtez10bNmOYKwYAAAAAq+KeNgAAAACwMJo2AAAAALAwmjYAAAAAsDCaNgAAAACwMJo2AAAAALAwmjYAAAAAsDCaNgAAAACwMJo2AAAAALAwmjYAAK6j4uJi2Ww25efn19s5Ro0apZSUlHo7PgDAWmjaAAC4zKhRo2Sz2a5aBg0aVKv9HQ6HTpw4oc6dO9dzUgDAzSLA1wEAALCaQYMG6Y033nBbZ7fba7Wvv7+/oqKi6iMWAOAmxUwbAABXsNvtioqKclsiIiIkSTabTUuWLNHgwYMVHBysNm3aaO3ata59r7w88syZM0pNTVXz5s0VHBysO++8060h3L9/vwYMGKDg4GDdeuutGjt2rM6dO+faXl1drcmTJys8PFy33nqrnn32WRlj3PI6nU7NnTtXrVu3VnBwsOLj490yAQBubDRtAAB4aObMmRo2bJj27dun1NRUjRgxQgUFBdcc+8UXX+iDDz5QQUGBlixZombNmkmSKioqlJycrIiICH322Wdas2aNNm/erAkTJrj2X7hwoVauXKnXX39dn376qU6fPq3MzEy3c8ydO1dvvfWWli5dqoMHD2rSpEn69a9/rU8++aT+/ggAAK+xmSv/dx0AADexUaNG6e2331ZQUJDb+unTp2v69Omy2Wx66qmntGTJEte2Xr16qVu3bnr11VdVXFys1q1bKy8vT127dtXQoUPVrFkzvf7661eda/ny5Xruued07NgxNWnSRJKUlZWlIUOG6Pjx44qMjFRMTIwmTZqkZ555RpJUVVWl1q1bq3v37lq3bp0uXLigpk2bavPmzUpMTHQde8yYMTp//rzeeeed+vgzAQC8iHvaAAC4Qv/+/d2aMklq2rSp678vb44uvb7W0yJ///vfa9iwYdq7d68GDhyolJQU9e7dW5JUUFCg+Ph4V8MmSX369JHT6VRhYaGCgoJ04sQJJSQkuLYHBASoR48erkskDx8+rPPnz+vBBx90O29lZaXuvvtuz988AMByaNoAALhCkyZN1K5du+tyrMGDB+vIkSPKysrSpk2b9MADD2j8+PFasGDBdTn+pfvfNm7cqJYtW7ptq+3DUwAA1sY9bQAAeGjXrl1Xve7YseM1xzdv3lzp6el6++239corr2jZsmWSpI4dO2rfvn2qqKhwjd2xY4f8/PzUoUMHhYWFKTo6Wrt373Ztr6qqUm5urut1p06dZLfbdfToUbVr185tcTgc1+stAwB8iJk2AACucOHCBZWUlLitCwgIcD1AZM2aNerRo4f69u2rv/3tb9qzZ49WrFhR47FmzZql7t27Ky4uThcuXNCGDRtcDV5qaqoyMjKUnp6u2bNn61//+pf+8Ic/KC0tTZGRkZKkiRMnat68ebrzzjsVGxurRYsW6ezZs67jh4SEaOrUqZo0aZKcTqf69u2r0tJS7dixQ6GhoUpPT6+HvxAAwJto2gAAuEJ2draio6Pd1nXo0EGHDh2SJL3wwgtatWqVxo0bp+joaL377rvq1KlTjccKDAzU888/r+LiYgUHB6tfv35atWqVJKlx48b68MMPNXHiRN1zzz1q3Lixhg0bpkWLFrn2nzJlik6cOKH09HT5+fnpt7/9rR599FGVlpa6xsyZM0fNmzfX3LlzVVRUpPDwcHXr1k3Tp0+/3n8aAIAP8PRIAAA8YLPZlJmZqZSUFF9HAQDcJLinDQAAAAAsjKYNAAAAACyMe9oAAPAAdxUAALyNmTYAAAAAsDCaNgAAAACwMJo2AAAAALAwmjYAAAAAsDCaNgAAAACwMJo2AAAAALAwmjYAAAAAsDCaNgAAAACwsP8Dj0VtoYqRtfIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIjCAYAAADvBuGTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACDoUlEQVR4nOzdeVhWdf7/8ed9syuLoqCiKAgqgkqmZZgKCu4LVlPmWFpZafuiNdlMbi1aactUmmVZTYuVZVqNkRu4lSlmIiqKiCguuIKibPd9fn808YuvaLJ5WF6P67qva+5zzv3hdfS+Jt+83+cci2EYBiIiIiIiIlIhVrMDiIiIiIiI1AYqrkRERERERCqBiisREREREZFKoOJKRERERESkEqi4EhERERERqQQqrkRERERERCqBiisREREREZFKoOJKRERERESkEqi4EhERERERqQQqrkRERERERCqBiisREak2Pv30U1577TWzY4iIiJSLxTAMw+wQIiIiAEOGDGH79u2kp6ebHUVERKTM1LkSEZEaKS8vD7vdbnaMKy43N9fsCCIichEqrkREpNwyMzO56667aNKkCS4uLoSFhfH++++XOCY+Ph6LxcIXX3zB888/T4sWLXB1dSU6OprU1NTi46Kiovj+++/Zv38/FosFi8VCQEBAiTUWLlzIv/71L5o3b069evXIyckB4Msvv6RLly64ubnRuHFjbrvtNjIzM0vkuOOOO3B3dyctLY3+/ftTv359/Pz8mD59On8McRiGQUBAALGxsReca15eHl5eXowbN+4v/1w+/vhjrr32WurVq0fDhg3p1asXP/74Y/F+i8XC1KlTL/hcQEAAd9xxR/H7Dz74AIvFQkJCAvfffz++vr60aNGCRYsWFW//v+bNm4fFYmH79u3F23bt2sXf/vY3vL29cXV1pWvXrixduvQvz0NERMrG0ewAIiJSMx09epTrrrsOi8XCgw8+iI+PD8uWLWPs2LHk5OTw6KOPljh+5syZWK1WJk6cSHZ2Ni+99BKjRo1i48aNAPzzn/8kOzubgwcP8uqrrwLg7u5eYo1nn30WZ2dnJk6cSH5+Ps7OznzwwQfceeedXHPNNcyYMYOjR4/y+uuvs379en799VcaNGhQ/HmbzcaAAQO47rrreOmll/jhhx+YMmUKRUVFTJ8+HYvFwm233cZLL73EyZMn8fb2Lv7st99+S05ODrfddtsl/1ymTZvG1KlT6d69O9OnT8fZ2ZmNGzeyatUq+vXrV64/6/vvvx8fHx8mT55Mbm4ugwcPxt3dnS+++ILIyMgSx37++eeEhYXRoUMHAJKTk7n++utp3rw5Tz31FPXr1+eLL75g+PDhfPXVV9xwww3lyiQiIqUwREREymHs2LFGs2bNjOPHj5fYfuuttxpeXl7GuXPnDMMwjNWrVxuA0b59eyM/P7/4uNdff90AjKSkpOJtgwcPNlq1anXBz/pjjdatWxevaxiGUVBQYPj6+hodOnQwzp8/X7z9u+++MwBj8uTJxdvGjBljAMZDDz1UvM1utxuDBw82nJ2djWPHjhmGYRgpKSkGYMydO7dEhmHDhhkBAQGG3W6/6J/Jnj17DKvVatxwww2GzWYrse/PnwOMKVOmXPD5Vq1aGWPGjCl+v2DBAgMwevToYRQVFZU4duTIkYavr2+J7YcPHzasVqsxffr04m3R0dFGx44djby8vBJZunfvbrRp0+ai5yIiImWnsUARESkzwzD46quvGDp0KIZhcPz48eJX//79yc7OZsuWLSU+c+edd+Ls7Fz8vmfPngCkpaVd9s8dM2YMbm5uxe83b95MVlYW999/P66ursXbBw8eTEhICN9///0Fazz44IPF//uPrltBQQErVqwAoG3btnTr1o1PPvmk+LiTJ0+ybNkyRo0ahcViuWi+b775BrvdzuTJk7FaS/4n9lKf+yv33HMPDg4OJbaNGDGCrKws4uPji7ctWrQIu93OiBEjinOvWrWKW265hTNnzhT/HZ04cYL+/fuzZ8+eC8YnRUSk/FRciYhImR07dozTp0/zzjvv4OPjU+J15513ApCVlVXiMy1btizxvmHDhgCcOnXqsn9uYGBgiff79+8HoF27dhccGxISUrz/D1arldatW5fY1rZtW4ASdygcPXo069evL/78l19+SWFhIbfffvsl8+3duxer1UpoaOjlndBl+r/nDTBgwAC8vLz4/PPPi7d9/vnnXHXVVcXnlJqaimEYPPPMMxf8PU2ZMgW48O9JRETKT9dciYhImf1xl77bbruNMWPGlHpMp06dSrz/v52XPxhleCLIn7tWVenWW2/lscce45NPPuHpp5/m448/pmvXrqUWcZXJZrOVur2083ZxcWH48OEsXryYOXPmcPToUdavX88LL7xQfMwff08TJ06kf//+pa4dHBxcCclFRARUXImISDn4+Pjg4eGBzWYjJiam0tYt6+hcq1atAEhJSaFPnz4l9qWkpBTv/4PdbictLa24swOwe/dugOI7EwJ4e3szePBgPvnkE0aNGsX69esv6+HGQUFB2O12duzYwVVXXXXR4xo2bMjp06dLbCsoKODw4cN/+TP+bMSIEXz44YesXLmSnTt3YhhG8UggUNylc3JyqtS/JxERKZ3GAkVEpMwcHBy46aab+Oqrr0rc8vsPx44dK9e69evXJzs7+7KP79q1K76+vrz99tvk5+cXb1+2bBk7d+5k8ODBF3zmzTffLP7fhmHw5ptv4uTkRHR0dInjbr/9dnbs2METTzyBg4MDt95661/mGT58OFarlenTp1/wDK4/d+iCgoJYs2ZNif3vvPPORTtXFxMTE4O3tzeff/45n3/+Oddee22JEUJfX1+ioqKYN29eqYVbef+eRESkdOpciYhIucycOZPVq1fTrVs37rnnHkJDQzl58iRbtmxhxYoVnDx5ssxrdunShc8//5zHH3+ca665Bnd3d4YOHXrR452cnHjxxRe58847iYyMZOTIkcW3Yg8ICOCxxx4rcbyrqys//PADY8aMoVu3bixbtozvv/+ep59+Gh8fnxLHDh48mEaNGvHll18ycOBAfH19/zJ/cHAw//znP3n22Wfp2bMnN954Iy4uLmzatAk/Pz9mzJgBwN1338348eO56aab6Nu3L7/99htxcXE0bty4TH9eTk5O3HjjjSxcuJDc3FxmzZp1wTFvvfUWPXr0oGPHjtxzzz20bt2ao0eP8tNPP3Hw4EF+++23Mv1MERG5BBPvVCgiIjXc0aNHjQceeMDw9/c3nJycjKZNmxrR0dHGO++8U3zMH7dR//LLL0t8dt++fQZgLFiwoHjb2bNnjb///e9GgwYNDKD4tuwXW+MPn3/+udG5c2fDxcXF8Pb2NkaNGmUcPHiwxDFjxowx6tevb+zdu9fo16+fUa9ePaNJkybGlClTLrht+h/uv/9+AzA+/fTTMv25vP/++8V5GjZsaERGRhrLly8v3m+z2Yx//OMfRuPGjY169eoZ/fv3N1JTUy96K/ZNmzZd9GctX77cAAyLxWIcOHCg1GP27t1rjB492mjatKnh5ORkNG/e3BgyZIixaNGiMp2XiIhcmsUwynAlsYiISA11xx13sGjRIs6ePXvZn3nsscd47733OHLkCPXq1avCdCIiUhvomisREZFS5OXl8fHHH3PTTTepsBIRkcuia65ERET+JCsrixUrVrBo0SJOnDjBI488YnYkERGpIVRciYiI/MmOHTsYNWoUvr6+/Pvf/77kLdVFRET+TNdciYiIiIiIVAJdcyUiIiIiIlIJVFyJiIiIiIhUAl1zVQq73c6hQ4fw8PDAYrGYHUdERERERExiGAZnzpzBz88Pq/XSvSkVV6U4dOgQ/v7+ZscQEREREZFq4sCBA7Ro0eKSx6i4KoWHhwfw+x+gp6enyWlERERERMQsOTk5+Pv7F9cIl6LiqhR/jAJ6enqquBIRERERkcu6XEg3tBAREREREakEKq5EREREREQqgYorERERERGRSqBrrkRERESkWjAMg6KiImw2m9lRpA5xcHDA0dGxUh7BpOJKRERERExXUFDA4cOHOXfunNlRpA6qV68ezZo1w9nZuULrqLgSEREREVPZ7Xb27duHg4MDfn5+ODs7V0oXQeSvGIZBQUEBx44dY9++fbRp0+YvHxR8KSquRERERMRUBQUF2O12/P39qVevntlxpI5xc3PDycmJ/fv3U1BQgKura7nX0g0tRERERKRaqEjHQKQiKuu7p2+wiIiIiIhIJVBxJSIiIiIiUglUXImIiIiImCg9PR2LxcLWrVur7GfccccdDB8+vMrWrwkCAgJ47bXXqvRnqLgSERERESmnO+64A4vFcsFrwIABl72Gv78/hw8fpkOHDlWYtOKioqKKz8/V1ZW2bdsyY8YMDMMwO1q1obsFioiIiIhUwIABA1iwYEGJbS4uLpf9eQcHB5o2bVrZsarEPffcw/Tp08nPz2fVqlXce++9NGjQgPvuu8/saADYbDYsFotpN0dR50pEREREqh3DMDhXUGTKq6ydGBcXF5o2bVri1bBhw+L9FouFuXPnMnDgQNzc3GjdujWLFi0q3v9/xwJPnTrFqFGj8PHxwc3NjTZt2pQo3pKSkujTpw9ubm40atSIe++9l7Nnzxbvt9lsPP744zRo0IBGjRrx5JNPXnBOdrudGTNmEBgYiJubG+Hh4SUyXUy9evVo2rQprVq14s4776RTp04sX768eH9+fj4TJ06kefPm1K9fn27duhEfH1/8d+rj41Pi51x11VU0a9as+P26detwcXEpfpj0K6+8QseOHalfvz7+/v7cf//9Jc71gw8+oEGDBixdupTQ0FBcXFzIyMggKyuLoUOH4ubmRmBgIJ988slfnltlUOdKRERERKqd84U2QifHmfKzd0zvTz3nyv1n8jPPPMPMmTN5/fXX+c9//sOtt95KUlIS7du3L/XYHTt2sGzZMho3bkxqairnz58HIDc3l/79+xMREcGmTZvIysri7rvv5sEHH+SDDz4AYPbs2XzwwQe8//77tG/fntmzZ7N48WL69OlT/DNmzJjBxx9/zNtvv02bNm1Ys2YNt912Gz4+PkRGRv7l+RiGwbp169i1axdt2rQp3v7ggw+yY8cOFi5ciJ+fH4sXL2bAgAEkJSXRpk0bevXqRXx8PH/72984deoUO3fuxM3NjV27dhESEkJCQgLXXHNN8fPOrFYr//73vwkMDCQtLY3777+fJ598kjlz5hT/zHPnzvHiiy8yf/58GjVqhK+vL3/72984dOgQq1evxsnJiYcffpisrKxy/d2VhYorEREREZEK+O6773B3dy+x7emnn+bpp58ufn/zzTdz9913A/Dss8+yfPly3njjjRJFwh8yMjLo3LkzXbt2BX6/EcMfPv30U/Ly8vjoo4+oX78+AG+++SZDhw7lxRdfpEmTJrz22mtMmjSJG2+8EYC3336buLj/X6jm5+fzwgsvsGLFCiIiIgBo3bo169atY968eZcsrubMmcP8+fMpKCigsLAQV1dXHn744eLcCxYsICMjAz8/PwAmTpzIDz/8wIIFC3jhhReIiopi3rx5AKxZs4bOnTvTtGlT4uPjCQkJIT4+vsTPf/TRR4v/d0BAAM899xzjx48v8edWWFjInDlzCA8PB2D37t0sW7aMX375hWuuuQaA9957r9RCtrKpuKrmEvef4uCpcwwL98NisZgdR0REROSKcHNyYMf0/qb97LLo3bs3c+fOLbHN29u7xPs/ipg/v7/Y3QHvu+8+brrpJrZs2UK/fv0YPnw43bt3B2Dnzp2Eh4cXF1YA119/PXa7nZSUFFxdXTl8+DDdunUr3u/o6EjXrl2LRwNTU1M5d+4cffv2LfFzCwoK6Ny58yXPddSoUfzzn//k1KlTTJkyhe7duxdnS0pKwmaz0bZt2xKfyc/Pp1GjRgBERkbyyCOPcOzYMRISEoiKiioursaOHcuGDRt48skniz+7YsUKZsyYwa5du8jJyaGoqIi8vDzOnTtX3N1ydnamU6dOxZ/ZuXMnjo6OdOnSpXhbSEgIDRo0uOS5VQYVV9VYkc3OPxcnsevIGT7dmMH02A60a+phdiwRERGRKmexWCp9NK+q1K9fn+Dg4Epbb+DAgezfv5///ve/LF++nOjoaB544AFmzZpVKev/cc3S999/T/PmzUvs+6sbcXh5eRWf6xdffEFwcDDXXXcdMTExnD17FgcHBxITE3FwKFmg/tHZ69ixI97e3iQkJJCQkMDzzz9P06ZNefHFF9m0aROFhYXFxVp6ejpDhgzhvvvu4/nnn8fb25t169YxduxYCgoKiosrNze3atOE0A0tqjG7AUM6NcPVycrGfScZ9O+1TPs2mZy8QrOjiYiIiEgZ/Pzzzxe8v9SYmo+PD2PGjOHjjz/mtdde45133gGgffv2/Pbbb+Tm5hYfu379eqxWK+3atcPLy4tmzZqxcePG4v1FRUUkJiYWv//zjR+Cg4NLvPz9/S/7nNzd3XnkkUeYOHEihmHQuXNnbDYbWVlZF6z7x90QLRYLPXv2ZMmSJSQnJ9OjRw86depEfn4+8+bNo2vXrsVducTEROx2O7Nnz+a6666jbdu2HDp06C9zhYSEXHDOKSkpnD59+rLPrbxUXFVjzo5WHuzThhWPRzIgrCk2u8GC9en0mZXAV4kH9UwBERERkWogPz+fI0eOlHgdP368xDFffvkl77//Prt372bKlCn88ssvPPjgg6WuN3nyZJYsWUJqairJycl89913xYXYqFGjcHV1ZcyYMWzfvp3Vq1fz0EMPcfvtt9OkSRMAHnnkEWbOnMk333zDrl27uP/++0sUFh4eHkycOJHHHnuMDz/8kL1797JlyxbeeOMNPvzwwzKd+7hx49i9ezdfffUVbdu2ZdSoUYwePZqvv/6affv28csvvzBjxgy+//774s9ERUXx2WefcdVVV+Hu7o7VaqVXr1588sknJa63Cg4OprCwkDfeeIO0tDT+85//8Pbbb/9lpnbt2jFgwADGjRvHxo0bSUxM5O6778bNza1M51YeKq5qgBYN6/H27V346K5rae1Tn+Nn85nw5W/c/PZPJB/KNjueiIiISJ32ww8/0KxZsxKvHj16lDhm2rRpLFy4kE6dOvHRRx/x2WefERoaWup6zs7OTJo0iU6dOtGrVy8cHBxYuHAh8Put0OPi4jh58iTXXHMNf/vb34iOjubNN98s/vyECRO4/fbbGTNmDBEREXh4eHDDDTeU+BnPPvsszzzzDDNmzKB9+/YMGDCA77//nsDAwDKdu7e3N6NHj2bq1KnY7XYWLFjA6NGjmTBhAu3atWP48OFs2rSJli1bFn8mMjISm81GVFRU8baoqKgLtoWHh/PKK6/w4osv0qFDBz755BNmzJhxWbkWLFiAn58fkZGR3Hjjjdx77734+vqW6dzKw2Ko/XGBnJwcvLy8yM7OxtPT0+w4JRQU2Xlv3T7eWLWHcwU2rBa47bpWTOjbDq96TmbHExERESmzvLw89u3bR2BgIK6urmbHqXQWi4XFixczfPhws6PIRVzqO1iW2kCdqxrG2dHKfVFBrJwQyZBOzbAb8NFP++k9O57PN2Vgt6tWFhERERExg4qrGqqZlxtv/v1qPr27G2183TmZW8A/vkrihrkb2HbwtNnxRERERETqHBVXNVz34Mb895Ge/Gtwe9xdHPntwGli31rPpK+TOJlbYHY8ERERkTrPMAyNBNYRKq5qAScHK3f3bM2qCZHc0Lk5hgGf/ZJBn9nxfPzzfmwaFRQRERERqXIqrmoRX09XXh1xFV+MiyCkqQenzxXyr2+2E/vWOhL3nzI7noiIiMgl6T5rYpbK+u6puKqFrg305ruHejB1aCgero5sz8zhprkbeOLL3zh+Nt/seCIiIiIlODn9fsfjc+fOmZxE6qo/vnt/fBfLS7diL0V1vhV7WR0/m8+Ly3bxZeJBADxcHZnQty23XdcKRwfV1iIiIlI9HD58mNOnT+Pr60u9evWwWCxmR5I6wDAMzp07R1ZWFg0aNKBZs2YXHFOW2sDU4mru3LnMnTuX9PR0AMLCwpg8eTIDBw4Efn/i84oVKzh06BDu7u50796dF198kZCQkIuuefbsWZ566im++eYbTpw4QWBgIA8//DDjx4+/7Fy1qbj6w5aMU0xesp3tmTkAhDT1YHpsB64N9DY5mYiIiMjv/8g9cuQIp0+fNjuK1EENGjSgadOmpRb1Naa4+vbbb3FwcKBNmzYYhsGHH37Iyy+/zK+//kpYWBjvvPMOISEhtGzZkpMnTzJ16lS2bt3Kvn37cHBwKHXNe++9l1WrVjF//nwCAgL48ccfuf/++/n6668ZNmzYZeWqjcUVgM1u8NkvGbwcl0L2+UIAbujcnEkDQ/D1rH0P7BMREZGax2azUVhYaHYMqUOcnJwuWltADSquSuPt7c3LL7/M2LFjL9i3bds2wsPDSU1NJSgoqNTPd+jQgREjRvDMM88Ub+vSpQsDBw7kueeeu6wMtbW4+sPJ3AJejkth4aYMDAPcXRx5NKYNY7oH4KRRQRERERGRYmWpDarNv6RtNhsLFy4kNzeXiIiIC/bn5uayYMECAgMD8ff3v+g63bt3Z+nSpWRmZmIYBqtXr2b37t3069fvop/Jz88nJyenxKs2867vzIwbO/LN/dcT7t+As/lFPPf9Tga9vpYNe4+bHU9EREREpEYyvbhKSkrC3d0dFxcXxo8fz+LFiwkNDS3eP2fOHNzd3XF3d2fZsmUsX74cZ2fni673xhtvEBoaSosWLXB2dmbAgAG89dZb9OrV66KfmTFjBl5eXsWvSxVvtUm4fwMW39edF2/qiHd9Z/ZkneXv727kwU+3cDj7vNnxRERERERqFNPHAgsKCsjIyCA7O5tFixYxf/58EhISigus7OxssrKyOHz4MLNmzSIzM5P169fj6lr6NUKzZs3i3XffZdasWbRq1Yo1a9YwadIkFi9eTExMTKmfyc/PJz///9+iPCcnB39//1o7Flia0+cKeGX5bj7+eT92A+o5O/BQnzaM7RGIs6PpNbiIiIiIiClq9DVXMTExBAUFMW/evAv2FRQU0LBhQ+bPn8/IkSMv2H/+/Hm8vLxYvHgxgwcPLt5+9913c/DgQX744YfLylDbr7m6lORD2Uxeklz80OHWjeszdVgYvdr6mJxMREREROTKq5HXXP3BbreX6CL9mWEYGIZx0f2FhYUUFhZitZY8LQcHB+x2e6VnrY3C/LxYND6C2TeH09jdhbTjuYx+/xfG/yeRg6f0YD8RERERkYsxtbiaNGkSa9asIT09naSkJCZNmkR8fDyjRo0iLS2NGTNmkJiYSEZGBhs2bODmm2/Gzc2NQYMGFa8REhLC4sWLAfD09CQyMpInnniC+Ph49u3bxwcffMBHH33EDTfcYNZp1jgWi4WburRg1cRI7ro+EAerhR+SjxDzSgJvrNxDXqHN7IgiIiIiItWOqcVVVlYWo0ePpl27dkRHR7Np0ybi4uLo27cvrq6urF27lkGDBhEcHMyIESPw8PBgw4YN+Pr6Fq+RkpJCdnZ28fuFCxdyzTXXMGrUKEJDQ5k5cybPP/98mR4iLL/zdHVi8tBQvn+4B9cGepNXaGf28t30f20Nq3YdNTueiIiIiEi1Uu2uuaoO6vI1VxdjGAZLfzvEC//dydGc38cyY9r7MnlIGC0b1TM5nYiIiIhI1ajR11xJ9WSxWIi9qjkrJ0QxrldrHK0WVuzMIubVBF5ZvlujgiIiIiJS56lzVQp1rv5aatYZpixNZn3qCQBaNHTjmSGh9AttgsViMTmdiIiIiEjlqNG3Yq8OVFxdHsMwWLb9CM99t4ND2XkARLb1YeqwMAIb1zc5nYiIiIhIxam4qiAVV2VzrqCIt1an8u6afRTY7Dg7WLm7ZyAP9gmmnrOj2fFERERERMpNxVUFqbgqn33Hc5m6NJmE3ccA8PNy5V9DQhnYoalGBUVERESkRlJxVUEqrsrPMAyW7zjK9O92cPDUeQB6BDdm6rBQgn09TE4nIiIiIlI2Kq4qSMVVxeUV2pgbv5e5CXspKLLjaLVwV49AHo5ug7uLRgVFREREpGbQrdjFdK5ODjzWty0rHoskpr0vRXaDd9akET07niVbM1FNLyIiIiK1jTpXpVDnqvKt2nWUad/uYP+JcwB0C/RmemwH2jXVqKCIiIiIVF8aC6wgFVdVI6/Qxvy1aby5OpW8QjsOVgujI1rxWN+2eLo6mR1PREREROQCGguUasnVyYEH+7RhxeORDOzQFJvdYMH6dPrMimdR4kHsdtX5IiIiIlJzqXNVCnWurow1u48x9dtk0o7lAtClVUOmx4YR5udlcjIRERERkd9pLLCCVFxdOQVFdt5fv49/r9zDuQIbVgvcdl0rJvRth1c9jQqKiIiIiLk0Fig1hrOjlfGRQaycEMmQTs2wG/DRT/vpPTuezzdlaFRQRERERGoMda5Koc6VeTbsPc6UJcnsyToLQLh/A56NDaNTiwbmBhMRERGROkljgRWk4spchTY7H25I57UVezibX4TFArde488T/UPwru9sdjwRERERqUM0Fig1mpODlbt7tmbVhEhu6Nwcw4DPfjlAn9nxfPzzfmwaFRQRERGRakidq1Koc1W9/LLvJJOXbGfXkTMAdGjuybRhHejSqqHJyURERESkttNYYAWpuKp+imx2PtmYwawfUziTVwTAzV1a8I+BITR2dzE5nYiIiIjUVhoLlFrH0cHKmO4BrJ4YxS1dWwDwZeJBes+K54P1+yiy2U1OKCIiIiJ1nTpXpVDnqvrbknGKyUu2sz0zB4CQph5Mj+3AtYHeJicTERERkdpEY4EVpOKqZrDZDT77JYOX41LIPl8IwA2dmzNpYAi+nq4mpxMRERGR2kBjgVInOFgt3HZdK1ZPjGLktS2xWGDxr5n0mZ3A/LVpFGpUUERERESuIHWuSqHOVc207eBpnlmSzG8HTgPQxtedabFhdA9qbG4wEREREamxNBZYQSquai673eDLxAO8+EMKJ3MLABjcqRn/GtyeZl5uJqcTERERkZpGY4FSZ1mtFkZc05LVE6IYHdEKqwW+33aY6NkJzI3fS0GRRgVFREREpGqoc1UKda5qj+RD2UxZkszm/acAaN24PlOHhdGrrY/JyURERESkJtBYYAWpuKpdDMPg6y2ZzFi2i+Nn8wEYENaUfw1pT4uG9UxOJyIiIiLVmcYCRf7EYrFwU5cWrJoYyV3XB+JgtfBD8hFiXkngjZV7yCu0mR1RRERERGoBda5Koc5V7bbrSA5TliSzcd9JAFo1qseUoaH0CWlicjIRERERqW40FlhBKq5qP8MwWPrbIV74706O5vw+KhjT3pfJQ8Jo2UijgiIiIiLyO40FivwFi8VC7FXNWTkhinG9WuNotbBiZxYxrybwyvLdGhUUERERkTJT56oU6lzVPalZZ5m6NJl1qccBaNHQjWeGhNIvtAkWi8XkdCIiIiJiFo0FVpCKq7rJMAyWbT/Cc9/t4FB2HgCRbX2YMjSU1j7uJqcTERERETOouKogFVd127mCIt5ancq7a/ZRYLPj7GDl7p6BPNgnmHrOjmbHExEREZErSMVVBam4EoB9x3OZ9m0y8SnHAGjm5cq/BocyqGNTjQqKiIiI1BEqripIxZX8wTAMlu84yvTvdnDw1HkArg9uxLRhYQT7epicTkRERESqmoqrClJxJf9XXqGNufF7mZuwl4IiO45WC3f1COTh6Da4u2hUUERERKS20q3YRSqZq5MDj/Vty4rHIolp34Qiu8E7a9LoMyueJVsz0e8oRERERESdq1KocyV/ZfWuLKZ+m8z+E+cAuDbQm+mxYYQ01fdFREREpDbRWGAFqbiSy5FXaGP+2jTeXJ1KXqEdB6uF0RGteKxvWzxdncyOJyIiIiKVoMaMBc6dO5dOnTrh6emJp6cnERERLFu2rHj/uHHjCAoKws3NDR8fH2JjY9m1a9cl17RYLKW+Xn755ao+HaljXJ0ceLBPG1Y8HsnADk2x2Q0WrE+nz6x4FiUexG7X7y1ERERE6hJTi6sWLVowc+ZMEhMT2bx5M3369CE2Npbk5GQAunTpwoIFC9i5cydxcXEYhkG/fv2w2WwXXfPw4cMlXu+//z4Wi4WbbrrpSp2W1DEtGtZj7m1d+Oiua2ntU5/jZwuY+OVv3DzvJ7ZnZpsdT0RERESukGo3Fujt7c3LL7/M2LFjL9i3bds2wsPDSU1NJSgo6LLWGz58OGfOnGHlypWXnUFjgVJeBUV23l+/j3+v3MO5AhtWC4zq1oqJ/drhVU+jgiIiIiI1TY0ZC/wzm83GwoULyc3NJSIi4oL9ubm5LFiwgMDAQPz9/S9rzaNHj/L999+XWqj9WX5+Pjk5OSVeIuXh7GhlfGQQKydEMqRTM+wG/Ofn/fSeHc/CXzI0KigiIiJSi5leXCUlJeHu7o6Liwvjx49n8eLFhIaGFu+fM2cO7u7uuLu7s2zZMpYvX46zs/Nlrf3hhx/i4eHBjTfeeMnjZsyYgZeXV/Hrcos3kYtp5uXGm3+/mk/v6UYbX3dO5hbw1NdJ3DB3A9sOnjY7noiIiIhUAdPHAgsKCsjIyCA7O5tFixYxf/58EhISigus7OxssrKyOHz4MLNmzSIzM5P169fj6ur6l2uHhITQt29f3njjjUsel5+fT35+fvH7nJwc/P39NRYolaLQZufDDem8tmIPZ/OLsFjg1mv8eaJ/CN71L+8XBSIiIiJijhp9K/aYmBiCgoKYN2/eBfsKCgpo2LAh8+fPZ+TIkZdcZ+3atfTq1YutW7cSHh5epgy65kqqQlZOHjOX7eLrXzMB8HJzYmL/dvz92pY4WC0mpxMRERGR0tTIa67+YLfbS3SR/swwDAzDuOj+P3vvvffo0qVLmQsrkari6+nKKyOu4svxEYQ09SD7fCHPfLOd2LfWkbj/lNnxRERERKSCTC2uJk2axJo1a0hPTycpKYlJkyYRHx/PqFGjSEtLY8aMGSQmJpKRkcGGDRu4+eabcXNzY9CgQcVrhISEsHjx4hLr5uTk8OWXX3L33Xdf6VMS+UvXBHjz3UM9mDYsDA9XR7Zn5nDT3A1M/PI3jp/9618ciIiIiEj1ZGpxlZWVxejRo2nXrh3R0dFs2rSJuLg4+vbti6urK2vXrmXQoEEEBwczYsQIPDw82LBhA76+vsVrpKSkkJ1d8llCCxcuxDCMvxwdFDGLo4OVMd0DWD0xilu6tgBgUeJBes+KZ8H6fRTZ7CYnFBEREZGyqnbXXFUHuuZKrrQtGaeYvGQ72zN/fwxASFMPpg0Lo1vrRiYnExEREanbavQNLaoDFVdiBpvdYOGmDF6OS+H0uUIAhl/lx9OD2uPr+dd3xxQRERGRylejb2ghUlc5WC2M6taK1ROiGHltSywW+GbrIfrMTmD+2jQKNSooIiIiUq2pc1UKda6kOth28DSTlySz9cBpANr4ujMtNozuQY3NDSYiIiJSh2gssIJUXEl1YbcbLEo8yMwfdnEytwCAwZ2a8a/B7Wnm5WZyOhEREZHaT2OBIrWE1Wrhlmv8WT0hijERrbBa4Ptth+kzK4E58akUFGlUUERERKS6UOeqFOpcSXWVfCibKUuS2fy/hw63blyfqcPC6NXWx+RkIiIiIrWTxgIrSMWVVGeGYbD410xe+O+u4ocO9w9rwjNDQmnRsJ7J6URERERqF40FitRiFouFG69uwaqJkdx1fSAOVgtxyUeJeSWBN1buIa/QZnZEERERkTpJnatSqHMlNUnKkTNMXrKdjftOAtCqUT2mDA2lT0gTk5OJiIiI1HwaC6wgFVdS0xiGwbfbDvP89zs4mvP7qGB0iC9ThobRspFGBUVERETKS2OBInWMxWJhWLgfKydEMa5XaxytFlbuyiLm1QReWb6b8wUaFRQRERGpaupclUKdK6npUrPOMnVpMutSjwPQvIEbk4eG0i+0CRaLxeR0IiIiIjWHxgIrSMWV1AaGYfDD9iM8+90ODmXnARDZ1ocpQ0Np7eNucjoRERGRmkHFVQWpuJLa5FxBEXNW7+WdNWkU2Ow4OVi4u2drHuoTTD1nR7PjiYiIiFRrKq4qSMWV1Eb7jucy7dtk4lOOAdDMy5V/DQ5lUMemGhUUERERuQgVVxWk4kpqK8MwWL7jKNO/28HBU+cBuD64EdOGhRHs62FyOhEREZHqR8VVBam4ktour9DG3Pi9zE3YS0GRHUerhbt6BPJwdBvcXTQqKCIiIvIH3YpdRC7J1cmBx/q2ZcVjkcS0b0KR3eCdNWn0mRXPkq2Z6HcuIiIiImWnzlUp1LmSumb1riymfpvM/hPnALg20JvpsWGENNX3X0REROo2jQVWkIorqYvyCm3MX5vGm6tTySu042C1MDqiFY/GtMXLzcnseCIiIiKm0FigiJSZq5MDD/Zpw8oJUQzs0BSb3WDB+nSiZ8ezKPEgdrt+DyMiIiJyKepclUKdKxFYu+cYU5Ymk3YsF4AurRoybVgYHZp7mZxMRERE5MrRWGAFqbgS+V1BkZ331+/j3yv3cK7AhtUCo7q1YkK/tjSo52x2PBEREZEqp7FAEakUzo5WxkcGsWpCFEPD/bAb8J+f99NndgILf8nQqKCIiIjIn6hzVQp1rkRKt2HvcaYsSWZP1lkAwlt4MT22A+H+DcwNJiIiIlJFNBZYQSquRC6u0Gbnww3pvLZiD2fzi7BY4NZr/Hmifwje9TUqKCIiIrWLxgJFpMo4OVi5u2drVk2M5MbOzTEM+OyXA/SeFc9/ft6PTaOCIiIiUkepc1UKda5ELt+m9JM88812dh05A0CYnyfTYzvQpVVDk5OJiIiIVJzGAitIxZVI2RTZ7HyyMYNZP6ZwJq8IgL91acE/BoTg4+FicjoRERGR8tNYoIhcUY4OVsZ0D2D1xChu6doCgEWJB+kzO54F6/dRZLObnFBERESk6qlzVQp1rkQqZkvGKSYv2c72zBwAQpp6MG1YGN1aNzI5mYiIiEjZaCywglRciVSczW6wcFMGL8elcPpcIQDDr/Jj0qD2NPF0NTmdiIiIyOXRWKCImM7BamFUt1asnhDF37u1xGKBb7Yeos+seN5dk0ahRgVFRESkllHnqhTqXIlUvm0HTzN5STJbD5wGINjXnenDwuge3NjcYCIiIiKXoLHAClJxJVI17HaDRYkHmfnDLk7mFgAwuFMz/jW4Pc283ExOJyIiInIhjQWKSLVktVq45Rp/Vk+IYkxEK6wW+H7bYfrMSmBOfCr5RTazI4qIiIiUmzpXpVDnSuTKSD6UzZQlyWzefwqA1o3rM2VYGJFtfUxOJiIiIvI7jQVWkIorkSvHMAwW/5rJC//dxfGz+QD0D2vCvwaH4u9dz+R0IiIiUtdpLFBEagyLxcKNV7dg1cRIxvYIxMFqIS75KDGvJPDvlXvIK9SooIiIiNQM6lyVQp0rEfOkHDnD5CXb2bjvJAAtvesxZWgo0e2bmJxMRERE6iKNBVaQiisRcxmGwbfbDvP89zs4mvP7qGB0iC+Th4bSqlF9k9OJiIhIXVJjxgLnzp1Lp06d8PT0xNPTk4iICJYtW1a8f9y4cQQFBeHm5oaPjw+xsbHs2rXrL9fduXMnw4YNw8vLi/r163PNNdeQkZFRlaciIpXIYrEwLNyPlROiGBfZGkerhZW7suj76hpe+TGF8wUaFRQREZHqx9TiqkWLFsycOZPExEQ2b95Mnz59iI2NJTk5GYAuXbqwYMECdu7cSVxcHIZh0K9fP2y2i//Dau/evfTo0YOQkBDi4+PZtm0bzzzzDK6urlfqtESkkri7ODJpYHt+eLQXPYIbU1Bk59+rUol5JYG45COo8S4iIiLVSbUbC/T29ubll19m7NixF+zbtm0b4eHhpKamEhQUVOrnb731VpycnPjPf/5T7gwaCxSpfgzD4IftR3j2ux0cys4DoFdbH6YODaW1j7vJ6URERKS2qjFjgX9ms9lYuHAhubm5REREXLA/NzeXBQsWEBgYiL+/f6lr2O12vv/+e9q2bUv//v3x9fWlW7dufPPNN5f82fn5+eTk5JR4iUj1YrFYGNixGSsmRPJg72CcHays2X2M/q+t4cUfdnGuoMjsiCIiIlLHmV5cJSUl4e7ujouLC+PHj2fx4sWEhoYW758zZw7u7u64u7uzbNkyli9fjrOzc6lrZWVlcfbsWWbOnMmAAQP48ccfueGGG7jxxhtJSEi4aIYZM2bg5eVV/LpY8SYi5qvn7MjE/u2Ie6wXUe18KLQZzI3fS/TsBL7bdkijgiIiImIa08cCCwoKyMjIIDs7m0WLFjF//nwSEhKKC6zs7GyysrI4fPgws2bNIjMzk/Xr15d6DdWhQ4do3rw5I0eO5NNPPy3ePmzYMOrXr89nn31Waob8/Hzy8/OL3+fk5ODv76+xQJFqzjAMVuzMYtq3yRw8dR6A64MbMXVoGG2aeJicTkRERGqDGjUW6OzsTHBwMF26dGHGjBmEh4fz+uuvF+/38vKiTZs29OrVi0WLFrFr1y4WL15c6lqNGzfG0dGxROcLoH379pe8W6CLi0vxHQv/eIlI9WexWOgb2oQVj0fySHQbnB2trE89wcDX1/L89zs4m69RQREREblyTC+u/i+73V6ii/RnhmFgGMZF9zs7O3PNNdeQkpJSYvvu3btp1apVpWcVkerB1cmBx/q2ZcVjkcS0b0KR3eDdtfvoMyueJVszNSooIiIiV4SpxdWkSZNYs2YN6enpJCUlMWnSJOLj4xk1ahRpaWnMmDGDxMREMjIy2LBhAzfffDNubm4MGjSoeI2QkJASnawnnniCzz//nHfffZfU1FTefPNNvv32W+6//34zTlFErqCWjeoxf0xXFtxxDQGN6pF1Jp9HFm5lxDs/s+uIblQjIiIiVcvU4iorK4vRo0fTrl07oqOj2bRpE3FxcfTt2xdXV1fWrl3LoEGDCA4OZsSIEXh4eLBhwwZ8fX2L10hJSSE7O7v4/Q033MDbb7/NSy+9RMeOHZk/fz5fffUVPXr0MOMURcQEvUN8+eHRXjzRvx2uTlZ+2XeSwf9ex9SlyWSfLzQ7noiIiNRSpt/QojrSc65Eao/M0+d57rsdLNt+BIDG7s48NbA9N3ZujtVqMTmdiIiIVHdlqQ1UXJVCxZVI7bN2zzGmLE0m7VguAFe3bMD02A50aO5lcjIRERGpzlRcVZCKK5HaqaDIzoL1+3h95R7OFdiwWuDv3VoysV87GtQr/fl5IiIiUrfVqFuxi4hcKc6OVsZFBrFqQhRDw/2wG/Dxzxn0nhXPZ79kYLfrd00iIiJSfupclUKdK5G64ae9J5iydDu7j54FILyFF9NjOxDu38DcYCIiIlJtaCywglRcidQdhTY7H25I57UVezibX4TFAiO6+vPkgBC862tUUEREpK7TWKCIyGVycrByd8/WrJoYyY2dm2MYsHDTAXrPiuc/P+/HplFBERERuUzqXJVCnSuRumtT+kkmL0lm5+HfHzoc5ufJ9NgOdGnV0ORkIiIiYgaNBVaQiiuRuq3IZufTXzKYFZdCTl4RADdd3YKnBobg4+FicjoRERG5kjQWKCJSAY4OVkZHBLBqYhS3dG0BwFdbDtJndjwL1u+jyGY3OaGIiIhUR+pclUKdKxH5s18zTjF5STJJmdkAhDT1YNqwMLq1bmRyMhEREalqGgusIBVXIvJ/2ewGCzdl8HJcCqfPFQIw/Co/Jg1qTxNPV5PTiYiISFXRWKCISCVzsFoY1a0VqydE8fduLbFY4Juth+gzK55316RRqFFBERGROk+dq1KocyUif2XbwdNMXpLM1gOnAQj2dWf6sDC6Bzc2N5iIiIhUKo0FVpCKKxG5HHa7waLEg8z8YRcncwsAGNypGf8c1B6/Bm4mpxMREZHKoLFAEZErwGq1cMs1/qyeEMWYiFZYLfD9tsNEz05gTnwq+UU2syOKiIjIFaTOVSnUuRKR8thxKIcpS7ezKf0UAK0b12fKsDAi2/qYnExERETKS2OBFaTiSkTKyzAMFv+ayQv/3cXxs/kA9AttwjNDQvH3rmdyOhERESkrjQWKiJjEYrFw49UtWD0xkrE9AnGwWvhxx1FiXkng3yv3kFeoUUEREZHaSp2rUqhzJSKVJeXIGSYv2c7GfScBaOldjylDQ4lu38TkZCIiInI5NBZYQSquRKQyGYbBt9sO8/z3Ozia8/uoYHSIL5OHhtKqUX2T04mIiMilaCxQRKQasVgsDAv3Y9WEKMZFtsbRamHlriz6vrqGV35M4XyBRgVFRERqA3WuSqHOlYhUpdSss0xdmsy61OMANG/gxjNDQukf1gSLxWJyOhEREfkzda5ERKqxYF93/jP2WuaOuho/L1cyT59n/MeJjFmwibRjZ82OJyIiIuWkzlUp1LkSkSvlXEERc1bv5Z01aRTY7Dg5WLi7Z2se6hNMPWdHs+OJiIjUebqhRQWpuBKRK23f8VymfZtMfMoxAJp5ufLPwe0Z3LGZRgVFRERMpOKqglRciYgZDMNgxc4spn+XzIGT5wHoHtSIacPCaNPEw+R0IiIidZOKqwpScSUiZsortPF2wl7mxu8lv8iOo9XCndcH8HB0GzxcncyOJyIiUqfohhYiIjWYq5MDj8a0ZcXjkcS0b0KR3eDdtfuInp3AN79mot+JiYiIVE/qXJVCnSsRqU5W78pi2rfJpJ84B8C1gd5Mjw0jpKn+/0lERKSqaSywglRciUh1k19kY/7afbyxag95hXYcrBZuv64Vj/Vti5ebRgVFRESqisYCRURqGRdHBx7oHczKCVEM6tgUm93ggw3pRM+O58vNB7Db9XsyERERs6lzVQp1rkSkulu75xhTliaTdiwXgKtbNmB6bAc6NPcyOZmIiEjtorHAClJxJSI1QUGRnQXr9/H6yj2cK7BhscCobi2Z2K8dDeo5mx1PRESkVtBYoIhIHeDsaGVcZBCrJkQxLNwPw4CPf86g96x4PvslQ6OCIiIiV5g6V6VQ50pEaqKf9p5gytLt7D56FoDwFl5Mi+3AVf4NzA0mIiJSg2kssIJUXIlITVVos/PRT/t5bfluzuQXYbHAiK7+PDkgBO/6GhUUEREpK40FiojUUU4OVsb2CGTlxEhu7Nwcw4CFmw7Qe1Y8//kpHZtGBUVERKqMOlelUOdKRGqLTeknmbwkmZ2HcwAI8/NkemwHurRqaHIyERGRmkFjgRWk4kpEapMim51Pf8lgVlwKOXlFANx0dQueGhiCj4eLyelERESqN40FiohIMUcHK6MjAlg1MYoRXf0B+GrLQfrMiuf9dfsostlNTigiIlI7qHNVCnWuRKQ2+zXjFJOXJJOUmQ1ASFMPpg0Lo1vrRiYnExERqX5qTOdq7ty5dOrUCU9PTzw9PYmIiGDZsmXF+8eNG0dQUBBubm74+PgQGxvLrl27LrnmHXfcgcViKfEaMGBAVZ+KiEiN0bllQ7554Hqev6EDDeo5sevIGUa88zOPLPyVozl5ZscTERGpsUwtrlq0aMHMmTNJTExk8+bN9OnTh9jYWJKTkwHo0qULCxYsYOfOncTFxWEYBv369cNms11y3QEDBnD48OHi12effXYlTkdEpMZwsFoY1a0VqydE8fduLbFYYMnWQ/SZFc87a/ZSqFFBERGRMqt2Y4He3t68/PLLjB079oJ927ZtIzw8nNTUVIKCgkr9/B133MHp06f55ptvyp1BY4EiUtckHczmmSXb2XrgNADBvu5MGxbG9cGNzQ0mIiJishozFvhnNpuNhQsXkpubS0RExAX7c3NzWbBgAYGBgfj7+19yrfj4eHx9fWnXrh333XcfJ06cuOTx+fn55OTklHiJiNQlHVt48fV93Xnpb51oVN+Z1KyzjJq/kQc+2cKh0+fNjiciIlIjmF5cJSUl4e7ujouLC+PHj2fx4sWEhoYW758zZw7u7u64u7uzbNkyli9fjrOz80XXGzBgAB999BErV67kxRdfJCEhgYEDB15ylHDGjBl4eXkVv/6qeBMRqY2sVgu3dPVn1YQoxkS0wmqB75MOEz07gTnxqeQXXXokW0REpK4zfSywoKCAjIwMsrOzWbRoEfPnzychIaG4wMrOziYrK4vDhw8za9YsMjMzWb9+Pa6urpe1flpaGkFBQaxYsYLo6OhSj8nPzyc/P7/4fU5ODv7+/hoLFJE6bcehHKYs3c6m9FMABDauz9RhYUS29TE5mYiIyJVTox8iHBMTQ1BQEPPmzbtgX0FBAQ0bNmT+/PmMHDnystf08fHhueeeY9y4cZd1vK65EhH5nWEYfLM1kxf+u4tjZ37/JVS/0CY8MyQUf+96JqcTERGpejXymqs/2O32El2kPzMMA8MwLrq/NAcPHuTEiRM0a9assiKKiNQZFouFGzq3YNWESO7uEYiD1cKPO44S80oCr6/YQ16hRgVFRET+YGpxNWnSJNasWUN6ejpJSUlMmjSJ+Ph4Ro0aRVpaGjNmzCAxMZGMjAw2bNjAzTffjJubG4MGDSpeIyQkhMWLFwNw9uxZnnjiCX7++WfS09NZuXIlsbGxBAcH079/f7NOU0SkxvNwdeJfQ0JZ9khPrmvtTX6RnVdX7Kbfq2tYufOo2fFERESqBVOLq6ysLEaPHk27du2Ijo5m06ZNxMXF0bdvX1xdXVm7di2DBg0iODiYESNG4OHhwYYNG/D19S1eIyUlhezsbAAcHBzYtm0bw4YNo23btowdO5YuXbqwdu1aXFxczDpNEZFao20TDz675zr+PbIzTTxdyDh5jrEfbuauDzax/0Su2fFERERMVe2uuaoOdM2ViMhfy80v4t+r9vD+un0U2gycHa2M79Wa+6KCcXN2MDueiIhIpajRN7SoDlRciYhcvtSss0z7Npm1e44D0LyBG88MCaV/WBMsFovJ6URERCpGxVUFqbgSESkbwzCISz7Cs9/tJPN/Dx3u2aYx04aF0drH3eR0IiIi5afiqoJUXImIlM/5AhtvrU7lnTVpFNjsODlYuLtnax7sHUx9F0ez44mIiJSZiqsKUnElIlIx6cdzmfZtMqtTjgHQzMuVfw5uz+COzTQqKCIiNYqKqwpScSUiUnGGYbByZxbTvkvmwMnfRwW7BzVi2rAw2jTxMDmdiIjI5VFxVUEqrkREKk9eoY23E/YyN34v+UV2HK0W7ugewCMxbfBwdTI7noiIyCWVpTYw9TlXIiJS+7k6OfBoTFtWPB5J39AmFNkN5q/bR/TsBL75NRP9jk9ERGqLchVXq1evruwcIiJSy/l71+Pd0V1ZcOc1BDSqR9aZfB79fCsj5v3MzsM5ZscTERGpsHKNBbq4uNCiRQvuvPNOxowZg7+/f1VkM43GAkVEqlZ+kY35a/fxxqo95BXacbBauP26VjzWty1ebhoVFBGR6qPKxwIzMzN58MEHWbRoEa1bt6Z///588cUXFBQUlCuwiIjULS6ODjzQO5iVE6IY1LEpNrvBBxvSiZ4dz5ebD2C3a1RQRERqngrf0GLLli0sWLCAzz77DIC///3vjB07lvDw8EoJaAZ1rkRErqy1e44xdWkye4/lAnB1ywZMj+1Ah+ZeJicTEZG67orfLfDQoUO88847zJw5E0dHR/Ly8oiIiODtt98mLCysostfcSquRESuvIIiOwvW7+P1lXs4V2DDYoFR3VoysV87GtRzNjueiIjUUVfkboGFhYUsWrSIQYMG0apVK+Li4njzzTc5evQoqamptGrViptvvrm8y4uISB3j7GhlXGQQqyZEMSzcD8OAj3/OoPeseD77JUOjgiIiUu2Vq3P10EMP8dlnn2EYBrfffjt33303HTp0KHHMkSNH8PPzw263V1rYK0WdKxER8/209wRTlm5n99GzAIS38GJabAeu8m9gbjAREalTqnwsMDo6mrvvvpsbb7wRFxeXUo8pKipi/fr1REZGlnV506m4EhGpHgptdj76aT+vLd/NmfwiLBYY0dWfJ/q3o5F76f/9ERERqUxX/Jqr2kbFlYhI9ZJ1Jo+Zy3bx9ZZMALzcnJjYry1/79YKB6vF5HQiIlKbXZHiKiUlhTfeeIOdO3cC0L59ex566CHatWtXnuWqFRVXIiLV0+b0kzyzJLn4ocOhzTx5dngYXVp5m5xMRERqqyq/ocVXX31Fhw4dSExMJDw8nPDwcLZs2UKHDh346quvyhVaRETkr3QN8ObbB69nemwYnq6O7Dicw01zf2LCF79x7Ey+2fFERKSOK1fnKigoiFGjRjF9+vQS26dMmcLHH3/M3r17Ky2gGdS5EhGp/k6czeelH1L4fPMBADxcHHmsb1tGR7TC0aHcN8MVEREpocrHAuvVq8e2bdsIDg4usX3Pnj2Eh4dz7ty5si5Zrai4EhGpOX7NOMXkJckkZWYD0K6JB9Njw+jWupHJyUREpDao8rHAqKgo1q5de8H2devW0bNnz/IsKSIiUi6dWzbkmweu54UbOtKgnhMpR88w4p2feWThrxzNyTM7noiI1CHl6ly9/fbbTJ48mVtuuYXrrrsOgJ9//pkvv/ySadOm4efnV3zssGHDKi/tFaLOlYhIzXQqt4BZP6bw6S8ZGAbUd3bgkZg23Hl9IE4aFRQRkXKo8rFAq/Xy/gNlsViw2WxlXd50Kq5ERGq2pIPZPLNkO1sPnAYg2NedacPCuD64sbnBRESkxtFzripIxZWISM1ntxss2nKQF5ft4kRuAQCDOzbjn4Pb49fAzeR0IiJSU1T5NVciIiLVndVq4Zau/qyaEMUd3QOwWuD7pMNEz07grdWp5BfVvMkKERGp3spdXCUkJDB06FCCg4MJDg5m2LBhpd7kQkRExExe9ZyYOiyM7x7qyTUBDTlfaOPluBQGvLaW+JQss+OJiEgtUq7i6uOPPyYmJoZ69erx8MMP8/DDD+Pm5kZ0dDSffvppZWcUERGpsFA/T74YF8GrI8Lx8XBh3/Fc7liwiXs/2syBkzX7ESIiIlI9lOuaq/bt23Pvvffy2GOPldj+yiuv8O6777Jz585KC2gGXXMlIlK7nckr5PUVe1iwIR2b3cDF0cr9UcGMi2yNq5OD2fFERKQaqfIbWri4uJCcnHzBQ4RTU1Pp0KEDeXk1+7kiKq5EROqG3UfPMHnJdn5OOwlAS+96TB4SSkxoE5OTiYhIdVHlN7Tw9/dn5cqVF2xfsWIF/v7+5VlSRETkimvbxIPP7rmON0Z2pqmnKxknz3H3R5u564NN7D+Ra3Y8ERGpYRzL86EJEybw8MMPs3XrVrp37w7A+vXr+eCDD3j99dcrNaCIiEhVslgsDA33o0+IL/9etYf31+1j1a4s1u05zrjI1twfFYybs0YFRUTkr5X7OVeLFy9m9uzZxddXtW/fnieeeILY2NhKDWgGjQWKiNRdqVlnmfZtMmv3HAegeQM3nhnSnv5hTbFYLCanExGRK61Kr7kqKirihRde4K677qJFixYVClpdqbgSEanbDMMgLvkIz363k8zT5wHo2aYxU4eFEeTjbnI6ERG5kqr8hhbu7u5s376dgICA8mas1lRciYgIwPkCG3PiU5mXkEaBzY6Tg4WxPVrzUJ9g6ruUa7JeRERqmCq/oUV0dDQJCQnlCiciIlJTuDk7MKFfO358rBe92/lQaDN4O2EvMa8k8N22Q5Rzsl5ERGqpcv3abeDAgTz11FMkJSXRpUsX6tevX2L/sGHDKiWciIhIdRDQuD7v33ENK3dmMe27ZA6cPM+Dn/7Kp0EZTBsWRpsmHmZHFBGRaqBcY4FW68UbXhaLBZvNVqFQZtNYoIiIXExeoY15CWnMiU8lv8iOo9XCHd0DeCSmDR6uTmbHExGRSlbl11zVdiquRETkrxw4eY7p3+1g+Y6jAPh4uPD0oBCGX9VcdxUUEalFqvyaq48++oj8/PwLthcUFPDRRx+VZ0kREZEaxd+7Hu+O7sqCO68hoFE9jp3J57HPf2PEvJ/ZeTjH7HgiImKCcnWuHBwcOHz4ML6+viW2nzhxAl9fX40FiohInZJfZGP+2n28sWoPeYV2rBYYHRHAY33b4uWmUUERkZqsyjtXhmGUOvJw8OBBvLy8yrOkiIhIjeXi6MADvYNZOSGKQR2bYjfggw3p9JkVzxebD2C3awJfRKQuKFNx1blzZ66++mosFgvR0dFcffXVxa/w8HB69uxJTEzMZa83d+5cOnXqhKenJ56enkRERLBs2bLi/ePGjSMoKAg3Nzd8fHyIjY1l165dl73++PHjsVgsvPbaa2U5TRERkXJp3sCNOaO68PHYbgT51OdEbgFPLtrGTW9vYHtmttnxRESkipXpVuzDhw8HYOvWrfTv3x939///lHpnZ2cCAgK46aabLnu9Fi1aMHPmTNq0aYNhGHz44YfExsby66+/EhYWRpcuXRg1ahQtW7bk5MmTTJ06lX79+rFv3z4cHBwuufbixYv5+eef8fPzK8spioiIVFiPNo1Z9kgvPtiwj9dX7OHXjNMMfXMdf7+2JU/0b0eDes5mRxQRkSpQrmuuPvzwQ0aMGIGrq2ulB/L29ubll19m7NixF+zbtm0b4eHhpKamEhQUdNE1MjMz6datG3FxcQwePJhHH32URx999LIz6JorERGpLEey83jhvztZ+tshABrWc+LJASHc0tUfB6vuKigiUt2VpTYo10OEx4wZA/x+d8CsrCzsdnuJ/S1btizzmjabjS+//JLc3FwiIiIu2J+bm8uCBQsIDAzE39//ouvY7XZuv/12nnjiCcLCwi7rZ+fn55e4+2FOju7yJCIilaOplyv/HtmZkde2ZMrS7ew+epZJXyfx2S8ZTI/twFX+DcyOKCIilaRcN7TYs2cPPXv2xM3NjVatWhEYGEhgYCABAQEEBgaWaa2kpCTc3d1xcXFh/PjxLF68mNDQ0OL9c+bMwd3dHXd3d5YtW8by5ctxdr74OMWLL76Io6MjDz/88GVnmDFjBl5eXsWvSxVvIiIi5RER1IjvH+7JM0NC8XBxZNvBbG6Ys56nvtrGibMXPt5ERERqnnKNBV5//fU4Ojry1FNP0axZswvuHBgeHn7ZaxUUFJCRkUF2djaLFi1i/vz5JCQkFBdY2dnZZGVlcfjwYWbNmkVmZibr168vdSQxMTGRwYMHs2XLluJrrQICAv5yLLC0zpW/v7/GAkVEpEpknclj5rJdfL0lEwBPV0cm9m/HqG6tNCooIlLNlGUssFzFVf369UlMTCQkJKTcIS8mJiaGoKAg5s2bd8G+goICGjZsyPz58xk5cuQF+1977TUef/xxrNb/35Cz2WxYrVb8/f1JT0+/rAy65kpERK6EzeknmbwkmR3/e+hwaDNPnh0eRpdW3iYnExGRP1T5c65CQ0M5fvx4ucL9FbvdXqKL9GeGYWAYxkX333777Wzbto2tW7cWv/z8/HjiiSeIi4urkrwiIiLl1TXAm28f6sH02DA8XR3ZcTiHm+b+xONfbOXYGY0KiojUNOW6ocWLL77Ik08+yQsvvEDHjh1xcir59PnL7fZMmjSJgQMH0rJlS86cOcOnn35KfHw8cXFxpKWl8fnnn9OvXz98fHw4ePAgM2fOxM3NjUGDBhWvERISwowZM7jhhhto1KgRjRo1KvEznJycaNq0Ke3atSvPqYqIiFQpB6uF0REBDO7YjJd+SOHzzQf4eksmy5OP8ljftoyOaIWjQ7l+FyoiIldYuYqrPx4U3KdPnxLXWxmGgcViwWazXdY6WVlZjB49msOHD+Pl5UWnTp2Ii4ujb9++HDp0iLVr1/Laa69x6tQpmjRpQq9evdiwYQO+vr7Fa6SkpJCdrQcziohIzdbI3YUX/9aJkd1aMnnJdrYdzGb6dzv4fNMBpsWGcV3rRn+9iIiImKpc11wlJCRccn9kZGS5A1UHuuZKRETMZLMbfL7pAC/F7eL0uUIAhoX78c/B7WniWfnPmBQRkYur8muuIiMjsVqtvPvuuzz11FMEBwcTGRlJRkYGDg4O5QotIiIiv3OwWvh7t5asnhDFqG4tsVhg6W+H6DMrnnfW7KWgyP7Xi4iIyBVXruLqq6++on///ri5ufHrr78W32AiOzubF154oVIDioiI1FUN6zvz/A0dWfpAD67yb0BugY0X/ruLga+vYX1q1dxYSkREyq9cxdVzzz3H22+/zbvvvlviZhbXX389W7ZsqbRwIiIiAh1bePH1fd156W+daFTfmb3Hchk1fyMPfLKFQ6fPmx1PRET+p1zFVUpKCr169bpgu5eXF6dPn65oJhEREfk/rFYLt3T1Z9XEKO7oHoDVAt8nHSZ6dgJvrU4lv+jybiYlIiJVp1zFVdOmTUlNTb1g+7p162jdunWFQ4mIiEjpvNycmDosjO8e6sk1AQ05X2jj5bgUBry2lviULLPjiYjUaeUqru655x4eeeQRNm7ciMVi4dChQ3zyySdMnDiR++67r7IzioiIyP8R6ufJF+MieHVEOD4eLuw7nssdCzZxz0ebOXDynNnxRETqpHLdit0wDF544QVmzJjBuXO//x+4i4sLEydO5Nlnn630kFeabsUuIiI1yZm8Ql5fsYcFG9Kx2Q1cHK3cHxXMuMjWuDrpLr4iIhVRltqgXMXVHwoKCkhNTeXs2bOEhobi7u5e3qWqFRVXIiJSE+0+eoYpS5L5Ke0EAC296zF5SCgxoU1MTiYiUnNdseKqtlJxJSIiNZVhGHy37TDPf7+TIzl5APQJ8WXykFACGtc3OZ2ISM2j4qqCVFyJiEhNl5tfxBurUnlvXRqFNgNnByvjIltzf1Qwbs4aFRQRuVwqripIxZWIiNQWe4+dZerSZNbu+f2hw80buPHMkPb0D2uKxWIxOZ2ISPWn4qqCVFyJiEhtYhgGcclHePa7nWT+76HDPds0ZuqwMIJ8asf10iIiVUXFVQWpuBIRkdrofIGNOfGpzEtIo8Bmx8nBwtgerXmoTzD1XRzNjiciUi2VpTYo13OuREREpOZxc3ZgQr92/PhYL3q386HQZvB2wl6iZyfw7W+H0O9bRUQqRp2rUqhzJSIidcGKHUeZ9l0yB07+PioY0boR02LDaNvEw+RkIiLVh8YCK0jFlYiI1BV5hTbmJaQxJz6V/CI7jlYLd3QP4JGYNni4OpkdT0TEdBoLFBERkcvi6uTAIzFtWPF4JP1Cm1BkN5i/bh99Ziew+NeDGhUUESkDda5Koc6ViIjUVfEpWUxdmkz6iXMAXBPQkGnDOhDqp/8eikjdpLHAClJxJSIidVl+kY35a/fx5qpUzhfasFpgdEQAj/Vti5ebRgVFpG7RWKCIiIiUm4ujAw/0DmbFhEgGdWyK3YAPNqTTZ1Y8X2w+gN2u38uKiJRGnatSqHMlIiLy/63bc5wpS7ez91guAJ1bNmD6sA50bOFlcjIRkaqnscAKUnElIiJSUkGRnQ827OP1FXvILbBhscDfr23JE/3b0aCes9nxRESqjMYCRUREpFI5O1q5t1cQKydEEXuVH4YBn2zMoPeseD7dmIFNo4IiIupclUadKxERkUv7Oe0EU5Ykk3L0DACdWngxPbYDV/k3MDeYiEgl01hgBam4EhER+WuFNjv/+Wk/ry7fzZn8IgBGdPXnyQHtaOTuYnI6EZHKobFAERERqXJODlbu6hHIyomR3HR1CwA+33yA3rPi+eindI0Kikido85VKdS5EhERKbvN6SeZvCSZHYdzAAht5sn02DC6BnibnExEpPw0FlhBKq5ERETKx2Y3+HTjfl6OSyEn7/dRwRuvbs5TA0Pw9XA1OZ2ISNlpLFBERERM4WC1cHtEAKsnRjGiqz8AX2/JJHpWAu+t20eRzW5yQhGRqqPOVSnUuRIREakcWw+cZvKS7Ww7mA1AuyYeTIsN47rWjUxOJiJyeTQWWEEqrkRERCqPzW7wxeYDvPTDLk6dKwRgWLgf/xzcniaeGhUUkepNY4EiIiJSbThYLYy8tiWrJkQxqltLLBZY+tsh+syKZ17CXgqKNCooIrWDOlelUOdKRESk6mzPzOaZJdv5NeM0AEE+9Zk2rAM92jQ2N5iISCk0FlhBKq5ERESqlt1usGjLQV5ctosTuQUADOrYlH8NDsWvgZvJ6URE/j+NBYqIiEi1ZrVauKWrP6smRnFH9wCsFvhv0hGiZyfw1upU8otsZkcUESkzda5Koc6ViIjIlbXzcA6Tl2xnU/opAAIb12fK0FCi2vmanExE6jqNBVaQiisREZErzzAMlmw9xPP/3cmxM/kA9A1twuQhofh71zM5nYjUVRoLFBERkRrHYrEwvHNzVk2I5O4egThYLSzfcZSYVxJ4bcVu8go1Kigi1Zs6V6VQ50pERMR8u4+eYcqSZH5KOwGAv7cbU4aEERPaxORkIlKXaCywglRciYiIVA+GYfB90mGe+24nR3LyAOgT4svkIaEENK5vcjoRqQtUXFWQiisREZHqJTe/iDdWpfLeujQKbQbODlbu7dWaB3oH4+bsYHY8EanFasw1V3PnzqVTp054enri6elJREQEy5YtK94/btw4goKCcHNzw8fHh9jYWHbt2nXJNadOnUpISAj169enYcOGxMTEsHHjxqo+FREREalC9V0ceWpgCD882ouebRpTYLPz5upUYl5J4Ifth9HvikWkOjC1uGrRogUzZ84kMTGRzZs306dPH2JjY0lOTgagS5cuLFiwgJ07dxIXF4dhGPTr1w+b7eIXtLZt25Y333yTpKQk1q1bR0BAAP369ePYsWNX6rRERESkigT5uPPRXdfy9m1X07yBG5mnzzP+4y2Mfv8X9h47a3Y8Eanjqt1YoLe3Ny+//DJjx469YN+2bdsIDw8nNTWVoKCgy1rvjzbeihUriI6OLtNnNBYoIiJSfZ0vsDEnPpV5CWkU2Ow4OVgY26M1D/UJpr6Lo9nxRKSWqDFjgX9ms9lYuHAhubm5REREXLA/NzeXBQsWEBgYiL+//2WtWVBQwDvvvIOXlxfh4eEXPS4/P5+cnJwSLxEREane3JwdmNCvHT8+1os+Ib4U2gzeTthL9OwEvv3tkEYFReSKM724SkpKwt3dHRcXF8aPH8/ixYsJDQ0t3j9nzhzc3d1xd3dn2bJlLF++HGdn50uu+d133+Hu7o6rqyuvvvoqy5cvp3Hjxhc9fsaMGXh5eRW/Lrd4ExEREfMFNK7P+3dcw/zRXfH3duNITh4PffYrf393I7uPnjE7nojUIaaPBRYUFJCRkUF2djaLFi1i/vz5JCQkFBdY2dnZZGVlcfjwYWbNmkVmZibr16/H1dX1omvm5uZy+PBhjh8/zrvvvsuqVavYuHEjvr6+pR6fn59Pfn5+8fucnBz8/f01FigiIlLD5BXamJeQxpz4VPKL7DhYLdzRPYBHY9rg4epkdjwRqYFq9K3YY2JiCAoKYt68eRfsKygooGHDhsyfP5+RI0de9ppt2rThrrvuYtKkSZd1vK65EhERqdkOnDzHs9/t4McdRwHw8XDh6UEhDL+qORaLxeR0IlKT1Mhrrv5gt9tLdJH+zDAMDMO46P7yrCkiIiK1j793Pd4Z3ZUP7ryGwMb1OXYmn8c+/41b5v3EjkO6tlpEqoapxdWkSZNYs2YN6enpJCUlMWnSJOLj4xk1ahRpaWnMmDGDxMREMjIy2LBhAzfffDNubm4MGjSoeI2QkBAWL14M/D4O+PTTT/Pzzz+zf/9+EhMTueuuu8jMzOTmm2826zRFRETEJFHtfPnh0Z480b8dbk4ObEo/xZA31jJ1aTLZ5wvNjicitYypxVVWVhajR4+mXbt2REdHs2nTJuLi4ujbty+urq6sXbuWQYMGERwczIgRI/Dw8GDDhg0lrp1KSUkhOzsbAAcHB3bt2sVNN91E27ZtGTp0KCdOnGDt2rWEhYWZdZoiIiJiIhdHBx7oHcyKCZEM7tgMuwEfbEinz6x4vth8ALu9Wl0hISI1WLW75qo60DVXIiIitde6PceZsnQ7e4/lAtC5ZQOmD+tAxxZeJicTkeqoRt/QojpQcSUiIlK7FRTZ+WDDPl5fsYfcAhsWC/z92pZM7NeOhvUv/cgXEalbavQNLURERESqmrOjlXt7BbFqYhSxV/lhGPDJxgx6z47n040Z2DQqKCLloM5VKdS5EhERqVt+TjvBlCXJpPzvocOdWngxbVgYnVs2NDmZiJhNY4EVpOJKRESk7im02fnPT/t5dfluzuQXATCiqz9PDmhHI3cXk9OJiFk0FigiIiJSRk4OVu7qEcjKiZHcdHULAD7ffIDes+L56Kd0jQqKyF9S56oU6lyJiIjI5vSTTF6SzI7Dvz90OLSZJ9Njw+ga4G1yMhG5kjQWWEEqrkRERATAZjf4dON+Xo5LISfv91HBG69uzlMDQ/D1cDU5nYhcCRoLFBEREakEDlYLt0cEsHpiFLde44/FAl9vySR6VgLvrdtHoc1udkQRqUbUuSqFOlciIiJSmq0HTjN5yXa2HcwGoF0TD6bFhnFd60YmJxORqqKxwApScSUiIiIXY7MbfLH5AC/9sItT5woBGBbux9OD2tPUS6OCIrWNxgJFREREqoiD1cLIa1uyemIUt13XEosFlv52iOjZ8cxL2EtBkUYFReoqda5Koc6ViIiIXK7tmdk8s2Q7v2acBiDIpz7ThnWgR5vG5gYTkUqhscAKUnElIiIiZWG3G3y15SAzl+3iRG4BAIM6NuWfg0Np3sDN5HQiUhEaCxQRERG5gqxWCzd39WfVxCju6B6A1QL/TTpCzOwE3lqdSn6RzeyIInIFqHNVCnWuREREpCJ2Hs5hypJkfkk/CUBAo3pMGRZG73a+JicTkbLSWGAFqbgSERGRijIMgyVbD/H8f3dy7Ew+AH1DmzB5SCj+3vVMTicil0tjgSIiIiIms1gsDO/cnFUTIrmnZyCOVgvLdxwl5pUEXluxm7xCjQqK1DbqXJVCnSsRERGpbHuOnmHykmR+SjsBgL+3G5OHhBHT3heLxWJyOhG5GI0FVpCKKxEREakKhmHwfdJhnvtuJ0dy8gDo3c6HKUPDCGhc3+R0IlIaFVcVpOJKREREqlJufhFvrk5l/to0Cm0Gzg5W7u3Vmgd6B+Pm7GB2PBH5ExVXFaTiSkRERK6EvcfOMnVpMmv3HAegeQM3/jW4PQM6NNWooEg1oeKqglRciYiIyJViGAZxyUd59rsdZJ4+D0DPNo2ZOiyMIB93k9OJiIqrClJxJSIiIlfa+QIbc+JTmZeQRoHNjpODhbt6BPJwnzbUd3E0O55InaXiqoJUXImIiIhZ0o/nMv27HazalQVAU09Xnh7cnqGdmmlUUMQEKq4qSMWViIiImG3lzqNM+3YHGSfPARDRuhHTYsNo28TD5GQidYuKqwpScSUiIiLVQV6hjXfWpPHW6lTyi+w4WC3c0T2AR2Pa4OHqZHY8kTqhLLWB9QplEhEREZEycnVy4OHoNqx4PJJ+oU2w2Q3eW7eP3rMS+HrLQfQ7cpHqRZ2rUqhzJSIiItVRfEoW077dwb7juQBcE9CQacM6EOqnf6+IVBWNBVaQiisRERGprvKLbMxfu483V6VyvtCG1QK3X9eKx/u1w8tNo4IilU1jgSIiIiK1lIujAw/0DmblhEgGd2yG3YAPf9pPn1nxfLHpAHa7fm8uYhZ1rkqhzpWIiIjUFOtTjzNlaTKpWWcB6NyyAdOHdaBjCy+Tk4nUDhoLrCAVVyIiIlKTFBTZ+WDDPl5fsYfcAhsWC4y8tiVP9GtHw/rOZscTqdE0FigiIiJShzg7Wrm3VxCrJkYRe5UfhgGfbsyg9+x4Ptm4H5tGBUWuCHWuSqHOlYiIiNRkG9NOMGVpMruOnAGgY3MvpseG0bllQ5OTidQ8GgusIBVXIiIiUtMV2ex89NN+Xl2+mzP5RQDc0rUF/xgQQiN3F5PTidQcGgsUERERqeMcHazc1SOQVROjuOnqFgB8sfkgvWfF89FP6RTZ7CYnFKl91LkqhTpXIiIiUtsk7j/JM98ks+NwDgDtm3nybGwYXQO8TU4mUr1pLLCCVFyJiIhIbWSzG3y6cT8vx6WQk/f7qOCNVzfnqYEh+Hq4mpxOpHrSWKCIiIiIXMDBauH2iABWT4zi1mv8sVjg6y2ZRM9K4L11+yjUqKBIhahzVQp1rkRERKQu2HrgNJOXbGfbwWwA2jXxYOqwMCKCGpmcTKT60FhgBam4EhERkbrCbjf4fPMBXvphF6fOFQIwNNyPfw5qT1MvjQqK1JixwLlz59KpUyc8PT3x9PQkIiKCZcuWFe8fN24cQUFBuLm54ePjQ2xsLLt27broeoWFhfzjH/+gY8eO1K9fHz8/P0aPHs2hQ4euxOmIiIiI1DhWq4WR17Zk9cQobruuJRYLfPvbIaJnxzMvYS8FRRoVFLlcphZXLVq0YObMmSQmJrJ582b69OlDbGwsycnJAHTp0oUFCxawc+dO4uLiMAyDfv36YbPZSl3v3LlzbNmyhWeeeYYtW7bw9ddfk5KSwrBhw67kaYmIiIjUOA3qOfPc8I58+2APOrdsQG6BjRnLdjHw9TWs23Pc7HgiNUK1Gwv09vbm5ZdfZuzYsRfs27ZtG+Hh4aSmphIUFHRZ623atIlrr72W/fv307Jly8v6jMYCRUREpC6z2w2+2nKQmct2cSK3AICBHZryryGhNG/gZnI6kSurxowF/pnNZmPhwoXk5uYSERFxwf7c3FwWLFhAYGAg/v7+l71udnY2FouFBg0aXPSY/Px8cnJySrxERERE6iqr1cLNXf1ZNTGKO7oHYLXAsu1HiJmdwFurU8kvKn2KSKSuM724SkpKwt3dHRcXF8aPH8/ixYsJDQ0t3j9nzhzc3d1xd3dn2bJlLF++HGdn58taOy8vj3/84x+MHDnyklXmjBkz8PLyKn6VpXgTERERqa283JyYOiyM7x/uybUB3pwvtPFyXAr9X13D6pQss+OJVDumjwUWFBSQkZFBdnY2ixYtYv78+SQkJBQXWNnZ2WRlZXH48GFmzZpFZmYm69evx9X10nevKSws5KabbuLgwYPEx8dfsrjKz88nPz+/+H1OTg7+/v4aCxQRERH5H8MwWLL1EM//dyfHzvz+76a+oU2YPCQUf+96JqcTqTo1+lbsMTExBAUFMW/evAv2FRQU0LBhQ+bPn8/IkSMvukZhYSG33HILaWlprFq1ikaNyvasBl1zJSIiIlK6M3mF/HvlHhasT6fIbuDiaOW+qCDGRwbh6uRgdjyRSlcjr7n6g91uL9FF+jPDMDAM46L74f8XVnv27GHFihVlLqxERERE5OI8XJ345+BQlj3Sk+5BjcgvsvPaij30fTWB5TuOUs1+by9yRZlaXE2aNIk1a9aQnp5OUlISkyZNIj4+nlGjRpGWlsaMGTNITEwkIyODDRs2cPPNN+Pm5sagQYOK1wgJCWHx4sXA74XV3/72NzZv3swnn3yCzWbjyJEjHDlyhIKCArNOU0RERKTWadPEg0/u7sabf+9MU09XDpw8zz0fbebODzaRfjzX7HgipnA084dnZWUxevRoDh8+jJeXF506dSIuLo6+ffty6NAh1q5dy2uvvcapU6do0qQJvXr1YsOGDfj6+havkZKSQnZ2NgCZmZksXboUgKuuuqrEz1q9ejVRUVFX6tREREREaj2LxcKQTn70bufLm6tTmb82jfiUY/RLXcO9vVrzQO9g3Jw1Kih1R7W75qo60DVXIiIiImW399hZpi5NZu3/HjrcvIEb/xrcngEdmmKxWExOJ1I+NfqGFtWBiisRERGR8jEMg7jkozz73Q4yT58HoGebxkwZGkawr7vJ6UTKTsVVBam4EhEREamY8wU25san8vaaNAqK7Dg5WLirRyAP9WmDu4upV6aIlEmNvlugiIiIiNR8bs4OPN6vHcsf60WfEF8KbQbzEtKInh3P0t8O6a6CUiupc1UKda5EREREKtfKnUeZ9u0OMk6eA+C61t5MG9aBdk09TE4mcmkaC6wgFVciIiIilS+v0MY7a9J4a3Uq+UV2HKwW7ugewCMxbfB0dTI7nkipNBYoIiIiItWOq5MDD0e3YcXjkfQLbYLNbvDeun30mZXA11sOalRQajx1rkqhzpWIiIhI1YtPyWLatzvY97+HDndt1ZDpsR0I9dO/v6T60FhgBam4EhEREbky8otsvLduH2+sTOV8oQ2rBW6/rhWP92uHl5tGBcV8GgsUERERkRrBxdGB+6OCWTkhksGdmmE34MOf9tNnVjxfbDqA3a4+gNQc6lyVQp0rEREREXOsTz3OlKXJpGadBeAq/wY8G9uBji28TE4mdZXGAitIxZWIiIiIeQqK7Hy4IZ3XVuwmt8CGxQIjr23JE/3a0bC+s9nxpI7RWKCIiIiI1FjOjlbu6dWaVROjiL3KD8OATzdm0Ht2PJ9s3I9No4JSTalzVQp1rkRERESqj41pJ5iyNJldR84A0LG5F9Niw7i6ZUOTk0ldoLHAClJxJSIiIlK9FNns/Ofn/bzy427O5BcBcEvXFvxjQAiN3F1MTie1mcYCRURERKRWcXSwcuf1gayaGMVNV7cA4IvNB+k9K54PN6RTZLObnFBEnatSqXMlIiIiUr0l7j/J5CXJJB/KAaB9M0+ejQ2ja4C3ycmkttFYYAWpuBIRERGp/mx2g0837ufluBRy8n4fFbyxc3OeGhSCr4eryemkttBYoIiIiIjUeg5WC7dHBLB6YhQjr/XHYoGvf82kz6wE5q9No1CjgnKFqXNVCnWuRERERGqerQdOM2XJdn47mA1A2ybuTBvWgYigRiYnk5pMY4EVpOJKREREpGay2w2+2HyAF3/YxalzhQAMDffjn4Pa09RLo4JSdhoLFBEREZE6yWq1cOu1LVk9MYrbrmuJxQLf/naIPrPjeTthLwVFGhWUqqPOVSnUuRIRERGpHbZnZjN5yXa2ZJwGoLVPfaYNC6NnGx9zg0mNobHAClJxJSIiIlJ72O0GX205yIs/7OL42QIABnZoyr+GhNK8gZvJ6aS601igiIiIiMj/WK0Wbu7qz8oJUdzRPQCrBZZtP0L07HjeXLWH/CKb2RGlllDnqhTqXImIiIjUXjsP5zBlSTK/pJ8EIKBRPaYMC6N3O1+Tk0l1pLHAClJxJSIiIlK7GYbBkq2HeP6/Ozl2Jh+AmPZNmDI0FH/veiank+pEY4EiIiIiIpdgsVgY3rk5qyZEck/PQBytFlbsPErMKwm8unw3eYUaFZSyU+eqFOpciYiIiNQte46eYcrSZDbsPQGAv7cbk4eEEdPeF4vFYnI6MZPGAitIxZWIiIhI3WMYBt8nHea573ZyJCcPgKh2PkwZGkZg4/ompxOzqLiqIBVXIiIiInVXbn4Rb65OZf7aNAptBs4OVu7pFcgDvYOp5+xodjy5wlRcVZCKKxERERHZe+wsU5cms3bPcQD8vFx5ZkgoAzo01ahgHaLiqoJUXImIiIgI/D4qGJd8lGe/20Hm6fMA9AhuzNRhYQT7upucTq4EFVcVpOJKRERERP7sfIGNufGpvL0mjYIiO45WC2N7BPJQdBvcXTQqWJvpVuwiIiIiIpXIzdmBx/u1Y/ljvYgO8aXIbjBvTRrRs+NZ+tsh1K8QUOeqVOpciYiIiMilrNx5lGnf7iDj5DkArmvtzbRhHWjX1MPkZFLZNBZYQSquREREROSv5BXaeGdNGm+tTiW/yI6D1cId3QN4JKYNnq5OZseTSqKxQBERERGRKubq5MDD0W1Y8Xgk/cOaYLMbvLduH31mJfD1loMaFayD1LkqhTpXIiIiIlJWCbuPMXVpMvuO5wLQtVVDpsWGEebnZXIyqQiNBVaQiisRERERKY/8IhvvrdvHGytTOV9ow2qB265rxYS+7fCqp1HBmkhjgSIiIiIiJnBxdOD+qGBWTohkcKdm2A346Kf99JkdzxebDmC3q69Rm6lzVQp1rkRERESkMqxPPc6UpcmkZp0F4Cr/BkyPDaNTiwbmBpPLVmM6V3PnzqVTp054enri6elJREQEy5YtK94/btw4goKCcHNzw8fHh9jYWHbt2nXJNb/++mv69etHo0aNsFgsbN26tYrPQkRERESkdNcHN2bZIz3556D21Hd2YOuB08S+tZ6nFydxKrfA7HhSyUwtrlq0aMHMmTNJTExk8+bN9OnTh9jYWJKTkwHo0qULCxYsYOfOncTFxWEYBv369cNms110zdzcXHr06MGLL754pU5DREREROSinBys3NOrNasmRjH8Kj8MAz7dmEHv2fF8snE/No0K1hrVbizQ29ubl19+mbFjx16wb9u2bYSHh5OamkpQUNAl10lPTycwMJBff/2Vq666qkwZNBYoIiIiIlVlY9oJpixNZteRMwB0bO7FtNgwrm7Z0ORkUpoaMxb4ZzabjYULF5Kbm0tERMQF+3Nzc1mwYAGBgYH4+/tX6s/Oz88nJyenxEtEREREpCp0a92I7x7qwZShoXi4OJKUmc2Nczbw5KLfOH423+x4UgGmF1dJSUm4u7vj4uLC+PHjWbx4MaGhocX758yZg7u7O+7u7ixbtozly5fj7OxcqRlmzJiBl5dX8auyizcRERERkT9zdLBy5/WBrJoYxd+6tADgi80H6TMrng83pFNks5ucUMrD9LHAgoICMjIyyM7OZtGiRcyfP5+EhITiAis7O5usrCwOHz7MrFmzyMzMZP369bi6ul5y3bKMBebn55Of//9/S5CTk4O/v7/GAkVERETkikjcf5LJS5JJPvT7BFX7Zp5Mjw3jmgBvk5NJjX6IcExMDEFBQcybN++CfQUFBTRs2JD58+czcuTIS66ja65EREREpCax2Q0+/SWDWXEpZJ8vBOCGzs2ZNDAEX89LNxak6tTIa67+YLfbS3SR/swwDAzDuOh+EREREZGaysFq4fbrWrF6YhQjr/XHYoHFv2bSZ3YC89emUahRwWrP1OJq0qRJrFmzhvT0dJKSkpg0aRLx8fGMGjWKtLQ0ZsyYQWJiIhkZGWzYsIGbb74ZNzc3Bg0aVLxGSEgIixcvLn5/8uRJtm7dyo4dOwBISUlh69atHDly5Iqfn4iIiIhIWXnXd2bGjZ1YfP/1hLfw4mx+Ec99v5PB/17LT3tPmB1PLsHU4iorK4vRo0fTrl07oqOj2bRpE3FxcfTt2xdXV1fWrl3LoEGDCA4OZsSIEXh4eLBhwwZ8fX2L10hJSSE7O7v4/dKlS+ncuTODBw8G4NZbb6Vz5868/fbbV/z8RERERETK6yr/Biy+/3pm3tiRhvWc2H30LCPf/ZmHPvuVI9l5ZseTUlS7a66qA11zJSIiIiLVyelzBcz+cTefbNyP3YB6zg48HN2Gu64PxNmx2l3pU6vU6BtaVAcqrkRERESkOtqemc3kJdvZknEagNY+9Zk2LIyebXzMDVaLqbiqIBVXIiIiIlJd2e0GX/+aycxlOzl+tgCAgR2a8q8hoTRv4GZyutqnRt8tUERERERELs5qtfC3Li1YOSGKO68PwMFqYdn2I0TPjufNVXvIL7KZHbHOUueqFOpciYiIiEhNsfNwDlOWJPNL+kkAAhrVY8rQMHqH+P7FJ+VyaCywglRciYiIiEhNYhgGS387xPPf7yTrzO/PhI1p34TJQ0Jp2aieyelqNo0FioiIiIjUIRaLhdirmrNyQiT39AzE0Wphxc6jxLyawKvLd5NXqFHBK0Gdq1KocyUiIiIiNdmeo2eYsjSZDf976HCLhm5MHhJK39AmWCwWk9PVLBoLrCAVVyIiIiJS0xmGwX+TjvDc9zs4/L+HDke182HK0DACG9c3OV3NoeKqglRciYiIiEhtkZtfxJurU5m/No1Cm4Gzg5V7egXyQO9g6jk7mh2v2lNxVUEqrkRERESktkk7dpap3+5gze5jAPh5ufKvIaEM7NBUo4KXoOKqglRciYiIiEhtZBgGP+44yvRvd5B5+jwAPYIbM3VYKMG+Hianq55UXFWQiisRERERqc3OF9iYm7CXtxP2UlBkx9FqYWyPQB6KboO7i0YF/0y3YhcRERERkYtyc3bg8b5tWf5YL6JDfCmyG8xbk0b07HiWbM1E/ZfyUeeqFOpciYiIiEhdsnLnUaZ9u4OMk+cAuK61N9OGdaBdU40KaiywglRciYiIiEhdk1do4501aby1OpX8IjsOVgtjIgJ4tG8bPF2dzI5nGo0FioiIiIhImbg6OfBwdBtWPB5J/7Am2OwG76/fR59ZCXyVeFCjgpdBnatSqHMlIiIiInVdwu5jTF2azL7juQB0bdWQabFhhPl5mZzsytJYYAWpuBIRERERgfwiG++t28cbK1M5X2jDaoHbrmvFhL7t8KpXN0YFNRYoIiIiIiIV5uLowP1RwaycEMngTs2wG/DRT/vpPTuezzdlYLerT/Nn6lyVQp0rEREREZELrU89zpSlyaRmnQXgKv8GTI8No1OLBuYGq0IaC6wgFVciIiIiIqUrtNn5YH06r63YTW6BDYsFbr2mJU/2b0fD+s5mx6t0GgsUEREREZEq4eRg5Z5erVk9MYrhV/lhGPDZLxn0nh3Pxz/vx1aHRwXVuSqFOlciIiIiIpdnY9oJpixNZteRMwB0bO7FtNgwrm7Z0ORklUNjgRWk4kpERERE5PIV2ez85+f9vPLjbs7kFwFwc5cW/GNgCI3dXUxOVzEaCxQRERERkSvG0cHKndcHsmpiFH/r0gKALxMP0mdWPB9uSKfIZjc54ZWhzlUp1LkSERERESm/xP0nmbwkmeRDOQCENPXg2eEduCbA2+RkZaexwApScSUiIiIiUjE2u8Gnv2QwKy6F7POFANzQuTmTBobg6+lqcrrLp7FAERERERExlYPVwu3XtWL1xChGXuuPxQKLf82kz+wE5q9No7AWjgqqc1UKda5ERERERCrXbwdOM3nJdn47mA1A2ybuTBvWgYigRiYnuzSNBVaQiisRERERkcpntxt8sfkAL/6wi1Pnfh8VHBrux9ODQmjm5WZyutJpLFBERERERKodq9XCrde2ZPXEKG6/rhVWC3z72yGiZyfwdsJeCopq9qigOlelUOdKRERERKTqbc/MZvKS7WzJOA1Aa5/6TBsWRs82PuYG+xONBVaQiisRERERkSvDbjf4+tdMZi7byfGzBQAMCGvKM0NDad7A/FFBjQWKiIiIiEiNYLVa+FuXFqycEMWd1wfgYLXwQ/IRBry6pvgW7jWFo9kBREREREREvNycmDI0jFu6+jNlaTLhLbzwcnMyO1aZqLgSEREREZFqo30zTz6/9zoKbTXv6iUVVyIiIiIiUq1YLBacHS1mxygzXXMlIiIiIiJSCVRciYiIiIiIVAIVVyIiIiIiIpVAxZWIiIiIiEglMLW4mjt3Lp06dcLT0xNPT08iIiJYtmxZ8f5x48YRFBSEm5sbPj4+xMbGsmvXrkuuaRgGkydPplmzZri5uRETE8OePXuq+lRERERERKSOM7W4atGiBTNnziQxMZHNmzfTp08fYmNjSU5OBqBLly4sWLCAnTt3EhcXh2EY9OvXD5vNdtE1X3rpJf7973/z9ttvs3HjRurXr0///v3Jy8u7UqclIiIiIiJ1kMUwjGp1A3lvb29efvllxo4de8G+bdu2ER4eTmpqKkFBQRfsNwwDPz8/JkyYwMSJEwHIzs6mSZMmfPDBB9x6662XlSEnJwcvLy+ys7Px9PSs2AmJiIiIiEiNVZbaoNpcc2Wz2Vi4cCG5ublERERcsD83N5cFCxYQGBiIv79/qWvs27ePI0eOEBMTU7zNy8uLbt268dNPP130Z+fn55OTk1PiJSIiIiIiUhamF1dJSUm4u7vj4uLC+PHjWbx4MaGhocX758yZg7u7O+7u7ixbtozly5fj7Oxc6lpHjhwBoEmTJiW2N2nSpHhfaWbMmIGXl1fx62LFm4iIiIiIyMWYXly1a9eOrVu3snHjRu677z7GjBnDjh07ivePGjWKX3/9lYSEBNq2bcstt9xS6ddPTZo0iezs7OLXgQMHKnV9ERERERGp/RzNDuDs7ExwcDDw+w0sNm3axOuvv868efMAirtJbdq04brrrqNhw4YsXryYkSNHXrBW06ZNATh69CjNmjUr3n706FGuuuqqi2ZwcXHBxcWlEs9KRERERETqGtM7V/+X3W4nPz+/1H2GYWAYxkX3BwYG0rRpU1auXFm8LScnh40bN5Z6HZeIiIiIiEhlMbW4mjRpEmvWrCE9PZ2kpCQmTZpEfHw8o0aNIi0tjRkzZpCYmEhGRgYbNmzg5ptvxs3NjUGDBhWvERISwuLFiwGwWCw8+uijPPfccyxdupSkpCRGjx6Nn58fw4cPN+ksRURERESkLjB1LDArK4vRo0dz+PBhvLy86NSpE3FxcfTt25dDhw6xdu1aXnvtNU6dOkWTJk3o1asXGzZswNfXt3iNlJQUsrOzi98/+eST5Obmcu+993L69Gl69OjBDz/8gKurqxmnKCIiIiIidUS1e85VdaDnXImIiIiICNTQ51yJiIiIiIjUZCquREREREREKoHpt2Kvjv6YlMzJyTE5iYiIiIiImOmPmuByrqZScVWKM2fOAODv729yEhERERERqQ7OnDmDl5fXJY/RDS1KYbfbOXToEB4eHlgsFlOz5OTk4O/vz4EDB3RzDbks+s5IWek7I2Wl74yUlb4zUlbV6TtjGAZnzpzBz88Pq/XSV1Wpc1UKq9VKixYtzI5Rgqenp+lfLKlZ9J2RstJ3RspK3xkpK31npKyqy3fmrzpWf9ANLURERERERCqBiisREREREZFKoOKqmnNxcWHKlCm4uLiYHUVqCH1npKz0nZGy0ndGykrfGSmrmvqd0Q0tREREREREKoE6VyIiIiIiIpVAxZWIiIiIiEglUHElIiIiIiJSCVRciYiIiIiIVAIVV9XAW2+9RUBAAK6urnTr1o1ffvnlksd/+eWXhISE4OrqSseOHfnvf/97hZJKdVGW78y7775Lz549adiwIQ0bNiQmJuYvv2NS+5T1/2f+sHDhQiwWC8OHD6/agFLtlPU7c/r0aR544AGaNWuGi4sLbdu21X+f6piyfmdee+012rVrh5ubG/7+/jz22GPk5eVdobRipjVr1jB06FD8/PywWCx88803f/mZ+Ph4rr76alxcXAgODuaDDz6o8pzloeLKZJ9//jmPP/44U6ZMYcuWLYSHh9O/f3+ysrJKPX7Dhg2MHDmSsWPH8uuvvzJ8+HCGDx/O9u3br3ByMUtZvzPx8fGMHDmS1atX89NPP+Hv70+/fv3IzMy8wsnFLGX9zvwhPT2diRMn0rNnzyuUVKqLsn5nCgoK6Nu3L+np6SxatIiUlBTeffddmjdvfoWTi1nK+p359NNPeeqpp5gyZQo7d+7kvffe4/PPP+fpp5++wsnFDLm5uYSHh/PWW29d1vH79u1j8ODB9O7dm61bt/Loo49y9913ExcXV8VJy8EQU1177bXGAw88UPzeZrMZfn5+xowZM0o9/pZbbjEGDx5cYlu3bt2McePGVWlOqT7K+p35v4qKigwPDw/jww8/rKqIUs2U5ztTVFRkdO/e3Zg/f74xZswYIzY29gokleqirN+ZuXPnGq1btzYKCgquVESpZsr6nXnggQeMPn36lNj2+OOPG9dff32V5pTqBzAWL158yWOefPJJIywsrMS2ESNGGP3796/CZOWjzpWJCgoKSExMJCYmpnib1WolJiaGn376qdTP/PTTTyWOB+jfv/9Fj5fapTzfmf/r3LlzFBYW4u3tXVUxpRop73dm+vTp+Pr6Mnbs2CsRU6qR8nxnli5dSkREBA888ABNmjShQ4cOvPDCC9hstisVW0xUnu9M9+7dSUz8f+3cf0xV9R/H8dcFvJeLw1BBuDZqgKZopQllJM1Vs7RNR2OrFt1d1hwzsjkq03B2bVSwRqytJU7njzVLli76Q4gS+7FJs5qCY3ml0R3aFtflMiNoKN7P9y/PtyuwCV3uBXk+trNxP+fzOed9zt47O28+55wT1qODfr9fjY2NevzxxyMSMyaWiXT/GxftACazCxcu6OrVq0pNTQ1pT01N1ZkzZ4YcEwgEhuwfCATGLE6MH6PJmett2rRJs2fPHnSRws1pNDlz7Ngx7d69W21tbRGIEOPNaHLG7/frq6++UlFRkRobG9XZ2anS0lJduXJFXq83EmEjikaTM88884wuXLig/Px8GWM0MDCgdevW8VgghjTc/e9ff/2lf/75R06nM0qRDcbMFTCJVFVVqa6uTvX19YqPj492OBiHenp65Ha7tWvXLiUnJ0c7HEwQwWBQs2bN0s6dO5WTk6OnnnpKW7Zs0Y4dO6IdGsapb775Rm+//ba2b9+ukydP6tNPP1VDQ4MqKiqiHRrwnzBzFUXJycmKjY3V+fPnQ9rPnz+vtLS0IcekpaWNqD9uLqPJmWuqq6tVVVWl5uZm3X333WMZJsaRkebML7/8oq6uLq1evdpqCwaDkqS4uDh1dHQoKytrbINGVI3mOuNyuTRlyhTFxsZabdnZ2QoEArp8+bLsdvuYxozoGk3ObN26VW63W2vXrpUk3XXXXert7VVJSYm2bNmimBj+/4//G+7+d9q0aeNq1kpi5iqq7Ha7cnJydPToUastGAzq6NGjysvLG3JMXl5eSH9JOnLkyLD9cXMZTc5I0jvvvKOKigo1NTUpNzc3EqFinBhpzsyfP1/t7e1qa2uzljVr1lhfaEpPT49k+IiC0Vxnli1bps7OTqsQl6Sff/5ZLpeLwmoSGE3O9PX1DSqgrhXnxpixCxYT0oS6/432FzUmu7q6OuNwOMy+ffvM6dOnTUlJiUlKSjKBQMAYY4zb7TabN2+2+re0tJi4uDhTXV1tfD6f8Xq9ZsqUKaa9vT1ah4AIG2nOVFVVGbvdbg4dOmS6u7utpaenJ1qHgAgbac5cj68FTj4jzZlz586ZxMREs379etPR0WEOHz5sZs2aZd58881oHQIibKQ54/V6TWJiojlw4IDx+/3myy+/NFlZWebJJ5+M1iEggnp6ekxra6tpbW01kkxNTY1pbW01Z8+eNcYYs3nzZuN2u63+fr/fJCQkmI0bNxqfz2c++OADExsba5qamqJ1CMOiuBoH3n//fXPbbbcZu91u7rvvPnP8+HFr3fLly43H4wnp/8knn5g77rjD2O12s3DhQtPQ0BDhiBFtI8mZ22+/3UgatHi93sgHjqgZ6XXm3yiuJqeR5sx3331nli5dahwOh8nMzDRvvfWWGRgYiHDUiKaR5MyVK1fMtm3bTFZWlomPjzfp6emmtLTUXLx4MfKBI+K+/vrrIe9NruWIx+Mxy5cvHzRm8eLFxm63m8zMTLN3796Ix30jbMYw9woAAAAA/xXvXAEAAABAGFBcAQAAAEAYUFwBAAAAQBhQXAEAAABAGFBcAQAAAEAYUFwBAAAAQBhQXAEAAABAGFBcAQAAAEAYUFwBACalrq4u2Ww2tbW1jdk+iouLVVBQMGbbBwCMLxRXAIAJqbi4WDabbdCycuXKGxqfnp6u7u5u3XnnnWMcKQBgsoiLdgAAAIzWypUrtXfv3pA2h8NxQ2NjY2OVlpY2FmEBACYpZq4AABOWw+FQWlpayDJ9+nRJks1mU21trVatWiWn06nMzEwdOnTIGnv9Y4EXL15UUVGRUlJS5HQ6NXfu3JDCrb29XQ8//LCcTqdmzpypkpIS/f3339b6q1ev6qWXXlJSUpJmzpypV199VcaYkHiDwaAqKyuVkZEhp9OpRYsWhcQEAJjYKK4AADetrVu3qrCwUKdOnVJRUZGefvpp+Xy+YfuePn1an3/+uXw+n2pra5WcnCxJ6u3t1WOPPabp06frxx9/1MGDB9Xc3Kz169db4999913t27dPe/bs0bFjx/THH3+ovr4+ZB+VlZX68MMPtWPHDv30008qKyvTs88+q2+//XbsTgIAIGJs5vp/qwEAMAEUFxdr//79io+PD2kvLy9XeXm5bDab1q1bp9raWmvd/fffryVLlmj79u3q6upSRkaGWltbtXjxYq1Zs0bJycnas2fPoH3t2rVLmzZt0q+//qqpU6dKkhobG7V69Wr99ttvSk1N1ezZs1VWVqaNGzdKkgYGBpSRkaGcnBx99tln6u/v14wZM9Tc3Ky8vDxr22vXrlVfX58+/vjjsThNAIAI4p0rAMCE9dBDD4UUT5I0Y8YM6+9/FzHXfg/3dcDnn39ehYWFOnnypB599FEVFBTogQcekCT5fD4tWrTIKqwkadmyZQoGg+ro6FB8fLy6u7u1dOlSa31cXJxyc3OtRwM7OzvV19enFStWhOz38uXLuueee0Z+8ACAcYfiCgAwYU2dOlVz5swJy7ZWrVqls2fPqrGxUUeOHNEjjzyiF154QdXV1WHZ/rX3sxoaGnTrrbeGrLvRj3AAAMY33rkCANy0jh8/Puh3dnb2sP1TUlLk8Xi0f/9+vffee9q5c6ckKTs7W6dOnVJvb6/Vt6WlRTExMZo3b55uueUWuVwuff/999b6gYEBnThxwvq9YMECORwOnTt3TnPmzAlZ0tPTw3XIAIAoYuYKADBh9ff3KxAIhLTFxcVZH6I4ePCgcnNzlZ+fr48++kg//PCDdu/ePeS2Xn/9deXk5GjhwoXq7+/X4cOHrUKsqKhIXq9XHo9H27Zt0++//64XX3xRbrdbqampkqQNGzaoqqpKc+fO1fz581VTU6M///zT2n5iYqJeeeUVlZWVKRgMKj8/X5cuXVJLS4umTZsmj8czBmcIABBJFFcAgAmrqalJLpcrpG3evHk6c+aMJOmNN95QXV2dSktL5XK5dODAAS1YsGDIbdntdr322mvq6uqS0+nUgw8+qLq6OklSQkKCvvjiC23YsEH33nuvEhISVFhYqJqaGmv8yy+/rO7ubnk8HsXExOi5557TE088oUuXLll9KioqlJKSosrKSvn9fiUlJWnJkiUqLy8P96kBAEQBXwsEANyUbDab6uvrVVBQEO1QAACTBO9cAQAAAEAYUFwBAAAAQBjwzhUA4KbEU+8AgEhj5goAAAAAwoDiCgAAAADCgOIKAAAAAMKA4goAAAAAwoDiCgAAAADCgOIKAAAAAMKA4goAAAAAwoDiCgAAAADC4H/pA0IQLT0cWQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def plot_learning_curve(rewards, title=\"Learning Curve\", label=\"Total reward\"):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(rewards, label='Episode Reward')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel(label)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# エージェントの学習\n",
        "# (agent.train()の呼び出しなど)\n",
        "\n",
        "# 学習後のエージェントの評価\n",
        "#evaluate_agent(agent, env, num_episodes=10)\n",
        "\n",
        "# 学習曲線のプロット\n",
        "plot_learning_curve(episode_reward_history, title=\"PPO Learning Curve\", label=\"Total reward\")\n",
        "plot_learning_curve(agent.loss_history_detail, title=\"loss curve\", label=\"Total loss (actor loss +  critic loss) \")\n",
        "plot_learning_curve(agent.actor_loss_history, title=\"actor loss curve\", label=\"actor loss\")\n",
        "plot_learning_curve(agent.critic_loss_history, title=\"critic loss curve\", label=\"critic loss\")\n",
        "plot_learning_curve(agent.entropy_history, title=\"entropy curve\", label=\"entropy\")\n",
        "plot_learning_curve(agent.kl_divergence_history, title=\"kl divergence curve\", label=\"kl divergence\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "w98R-WQ4TYPe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6da5ca73-272e-4584-ccdd-9e6feb694748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.0589, 0.0519, 0.0259, 0.8633]], grad_fn=<DivBackward0>) cnt: tensor([[0.4984]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4984]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.4983906 <class 'numpy.ndarray'>\n",
            "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.0753, 0.0626, 0.0238, 0.8383]], grad_fn=<DivBackward0>) cnt: tensor([[0.4961]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4961]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49610728 <class 'numpy.ndarray'>\n",
            "[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.1034, 0.0779, 0.0218, 0.7969]], grad_fn=<DivBackward0>) cnt: tensor([[0.5005]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.5005]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.5005348 <class 'numpy.ndarray'>\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1]\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.]]) dsc tensor([[0.1338, 0.0880, 0.0203, 0.7579]], grad_fn=<DivBackward0>) cnt: tensor([[0.4952]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4952]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.4952285 <class 'numpy.ndarray'>\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1]\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc tensor([[0.1289, 0.0822, 0.0223, 0.7665]], grad_fn=<DivBackward0>) cnt: tensor([[0.4943]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4943]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49430335 <class 'numpy.ndarray'>\n",
            "[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.0739, 0.0615, 0.0244, 0.8403]], grad_fn=<DivBackward0>) cnt: tensor([[0.4989]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4989]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49887437 <class 'numpy.ndarray'>\n",
            "[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.2125, 0.1226, 0.0156, 0.6494]], grad_fn=<DivBackward0>) cnt: tensor([[0.4967]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4967]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49668497 <class 'numpy.ndarray'>\n",
            "[0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.2288, 0.1292, 0.0148, 0.6272]], grad_fn=<DivBackward0>) cnt: tensor([[0.5017]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.5017]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.50170946 <class 'numpy.ndarray'>\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.]]) dsc tensor([[0.2704, 0.1359, 0.0136, 0.5802]], grad_fn=<DivBackward0>) cnt: tensor([[0.4973]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4973]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49726993 <class 'numpy.ndarray'>\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1]\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc tensor([[0.2712, 0.1293, 0.0149, 0.5846]], grad_fn=<DivBackward0>) cnt: tensor([[0.4966]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4966]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49662063 <class 'numpy.ndarray'>\n",
            "[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.1247, 0.0923, 0.0190, 0.7639]], grad_fn=<DivBackward0>) cnt: tensor([[0.4990]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4990]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49904174 <class 'numpy.ndarray'>\n",
            "[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.2237, 0.1349, 0.0139, 0.6275]], grad_fn=<DivBackward0>) cnt: tensor([[0.4980]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4980]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49795932 <class 'numpy.ndarray'>\n",
            "[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.2387, 0.1426, 0.0134, 0.6052]], grad_fn=<DivBackward0>) cnt: tensor([[0.5018]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.5018]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.50179034 <class 'numpy.ndarray'>\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.]]) dsc tensor([[0.2957, 0.1426, 0.0129, 0.5489]], grad_fn=<DivBackward0>) cnt: tensor([[0.4972]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4972]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49721253 <class 'numpy.ndarray'>\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc tensor([[0.2661, 0.1308, 0.0148, 0.5883]], grad_fn=<DivBackward0>) cnt: tensor([[0.4949]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4949]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49485174 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.1845, 0.1189, 0.0161, 0.6805]], grad_fn=<DivBackward0>) cnt: tensor([[0.4976]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4976]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49756032 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.3314, 0.1656, 0.0100, 0.4930]], grad_fn=<DivBackward0>) cnt: tensor([[0.4939]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4939]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49387884 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.2792, 0.1509, 0.0121, 0.5578]], grad_fn=<DivBackward0>) cnt: tensor([[0.4990]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4990]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49896446 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.]]) dsc tensor([[0.3619, 0.1645, 0.0096, 0.4640]], grad_fn=<DivBackward0>) cnt: tensor([[0.4927]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4927]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.4926921 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc tensor([[0.3636, 0.1536, 0.0109, 0.4719]], grad_fn=<DivBackward0>) cnt: tensor([[0.4937]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4937]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49368525 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.1958, 0.1312, 0.0145, 0.6585]], grad_fn=<DivBackward0>) cnt: tensor([[0.4960]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4960]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.4959667 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.2869, 0.1668, 0.0106, 0.5357]], grad_fn=<DivBackward0>) cnt: tensor([[0.4898]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4898]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.48977154 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.]]) dsc tensor([[0.2677, 0.1586, 0.0118, 0.5619]], grad_fn=<DivBackward0>) cnt: tensor([[0.4976]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4976]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49755332 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.]]) dsc tensor([[0.2781, 0.1558, 0.0114, 0.5547]], grad_fn=<DivBackward0>) cnt: tensor([[0.4917]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4917]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49165666 <class 'numpy.ndarray'>\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1]\n",
            "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.]]) dsc tensor([[0.2568, 0.1443, 0.0130, 0.5859]], grad_fn=<DivBackward0>) cnt: tensor([[0.4911]], grad_fn=<DivBackward0>)\n",
            "tensor(3) act_dsc\n",
            "tensor([[0.4911]], grad_fn=<DivBackward0>) act_cnt\n",
            "0.49107942 <class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "def one_hot_encoding(levels, maintenance_status, n_units=2,n_states=5, MAX_maintenance_time=0):\n",
        "    level_ohe = []\n",
        "    mstatus_ohe = []\n",
        "    for unit_idx in range(n_units):\n",
        "        l = [0] * n_states\n",
        "        m = [0] * (MAX_maintenance_time + 1)\n",
        "        l[levels[unit_idx]] = 1\n",
        "        m[maintenance_status[unit_idx]] = 1\n",
        "        level_ohe = level_ohe + l\n",
        "        mstatus_ohe = mstatus_ohe + m\n",
        "    return level_ohe, mstatus_ohe\n",
        "\n",
        "\n",
        "def get_color(action):\n",
        "    if action < 0:\n",
        "        print(action)\n",
        "        return \"white\"\n",
        "    #cmap = [\"red\",\"sandybrown\",\"orange\",\"lawngreen\",\"darkorange\",\"lightgreen\",\"green\",\"lightblue\"]\n",
        "    cmap = [\"red\",\"orange\",\"orange\",\"lightgreen\",\"orange\",\"lightgreen\",\"lightgreen\",\"lightblue\"]\n",
        "    return cmap[action]\n",
        "\n",
        "def plot_action(ax, center_x, center_y, act_dsc, act_cnt):\n",
        "    size = 1\n",
        "    opt_action = patches.Rectangle(\n",
        "        (center_x-size/2, center_y-size/2),\n",
        "        1,\n",
        "        1,\n",
        "        linewidth = 0,\n",
        "        facecolor = get_color(act_dsc)\n",
        "    )\n",
        "    ax.add_patch(opt_action)\n",
        "    #print(act_dsc)\n",
        "    if act_dsc==0:\n",
        "        ax.text(center_x,center_y,f'M12',ha='center', va='center')\n",
        "    elif act_dsc==1:\n",
        "        ax.text(center_x,center_y,f'M1',ha='center', va='center')\n",
        "    elif act_dsc==2:\n",
        "        ax.text(center_x,center_y,f'M2',ha='center', va='center')\n",
        "    else: #稼働継続\n",
        "        print(act_cnt, type(act_cnt))\n",
        "        #ax.text(center_x, center_y,f'{(round(act_cnt[0],2),round(1-act_cnt[0],2))}',ha='center', va='center',fontsize=5)\n",
        "        ax.text(center_x, center_y, f'{(round(float(act_cnt), 2), round(1 - float(act_cnt), 2))}', ha='center', va='center', fontsize=5)\n",
        "\n",
        "\n",
        "\n",
        "def optimal_policy(s1,m1,m2,m3,b,d,t):\n",
        "    fig, ax = plt.subplots()\n",
        "    x = 5\n",
        "    for s2 in range(x):\n",
        "        for s3 in range(x):\n",
        "            level_ohe, mstatus_ohe = one_hot_encoding(levels=[s2,s3],maintenance_status=[m2,m3])\n",
        "            state = level_ohe + mstatus_ohe + list([b,d])\n",
        "            print(state)\n",
        "            act_dsc, act_cnt, log_prob, val = agent.choose_action_max_prob(state)\n",
        "            act_dsc = act_dsc.item()\n",
        "            act_cnt = act_cnt.squeeze().cpu().detach().numpy().copy()\n",
        "            #print(act_dsc,act_cnt)\n",
        "            plot_action(ax, s2, s3, act_dsc, act_cnt)\n",
        "    ax.set_xlim(-0.5,x+0.5)\n",
        "    ax.set_ylim(-0.5,x+0.5)\n",
        "    #cbar = plt.colorbar(scatter, cax=cax, ticks=np.arange(0.5, 8.5, 1))\n",
        "    #cbar.ax.set_yticklabels([f'{i:b}' for i in range(8)])\n",
        "    ax.set_aspect('equal', adjustable='box')  # アスペクト比を保持\n",
        "    ax.set_xlabel(\"s1\") #変更\n",
        "    ax.set_ylabel(\"s2\") #変更\n",
        "    # グラフを表示\n",
        "    ax.set_title(\"(s1=\"+str(s1)+\", s2, s3, m1=\"+str(m1)+\", m2=\"+str(m2)+\", m3=\"+str(m3)+\", b=\"+str(b)+\", d=\"+str(d)+\", t=\"+str(t)+\")\")\n",
        "    plt.show()\n",
        "optimal_policy(s1=0,m1=0,m2=0,m3=0,b=0,d=1,t=1)\n",
        "#optimal_policy(s1=0,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=1,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=2,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=3,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=4,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=4,m1=0,m2=0,m3=0,b=0,d=0,t=1)\n",
        "#optimal_policy(s1=0,m1=1,m2=1,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=0,m1=0,m2=0,m3=0,b=1,d=0,t=0.5)\n",
        "#optimal_policy(s1=0,m1=0,m2=0,m3=0,b=-1,d=0,t=1)\n",
        "#optimal_policy(s1=1,m1=0,m2=0,m3=0,b=-1,d=0,t=1)\n",
        "#optimal_policy(s1=2,m1=0,m2=0,m3=0,b=-1,d=0,t=1)\n",
        "#optimal_policy(s1=3,m1=0,m2=0,m3=0,b=-1,d=0,t=1)\n",
        "#optimal_policy(s1=4,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=0,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=1,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=2,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=3,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=4,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "s1 = 4\n",
        "s2 = 4\n",
        "s3 = 4\n",
        "m1 = 0\n",
        "m2 = 0\n",
        "m3 = 0\n",
        "inventory = 0\n",
        "#demand = 0\n",
        "remain_interval = 1\n",
        "level_ohe, mstatus_ohe = one_hot_encoding(levels=[s1,s2,s3],maintenance_status=[m1,m2,m3])\n",
        "state = level_ohe + mstatus_ohe + list([inventory,demand,remain_interval])\n",
        "#act_dsc, act_cnt, log_prob, val = agent.choose_action_max_prob(state)\n",
        "#act_dsc = act_dsc.item()\n",
        "#act_dsc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3bLWs2RTYPe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DRL",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.1.undefined"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}