{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbeTetsuyaR/AbePPO/blob/main/AbePPO0904_without_ohe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qCrwylLHTYPW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import cProfile\n",
        "import sys\n",
        "import copy\n",
        "from torch.distributions.categorical import Categorical\n",
        "import math\n",
        "import os\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.colors as mcolors\n",
        "from tqdm import tqdm  # tqdmをインポート\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats import gamma, uniform, truncnorm\n",
        "#import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L6hr_FE6TYPY"
      },
      "outputs": [],
      "source": [
        "class Environment:\n",
        "    def __init__(self, n_units=2):\n",
        "        self.n_units = n_units #number of unit\n",
        "        #self.n_states = 5 #number of state\n",
        "        self.inventory = 0\n",
        "        self.demand = 0\n",
        "        self.maintenance_status = [0] * self.n_units\n",
        "        self.interval = 24\n",
        "        self.remain_interval = 24\n",
        "        self.MAX_speed = 10/self.interval\n",
        "        self.MAX_inventory = 0\n",
        "        self.MAX_demand = 15\n",
        "        self.MAX_maintenance_time = 0\n",
        "\n",
        "        self.load_total=1\n",
        "\n",
        "        self.cp = 500#\n",
        "        self.cc = 1800#\n",
        "\n",
        "        self.cps = 0\n",
        "        self.co = 5\n",
        "        self.cs = 500#\n",
        "\n",
        "        self.levels = [0] * self.n_units\n",
        "        #self.flags = [0] * self.n_units\n",
        "        self.shape = 3\n",
        "        self.penalty = 1\n",
        "        self.L = 100#\n",
        "        #self.P_Cost =[[100,110,130,160,2540],\n",
        "                      #[110,120,140,170,2550],\n",
        "                      #[130,140,160,190,2570],\n",
        "                      #[160,170,190,220,2600],\n",
        "                      #[2540,2550,2570,2600,5000]]#convex化\n",
        "\n",
        "        self.P_Cost =[[0,0,0,0,2500],\n",
        "                      [0,0,0,0,2500],\n",
        "                      [0,0,0,0,2500],\n",
        "                      [0,0,0,0,2500],\n",
        "                      [2500,2500,2500,2500,5000]]#平滑化\n",
        "        self.P_Cost_L = 2500\n",
        "\n",
        "        self.Visit =[[0,0,0,0,0],\n",
        "                      [0,0,0,0,0],\n",
        "                      [0,0,0,0,0],\n",
        "                      [0,0,0,0,0],\n",
        "                      [0,0,0,0,0]]\n",
        "        self.cntCount=[0,0]\n",
        "\n",
        "        self.failure_keep1 = 0 #1つ故障しているのに保全を選択しなかった回数\n",
        "        self.failure_keep2 = 0 #2つ故障しているのに保全を選択しなかった回数\n",
        "        self.failure_keep3 = 0 #3つ故障しているのに保全を選択しなかった回数\n",
        "        self.replace_chance = 0 #保全を選択できた回数\n",
        "\n",
        "    def init_random(self):\n",
        "        levels = [0,0]\n",
        "        flags = [0,0]\n",
        "        self.load_total=1\n",
        "        return levels,  flags, self.load_total\n",
        "\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.levels = np.zeros(self.n_units)\n",
        "\n",
        "    def complete_maintenance(self, unit_idx):\n",
        "        self.levels[unit_idx] = 0\n",
        "\n",
        "    def get_ability(self, level): #良品率\n",
        "        if level == 0:\n",
        "            return 1\n",
        "        elif level == 1:\n",
        "            return 0.8\n",
        "        elif level ==2:\n",
        "            return 0.5\n",
        "        elif level == 3:\n",
        "            return 0.1\n",
        "        return (self.n_states - 1 - level) / (self.n_states - 1)\n",
        "\n",
        "    def update_demand(self, speed, ability, time):\n",
        "        if self.demand >= self.inventory:\n",
        "            self.demand -= self.inventory\n",
        "            self.inventory = 0.0\n",
        "        else:\n",
        "            self.inventory -= self.demand\n",
        "            self.demand = 0.0\n",
        "        return max(0, self.demand-self.inventory-ability*speed*time)\n",
        "\n",
        "    def update_inventory(self, speed, ability, time):\n",
        "        if self.demand <= self.inventory + ability * speed * time:\n",
        "            return min(self.MAX_inventory, -self.demand+self.inventory+ability*speed*time), max(0, -self.MAX_inventory-self.demand+self.inventory+ability*speed*time)\n",
        "        else:\n",
        "            return 0.0, 0.0\n",
        "\n",
        "    def get_maintenance_time(self,level):\n",
        "        return 0\n",
        "\n",
        "    def update_maintenance_time(self, unit_idx):\n",
        "        return 0\n",
        "\n",
        "    def one_hot_encode(self):\n",
        "        level_ohe = []\n",
        "        #mstatus_ohe = []\n",
        "        for unit_idx in range(self.n_units):\n",
        "            l = [0] * self.n_states\n",
        "            #m = [0] * (self.MAX_maintenance_time + 1)\n",
        "            l[min(math.floor(self.levels[unit_idx]),self.n_states-1)] = 1\n",
        "            #m[self.maintenance_status[unit_idx]] = 1\n",
        "            level_ohe = level_ohe + l\n",
        "            #mstatus_ohe = mstatus_ohe + m\n",
        "        return level_ohe #mstatus_oheは削除\n",
        "\n",
        "\n",
        "\n",
        "    def operation(self, replacements, load_rate):\n",
        "        #print(self.levels,\"levels_before\")\n",
        "        reward = 0\n",
        "        #print(load_rate)\n",
        "\n",
        "        flag = 0\n",
        "\n",
        "        #保全の意思決定\n",
        "        #print(replacements)\n",
        "\n",
        "        if replacements==[1,1]: #稼働継続\n",
        "\n",
        "          #reward -= self.P_Cost[min(math.floor(self.levels[0]),self.n_states-1)][min(math.floor(self.levels[1]),self.n_states-1)] #rewardを最初に計算\n",
        "          if self.levels[0]>self.L:\n",
        "            reward -= self.P_Cost_L\n",
        "          if self.levels[1]>self.L:\n",
        "            reward -= self.P_Cost_L\n",
        "          #print(reward)\n",
        "          # パラメータの設定\n",
        "          scales=[0,0]\n",
        "          shape0 = 0.69  # ガンマ分布のパラメータ v1 用 0.69 100倍にしてみる\n",
        "          shape1 = 0.69   # ガンマ分布のパラメータ v2 用\n",
        "          tau = 0.5  # ケンドールの順位相関係数\n",
        "\n",
        "          theta = 1 / (1 - tau)\n",
        "\n",
        "          #if load_rate<0:##\n",
        "            #load_rate=0\n",
        "          #if load_rate>1:\n",
        "            #load_rate=1\n",
        "          loads=[0,0]\n",
        "          loads[0]=load_total*load_rate\n",
        "          loads[1]=load_total*(1-load_rate)\n",
        "\n",
        "          #print(speeds, \"speeds\")\n",
        "          #尺度パラメータ計算\n",
        "          for i in range(self.n_units):\n",
        "            scales[i]=6.491*(loads[i]**2)+0.726\n",
        "            #scales[i]=6.491*(speeds[i]**0.5)+0.726\n",
        "            #scales[i]=scales[i] #1/10000倍にしてみる\n",
        "\n",
        "\n",
        "          # 一様分布から独立にサンプリング\n",
        "          u = uniform.rvs(size=1)\n",
        "          v = uniform.rvs(size=1)\n",
        "          #print(\"u,v:\",u,v)\n",
        "          # ガンベルコピュラの逆関数を適用\n",
        "          x = (-np.log(u.item())) ** theta#arrayをfloatに\n",
        "          y = (-np.log(v.item())) ** theta\n",
        "          #print(\"x,y:\",x,y)\n",
        "\n",
        "          t = (x + y) ** (1/theta)\n",
        "          #print(\"t:\",t)\n",
        "\n",
        "          u_new = np.exp(-t * (x / (x + y)))\n",
        "          v_new = np.exp(-t * (y / (x + y)))\n",
        "\n",
        "          # ガンマ分布に変換\n",
        "          v1 = gamma.ppf(u_new, shape0, scale=scales[0])\n",
        "          v2 = gamma.ppf(v_new, shape1, scale=scales[1])\n",
        "          #print(v1,v2)\n",
        "          #v1 = gamma.rvs(shape0, scale=scales[0])\n",
        "          #v2 = gamma.rvs(shape1, scale=scales[1])\n",
        "\n",
        "          #print(\"稼働継続\")\n",
        "          #print(v1,v2, \"劣化増分\")\n",
        "          self.levels[0]+=v1\n",
        "          self.levels[1]+=v2\n",
        "          #print(self.levels, \"劣化\")\n",
        "\n",
        "\n",
        "\n",
        "        elif replacements==[0,1]: #1個取替(順張り) #0907\n",
        "          reward -= self.cs\n",
        "\n",
        "          if self.levels[0]>self.levels[1]:\n",
        "            unit_replaced=0\n",
        "          else:\n",
        "            unit_replaced=1\n",
        "\n",
        "          if self.levels[unit_replaced]<self.L:\n",
        "            reward -= self.cp\n",
        "          else:\n",
        "            reward -= self.cc\n",
        "          self.levels[unit_replaced]=0\n",
        "\n",
        "        elif replacements==[1,0]:#1個取替(逆張り)\n",
        "          reward -= self.cs\n",
        "\n",
        "          if self.levels[0]>self.levels[1]:\n",
        "            unit_replaced=1\n",
        "          else:\n",
        "            unit_replaced=0\n",
        "\n",
        "          if self.levels[unit_replaced]<self.L:\n",
        "            reward -= self.cp\n",
        "          else:\n",
        "            reward -= self.cc\n",
        "          self.levels[unit_replaced]=0\n",
        "\n",
        "        else: #両方取替\n",
        "          reward -= self.cs\n",
        "          if self.levels[0]<self.L:\n",
        "            reward -= self.cp\n",
        "          else:\n",
        "            reward -= self.cc\n",
        "          if self.levels[1]<self.L:\n",
        "            reward -= self.cp\n",
        "          else:\n",
        "            reward -= self.cc\n",
        "          self.levels=[0,0]\n",
        "\n",
        "        #print(self.levels)\n",
        "        #print(reward)\n",
        "\n",
        "        #level_ohe= self.one_hot_encode()\n",
        "\n",
        "        #print(f'状態:{self.levels}, 保全状態:{self.maintenance_status}, 在庫:{self.inventory}, 需要:{self.demand}, 残り時間:{self.remain_interval}, 保全行動:{replacements}, {speeds}')\n",
        "        #print(\"#############\")\n",
        "\n",
        "        flags = [0,0]#故障フラグ\n",
        "        if self.levels[0] >= self.L:\n",
        "          flags[0] = 1\n",
        "        if self.levels[1] >= self.L:\n",
        "          flags[1] = 1\n",
        "\n",
        "        #切断正規分布\n",
        "        dist_N = truncnorm(0, 2, loc=1, scale=1)\n",
        "        self.load_total=float(dist_N.rvs(1))\n",
        "        #print(self.load_total)\n",
        "\n",
        "        #self.Visit[min(math.floor(self.levels[0]),self.n_states-1)][min(math.floor(self.levels[1]),self.n_states-1)] += 1\n",
        "        #levels_after=[]\n",
        "        #for i in range(self.n_units):\n",
        "          #l=list([self.levels[i][0]])\n",
        "          #levels_after =levels_after+l\n",
        "        #print(self.levels,\"levels_after\")\n",
        "\n",
        "        return reward, self.levels, flags, self.load_total\n",
        "\n",
        "        #return reward, level_ohe, mstatus_ohe, \\\n",
        "        #       0, (self.demand-mean)/variance, self.remain_interval * 2 / self.interval - 1, flag\n",
        "\n",
        "\n",
        "    #劣化レベル順にすべき可能性"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z_7ruy0iTYPa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "35ba98d4-e38e-46b9-bf4e-0abef4932f1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    def generate_advantage(self):\\n        advantage = []\\n        gae = 0\\n        gamma = math.exp(-self.beta)\\n        lambd = 0.0\\n        for t in reversed(range(len(self.rewards))):\\n            if t == len(self.rewards) - 1:\\n                delta = self.rewards[t] - self.vals[t]\\n            else:\\n                delta = self.rewards[t] + gamma * self.vals[t+1] - self.vals[t]\\n            gae = delta + lambd * gamma * gae  # Assuming lambda = 1 for simplicity, otherwise use gamma * lambda * gae\\n            advantage.insert(0, gae)\\n        self.advantage = np.array(advantage, dtype=np.float32)\\n\\n    def generate_advantage(self):\\n\\n        advantage = []\\n        gae = 0\\n        for t in reversed(range(len(self.rewards))):\\n            gamma = 1\\n            if t == len(self.rewards) - 1:\\n                delta = self.rewards[t] - self.vals[t]\\n            else:\\n                gamma = math.exp(-self.beta*1) #修正\\n                delta = self.rewards[t] + gamma * self.vals[t+1] - self.vals[t]\\n            gae = delta + gamma * gamma * gae\\n            advantage.insert(0, gae)\\n        self.advantage = np.array(advantage,dtype=np.float32)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "class PPOMemory:\n",
        "    def __init__(self,batch_size, interval, beta, GAE_lam):\n",
        "        self.states = []\n",
        "        self.probs_dsc = []\n",
        "        self.probs_cnt = []\n",
        "        self.vals = []\n",
        "        self.acts_dsc = []\n",
        "        self.acts_cnt = []\n",
        "        self.rewards = []\n",
        "        self.time = []\n",
        "        self.batch_size = batch_size\n",
        "        self.interval = interval\n",
        "        self.beta = beta\n",
        "        self.advantage = []\n",
        "        self.lam = GAE_lam\n",
        "\n",
        "\n",
        "\n",
        "    def generate_advantage(self):\n",
        "        advantage = []\n",
        "        adv = 0\n",
        "        #gamma = math.exp(-self.beta)\n",
        "        #lambd = 0.0\n",
        "        beta=0.99\n",
        "        for t in reversed(range(len(self.rewards))):\n",
        "            if t == len(self.rewards) - 1:\n",
        "                adv = self.rewards[t] - self.vals[t]\n",
        "            else:\n",
        "                adv = self.rewards[t] + beta * self.vals[t+1] - self.vals[t]\n",
        "            #gae = delta + lambd * gamma * gae  # Assuming lambda = 1 for simplicity, otherwise use gamma * lambda * gae\n",
        "            advantage.insert(0, adv)\n",
        "        self.advantage = np.array(advantage, dtype=np.float32)\n",
        "\n",
        "\n",
        "    def generate_batches(self):\n",
        "        n_states = len(self.states)\n",
        "        batch_start = np.arange(0, n_states, self.batch_size)\n",
        "        indices = np.arange(n_states, dtype=np.int64)\n",
        "        np.random.shuffle(indices)\n",
        "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
        "\n",
        "        return np.array(self.states),\\\n",
        "               np.array(self.acts_dsc),\\\n",
        "               np.array(self.acts_cnt),\\\n",
        "               np.array(self.probs_dsc),\\\n",
        "               np.array(self.probs_cnt),\\\n",
        "               np.array(self.vals),\\\n",
        "               np.array(self.rewards),\\\n",
        "               np.array(self.advantage),\\\n",
        "               batches\n",
        "\n",
        "\n",
        "\n",
        "    def store_memory(self, state, act_dsc, act_cnt, probs_dsc, probs_cnt, vals, reward, time):\n",
        "        self.states.append(state)\n",
        "        self.acts_dsc.append(act_dsc)\n",
        "        self.acts_cnt.append(act_cnt)\n",
        "        self.probs_dsc.append(probs_dsc)\n",
        "        self.probs_cnt.append(probs_cnt)\n",
        "        self.vals.append(vals)\n",
        "        self.rewards.append(reward)\n",
        "        self.time.append(time)\n",
        "\n",
        "    def clear_memory(self):\n",
        "        self.states = []\n",
        "        self.probs_dsc = []\n",
        "        self.probs_cnt = []\n",
        "        self.acts_dsc = []\n",
        "        self.acts_cnt = []\n",
        "        self.rewards = []\n",
        "        self.vals = []\n",
        "        self.time = []\n",
        "\n",
        "\"\"\"\n",
        "    def generate_advantage(self):\n",
        "        advantage = []\n",
        "        gae = 0\n",
        "        gamma = math.exp(-self.beta)\n",
        "        lambd = 0.0\n",
        "        for t in reversed(range(len(self.rewards))):\n",
        "            if t == len(self.rewards) - 1:\n",
        "                delta = self.rewards[t] - self.vals[t]\n",
        "            else:\n",
        "                delta = self.rewards[t] + gamma * self.vals[t+1] - self.vals[t]\n",
        "            gae = delta + lambd * gamma * gae  # Assuming lambda = 1 for simplicity, otherwise use gamma * lambda * gae\n",
        "            advantage.insert(0, gae)\n",
        "        self.advantage = np.array(advantage, dtype=np.float32)\n",
        "\n",
        "    def generate_advantage(self):\n",
        "\n",
        "        advantage = []\n",
        "        gae = 0\n",
        "        for t in reversed(range(len(self.rewards))):\n",
        "            gamma = 1\n",
        "            if t == len(self.rewards) - 1:\n",
        "                delta = self.rewards[t] - self.vals[t]\n",
        "            else:\n",
        "                gamma = math.exp(-self.beta*1) #修正\n",
        "                delta = self.rewards[t] + gamma * self.vals[t+1] - self.vals[t]\n",
        "            gae = delta + gamma * gamma * gae\n",
        "            advantage.insert(0, gae)\n",
        "        self.advantage = np.array(advantage,dtype=np.float32)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MJC8xTojTYPa"
      },
      "outputs": [],
      "source": [
        "class ActorNetwork(nn.Module):\n",
        "    def __init__(self, n_units, n_states, MAX_maintenance_time, input_dims, alpha, fc1_dims=64, fc2_dims=64, fc3_dims=64, chkpt_dir=\"\"):\n",
        "        super(ActorNetwork, self).__init__()\n",
        "        self.n_units = n_units\n",
        "        self.n_states = n_states\n",
        "        self.MAX_maintenance_time = MAX_maintenance_time\n",
        "        self.checkpoint_file = os.path.join(chkpt_dir, \"actor_torch_ppo\")\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dims, fc1_dims)\n",
        "        self.fc2 = nn.Linear(fc1_dims, fc2_dims)\n",
        "        self.fc3 = nn.Linear(fc1_dims, fc3_dims)\n",
        "\n",
        "        self.dsc = nn.Linear(fc2_dims, 2 ** n_units) #離散行動\n",
        "        # 以下に初期化コードを追加\n",
        "        self.init_dsc_weights()\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.Tanh = nn.Tanh()\n",
        "\n",
        "        self.mean = nn.Linear(fc3_dims, n_units-1)\n",
        "        self.log_std = nn.Linear(fc3_dims, n_units-1)\n",
        "\n",
        "        # mean レイヤーの初期化\n",
        "        self.init_mean_weights()\n",
        "        # std レイヤーの初期化\n",
        "        self.init_std_weights()\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
        "\n",
        "        #0824 optimizer追加\n",
        "        self.optimizer_discrete = optim.Adam([\n",
        "            {'params':self.fc1.parameters()},\n",
        "            {'params':self.fc2.parameters()},\n",
        "            {'params':self.dsc.parameters()},\n",
        "        ], lr=alpha)\n",
        "\n",
        "        self.optimizer_continuous = optim.Adam([\n",
        "            {'params':self.fc1.parameters()},\n",
        "            {'params':self.fc3.parameters()},\n",
        "            {'params':self.mean.parameters()},\n",
        "            {'params':self.log_std.parameters()},\n",
        "        ], lr=alpha*3)#0908\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.to(self.device)\n",
        "\n",
        "        self.scheduler_actor = optim.lr_scheduler.StepLR(self.optimizer, step_size=5, gamma=0.95)\n",
        "\n",
        "    def init_dsc_weights(self):\n",
        "        # ここで特定の出力確率を設定するための重みとバイアスを設定\n",
        "        with torch.no_grad():\n",
        "            # すべての出力がほぼ等しくなるように設定\n",
        "            self.dsc.weight.fill_(0.0)\n",
        "            # 特定の確率分布に調整\n",
        "            self.dsc.bias.data = torch.log(torch.tensor([0.01, 0.01, 0.01, 0.97]))  # logを取るのがポイント\n",
        "\n",
        "    def init_mean_weights(self):\n",
        "        # mean レイヤーの初期化\n",
        "        with torch.no_grad():\n",
        "            self.mean.weight.fill_(0.0)\n",
        "            self.mean.bias.fill_(0.0)  # ここで固定出力0.5を設定#0に変更\n",
        "\n",
        "    def init_std_weights(self):\n",
        "        # std レイヤーの初期化\n",
        "        with torch.no_grad():\n",
        "            self.log_std.weight.fill_(0.0)\n",
        "            self.log_std.bias.fill_(0.0)  # ここで固定出力0.7を設定\n",
        "\n",
        "    #離散行動空間を制限するための関数, 返り値はmaskで制限されるところは-inf,されないところは1。返り値はバッチ数*2\n",
        "    def create_dsc_mask(self, state): #state=[s,m,b,d,t], action=[P(replace), P(keep)]\n",
        "        mask = torch.zeros(state.size(0),2**self.n_units)\n",
        "        #保全を選択できる時点にて、保全中のユニットは保全を選択できない\n",
        "        for unit_idx in range(self.n_units):\n",
        "            for a in range(2 ** self.n_units):\n",
        "                action_list = [int(bit) for bit in format(a, f'0{self.n_units}b')] #action_list=[r1,r2,r3,...]\n",
        "\n",
        "                #エラーのため省略\n",
        "                #if action_list[unit_idx] == 0:\n",
        "                    #保全の意思決定時点のとき、保全中の場合は保全を選択できない\n",
        "                    #保全の意思決定時点でないとき、保全を選択できない\n",
        "                    #mask[(state[:,(self.n_states*self.n_units-1+(self.MAX_maintenance_time+1)*unit_idx+1)] == 0)\\\n",
        "                        #, a] = torch.tensor(1)\n",
        "\n",
        "\n",
        "        mask[(state[:, 4] == 1) & (state[:, 9] == 1) & \\\n",
        "             (state[:,self.n_states*self.n_units-1 + 1] == 1)\n",
        "            ,1:] = torch.tensor(1) #2 ** self.n_units-1\n",
        "            #状態とユニット数により要変更\n",
        "\n",
        "        return mask.bool()\n",
        "\n",
        "    def create_cnt_mask(self, state):\n",
        "        mask= torch.zeros(state.size(0), self.n_units)\n",
        "        for unit_idx in range(self.n_units):\n",
        "            a = 2**(self.n_units)-1 - 2**(self.n_units-1-unit_idx)\n",
        "\n",
        "            #エラーのため省略\n",
        "            #保全の意思決定ができる時\n",
        "            mask[(state[:,-1] == 1) & \\\n",
        "                 ((dist_dsc[:,a] <= 0.0001) |\n",
        "                  (state[:,unit_idx*self.n_states+self.n_states-1] == 1) | \\\n",
        "                  (state[:,(self.n_states*self.n_units-1+(self.MAX_maintenance_time+1)*unit_idx+1)] == 0)), unit_idx] = torch.tensor(1)\n",
        "            mask[((state[:,unit_idx*self.n_states+self.n_states-1] == 1) | \\\n",
        "                  (state[:,(self.n_states*self.n_units-1+(self.MAX_maintenance_time+1)*unit_idx+1)] == 0)), unit_idx] = torch.tensor(1)\n",
        "\n",
        "\n",
        "        return mask.bool()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, state):\n",
        "        state_rev = state.clone()#0907\n",
        "        if state[0][0]>state[0][1]:\n",
        "          state_rev[:, [0, 1]] = state_rev[:, [1, 0]]\n",
        "          state_rev[:, [2, 3]] = state_rev[:, [3, 2]] #flag\n",
        "\n",
        "        #print(state[0,-1].item())\n",
        "        x = F.relu(self.fc1(state_rev))\n",
        "        x2 = F.relu(self.fc2(x))\n",
        "        x3 = F.relu(self.fc3(x))\n",
        "\n",
        "        #first_mask = self.create_dsc_mask(state)\n",
        "\n",
        "        #離散行動の分布\n",
        "        dist_dsc = self.dsc(x2)\n",
        "        #dist_dsc = dist_dsc.masked_fill(first_mask,-1e5)\n",
        "\n",
        "        dist_dsc = self.softmax(dist_dsc)\n",
        "        #if (state[0,4]==1 and state[0,9]==1 and state[0,14]==1 and state[0,15]==1 and state[0,19]==1 and state[0,23]==1 and state[0,-1]==1):\n",
        "        #print(state)\n",
        "        #    print(dist_dsc)\n",
        "        #    print(\"&&&&&&&&\")\n",
        "\n",
        "\n",
        "        #second_mask = self.create_cnt_mask(state)\n",
        "        dist_dsc = Categorical(dist_dsc)\n",
        "\n",
        "        #連続行動の分布\n",
        "        mean = self.mean(x3)\n",
        "        #mean = self.softmax(mean)\n",
        "        #mean = self.Tanh(mean)/2+0.5#[0,1]に補正\n",
        "        mean = self.Tanh(mean)\n",
        "\n",
        "        #load_max=min(state[0,-1].item(),1) #operationへ移動\n",
        "        #load_min=max(state[0,-1].item() -1,0)\n",
        "        #mean=load_min + (load_max-load_min)*mean\n",
        "\n",
        "        #mean = mean.masked_fill(second_mask, -1) #セカンドマスク\n",
        "\n",
        "        #print(dist_dsc, mean)\n",
        "        #print(state)\n",
        "        #print(dist_dsc)\n",
        "        #mean = torch.clamp(mean,min=-5,max=5)\n",
        "        log_std = self.log_std(x3)\n",
        "        log_std = torch.clamp(log_std,min=-20,max=2)\n",
        "        std = log_std.exp()\n",
        "        #std = std.masked_fill(second_mask, 1e-4) #セカンドマスク\n",
        "        #print(mean)\n",
        "        #print(\"AAAA\")\n",
        "\n",
        "        #print(mean,std)\n",
        "\n",
        "        #dist_cnt = torch.distributions.MultivariateNormal(loc=mean, covariance_matrix = torch.stack([torch.diag(x**2+1e-10) for x in std]))\n",
        "        #mean=state[0,-1].item()/2#試験\n",
        "\n",
        "        variance = std ** 2\n",
        "        #print(variance)\n",
        "        #if variance > mean*(1-mean)/2:#補正\n",
        "            #variance = mean*(1-mean)/2\n",
        "        variance = torch.min(variance, mean*(1-mean)/2)\n",
        "\n",
        "        # alpha と beta の計算式を安全に実施\n",
        "        epsilon = 1e-6  # ゼロ除算を防ぐための小さな値\n",
        "        mean_clamped = mean.clamp(min=epsilon, max=1-epsilon)  # mean を [epsilon, 1-epsilon] でクランプ\n",
        "        variance_clamped = variance.clamp(min=epsilon)  # variance を epsilon 以上でクランプ\n",
        "\n",
        "        alpha = ((1 - mean_clamped) / variance_clamped - 1 / mean_clamped) * (mean_clamped ** 2)\n",
        "        beta = alpha * (1 / mean_clamped - 1)\n",
        "        #print(\"After:\", mean)\n",
        "        # これらの値が正であることを保証\n",
        "        alpha = torch.max(alpha, torch.tensor(epsilon))\n",
        "        beta = torch.max(beta, torch.tensor(epsilon))\n",
        "\n",
        "\n",
        "        #dist_cnt = torch.distributions.Beta(alpha, beta) #ベータ分布にしてみる\n",
        "        #print(state[0,-1].item(),mean)\n",
        "        #print(state[0][0],state[0][1])\n",
        "        if state[0][0]<state[0][1]:\n",
        "          dist_cnt = torch.distributions.Normal(loc=mean, scale=std) #1次元化のため\n",
        "        #elif state[0][0]>state[0][1]:\n",
        "        else:\n",
        "          #revised_probs = dist_dsc.probs.clone()\n",
        "          #revised_probs[:, [1, 2]] = revised_probs[:, [2, 1]]  #0 要素の交換\n",
        "          #dist_dsc = torch.nn.ParameterDict({'probs': torch.nn.Parameter(revised_probs)})\n",
        "          dist_cnt = torch.distributions.Normal(loc=-mean, scale=std)\n",
        "        #else:\n",
        "          #dist_cnt = torch.distributions.Normal(loc=0.0, scale=std)\n",
        "\n",
        "        return dist_dsc, dist_cnt\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        torch.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        self.load_state_dict(torch.load(self.checkpoint_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "78j9p-tgTYPb"
      },
      "outputs": [],
      "source": [
        "class CriticNetwork(nn.Module):\n",
        "    def __init__(self, input_dims, alpha, fc1_dims=32, fc2_dims=32, fc3_dims=64, chkpt_dir=\"\"):\n",
        "        super(CriticNetwork, self).__init__()\n",
        "\n",
        "        self.checkpoint_file = os.path.join(chkpt_dir, \"critic_torch_ppo\")\n",
        "        self.critic = nn.Sequential(\n",
        "            nn.Linear(input_dims, fc1_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(fc1_dims,fc2_dims),\n",
        "            nn.ReLU(),\n",
        "            #nn.Linear(fc2_dims,fc3_dims),\n",
        "            #nn.ReLU(),\n",
        "            nn.Linear(fc2_dims,1)\n",
        "        )\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.to(self.device)\n",
        "\n",
        "        self.scheduler_critic = optim.lr_scheduler.StepLR(self.optimizer, step_size=5, gamma=0.95)\n",
        "\n",
        "        # 重みの初期化\n",
        "        #self.init_weights()\n",
        "\n",
        "    #def init_weights(self):\n",
        "        #with torch.no_grad():\n",
        "            #self.mean.weight.fill_(0.0)\n",
        "            #self.mean.bias.fill_(0.0)  # ここで固定出力0.5を設定#0に変更\n",
        "\n",
        "        #for layer in self.critic:\n",
        "            #if isinstance(layer, nn.Linear):\n",
        "                #torch.nn.init.xavier_uniform_(layer.weight)  # Xavier初期化を適用\n",
        "                #torch.nn.init.constant_(layer.bias, -13000)  # バイアスを14000で初期化\n",
        "\n",
        "\n",
        "    def forward(self, state):\n",
        "        state_rev = state.clone()#0907\n",
        "        if state[0][0]>state[0][1]:\n",
        "          state_rev[:, [0, 1]] = state_rev[:, [1, 0]]\n",
        "          state_rev[:, [2, 3]] = state_rev[:, [3, 2]]#flag\n",
        "        value = self.critic(state_rev)#0908\n",
        "\n",
        "        return value\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        torch.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        self.load_state_dict(torch.load(self.checkpoint_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jRw3Bjb7TYPb",
        "outputId": "d94726e5-62b8-4843-e134-d925a0586d52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DMZpQl6gTYPc"
      },
      "outputs": [],
      "source": [
        "test_batch = 0\n",
        "class Agent:\n",
        "    def __init__(self, n_units, n_states, MAX_maintenance_time, input_dims, beta=0.0005, GAE_lam=0.00, interval=24,\n",
        "                 alpha_actor=0.03, alpha_critic=0.01,\n",
        "                 policy_clip=0.2, batch_size=512*4, n_epochs=4):\n",
        "        self.beta = beta\n",
        "        self.policy_clip = policy_clip\n",
        "        self.n_epochs = n_epochs\n",
        "\n",
        "        self.loss_history = []\n",
        "        self.loss_history_detail = []\n",
        "\n",
        "        self.actor_loss_history = []\n",
        "        self.actor_loss_history_detail = []\n",
        "        self.critic_loss_history = []\n",
        "        self.critic_loss_history_detail = []\n",
        "        self.entropy_history = []\n",
        "        self.kl_divergence_history = []\n",
        "\n",
        "        self.actor = ActorNetwork(n_units, n_states, MAX_maintenance_time, input_dims, alpha_actor)\n",
        "        self.critic = CriticNetwork(input_dims, alpha_critic)\n",
        "        self.memory = PPOMemory(batch_size, interval=interval, beta=beta, GAE_lam=GAE_lam)\n",
        "\n",
        "    def remember(self,state,action_dsc,action_cnt,probs_dsc,probs_cnt,vals,reward, time):\n",
        "        self.memory.store_memory(state,action_dsc,action_cnt,probs_dsc,probs_cnt,vals,reward, time)\n",
        "\n",
        "    def save_models(self):\n",
        "        print(\"... saving models ...\")\n",
        "        self.actor.save_checkpoint()\n",
        "        self.critic.save_checkpoint()\n",
        "\n",
        "    def load_models(self):\n",
        "        print(\"... loading models ...\")\n",
        "        self.actor.load_checkpoint()\n",
        "        self.critic.load_checkpoint()\n",
        "\n",
        "    def choose_action(self,observation):\n",
        "        state = torch.tensor(np.array([observation]),dtype=torch.float).to(self.actor.device)\n",
        "        dist_dsc, dist_cnt = self.actor(state)\n",
        "\n",
        "        #state_rev = state.clone()\n",
        "        #state_rev[:, [0, 1]] = state_rev[:, [1, 0]]\n",
        "        #value = (self.critic(state)+self.critic(state_rev))/2\n",
        "        value = self.critic(state)#0907\n",
        "\n",
        "        act_dsc = dist_dsc.sample()\n",
        "\n",
        "\n",
        "        act_cnt = dist_cnt.sample()\n",
        "\n",
        "        log_prob_dsc = torch.squeeze(dist_dsc.log_prob(act_dsc)).item()\n",
        "\n",
        "        if act_dsc.item() == 3:\n",
        "          log_prob_cnt = torch.squeeze(dist_cnt.log_prob(act_cnt)).item()\n",
        "          #print(log_prob_cnt, \"log_prob_cnt\")\n",
        "        else:\n",
        "          #log_prob_cnt = 0 #dist_cntを参照しないことの補正\n",
        "          log_prob_cnt = torch.squeeze(dist_cnt.log_prob(act_cnt)).item()\n",
        "\n",
        "\n",
        "        log_prob = log_prob_dsc + log_prob_cnt\n",
        "\n",
        "        value = torch.squeeze(value).item()\n",
        "\n",
        "        return act_dsc, act_cnt, log_prob_dsc, log_prob_cnt, value\n",
        "\n",
        "    def choose_action_max_prob(self,observation):\n",
        "        state = torch.tensor(np.array([observation]),dtype=torch.float).to(self.actor.device)\n",
        "        dist_dsc, dist_cnt = self.actor(state)\n",
        "        print(\"state:\", state, \"dist_dsc.probs:\", dist_dsc.probs, \"dist_cnt.mean:\",dist_cnt.mean,\"dist_cnt.scale\", dist_cnt.scale)\n",
        "        act_dsc = torch.argmax(dist_dsc.probs)\n",
        "        act_cnt = dist_cnt.mean\n",
        "        #print(act_dsc, \":act_dsc\")\n",
        "        #print(act_cnt, \":act_cnt\")\n",
        "\n",
        "        value = self.critic(state)\n",
        "\n",
        "\n",
        "        log_prob_dsc = torch.squeeze(dist_dsc.log_prob(act_dsc)).item()\n",
        "        log_prob_cnt = torch.squeeze(dist_cnt.log_prob(act_cnt)).item()\n",
        "        log_prob = log_prob_dsc + log_prob_cnt\n",
        "\n",
        "        value = torch.squeeze(value).item()\n",
        "\n",
        "        return act_dsc, act_cnt, log_prob_dsc, log_prob_cnt, value\n",
        "\n",
        "    def learn(self,episode, threshold):\n",
        "        self.memory.generate_advantage()\n",
        "        actor_loss_sum = 0\n",
        "        critic_loss_sum = 0\n",
        "        entropy_sum = 0\n",
        "        kl_divergence_sum = 0\n",
        "        for _ in range(self.n_epochs):\n",
        "        #for _ in tqdm(range(self.n_epochs), desc=\"Training Progress\"):  # tqdmを用いて進捗表示\n",
        "            \"\"\"\n",
        "            rewards = self.memory.rewards\n",
        "            values = self.memory.vals\n",
        "            times = self.memory.time\n",
        "            advantage = np.zeros(len(reward_arr),dtype=np.float32)\n",
        "            for t in range(len(reward_arr)-1):\n",
        "                a_t = 0\n",
        "                for k in range(t, len(reward_arr)-1):\n",
        "                    a_t += math.exp(-self.beta * times[k]) * \\\n",
        "                        (reward_arr[k]+math.exp(-self.beta * (-times[k]%self.interval+self.interval))*values[k+1]-values[k])\n",
        "                advantage[t] = a_t\n",
        "            advantage = torch.tensor(advantage).to(self.actor.device)\n",
        "            \"\"\"\n",
        "            state_arr, act_dsc_arr, act_cnt_arr, old_probs_dsc_arr, old_probs_cnt_arr, vals_arr, reward_arr, advantage, batches=self.memory.generate_batches()\n",
        "            values = vals_arr\n",
        "            \"\"\"\n",
        "            values = vals_arr\n",
        "            times = time_arr\n",
        "            advantage = np.zeros(len(reward_arr),dtype=np.float32)\n",
        "            for t in range(len(reward_arr)-1):\n",
        "                a_t = 0\n",
        "                for k in range(t, len(reward_arr)-1):\n",
        "                    a_t += math.exp(-self.beta * times[k]) * (reward_arr[k]+self.gamma*values[k+1]-values[k])\n",
        "                advantage[t] = a_t\n",
        "            \"\"\"\n",
        "            advantage = torch.tensor(advantage).to(self.actor.device)\n",
        "\n",
        "            values = torch.tensor(values).to(self.actor.device)\n",
        "            start = time.time()\n",
        "            for batch in batches:  # 各バッチの進捗を表示\n",
        "                states = torch.tensor(state_arr[batch], dtype=torch.float).to(self.actor.device)\n",
        "                log_old_probs_dsc = torch.tensor(old_probs_dsc_arr[batch]).to(self.actor.device)\n",
        "                log_old_probs_cnt = torch.tensor(old_probs_cnt_arr[batch]).to(self.actor.device)\n",
        "                acts_dsc = torch.tensor(act_dsc_arr[batch]).to(self.actor.device)\n",
        "                acts_cnt = torch.tensor(act_cnt_arr[batch]).to(self.actor.device)\n",
        "\n",
        "                dist_dsc, dist_cnt = self.actor(states)\n",
        "\n",
        "                critic_value = self.critic(states)#0907\n",
        "                critic_value = torch.squeeze(critic_value)\n",
        "\n",
        "                log_new_probs_dsc = dist_dsc.log_prob(acts_dsc) #pi_new\n",
        "                log_new_probs_cnt = dist_cnt.log_prob(acts_cnt)\n",
        "\n",
        "                #log_new_probs = dist_dsc.log_prob(acts_dsc) + dist_cnt.log_prob(acts_cnt)\n",
        "                #print(\"log_old_probs_cnt.exp():\",log_old_probs_cnt.exp())\n",
        "                #print(\"log_new_probs_cnt.exp():\",log_new_probs_cnt.exp())\n",
        "                #print(\"log_old_probs_cnt:\",log_old_probs_cnt)\n",
        "                #print(\"log_new_probs_cnt\",log_new_probs_cnt)\n",
        "\n",
        "                prob_ratio_dsc = log_new_probs_dsc.exp()/log_old_probs_dsc.exp() #確率比\n",
        "                prob_ratio_cnt = log_new_probs_cnt.exp()/log_old_probs_cnt.exp()\n",
        "                #print(\"prob_ratio_dsc:\",prob_ratio_dsc)\n",
        "                #print(\"prob_ratio_cnt:\",prob_ratio_cnt)\n",
        "\n",
        "\n",
        "                weighted_probs_dsc = advantage[batch]*prob_ratio_dsc\n",
        "                weighted_clipped_probs_dsc = torch.clamp(prob_ratio_dsc, 1-self.policy_clip, 1+self.policy_clip)*advantage[batch]\n",
        "                actor_loss_dsc = -torch.min(weighted_probs_dsc, weighted_clipped_probs_dsc).mean()\n",
        "\n",
        "                weighted_probs_cnt = advantage[batch]*prob_ratio_cnt\n",
        "                weighted_clipped_probs_cnt = torch.clamp(prob_ratio_cnt, 1-self.policy_clip, 1+self.policy_clip)*advantage[batch]\n",
        "                actor_loss_cnt = -torch.min(weighted_probs_cnt, weighted_clipped_probs_cnt).mean()\n",
        "\n",
        "                returns = advantage[batch] + values[batch]\n",
        "                critic_loss = F.mse_loss(returns.float(),critic_value.float())\n",
        "                #critic_loss = critic_loss.float()\n",
        "                #print(actor_loss)\n",
        "                #print(critic_loss)\n",
        "                #print(\"#####\")\n",
        "                entropy_dsc = dist_dsc.entropy().sum(dim=0).mean()\n",
        "                entropy_cnt = dist_cnt.entropy().sum(dim=0).mean()\n",
        "                entropy = torch.clamp(entropy_dsc,min=0) + torch.clamp(entropy_cnt,min=0)\n",
        "                #entropy = torch.clamp(dist_dsc.entropy().mean(),min=0) + torch.clamp(dist_cnt.entropy().mean(), min=0.0)\n",
        "\n",
        "                total_loss_dsc = actor_loss_dsc #+ 0.01 * entoropy_dsc\n",
        "                total_loss_cnt = actor_loss_cnt #+ 0.01 * entoropy_cnt\n",
        "                total_loss = total_loss_dsc + total_loss_cnt + 0.5*critic_loss #+ 0.01*entropy\n",
        "\n",
        "                if episode >= threshold:\n",
        "                  print(\"FLAG\")\n",
        "                  self.actor.optimizer_discrete.zero_grad()\n",
        "                  total_loss_dsc.backward(retain_graph=True)\n",
        "                  self.actor.optimizer_discrete.step()\n",
        "\n",
        "                #if episode >= threshold:\n",
        "                  #print(\"FLAG\")\n",
        "                  self.actor.optimizer_continuous.zero_grad()\n",
        "                  total_loss_cnt.backward(retain_graph=True)\n",
        "                  self.actor.optimizer_continuous.step()\n",
        "\n",
        "                self.critic.optimizer.zero_grad()\n",
        "                critic_loss.backward()\n",
        "                self.critic.optimizer.step()\n",
        "\n",
        "                self.loss_history_detail.append(total_loss.item())\n",
        "\n",
        "                actor_loss_sum += actor_loss_dsc.item()+actor_loss_cnt.item()\n",
        "                critic_loss_sum += critic_loss.item()\n",
        "                entropy_sum += entropy.item()\n",
        "                kl_divergence_sum += torch.distributions.kl_divergence(Categorical(logits=log_old_probs_dsc+log_old_probs_cnt), Categorical(logits=log_new_probs_dsc+log_new_probs_cnt)).mean().item()\n",
        "\n",
        "                print(\"advantage[batch].size(),advantage[batch]:\",advantage[batch].size(),advantage[batch])\n",
        "\n",
        "        print(f'actor loss: {actor_loss_sum}, critic loss: {critic_loss_sum}, entropy: {entropy_sum}, KL divergence: {kl_divergence_sum}')\n",
        "        self.loss_history.append(np.mean(self.loss_history_detail[-self.n_epochs:]))\n",
        "        self.actor_loss_history.append(actor_loss_sum)\n",
        "        self.critic_loss_history.append(critic_loss_sum)\n",
        "        self.entropy_history.append(entropy_sum)\n",
        "        self.kl_divergence_history.append(kl_divergence_sum)\n",
        "            # Update sums\n",
        "        #self.actor.scheduler_actor.step()  # 学習率を更新\n",
        "        #self.critic.scheduler_critic.step()  # 学習率を更新\n",
        "        self.memory.clear_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l4PW7F3zTYPc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PkbRyHFHTYPc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7JV5KgBxTYPd"
      },
      "outputs": [],
      "source": [
        "#エージェントの初期化\n",
        "n_units = 2\n",
        "n_states = 5\n",
        "MAX_maintenance_time = 0\n",
        "#input_size = n_units * n_states + n_units * (MAX_maintenance_time) + 2 #MDPのため[残り時間]と[保全意思決定時]の2つの入力は入れない\n",
        "input_size = n_units*2 + 1 #flagを追加\n",
        "action_size = 2**n_units  # 行動数は2^3個\n",
        "batch_size = 512*4#512-5120\n",
        "interval = 24\n",
        "alpha_actor = 0.00003#ここを変更する0.003\n",
        "alpha_critic = 0.1#ここを変更する0.1\n",
        "n_epochs = 4\n",
        "policy_clip = 0.1\n",
        "beta=0.0005\n",
        "\n",
        "\n",
        "agent = Agent(n_units=n_units,\n",
        "              input_dims=input_size,\n",
        "              n_states=n_states,\n",
        "              MAX_maintenance_time=MAX_maintenance_time,\n",
        "              beta=beta,\n",
        "              interval=interval,\n",
        "              alpha_actor=alpha_actor,\n",
        "              alpha_critic=alpha_critic,\n",
        "              policy_clip=policy_clip,\n",
        "              batch_size=batch_size,\n",
        "              n_epochs=n_epochs)\n",
        "env = Environment()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observation0=[0,0,0,0,1]\n",
        "state0 = torch.tensor(np.array([observation0]),dtype=torch.float).to(agent.actor.device)\n",
        "dist_dsc0, dist_cnt0 = agent.actor(state0)\n",
        "value0 = agent.critic(state0)\n",
        "print(\"state:\", state0, \"dist_dsc.probs:\", dist_dsc0.probs, \"dist_cnt.mean:\",dist_cnt0.mean,\"dist_cnt.scale\", dist_cnt0.scale,\"value0:\",value0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV6_pfkGblJK",
        "outputId": "883f15ae-b0a9-4d43-e180-64a241c13620"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state: tensor([[0., 0., 0., 0., 1.]]) dist_dsc.probs: tensor([[0.0100, 0.0100, 0.0100, 0.9700]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[1.]], grad_fn=<ExpBackward0>) value0: tensor([[0.0933]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15IhPu1nTYPd",
        "outputId": "ebff2c57-e95d-4e81-b7c1-4bd8eaf6be1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-1ec0023f76a2>:242: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.load_total=float(dist_N.rvs(1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2500.0183, -5000.3467, -2499.9119,  ..., -4999.9883, -2498.7441,\n",
            "        -4999.4214])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-4.9999e+03, -1.5920e-01, -2.4999e+03,  ..., -5.0001e+03,\n",
            "        -4.9995e+03, -5.0001e+03])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-5.0001e+03, -5.0000e+03,  1.8686e-01,  ..., -4.9999e+03,\n",
            "        -5.0002e+03, -5.0000e+03])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-4999.6938, -5000.0518, -5000.0869,  ..., -5003.7305, -5000.2661,\n",
            "        -5000.0518])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-5000.0532, -4999.5298, -2499.9126,  ..., -4998.9727, -4999.9976,\n",
            "        -2499.9614])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-4.9998e+03, -5.0020e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
            "         8.0841e-02, -5.0000e+03])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-4999.9312, -2499.8213, -5000.0596,  ..., -2499.9829, -5000.1914,\n",
            "        -5000.1118])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-4.9999e+03, -1.6885e-01, -5.0001e+03,  ..., -5.0000e+03,\n",
            "        -2.4984e+03, -4.9998e+03])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-5000.0024, -2499.9346, -4999.9746,  ..., -5000.0513, -2500.0449,\n",
            "        -2499.8606])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-4998.9609, -5000.0801, -2499.9216,  ..., -4999.9102, -4999.9829,\n",
            "        -5000.0029])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-5.0000e+03, -4.9999e+03, -5.0003e+03,  ..., -2.4998e+03,\n",
            "         4.8299e-02, -5.0002e+03])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-4.9998e+03, -4.9999e+03, -4.9999e+03,  ...,  2.5083e-01,\n",
            "        -5.0000e+03, -2.4995e+03])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-5000.2900, -5000.1758, -5000.0449,  ..., -2499.9373, -5000.2524,\n",
            "        -5000.0576])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-4999.9688, -5000.0200, -5000.4604,  ..., -4999.9272, -4999.7485,\n",
            "        -5000.0957])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-4999.6802, -4999.9653, -2500.1089,  ..., -2499.3098, -5000.0542,\n",
            "        -2499.9207])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2499.2449, -2500.8701, -5000.0825,  ..., -4999.9609, -5000.1606,\n",
            "        -2500.0457])\n",
            "actor loss: 132743.36124539957, critic loss: 124293652.0, entropy: 58433.786376953125, KL divergence: 0.13246960311909456\n",
            "... saving models ...\n",
            "状態[155.5113724067923, 145.48945745481092, 1, 1, 1.0917500696097084], 離散行動：[1, 1], 連続行動：0.5681610479950905\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "0エピソード目の累積報酬：-424131.63446220686, 一つ保全の回数：7965, 二つ保全の回数：160, 三つ保全の回数：67, 違反回数：0,episode_reward_history：[-424131.63446220686]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-5111.5986, -2548.9165, -5004.8096,  ..., -4986.6016, -2493.2258,\n",
            "        -2505.9080])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-5008.6948, -4972.2568, -4982.1167,  ..., -5187.3423,   -24.2863,\n",
            "        -2520.2876])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-4980.1514, -1185.0045,    -8.8596,  ..., -2513.3159, -2487.2180,\n",
            "        -5083.8433])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-5613.0654, -5002.3501, -2497.0129,  ..., -4963.3159, -5014.1606,\n",
            "          -11.7867])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2524.1125, -5032.6641, -1455.8121,  ..., -2533.7791, -2545.7810,\n",
            "        -2488.5999])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1609.9636, -2509.7312, -4990.0737,  ..., -5012.2944,    -7.5173,\n",
            "        -5105.0488])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -11.1511, -2486.4060, -2564.8459,  ..., -4975.6572, -5060.0371,\n",
            "        -2601.3438])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2498.5564, -5050.4106, -2483.3564,  ...,   -57.5720, -5007.4175,\n",
            "        -5004.5332])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-5087.1616, -2491.7012, -5006.1553,  ..., -5068.4424, -5097.8511,\n",
            "        -4997.9097])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-4964.2158, -5040.7642, -2507.5833,  ..., -5876.3623, -2547.0535,\n",
            "        -2868.6511])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2506.5034, -3090.5303, -4980.9917,  ...,   -25.3527, -2525.8223,\n",
            "        -5013.2334])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -50.6700, -5001.5137, -2510.3657,  ...,    -8.7772, -5018.5850,\n",
            "        -2736.6084])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2501.7273, -2494.7131, -5017.0596,  ..., -4966.2979,  -887.7170,\n",
            "        -5031.5137])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-5002.2104, -5000.6338, -5020.9707,  ..., -5006.4727, -4963.5015,\n",
            "        -5099.3838])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-4976.3335, -4988.4214, -4995.1382,  ..., -5014.5718, -5002.0337,\n",
            "        -2560.6582])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2564.8459, -5005.5337, -5009.8042,  ..., -2486.9275, -2716.9480,\n",
            "        -1379.4575])\n",
            "actor loss: 118053.4560874348, critic loss: 123549932.0, entropy: 58859.206787109375, KL divergence: 0.05849393921152692\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[539.1650915014089, 266.0374376802575, 1, 1, 1.7813457942372533], 離散行動：[1, 1], 連続行動：0.6959567070007324\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "1エピソード目の累積報酬：-340464.372321981, 一つ保全の回数：7848, 二つ保全の回数：264, 三つ保全の回数：80, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-be54b0bca3e3>:206: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(self.checkpoint_file))\n",
            "<ipython-input-5-b57aabd33ec4>:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(self.checkpoint_file))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 221.8838, -166.7880,   66.5364,  ...,   64.1134,    9.8670,\n",
            "         -21.3954])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -47.8910, -1865.1173,   218.1962,  ...,     9.4666,    88.3094,\n",
            "          -11.0273])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 290.3557,  127.2238,  -69.5922,  ..., -628.7418,   12.1257,\n",
            "        -338.7152])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-154.4564,  269.7303,  -21.5044,  ...,  177.9340, -133.2285,\n",
            "        -933.2593])\n",
            "actor loss: 6135.795343424353, critic loss: 5183255.671875, entropy: 47283.605224609375, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[38.51433223333357, 55.66215010979666, 0, 0, 2.6578880874948396], 離散行動：[0, 0], 連続行動：0.8201333582401276\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "31エピソード目の累積報酬：-40793.60409964634, 一つ保全の回数：6460, 二つ保全の回数：1212, 三つ保全の回数：520, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-880.3787, -342.3170,  -69.8339,  ...,  -61.8098, -111.9786,\n",
            "        -690.0628])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-151.2561,  104.2316,  261.6094,  ...,   97.8197, -139.4204,\n",
            "        -257.7610])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -8.4819,  -96.8574,  143.9405,  ..., -135.6896,   90.1039,\n",
            "          33.5357])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  69.0777, -255.6978,   51.3812,  ...,  111.8317, -367.9714,\n",
            "        -101.3372])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 678.3475, -835.1779, -161.6003,  ..., -217.2532,   36.8892,\n",
            "        -240.6230])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 5.4228e+01,  7.6576e+02,  3.5068e+01,  ...,  5.5474e+01,\n",
            "        -3.9683e-01,  3.7721e+02])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  435.6737,   -11.8642,  -155.0356,  ...,    69.4187,   332.2126,\n",
            "        -2171.2822])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 419.7675,  116.5577,   91.2151,  ...,  126.1379, -211.7091,\n",
            "        -191.3036])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 244.1918,  120.4986,  211.8713,  ...,  200.8334,  123.9855,\n",
            "        -192.4442])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -104.4416,  -384.8382,  -628.3693,  ...,  -213.5667, -1846.8171,\n",
            "          171.8900])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1920.4102,   555.3859,    12.4871,  ...,  -207.6851,  -285.8244,\n",
            "           47.9129])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-162.6866,    0.6419, -517.8470,  ...,  -84.1640,  -85.6704,\n",
            "         154.5524])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1.3304e+00, -5.6259e+02, -9.3274e-01,  ..., -6.3291e+02,\n",
            "        -2.1855e+03,  1.8167e+02])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-350.4456,   43.0832, -169.3294,  ..., -195.9482,  127.3111,\n",
            "         148.5513])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-705.7984,   55.5035,  319.9360,  ..., -100.4980,  256.8096,\n",
            "        -281.1581])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -10.8432,   96.6554,  -76.0631,  ..., -187.1067, -557.9133,\n",
            "        -301.6988])\n",
            "actor loss: 6334.557107519431, critic loss: 5946952.40625, entropy: 43216.772216796875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[1.542609020195342, 27.345727501548147, 0, 0, 2.0363002452001275], 離散行動：[1, 1], 連続行動：0.4510723389685154\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "32エピソード目の累積報酬：-30738.497974633683, 一つ保全の回数：6474, 二つ保全の回数：1208, 三つ保全の回数：510, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 48.0652, -35.9560, 173.7393,  ..., 586.8655, -48.1538, -73.0313])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  116.7739,   274.2868,  -383.1140,  ..., -1706.2538,   -77.2894,\n",
            "          486.8986])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-549.0138,    2.1827,  142.0866,  ...,   67.9522, -130.2255,\n",
            "        -122.0957])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -275.7585,  -620.0024,  -236.2959,  ...,   -39.6147,  -165.8617,\n",
            "        -1850.3098])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-275.1791, -852.0470,  -58.6744,  ..., -272.0254,   34.7841,\n",
            "          33.6962])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 639.8125,  654.8884, -125.9306,  ..., -191.9704,  334.8585,\n",
            "        -847.6597])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2091.2305,   -97.6562,    -7.7737,  ..., -2799.1580,   259.7279,\n",
            "        -1792.9591])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-408.3900,   50.4152,   90.8684,  ..., -123.5426, -420.5590,\n",
            "        -218.3724])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-218.9209,  137.1197, -204.1981,  ...,    2.8125,   87.1589,\n",
            "          27.2388])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 264.8845, -415.2003, -958.7596,  ...,   89.4096,   36.5513,\n",
            "          18.3485])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   3.4977,   62.7651,  172.8880,  ..., -225.9784,  137.6727,\n",
            "        -101.1945])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-502.1928, -210.7621, -523.0395,  ...,  283.7741, -549.9708,\n",
            "         115.0546])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  62.0718, -108.5536, -190.6391,  ...,   20.8068,  145.1945,\n",
            "        -199.9726])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -28.4273,   82.7753, -787.5596,  ...,   94.6248,  100.6387,\n",
            "          42.6437])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-627.7227,   -5.8129, 1049.4912,  ..., -192.4356, -100.7231,\n",
            "        -105.1164])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -40.6329,  -140.7798,   -10.2135,  ...,   -96.1575, -2428.7849,\n",
            "         -502.0173])\n",
            "actor loss: 6095.521778769101, critic loss: 5673841.453125, entropy: 40519.230224609375, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0, 3.7632087595586023, 0, 0, 1.608430142733015], 離散行動：[1, 1], 連続行動：0.6273599714040756\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "33エピソード目の累積報酬：-41515.47372239095, 一つ保全の回数：6493, 二つ保全の回数：1197, 三つ保全の回数：502, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-535.2841,   70.9386,   86.7555,  ..., -229.2327, -225.0369,\n",
            "          73.1415])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-114.6369, -606.3619, -768.1307,  ..., -143.3992, -397.1915,\n",
            "        -145.0777])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 199.4305,   43.1196, -169.5791,  ...,  -21.7032,  117.8660,\n",
            "        -850.9204])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-338.1150, -759.5245,  116.7175,  ...,  -92.7781, -126.3542,\n",
            "        -215.4695])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -91.7982, -756.2559, -280.1649,  ..., -302.5849,  123.0746,\n",
            "         226.4864])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-522.9421,  -63.7270, -503.5940,  ...,  103.7237, -118.0942,\n",
            "         102.3071])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -158.8599,  -568.1743,    94.9827,  ...,  -706.0797,  -125.1290,\n",
            "        -1079.9312])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   68.9024,  -256.7330,  -269.1826,  ..., -2767.7634,   330.8561,\n",
            "          357.9664])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 201.8676, -397.4781,  -12.4940,  ...,  189.8380,  120.9974,\n",
            "        -385.6023])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-152.8512,  113.4608, -131.2844,  ..., -685.2432,  538.5584,\n",
            "          63.9279])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-274.8624, -471.0983,  177.9089,  ...,  200.3336, -228.5074,\n",
            "        -169.0645])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 223.0611,  -99.9696, -225.8538,  ..., -787.0414,  216.9722,\n",
            "        -124.1611])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  48.0817,  103.1383, -164.5987,  ...,  -61.4534,  -14.8703,\n",
            "         -10.0099])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -70.8860,  -60.9877, -804.0690,  ...,  201.7920,   -6.3166,\n",
            "         -11.7188])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-359.5689, -267.9646, -658.0922,  ..., -105.9494, -366.0905,\n",
            "        -484.1136])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([333.6323, 138.2241, -61.2181,  ..., -56.8322,   7.1855, 545.7010])\n",
            "actor loss: 5971.329934654477, critic loss: 5903394.84375, entropy: 41900.748291015625, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[14.929101516973768, 0.1918350051078908, 0, 0, 1.3274663074411703], 離散行動：[1, 1], 連続行動：0.42872096598148346\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "34エピソード目の累積報酬：-24607.603346491414, 一つ保全の回数：6521, 二つ保全の回数：1156, 三つ保全の回数：515, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-85.2971,  89.8263,  30.8314,  ..., 286.8751, 177.3871,  88.6454])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-172.4780,  346.1110, -563.0384,  ...,  -61.8315, -135.5205,\n",
            "        -224.2984])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1967.9509,   175.2799,  -369.3229,  ...,    77.2517,   -74.7626,\n",
            "         -590.7583])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-197.6874, -105.6702,    6.3266,  ...,  148.3306,  187.0931,\n",
            "          67.0840])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -429.5175,    25.3932,  -351.0842,  ...,  -198.9244,  -238.3350,\n",
            "        -1163.1375])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2643.4067,   188.7808,   313.3392,  ..., -2549.5518,   153.9394,\n",
            "        -2539.2104])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 181.7791,  281.2361, -424.3594,  ...,  276.8878,  239.2606,\n",
            "         -79.9090])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-296.9820, -329.7437,  145.7339,  ...,   30.2027,  116.1013,\n",
            "          10.2400])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 271.8294, -103.1564, -319.2639,  ..., -611.2578,  -17.4110,\n",
            "          79.1030])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([1089.6200, -316.2640, -179.4532,  ...,   86.9762,   44.3376,\n",
            "         476.7245])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -118.5342, -2112.8342,  1314.8373,  ...,  -116.0615,    33.3792,\n",
            "         -567.0549])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -159.8825,    74.6574,  -279.0226,  ..., -1166.7352,  -324.5058,\n",
            "         -641.4416])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-226.6148, -373.7399, -252.4443,  ...,  167.2070,  -48.1527,\n",
            "         261.2952])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 124.2757, 1006.3794,  -74.7626,  ...,  147.7199, -705.5764,\n",
            "          52.9518])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  60.7597,    4.7601, -116.4422,  ...,  125.5703,   -7.2333,\n",
            "         163.5226])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  85.5048, -116.6410, -131.2816,  ...,   50.5637,  -81.0911,\n",
            "        -146.5664])\n",
            "actor loss: 5714.562929625883, critic loss: 7139783.21875, entropy: 42117.4501953125, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[7.1444613352607576, 7.760478290351127, 0, 0, 1.4961753607234591], 離散行動：[1, 1], 連続行動：0.6000096350908279\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "35エピソード目の累積報酬：-38135.681688042074, 一つ保全の回数：6514, 二つ保全の回数：1174, 三つ保全の回数：504, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  42.8720,  611.0400, -355.3760,  ..., -205.8690, -322.5268,\n",
            "        -838.5453])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -48.1227,   20.9497, -235.5312,  ...,   61.9716,  131.7515,\n",
            "        -344.3633])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -456.7255,   772.4706, -1577.7627,  ...,  -182.6200,    69.1189,\n",
            "          442.1372])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 224.2678,  760.0013,   92.9965,  ..., -227.2791, -191.9264,\n",
            "          93.2363])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-156.6857,  -37.7606, -292.9268,  ..., -510.0500,   21.9199,\n",
            "         384.1384])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-757.5969,   92.4596, -217.7483,  ...,  200.4319, -359.8454,\n",
            "         238.0668])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -36.1240, -267.7964,   94.7040,  ...,  120.8172,  -16.9072,\n",
            "         -17.6656])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -145.8043,  -894.3526,  -121.6261,  ...,  -349.8725, -2609.2385,\n",
            "          212.2324])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-211.1994,  -20.0676,  -70.7218,  ...,  147.9388, -148.5438,\n",
            "         -95.2059])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-477.2869, -130.7352, -204.0930,  ..., -329.0141,  -55.1479,\n",
            "        -414.4789])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  92.4971, -278.8398,  199.7433,  ...,  321.1074, -362.1008,\n",
            "        -330.7057])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 382.5356,  170.6661, -190.7658,  ...,   61.4795,    3.8747,\n",
            "         335.8315])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2293.4360,  -121.0982,   -84.5153,  ...,  -325.3563,   192.4210,\n",
            "         -115.6292])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -53.0626, -258.6136,  171.0603,  ..., -220.7003,  295.6219,\n",
            "        -248.3436])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -24.7304, -2175.5874,   214.5816,  ...,  -106.9785, -1013.2241,\n",
            "         -144.6725])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-429.5872,  -82.9766,   36.8679,  ...,  136.3527,   65.0220,\n",
            "         -24.0005])\n",
            "actor loss: 5877.282443120785, critic loss: 6892089.375, entropy: 40961.978271484375, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0.4913865885780771, 60.72448077455837, 0, 0, 1.550579633891839], 離散行動：[1, 1], 連続行動：0.49452976137399673\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "36エピソード目の累積報酬：-32355.02832136693, 一つ保全の回数：6479, 二つ保全の回数：1201, 三つ保全の回数：512, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  170.6158, -2095.6033,    74.9536,  ...,   251.1529,   -34.2382,\n",
            "         -717.0436])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  69.0387, -606.0532,  -42.8210,  ...,    5.4111, -136.8694,\n",
            "          51.1202])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([1011.5549, -379.1025,  -84.4736,  ...,   84.8541,  118.1212,\n",
            "        -504.4582])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-205.9652,  152.0397,  247.7385,  ...,  504.2049,   69.4570,\n",
            "         544.4633])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-163.7103,   34.3375, -112.7943,  ...,  -12.6336, -206.1136,\n",
            "        -208.7106])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-846.3387, -257.6807,   88.0904,  ..., -206.5626,  202.4249,\n",
            "         116.1145])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-531.8165, -247.9797, -186.0457,  ...,  217.4516,  239.4581,\n",
            "         -88.1458])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-443.5233, -537.5016,  627.7142,  ..., -160.2234, -222.5099,\n",
            "          60.5214])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   18.9983,   -25.8118, -2059.7893,  ...,   469.8499,  -335.3924,\n",
            "         -107.3521])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-451.8380, -288.1341, -194.6710,  ...,  -48.6259,  200.2738,\n",
            "          64.0422])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-211.7755, -145.6810,  223.1901,  ..., -187.1501,  401.7380,\n",
            "         295.9751])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -56.8219,  -473.2528,  -237.2950,  ...,    42.8394,   428.8712,\n",
            "        -2435.4629])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 382.2240, -620.3990,  240.3740,  ...,  -17.8093,  449.4624,\n",
            "          85.6188])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 110.2613,  -83.6278, -468.4388,  ..., -146.6994, -821.8469,\n",
            "         -55.3192])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-496.7884,  -92.3144, -222.2703,  ...,  306.3685, -201.6019,\n",
            "        -130.5378])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -893.8578,  -444.4543,  -517.7966,  ...,   -69.3106, -2113.2388,\n",
            "        -1112.1680])\n",
            "actor loss: 5398.287270546492, critic loss: 6148264.09375, entropy: 40904.8447265625, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0, 15.364635180767927, 0, 0, 1.7721676393148138], 離散行動：[1, 1], 連続行動：0.46709514036774635\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "37エピソード目の累積報酬：-36647.148505796664, 一つ保全の回数：6490, 二つ保全の回数：1184, 三つ保全の回数：518, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-191.5700,  353.8847, -165.0297,  ..., -365.3875,  454.8967,\n",
            "        -556.4833])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -22.9314,   -3.5479,   -2.5059,  ..., -187.2574,  236.7202,\n",
            "         -93.3243])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -96.5370,    7.1629,   43.1030,  ...,  140.7619, -133.4881,\n",
            "        -305.9108])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-589.9919, -307.7657, -339.1621,  ..., -780.6876, -234.0151,\n",
            "        -192.3472])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2641.9641,   -49.2108,   197.9999,  ...,   168.7642,  -124.6594,\n",
            "         -151.3675])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-155.7611, -396.7435,  -61.3708,  ...,  243.5718, -580.9026,\n",
            "        -160.1501])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 123.8497,  353.8847, -192.6147,  ...,  -66.4916,  -48.1249,\n",
            "         -38.2752])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -186.3786,  -880.5803,   277.4059,  ..., -2394.2356,  -154.1007,\n",
            "         -116.9216])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 256.6837, -471.2060,  272.6485,  ...,   -3.4018, -596.4804,\n",
            "         -83.0166])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-118.0125,  115.2553, -157.6267,  ...,  -80.3446,  277.4059,\n",
            "         141.5460])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([350.1672, -97.4864, 241.8297,  ..., 252.7197, 239.2702, 151.3113])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -32.5590,  -17.7659, -227.0291,  ..., -679.9966, -170.6877,\n",
            "        -946.7950])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  77.6095,  -87.6165,  140.7619,  ..., -226.3556, -688.3469,\n",
            "         148.3836])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -494.9689,  -278.5477, -2254.3699,  ..., -2656.2771, -1587.1985,\n",
            "          327.8190])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  32.7938,   69.5694, -143.6609,  ..., -212.0797, -187.5589,\n",
            "         178.6815])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -68.5823,   69.0487, -725.4035,  ..., -280.0121,   93.0640,\n",
            "         188.5107])\n",
            "actor loss: 5298.485092663822, critic loss: 4456890.296875, entropy: 41999.949462890625, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[24.75651950282196, 43.13584585942989, 0, 0, 1.790490264918001], 離散行動：[1, 1], 連続行動：-0.04290640354156494\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "38エピソード目の累積報酬：-34290.15603842583, 一つ保全の回数：6432, 二つ保全の回数：1261, 三つ保全の回数：499, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-295.8495,   30.0010, -980.3116,  ...,  129.9169, -265.9454,\n",
            "         227.5919])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-574.7860,  -90.8717,    9.4862,  ..., -624.7631, -196.9285,\n",
            "         135.0014])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-951.6941, -607.5019,  177.4043,  ...,  828.0447, -790.4299,\n",
            "           3.3773])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 185.5901,   25.0314,  399.1445,  ..., -334.0542, -254.5835,\n",
            "         242.7512])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 442.3575,   98.2954, -487.1672,  ...,    5.1594,  276.2323,\n",
            "         -72.9731])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -95.7336, -1002.4255,     9.0329,  ...,  -488.2947,    93.3870,\n",
            "          161.3059])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-317.3479, -373.9599,  144.1395,  ..., -370.7662, -864.5939,\n",
            "        -444.9263])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   88.5115,  -144.6065,  -384.3878,  ...,   275.9726, -1225.9738,\n",
            "        -1110.3746])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -758.3844, -2183.2417,   -89.2949,  ...,  -271.0192,   212.5188,\n",
            "          173.2160])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 175.0705, -289.1282,  -36.5644,  ..., -239.7102,  120.6024,\n",
            "        -252.3757])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  18.8719,   67.0960, -575.9713,  ...,  -58.2753, -199.0028,\n",
            "         247.3202])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-565.3724, -972.3536,  109.2855,  ...,  148.6378, -260.0273,\n",
            "        -121.3940])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 329.7288, -667.7565,   88.1456,  ...,   46.6497,  -81.2580,\n",
            "         -20.6073])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  114.1178,  -327.5461,  -251.3936,  ...,  -100.2872, -1563.0083,\n",
            "         -304.5503])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-571.4413,  104.8554, -243.4688,  ..., -408.8934,  155.5349,\n",
            "           7.3844])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -40.6617,  -855.2383,  -138.1648,  ...,  -346.7610,   104.1516,\n",
            "        -1559.3728])\n",
            "actor loss: 5049.716062165267, critic loss: 3979600.328125, entropy: 43465.92138671875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0, 11.663069333830652, 0, 0, 2.1397048196419255], 離散行動：[1, 1], 連続行動：0.7060790956020355\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "39エピソード目の累積報酬：-31712.777109955623, 一つ保全の回数：6442, 二つ保全の回数：1249, 三つ保全の回数：501, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  90.4936,   -1.7295, -111.1249,  ..., -213.5706,  105.1299,\n",
            "         -70.2408])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-664.0471,   49.9520,    1.4725,  ...,   31.3144,  -14.1358,\n",
            "         -13.3007])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 189.5290, -105.1207,  179.6270,  ...,  123.5751,   69.1760,\n",
            "         108.2576])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  74.9713,  -84.3696,  319.7012,  ...,   27.8704,  -89.6936,\n",
            "        -647.8685])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2181.6384,    67.1014,    28.8275,  ...,  -558.5938,  -163.3530,\n",
            "          -54.7203])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2029.9088,     5.8672,  -376.9513,  ...,  -202.5929,   431.5325,\n",
            "         -854.6903])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-240.4572,  107.4878,   94.8960,  ..., -127.4070,  158.2989,\n",
            "         175.2514])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   41.5649, -2587.5369,    47.1285,  ...,   -94.4707,   141.0362,\n",
            "         -372.7801])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-353.6206, -682.7273,   45.3895,  ...,   37.5361,  196.2392,\n",
            "          79.3210])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-18.7280, 151.2655, -84.4205,  ..., 298.9097, 703.7207, -22.7320])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -30.4053,  -38.6437,   30.2497,  ...,   66.0837, -653.9849,\n",
            "        -529.6345])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -148.8207,   -87.1399,  -330.2599,  ...,   -51.5274, -2269.3372,\n",
            "         -423.5503])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -103.5825,  -122.9402,  -450.1995,  ..., -1890.0094,  -342.1607,\n",
            "         -108.0488])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-630.9006,   16.3175,   29.9320,  ...,  321.7971, -504.0307,\n",
            "         142.9950])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -70.4714,  -75.7822,  168.5484,  ...,  -52.1552, -542.2661,\n",
            "         -82.8035])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  144.0769,  -134.6111,   -32.5206,  ..., -1770.9091,   -61.9653,\n",
            "            9.3464])\n",
            "actor loss: 5264.490963952418, critic loss: 4625066.15625, entropy: 43842.5029296875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0, 8.400174949129076, 0, 0, 2.4049213685769537], 離散行動：[1, 1], 連続行動：0.7026189863681793\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "40エピソード目の累積報酬：-32592.191967588562, 一つ保全の回数：6416, 二つ保全の回数：1259, 三つ保全の回数：517, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -288.5845,  -217.3526,   393.0614,  ...,   -65.2946, -1198.0608,\n",
            "          -17.6836])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 119.7296, -428.6632, -207.6487,  ...,  123.6774, -169.0630,\n",
            "        -229.7679])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 257.9052, -672.7142,   73.4891,  ...,   10.8388,   -7.7444,\n",
            "        1035.5153])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 193.7868, -793.6893, -249.6227,  ...,   23.2913, -157.7336,\n",
            "        -788.4132])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-23.2730,  37.0836, 162.3356,  ...,  91.6854, 119.0702, 100.9990])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-127.4529,   17.6805, -132.9632,  ...,  139.6196,   61.9527,\n",
            "        -167.1759])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  185.8985,    83.8961,  -265.5588,  ...,  -607.8462, -1972.4583,\n",
            "           89.9100])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 194.4019, -225.5154, -231.8272,  ..., -139.7907, -688.2455,\n",
            "         276.4527])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -180.7448, -2517.9829,    70.0588,  ...,  -493.7897, -1996.1796,\n",
            "           60.7446])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -257.3222, -2178.7737,  -414.9326,  ...,   133.9450,    65.1493,\n",
            "         -126.7586])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-152.6184,  -34.1404,  -87.0400,  ..., -172.3081,  409.7854,\n",
            "         -85.2016])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  95.1862,  157.9085,  -94.1967,  ..., -741.3714, -171.7903,\n",
            "           3.2024])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   1.9656,  -22.8848, -142.4387,  ..., -226.2232, -211.9520,\n",
            "        -179.3583])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -71.0183, -795.0695, -283.7541,  ...,  -38.7709, -467.1085,\n",
            "          42.2487])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -6.4037,  315.6123, -163.5441,  ...,  214.3022, -158.2837,\n",
            "         139.3624])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-322.3232,  190.8025, 1058.7629,  ...,  100.2483, -276.3670,\n",
            "        -397.1752])\n",
            "actor loss: 4980.482228616704, critic loss: 4844925.828125, entropy: 41816.737060546875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[25.921232714529108, 79.78777782151462, 0, 0, 2.2972399865113537], 離散行動：[1, 1], 連続行動：0.6725080460309982\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "41エピソード目の累積報酬：-24698.39955578173, 一つ保全の回数：6457, 二つ保全の回数：1245, 三つ保全の回数：490, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-138.5198,   67.4062,  176.9552,  ...,  285.7533,  129.8240,\n",
            "         238.6916])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  52.8292,  -54.6942,  136.5503,  ..., -584.1961,   53.4449,\n",
            "         444.4364])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   44.9601,  -487.7112,    57.5482,  ..., -1531.0112,  -553.6129,\n",
            "         -165.4256])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-234.5314,  -13.4259,   39.1843,  ..., -549.9284,  644.9900,\n",
            "        -272.4424])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-305.1002,  204.0494,   61.1213,  ..., -250.4770,  135.5769,\n",
            "          77.0268])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  33.8567,  -14.9433,   23.5274,  ..., -131.4269, -893.2894,\n",
            "        -331.0945])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -75.4956, -215.9432,  115.4851,  ...,  241.9742,   67.8084,\n",
            "        -258.0339])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 156.0644,  139.3687, -287.2614,  ..., -251.1932,    6.4614,\n",
            "         173.6620])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -46.0062,  -53.8594,  -54.0851,  ..., -311.1914, -303.8072,\n",
            "         147.6570])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-593.0457,  168.0221,  115.4464,  ...,  -86.9064,  171.3603,\n",
            "         320.4166])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2063.0503,   137.9810,    80.0114,  ..., -2122.5044,  -167.9081,\n",
            "          -32.8788])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 107.6717,   -9.3302,   73.3652,  ...,   37.7289, -116.1437,\n",
            "          17.3777])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 125.1861,  245.1698,  -60.4404,  ...,   90.9316, -138.6597,\n",
            "          24.4039])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-313.4991,   57.0058,   49.1896,  ...,  197.2992,  -13.8668,\n",
            "        -257.4349])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -26.8417,  -48.2812,   99.2162,  ...,  343.4014, -688.7039,\n",
            "         -72.4266])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   56.8688,   -27.1620,    36.4778,  ..., -1133.8091,   -41.2256,\n",
            "          -63.1424])\n",
            "actor loss: 4564.946656838649, critic loss: 4407677.59375, entropy: 39480.651123046875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[13.695608193317154, 0, 0, 0, 1.2606850459420929], 離散行動：[1, 1], 連続行動：0.7133035659790039\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "42エピソード目の累積報酬：-24344.87882615109, 一つ保全の回数：6470, 二つ保全の回数：1260, 三つ保全の回数：462, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   61.6040,  -176.3514, -1928.9235,  ...,    85.2248,   130.5709,\n",
            "         -310.8908])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-240.5041,  -50.1144,  167.5715,  ...,  262.0325, -650.1153,\n",
            "         110.9202])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  212.1256, -2184.0303,  -385.9063,  ...,  -212.0183,   385.1512,\n",
            "         -122.1713])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 714.0330, -225.3323,  114.3512,  ..., -278.8291,  505.5155,\n",
            "          25.6649])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  146.2344,    -6.1490,   104.7156,  ...,  -580.3436, -2007.4908,\n",
            "         -327.0440])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  207.3560,   210.0487, -2111.1777,  ...,  -250.3958,  -657.3165,\n",
            "          -56.6394])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 229.3963, -171.3881, -633.6740,  ...,    8.8865,  -31.5553,\n",
            "         253.3248])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  328.1295,  -665.0620, -1353.8126,  ...,   201.1581,   -77.6576,\n",
            "          -30.9945])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -345.6578,   -16.4786,  -343.4605,  ...,   439.4646, -2165.6790,\n",
            "         -173.0288])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 155.7878,  205.1974,   36.3494,  ...,  375.6738,  398.9041,\n",
            "        -355.9669])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-398.6661,  -48.6712, -162.3315,  ...,  114.8049,  152.3036,\n",
            "         181.3148])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -30.3691,  471.4273,  -58.5538,  ...,  359.5088, -217.1261,\n",
            "          24.0868])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  69.4840,  807.4924, -372.0826,  ..., -600.6263, -397.7404,\n",
            "        -880.9807])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-277.5214, -132.5235, -215.5146,  ...,  -76.1537,  132.6484,\n",
            "        -435.0720])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 241.6644, -141.9502,   27.9935,  ...,  -50.9250,   14.2215,\n",
            "         380.8398])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-227.9545, -599.0843, -146.3325,  ..., -189.0439,  190.2398,\n",
            "        -407.7401])\n",
            "actor loss: 4654.05251941736, critic loss: 4442311.203125, entropy: 38729.38671875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[65.50797849055739, 2.284078415639695, 0, 0, 1.7170445190503218], 離散行動：[0, 0], 連続行動：0.42091014981269836\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "43エピソード目の累積報酬：-31222.72346644917, 一つ保全の回数：6490, 二つ保全の回数：1238, 三つ保全の回数：464, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 817.4866,  335.0544,  -52.1139,  ...,   30.2642, -144.1093,\n",
            "         -28.1437])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([    3.7592,    30.8798,   -23.6688,  ...,    26.4434,  -215.8306,\n",
            "        -1718.2411])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 170.0162, -137.7911,  103.5035,  ...,  655.8183, -110.7059,\n",
            "        -358.7194])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1304.7140,   107.7695,  -790.4894,  ...,    63.4541,   -98.2726,\n",
            "         -286.0605])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-361.8768,   15.0063,  117.9859,  ..., -105.0295, -953.8405,\n",
            "          50.5061])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 246.2281,   38.4899,  378.8024,  ...,  393.8933, -148.8314,\n",
            "        -342.0253])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -65.1879, -399.0751,  -55.1630,  ...,  -92.6838,  -95.0721,\n",
            "         108.7779])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 2.2401e+01, -8.7464e+01,  7.8897e+01,  ...,  7.8193e-02,\n",
            "         5.0284e+02,  2.0376e+02])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-494.9822,  -51.1012, -519.7354,  ...,  -58.3407, -225.5020,\n",
            "         261.1607])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 119.4257, -175.3898,  102.4478,  ...,  217.2059, -463.9026,\n",
            "         -81.6951])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   91.1832, -2418.6460,   291.4281,  ...,  -392.8213,   -84.4413,\n",
            "          127.1575])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -74.7149, -413.2419,  -89.0072,  ...,  457.0222, -103.1361,\n",
            "         215.4861])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1024.9922,   -35.3256,  -375.1143,  ...,    83.6796,    22.7866,\n",
            "           12.5921])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-394.9614,  157.3472,  259.8277,  ...,  -12.5624,   20.2234,\n",
            "         253.8826])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -8.7664, -230.9929, -176.5327,  ...,  -13.7864,   42.5891,\n",
            "        -101.7956])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-210.1052, -606.3445, -187.3839,  ...,  -61.9349,  126.1744,\n",
            "        -143.5527])\n",
            "actor loss: 4335.278458975266, critic loss: 3624125.3125, entropy: 38236.83837890625, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[31.57257312932391, 1.0572762114678855, 0, 0, 1.2583404287031974], 離散行動：[1, 1], 連続行動：0.16142702102661133\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "44エピソード目の累積報酬：-27799.181043978075, 一つ保全の回数：6471, 二つ保全の回数：1237, 三つ保全の回数：484, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -69.0460, -343.6801,   24.2765,  ..., -110.4670,  124.0206,\n",
            "          16.5937])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 112.5448,  227.5771, -164.7432,  ..., -403.7458,   53.2979,\n",
            "          32.9326])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-684.7993, -807.9154, -172.3284,  ...,   83.4895,  -27.2871,\n",
            "         -47.2065])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -49.0935, -683.7504, -882.6302,  ..., -937.3493,   84.2277,\n",
            "         -72.7166])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -278.4457,  -270.7037,   144.1163,  ..., -1976.8149,  -344.3613,\n",
            "          -46.6453])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  41.5188, -346.3615, -329.1856,  ...,  -82.9608,   83.0207,\n",
            "         -56.8289])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-184.0584,  -77.5743, -300.7811,  ...,   62.1127,  164.0659,\n",
            "          68.1241])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 650.3671, -312.4078, -573.0327,  ...,  -10.3955,  111.1523,\n",
            "          64.4807])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   20.7127,   180.5322,    77.8359,  ..., -1216.3143,   148.2979,\n",
            "          -82.0201])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 3.7168e+02, -4.4031e+02, -8.3691e+02,  ...,  6.0383e+00,\n",
            "         1.0230e+02, -3.4203e-01])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -120.3303,    44.0312,    86.4677,  ...,   296.4221,   150.9908,\n",
            "        -2181.8853])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-208.1412, -155.8541,  132.6054,  ...,  -56.4106,   58.6380,\n",
            "          94.6118])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -73.2522,    41.2805, -1726.3765,  ...,  -127.2354,    -6.6561,\n",
            "          218.7474])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -93.6075,  -507.4694,  -806.5043,  ...,  -112.6879, -1931.4451,\n",
            "          -93.3755])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -91.2438,  -47.1577, -403.2776,  ..., -103.6436,  183.3636,\n",
            "        -118.0778])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([1034.4812, -830.9905, -226.3701,  ...,  -64.9190,   50.4668,\n",
            "          50.0167])\n",
            "actor loss: 4304.811301641209, critic loss: 3544191.375, entropy: 38495.017578125, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[154.11626435304078, 21.951654385204456, 1, 0, 1.5970783053179294], 離散行動：[0, 1], 連続行動：0.4930615979246795\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "45エピソード目の累積報酬：-35677.4076327358, 一つ保全の回数：6450, 二つ保全の回数：1289, 三つ保全の回数：453, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 309.2467, -457.2209, -140.4493,  ..., -137.8709, -150.2193,\n",
            "        -310.1274])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -130.8141,    63.8767,   -31.1930,  ...,   417.3727, -2432.2725,\n",
            "         -244.8466])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -332.9167,   175.1468,  -254.7193,  ..., -1052.9032,   477.1908,\n",
            "          164.0141])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 185.8043, -102.1667,   22.8838,  ..., -109.6181,  122.5008,\n",
            "         186.7175])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -96.1351, -463.6433, -901.1461,  ...,  288.9229,   57.3909,\n",
            "          89.6795])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  57.9384,    0.7178, -402.2128,  ..., -158.2913,   89.5836,\n",
            "         114.5982])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-393.3439, -538.2770,  190.9487,  ..., -221.7281, -177.0681,\n",
            "         -25.6487])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  43.4662, -213.8776, -897.4174,  ...,   94.8947, -293.9010,\n",
            "         -18.5766])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  36.2202, -932.5305,  191.3138,  ...,  -11.4209, -131.7242,\n",
            "        -370.0063])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 177.0486, -112.5722,   66.5130,  ...,   46.4644,  169.8677,\n",
            "        -559.2161])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 142.2417,   79.0260,  112.1777,  ...,  417.4686, -137.6465,\n",
            "          55.6684])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   6.4162,  -27.3897, -158.4502,  ...,   45.1427,   61.6250,\n",
            "         446.3335])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   9.3487, -284.4895,  241.3804,  ..., -302.4420,  -60.1456,\n",
            "        -162.9769])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1349.6117,   377.5742,    20.2019,  ...,  -108.6057,  -241.4967,\n",
            "           82.3275])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-293.2640,   62.6751,  152.2548,  ..., -162.8501, -168.2620,\n",
            "         144.6886])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-370.0063, -533.7539,   54.9541,  ..., -171.2377,   51.0621,\n",
            "        -536.4045])\n",
            "actor loss: 4283.014603267931, critic loss: 3857347.515625, entropy: 36868.26220703125, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0, 6.895772277308165, 0, 0, 1.4340020122939554], 離散行動：[1, 1], 連続行動：0.30670347809791565\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "46エピソード目の累積報酬：-26795.163735319074, 一つ保全の回数：6428, 二つ保全の回数：1263, 三つ保全の回数：501, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 427.0832, -907.7350,  129.3038,  ...,  -24.3055,    8.5186,\n",
            "        -558.4470])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-126.0521,  197.5511,  117.1594,  ...,  -46.3897,  181.6971,\n",
            "          99.9143])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1874.0188,    83.5744,  -133.3073,  ...,  -121.3277,   -12.5846,\n",
            "        -1440.4846])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-725.5897, -289.3167,   19.0683,  ..., -269.0681,  241.9577,\n",
            "          98.2719])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  26.5910,   81.4016, -277.9073,  ...,   13.7686,   92.3257,\n",
            "        -370.0071])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 94.0262, -88.7455, 349.7373,  ..., 335.2903, 369.1267, -46.3520])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   2.6248,  -68.3537, -308.5296,  ..., -218.6576,   86.8483,\n",
            "        -138.8500])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-518.3001, -401.1009, -212.4703,  ..., -116.5963, -250.3505,\n",
            "          87.0118])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 108.0511, -218.0250,  -85.2964,  ...,  -22.1904, -157.0709,\n",
            "          94.3138])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-296.4775,   99.7919, -828.8113,  ..., -176.1263,  156.4473,\n",
            "          78.8697])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -40.2075, -813.4051,  270.8258,  ...,  -31.5763,  -63.8355,\n",
            "         -93.6870])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -497.4784,   -62.1241,   169.7901,  ...,   -41.1651, -1189.6331,\n",
            "           63.9730])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 150.6396,  190.8507, -536.0869,  ..., -314.9312,   98.8977,\n",
            "           3.1870])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  64.0639, -645.9486, -606.0347,  ...,  143.1609,  383.6717,\n",
            "         436.3871])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  203.2052,  -193.5718,  -272.0336,  ...,  -162.0947, -1876.3292,\n",
            "           90.4931])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-200.3557,  240.8898, -205.2369,  ...,  234.0136, -171.6574,\n",
            "         -90.6927])\n",
            "actor loss: 4091.7379194888845, critic loss: 3572232.640625, entropy: 37072.492919921875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[8.708260686684673, 1.7333522067833376, 0, 0, 1.190644294991611], 離散行動：[1, 1], 連続行動：0.5350742526352406\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "47エピソード目の累積報酬：-28350.54887778851, 一つ保全の回数：6461, 二つ保全の回数：1275, 三つ保全の回数：456, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -223.6028,    50.5068,   206.9112,  ...,  -542.6365, -2118.7017,\n",
            "         -457.7238])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 106.7388, -943.4775,  196.9517,  ...,   61.2910, -421.2162,\n",
            "         200.0374])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -55.4114, -371.9521,   15.1833,  ...,  -60.9058,  289.6597,\n",
            "         -88.2939])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -49.7976,  -227.8552,   153.1838,  ...,  -289.8828, -1789.1387,\n",
            "          320.9622])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  44.8960, -186.9872,   41.3891,  ...,  112.8822,  119.1517,\n",
            "        -326.8135])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-657.5010, -270.0986, -235.6342,  ...,   -7.1391,  193.4133,\n",
            "         144.1146])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 69.9725, 101.0576, 111.8800,  ..., -97.5615,  45.0986, -67.4499])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 188.5679,  140.4531,  190.7769,  ..., -182.6214,  144.2568,\n",
            "         166.1948])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 124.5418, -354.6609, -331.2437,  ...,  -65.5275,  362.8926,\n",
            "         291.8280])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -113.6264,   -30.4478,   -18.6403,  ...,    61.7537, -1427.4545,\n",
            "           97.8707])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-181.4183,  363.0475,  -97.7220,  ...,  255.3889,  216.7631,\n",
            "        -188.8785])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 162.5591,  187.2704, -186.2071,  ...,  137.5576,   43.2863,\n",
            "         198.6184])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -17.1508,  224.8843,    1.7936,  ...,   38.0253,  169.6365,\n",
            "        -130.6280])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  49.6247, -660.6848, -278.9006,  ..., -119.1973,  -78.2458,\n",
            "        -111.6469])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  82.6034, -169.4385, -536.8244,  ..., -101.5889,   47.8291,\n",
            "         -31.6946])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-467.2958, -243.2383, -183.8648,  ...,  101.2469,  269.6388,\n",
            "        -282.4195])\n",
            "actor loss: 3932.771992305422, critic loss: 2891986.0, entropy: 35569.085693359375, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0.5434036567738524, 2.6036518418172534, 0, 0, 1.5959159929201177], 離散行動：[1, 1], 連続行動：0.4853011602535844\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "48エピソード目の累積報酬：-27987.390708409726, 一つ保全の回数：6451, 二つ保全の回数：1266, 三つ保全の回数：475, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-368.5297,  142.7263,   70.0741,  ...,  260.1504, -310.7015,\n",
            "        -193.8740])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  72.0023,  172.6277,   70.0756,  ...,   54.9597, -128.1565,\n",
            "        -255.2376])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 241.9762, -289.0940,  150.6080,  ...,   22.1113,  355.2605,\n",
            "        -509.4269])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 104.4414, -625.1777, -394.9492,  ..., -268.9701, -290.7493,\n",
            "        -371.5958])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -650.1475,  -353.2264,  -102.2261,  ...,    57.1839, -1476.6180,\n",
            "          142.7108])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -32.1832, -904.0150, -128.4327,  ..., -840.0033,  -54.8235,\n",
            "         183.6080])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-495.5002,  -95.8420, -219.1919,  ...,  198.2004,    1.5556,\n",
            "          28.7310])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -27.5702,   99.4797, -279.8455,  ...,  -74.2324,   66.2753,\n",
            "         -85.6327])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -6.0572, -95.3089, 136.2213,  ..., -12.1307, 107.3636,  52.0167])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-129.6594,  -15.9361, -758.4980,  ...,  -82.1710,  108.8631,\n",
            "          91.4728])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  25.3859, -186.6930,  -56.0485,  ...,   33.7685, -169.1008,\n",
            "         -12.4382])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -255.4995,    34.4327, -1277.6273,  ...,  -104.8072,  -158.2062,\n",
            "          140.6938])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-405.0753,  -13.5681,  261.2881,  ...,    2.5712,  -24.8138,\n",
            "         226.3949])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-174.6031,  -19.5441, -171.9087,  ..., -270.3438, -371.2892,\n",
            "         -11.0861])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-131.7323,  196.4024,   -5.7295,  ..., -218.1547,   83.9779,\n",
            "          51.0104])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 267.6088,  267.1599, -358.0614,  ..., -375.8773,  -59.2579,\n",
            "          41.6293])\n",
            "actor loss: 4060.0537340798664, critic loss: 2719155.7109375, entropy: 36183.884033203125, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[5.9205199794880015, 35.3855767312945, 0, 0, 2.1247956524560965], 離散行動：[1, 1], 連続行動：-0.031498849391937256\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "49エピソード目の累積報酬：-25957.368770391484, 一つ保全の回数：6437, 二つ保全の回数：1287, 三つ保全の回数：468, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-363.2635, -147.8301,  151.3657,  ..., -170.8553,  141.4262,\n",
            "        -287.6646])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([273.3310, -37.6840, 274.0544,  ...,  26.0487, 237.6866, 175.2605])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  95.9390, -328.0167,  150.8920,  ...,  282.1316, -404.2993,\n",
            "        -193.9072])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 269.7637,  -85.0727, -163.0777,  ..., -121.9806,   93.4350,\n",
            "        -139.1275])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-3.5391e-02, -9.2659e+01,  5.8444e+01,  ...,  2.2990e+02,\n",
            "        -1.7174e+03, -3.8588e+01])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -562.7954,   160.8628,  -176.1011,  ...,   229.7137,  -465.5464,\n",
            "        -1161.4629])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -72.1190,  205.8327, -183.9114,  ...,  177.1650,   -4.5304,\n",
            "         190.5729])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 169.1650, -237.9030, -137.5374,  ...,  242.1839,  144.3059,\n",
            "         -48.3910])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -14.8810, -570.2565,  134.9226,  ...,  107.4822,   83.8654,\n",
            "         106.2269])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 161.5569, -184.0916, -247.9004,  ...,   94.7814,  -79.3095,\n",
            "        -310.9813])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -211.6274,   -66.4894,  -456.1981,  ..., -1261.5934, -1570.1357,\n",
            "           93.9025])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -58.8047, -375.9841,    2.6692,  ..., -141.3059,  116.5931,\n",
            "         116.5825])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -209.3914,  -123.1870,     6.9158,  ...,   149.3672,    91.9595,\n",
            "        -1968.0553])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  121.7401,  -431.0995, -1625.3134,  ...,   -63.3699,  -297.9427,\n",
            "          145.0392])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  65.1462, -338.8065,  329.8316,  ...,   54.7452, -167.9519,\n",
            "         202.1820])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   94.6213,   218.4093,  -506.4734,  ...,   -17.1849,  -255.9836,\n",
            "        -1303.7866])\n",
            "actor loss: 3987.832524405409, critic loss: 2979758.3125, entropy: 36489.963134765625, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0, 10.597546662505065, 0, 0, 1.6831988723120628], 離散行動：[1, 1], 連続行動：0.9606525599956512\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "50エピソード目の累積報酬：-28597.84502397488, 一つ保全の回数：6439, 二つ保全の回数：1301, 三つ保全の回数：452, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  184.4544, -1265.9760,  -552.1874,  ...,   -39.0946, -2477.0337,\n",
            "           74.3985])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  31.6738,  109.5742,    5.7022,  ..., -380.2689,  -33.7072,\n",
            "          99.9384])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 352.5786, -496.7629, -139.4131,  ...,   20.7689,  171.3024,\n",
            "          -7.2540])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-9.1580e+01,  3.7241e+01, -2.3304e+02,  ..., -1.3482e+03,\n",
            "        -8.6024e+00, -1.2810e+00])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 104.0754,   86.3167, -439.3892,  ..., -593.9038, -188.3209,\n",
            "        -438.2004])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -32.1037,  -44.3707,  -79.5737,  ..., -317.7872,   47.3033,\n",
            "          76.6347])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-141.3674,  198.4506,   -8.0655,  ..., -342.8916, -275.5357,\n",
            "         104.0505])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -67.6149, -857.0687,  -34.8831,  ...,  242.6422,  236.0102,\n",
            "         306.1288])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -57.2183, -232.9138,   59.4495,  ...,  202.5340, -182.0887,\n",
            "        -806.3199])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([218.5551, -27.4386, 234.4397,  ...,  12.3488, -74.0759, 260.2740])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -41.6287,  132.2854,   81.8647,  ...,    9.9300,  -85.7309,\n",
            "        -467.5723])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  86.7217,  -67.5238,   58.3214,  ..., -560.0659,   45.9404,\n",
            "        -174.5802])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -66.3829, -705.8651,  -41.6944,  ...,  233.9173, -125.1090,\n",
            "          78.0900])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -23.4938, -364.4833,  173.3862,  ..., -869.5937, -320.0951,\n",
            "        -347.9794])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  182.4860, -1165.7037,  -447.3206,  ...,   238.5489,  -185.4339,\n",
            "         -382.3351])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1854.6836,  -857.3132,  -289.2285,  ...,   177.1122,    37.3138,\n",
            "            9.6436])\n",
            "actor loss: 3642.1311649525305, critic loss: 2904417.609375, entropy: 34612.47265625, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0, 33.96516718600017, 0, 0, 2.334286619211053], 離散行動：[1, 1], 連続行動：0.9096567630767822\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "51エピソード目の累積報酬：-29063.005302638492, 一つ保全の回数：6470, 二つ保全の回数：1314, 三つ保全の回数：408, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-101.5062, -236.9615,  123.1707,  ...,   -7.8922,  150.2483,\n",
            "         220.4290])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  55.0700, -103.2498, -210.3921,  ...,  -97.0527,   -3.0980,\n",
            "         148.0323])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-287.1304,  337.9089,  111.5689,  ...,  117.0351, -124.7093,\n",
            "         -13.7382])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -230.6111, -2016.4476,   172.0259,  ...,    48.1333,    29.3913,\n",
            "          201.5090])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-274.1535, -158.1796,   37.1481,  ..., -183.1518,   66.1351,\n",
            "        -532.6467])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 208.4889,   19.5530,  161.2648,  ..., -202.5791,   66.6936,\n",
            "          67.5411])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1398.9862,   116.0716,   -23.5976,  ...,   119.2683,    99.4382,\n",
            "          130.3153])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -6.3966, -389.5782,  284.3998,  ...,  127.2490, -275.8715,\n",
            "        -816.3748])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 215.4610,   83.9154, -149.6463,  ...,   37.9077,   45.1450,\n",
            "        -180.7851])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 100.7160, -697.3314,  206.1141,  ...,  193.6846,  -76.0345,\n",
            "        -913.0642])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   8.4775, -850.8605,  -20.6558,  ..., -955.2610,  246.4903,\n",
            "         228.5498])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 225.3839, -700.7294, -302.5551,  ...,   68.3282,  102.1272,\n",
            "          13.8123])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  23.1472,  163.0613,  -57.6754,  ...,  182.7001,  -45.9375,\n",
            "        -922.4956])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  400.0380, -1807.8740,   133.7907,  ...,  -200.5668,   -92.4413,\n",
            "          140.5094])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  91.9630,  -99.5086, -622.8878,  ...,   87.3668, -894.3925,\n",
            "         204.5438])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-85.4086, 194.7934,  -0.9450,  ..., 110.5886,  83.6923, -95.1134])\n",
            "actor loss: 3669.1843305026127, critic loss: 3074186.625, entropy: 34287.887939453125, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[31.936017910421043, 4.614733134337965, 0, 0, 1.5812800032085301], 離散行動：[1, 1], 連続行動：0.5723742768168449\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "52エピソード目の累積報酬：-25933.514388994052, 一つ保全の回数：6513, 二つ保全の回数：1273, 三つ保全の回数：406, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([171.7365,  12.4584, -43.0915,  ..., 148.5166,  29.6341, 242.3494])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  46.1875, -266.5536,   78.3609,  ...,  -83.3180,  -60.6797,\n",
            "         128.4816])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  79.0275,   21.0390,  183.3846,  ...,   48.4583, -285.2870,\n",
            "         125.2997])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([    9.7411, -1214.9125,   391.9908,  ...,    65.0799,  -172.9984,\n",
            "          145.0857])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-424.6162,  212.7587,  324.8361,  ...,  307.1891,   47.7121,\n",
            "        -409.8074])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  43.9859,  187.9907, -198.3470,  ...,   95.6149,  260.7841,\n",
            "         188.5918])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  35.2247,  222.8796,   29.9002,  ..., -531.4564,  108.0477,\n",
            "          40.5703])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-269.1334, -419.3596, -411.2099,  ...,  165.1773,  -99.2145,\n",
            "        -335.0848])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1658.6022,    68.6563,  -102.1730,  ...,  -536.1984,   109.9094,\n",
            "          -97.4165])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  81.7253,  -15.6303,  132.2823,  ..., -260.8826, -154.5619,\n",
            "        -108.9664])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  152.3483,  -356.0527,  -124.7458,  ...,     9.6951, -1237.8459,\n",
            "          -25.3468])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-243.1946,  -40.6979,  -38.7138,  ...,   11.6357,  117.3650,\n",
            "         -91.7596])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-168.0047,  118.5145,  173.1843,  ..., -347.4643,    8.4475,\n",
            "         293.3562])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -125.7648,    64.8930,    -5.2983,  ...,  -140.8651,   321.5248,\n",
            "        -2108.4326])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-347.4309,  152.6196, -269.1334,  ...,   27.6231, -304.7563,\n",
            "         -95.3531])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1405.7578,   318.9487,  -135.3435,  ...,  -117.3308,  -486.1861,\n",
            "           55.1914])\n",
            "actor loss: 3620.081581570656, critic loss: 3429257.109375, entropy: 32565.877319335938, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0.16146659889320772, 3.283744460922204, 0, 0, 2.6363527342661737], 離散行動：[1, 1], 連続行動：0.4801441542804241\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "53エピソード目の累積報酬：-25131.520886451133, 一つ保全の回数：6537, 二つ保全の回数：1300, 三つ保全の回数：355, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 101.6078,  119.8093, -311.3202,  ...,  185.3459,  109.2451,\n",
            "        -111.0523])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-145.3092,   77.2754,  -20.6190,  ...,   95.6715,  -97.0653,\n",
            "        -204.6380])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 219.0472,    1.8111,  164.6533,  ...,   52.7236,  300.5010,\n",
            "        -133.2187])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  473.9764, -2365.6458,   112.9671,  ...,   -34.6032,    68.9387,\n",
            "          219.8891])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  10.1606,   78.9494, -137.4351,  ...,  122.7227, -179.4991,\n",
            "         -36.0815])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 218.9032,  705.3764,   97.7675,  ..., -262.7277,  -52.3295,\n",
            "        -146.1746])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  84.2180,  173.1942,  176.5115,  ...,  422.7073, -707.8535,\n",
            "        -252.0972])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 494.7310,   42.9517, -426.0413,  ...,  -37.2527,   75.5368,\n",
            "         278.5753])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  151.6051,   -89.8213,   -43.3947,  ...,  -184.8450,  -314.0114,\n",
            "        -1902.8802])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 128.8491,  242.9767, -216.7310,  ...,   31.3434,  -40.3187,\n",
            "          71.4257])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  74.4900, -414.9857,   46.3550,  ...,  101.1210,  164.4202,\n",
            "         243.5492])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  93.9955,  276.9907,  208.3660,  ..., -375.7796,  -18.8045,\n",
            "         124.0571])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  95.7238, -116.8187, -375.5424,  ..., -293.9113, -797.1010,\n",
            "        -243.0393])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -26.1703,  137.6402, -144.7336,  ...,   14.1639,  -59.4311,\n",
            "         -11.6472])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 122.2384,  319.2052,  181.5052,  ..., -144.2418,   21.3224,\n",
            "         136.3596])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2442.9792,    41.2327,  -295.1099,  ...,    35.7871,   -82.3816,\n",
            "         -584.4556])\n",
            "actor loss: 3069.450677846224, critic loss: 4672241.40625, entropy: 30162.05419921875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[1.7427621539165052, 25.708345816651107, 0, 0, 2.510315559892495], 離散行動：[1, 1], 連続行動：0.4380650147795677\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "54エピソード目の累積報酬：-26864.082786618008, 一つ保全の回数：6574, 二つ保全の回数：1324, 三つ保全の回数：294, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-130.2775,  142.7515,   72.1709,  ...,  -39.5627,   36.1976,\n",
            "          76.7454])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([157.0264, -41.5728, 137.2930,  ..., 320.7044,   1.2388, 118.8795])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -2.9478, -328.8244, -100.9477,  ...,   67.7029,   27.0603,\n",
            "          32.3506])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 414.9023,   18.0212, -153.7777,  ...,  -53.5240,   37.8095,\n",
            "         107.3528])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  84.9987,  -37.1982,  -76.1529,  ...,   89.6205, -222.4981,\n",
            "         135.1212])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   3.3617, -398.1767,  210.5335,  ...,  -77.3102,  103.8355,\n",
            "         -89.7371])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  162.9662,    31.0635,  -279.4537,  ...,     9.6468,   -12.5689,\n",
            "        -2048.7295])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   76.2594,   -45.7454,   180.3693,  ...,  -379.8145, -1753.2987,\n",
            "          228.0718])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-415.6661,  -75.5240,    8.7737,  ...,  237.5874,  143.0066,\n",
            "         181.8717])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -16.7117, -369.3564,  214.9911,  ...,   30.9801,   62.7297,\n",
            "        -169.6262])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -21.4058,  188.2795,   21.3129,  ...,   85.3820,  147.9078,\n",
            "        -265.2254])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-107.3247,    5.2308,  121.7435,  ..., -511.6079,  -40.0822,\n",
            "         -55.0730])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -7.6414,  584.1292,   24.8441,  ...,  148.8760, -105.3576,\n",
            "         -29.1707])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -53.1661, -2796.4294,  -259.0426,  ...,   118.1983,   182.6039,\n",
            "          208.5035])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -147.4108,  -343.0771,  -145.5627,  ...,    71.8214, -1473.9050,\n",
            "          -12.2748])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-135.3868,  -72.7540, -389.1695,  ...,  432.1375, -228.5030,\n",
            "         154.2661])\n",
            "actor loss: 2874.2871279457386, critic loss: 3287771.8125, entropy: 30091.069213867188, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0, 19.313825022963954, 0, 0, 2.410426361244618], 離散行動：[1, 1], 連続行動：0.42470354586839676\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "55エピソード目の累積報酬：-26663.368338251643, 一つ保全の回数：6575, 二つ保全の回数：1331, 三つ保全の回数：286, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-5.3982e+02, -7.0983e+01, -1.3260e+02,  ...,  1.6762e+02,\n",
            "         2.5352e-01, -5.0815e+02])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-912.6987,  -36.7519,  -62.5715,  ...,   47.7260,    5.3305,\n",
            "         221.0226])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -66.5924,    18.0617,  -142.2874,  ...,  -153.0748, -1670.1516,\n",
            "           53.4920])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-626.6606,  -79.9921,  347.5648,  ...,   85.8619,  -16.8538,\n",
            "         159.5314])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  22.9963,   81.2898, -281.0149,  ...,  141.5933,   -6.2626,\n",
            "        -118.0975])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   17.4940,   164.8186,   189.7697,  ...,    67.8835, -1106.5496,\n",
            "         -262.2232])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 278.3821,   17.9888, -127.7935,  ..., -455.4755,   17.7911,\n",
            "         173.6078])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-142.2874,   99.6073, -247.8983,  ...,  -83.4462,  461.9704,\n",
            "        -185.9401])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-152.3416, -345.7328,  154.5422,  ..., -176.9677,  102.0861,\n",
            "        -279.4799])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-113.6290,  -50.2288,  -75.1213,  ...,  -66.2639,   14.3316,\n",
            "         -88.3202])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2.0155e+02,  1.5880e+02, -1.7910e-02,  ..., -1.0473e+02,\n",
            "        -1.6139e+02, -6.1959e+02])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 106.5453,   37.1485,   85.9062,  ..., -502.3581,  -60.2701,\n",
            "         221.1762])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  62.0988,   69.9164,  205.4513,  ...,  111.8854,   -1.8182,\n",
            "        -221.0994])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  101.3635,   340.5660,   -25.1816,  ...,  -164.1038, -1503.5890,\n",
            "          266.7230])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 156.9979, -702.0985,  485.5331,  ..., -145.8228,  -19.9080,\n",
            "         -52.2567])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-134.9741,   -8.5673,  154.3300,  ...,   48.3554, -238.1135,\n",
            "        -135.3864])\n",
            "actor loss: 3768.826503612554, critic loss: 3508184.859375, entropy: 26297.833129882812, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[3.8017409584737365, 13.485214146389634, 0, 0, 1.607312914576378], 離散行動：[1, 1], 連続行動：0.4186873063445091\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "56エピソード目の累積報酬：-24689.653316803906, 一つ保全の回数：6553, 二つ保全の回数：1374, 三つ保全の回数：265, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 344.8929, -466.3207, -115.7206,  ..., -612.5585,   82.5576,\n",
            "         161.3916])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  92.1144,   66.1808,  254.2426,  ...,  110.1317, -212.1469,\n",
            "        -533.0995])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-497.8519, -200.0396,   92.5263,  ...,   85.3223,  603.3113,\n",
            "         123.3040])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-235.6767,  108.4973, -458.3084,  ...,   10.6105, -191.1834,\n",
            "         -44.9691])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-846.1757,    6.2396,  118.5930,  ...,  101.3640, -319.1479,\n",
            "          83.0021])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 170.2481,  288.2030,   72.4729,  ..., -367.2223,  164.7070,\n",
            "          34.3378])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 144.4711,  -91.1457,   22.8383,  ...,  125.0616, -538.2701,\n",
            "         108.7253])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  16.6030,  -50.7419,  103.9091,  ...,   80.0157, -261.9019,\n",
            "         211.6326])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  39.5976,  374.3665, -257.7126,  ...,  151.5262,   94.5324,\n",
            "         -48.9957])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  24.4300,   45.8147, -328.6718,  ...,  -72.7558,   76.9322,\n",
            "        -298.8619])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-245.6460, -231.5145,   12.5905,  ..., -257.4217,  165.1997,\n",
            "         -34.4632])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 238.7954, -424.3783,  -98.4143,  ...,  132.6775,  110.3560,\n",
            "        -419.4589])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-107.3285,  -36.3821, -182.2737,  ...,   90.2989,  198.8008,\n",
            "          86.3983])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([129.8122, 161.2796, -84.6752,  ..., -28.5592, 137.9506, 286.6884])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 75.6561, 100.8823,   4.2409,  ..., 716.0204, -73.1770,  -8.2622])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 370.3285, -331.7747,   43.7236,  ...,  -21.5149, -126.9723,\n",
            "        -199.0078])\n",
            "actor loss: 2695.6809270482363, critic loss: 3223503.0703125, entropy: 18895.235961914062, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[84.34331114999125, 23.252082808054936, 0, 0, 2.017568742703244], 離散行動：[1, 1], 連続行動：0.6054831445217133\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "57エピソード目の累積報酬：-21407.294571222526, 一つ保全の回数：6575, 二つ保全の回数：1342, 三つ保全の回数：275, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-450.8763,   65.7927,  159.3271,  ...,  185.5773,  -27.4064,\n",
            "         -97.1448])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  5.6247, -67.5549, 161.8419,  ..., 213.4882, 170.6073, -30.6152])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 126.9310, -165.3820, -176.3929,  ...,   90.0157,  -18.6965,\n",
            "         208.7637])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-202.5017, -343.7536, -330.9655,  ..., -112.6148,  -39.2439,\n",
            "         157.8148])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 236.6272, -231.8104,  -86.8396,  ...,   53.0012,   18.5420,\n",
            "        -165.3071])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-255.6148,  155.8898,  254.3025,  ...,  123.8937, -641.8008,\n",
            "          79.5828])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-189.4998,  228.0840,  102.9813,  ...,  118.5783, -151.5556,\n",
            "         117.8930])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 288.6970, -306.1706, -106.0173,  ...,  -35.5539, -456.2785,\n",
            "         241.9508])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  68.2541, -247.6767,  -39.6350,  ..., -738.1570,  223.3232,\n",
            "          68.3426])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  26.6199,  -46.5461,  161.1927,  ...,   89.6901, -215.3766,\n",
            "        -333.3719])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -19.4374, -149.4359, -116.6844,  ...,   69.9445,   10.2090,\n",
            "         143.5336])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  61.5193,   12.5437,    8.4366,  ..., -262.4626,  189.7533,\n",
            "         232.3993])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 165.1555,  199.3567,  155.6242,  ...,   60.8154, -603.0140,\n",
            "         -29.4966])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-148.5027,    2.9220, -136.1862,  ...,   94.5627,   27.8295,\n",
            "        -113.0811])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 196.5100,    6.8505,  221.2862,  ...,  239.4666, -159.2849,\n",
            "          94.9035])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 291.0829, -527.7573,   74.1729,  ...,  -54.2916,  131.6164,\n",
            "        -148.2311])\n",
            "actor loss: 2307.71654917482, critic loss: 2824533.421875, entropy: 20398.138549804688, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[17.533833862263425, 51.8970065579297, 0, 0, 1.7209648078440787], 離散行動：[1, 1], 連続行動：0.6168411895632744\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "58エピソード目の累積報酬：-27821.24598153389, 一つ保全の回数：6573, 二つ保全の回数：1392, 三つ保全の回数：227, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  129.9058,    63.2048, -1379.4856,  ...,  -252.6362,   152.5129,\n",
            "          128.0993])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 261.5514,  300.3096,    1.2778,  ...,    9.2241,   86.0926,\n",
            "        -207.3005])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-109.6840,   37.6469,  102.7917,  ...,  -68.3670,  -13.7241,\n",
            "         191.8747])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  45.5379, -302.2634, -171.9942,  ...,  217.9893,   81.1573,\n",
            "          -3.6731])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 53.4598, 139.2712, 397.6541,  ...,  74.3622,  52.2059, 235.4968])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   70.7027, -1992.9829,    99.5604,  ...,    69.3649,   120.1588,\n",
            "           65.9369])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-270.8265,   17.1586,    6.0345,  ...,  236.0770,  -67.6273,\n",
            "          11.9168])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-43.5354,  10.4531, 201.2873,  ...,  52.2320, 333.4846,  16.1407])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 123.3889,   35.7837, -239.5052,  ..., -101.8124, -295.6101,\n",
            "          73.9846])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -29.8438,  128.0089, -595.8684,  ...,  -25.2503,  -31.0023,\n",
            "          54.3715])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -648.3059,    62.0437,  -432.3511,  ..., -1366.2159,   235.4968,\n",
            "         -187.4518])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  72.3999,  472.2314, -235.6452,  ...,  -30.7748,   -6.6087,\n",
            "          22.5700])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-121.1626,   14.7364,  282.3713,  ...,  413.2943,   22.0167,\n",
            "         177.1192])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -23.3684,  266.3908, -176.9867,  ..., -193.6858,  -13.8944,\n",
            "           3.9902])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  81.0403,  405.6211, -128.4035,  ...,  123.7213,   11.8107,\n",
            "         124.6582])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-136.6746,  -64.1326,  -33.4299,  ...,   43.5935, -304.0164,\n",
            "        -519.1192])\n",
            "actor loss: 2405.285877831666, critic loss: 3385023.171875, entropy: 24305.578857421875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[48.57870746976899, 11.058623007274468, 0, 0, 1.3896447074279075], 離散行動：[0, 1], 連続行動：0.5348544903099537\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "59エピソード目の累積報酬：-24230.122184200784, 一つ保全の回数：6601, 二つ保全の回数：1397, 三つ保全の回数：194, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 289.0758,   18.0194,  220.4300,  ..., -175.6890, -196.5806,\n",
            "         -94.4298])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-512.3853, -267.7130,   -0.6082,  ...,   23.0388,   85.6882,\n",
            "         178.2754])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  22.4121, -345.0635,   83.7378,  ...,   37.1497,  112.9605,\n",
            "         -39.5676])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   2.4627,  379.9861,   -0.9925,  ...,  140.7646, -178.8792,\n",
            "           3.4431])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 296.6270,  225.0512, -483.8024,  ...,  -88.8339,   61.7103,\n",
            "          -2.9830])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([104.4445,  15.8790,  27.5231,  ..., 133.8323, 146.9494, 154.4202])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  42.7001,  -21.0525, -192.4116,  ...,  -89.5872,   -8.7317,\n",
            "         335.5609])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 161.4204,   95.6694, -178.8792,  ..., -157.8417,  269.2096,\n",
            "         190.2352])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 56.3203, 170.3885,  21.0089,  ..., 215.2985, 198.4650,  56.1478])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   97.7238,   159.6163, -1452.1398,  ...,    45.9975,    46.6742,\n",
            "          121.2437])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 230.3657,  230.3375,   41.0254,  ..., -398.5331,  141.9574,\n",
            "         151.2515])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -69.8447,   74.9688,  144.3396,  ..., -200.3785, -867.5895,\n",
            "        -295.3792])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -73.6312, -256.8779,   36.7540,  ...,   22.6394,   72.9924,\n",
            "        -154.9483])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 159.4778,  -16.6129,  197.8786,  ...,   90.6210, -256.9474,\n",
            "        -647.9977])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -75.8295, -315.4065, -424.2024,  ...,  -44.3961, -432.6736,\n",
            "         -56.2341])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  58.3156,  104.8827,  -60.2120,  ..., -300.8880,  112.6474,\n",
            "          86.0796])\n",
            "actor loss: 2806.567085470026, critic loss: 3473436.296875, entropy: 26855.533325195312, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[18.886307743849457, 37.68697934519464, 0, 0, 1.7747540258421446], 離散行動：[1, 1], 連続行動：0.4054017439484596\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "60エピソード目の累積報酬：-24100.123458682312, 一つ保全の回数：6592, 二つ保全の回数：1423, 三つ保全の回数：177, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   64.9009,   202.9723,  -110.0492,  ...,   234.2848,   174.6216,\n",
            "        -1132.6897])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-347.6771,  168.3386, -108.6761,  ...,  145.5515,   -2.8196,\n",
            "        -184.9388])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  16.1277, -408.1445,  165.7578,  ...,  199.6237,  -14.6009,\n",
            "         304.4001])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2238.2229,  -220.4972,   230.2219,  ...,   133.1143,  -183.4601,\n",
            "         -143.6966])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   3.5873, -128.5377, -306.8360,  ..., -376.3464,  -69.5994,\n",
            "        -329.5922])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-282.7835,  -48.1083,  418.0164,  ...,   76.5659,   60.6414,\n",
            "        -309.5750])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 216.8969,  201.2662,  202.0859,  ...,  -20.9512, -113.6529,\n",
            "        -260.6391])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([155.8269, 106.5325,  74.0178,  ...,  98.0345, 151.7148, 205.0233])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 299.3011, -699.1915, -119.3864,  ...,  283.3652,  160.0907,\n",
            "         -24.8156])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-167.2447,   -7.6871, -471.4856,  ...,  155.4713,  202.9223,\n",
            "         -93.1107])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([216.6913, 151.3816, 161.8567,  ..., 235.7384,  72.7535, 143.7003])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 309.6056,  413.6450,  107.2096,  ..., -317.9474,  322.5845,\n",
            "        -102.8405])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  16.4973, -325.7225,  268.5113,  ...,  209.4727, -222.1954,\n",
            "         142.9658])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 114.7427,  114.8534,   80.1122,  ..., -340.1289, -664.6198,\n",
            "          36.2463])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  123.5907,   176.5427,   257.3481,  ...,  -114.2145,  -179.4752,\n",
            "        -1874.9178])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -83.2249, -515.8648,  126.1369,  ...,   58.2663,  179.7013,\n",
            "        -518.2081])\n",
            "actor loss: 2581.2272041811448, critic loss: 3693516.265625, entropy: 26329.117431640625, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[7.6170675396723215, 45.67362699940313, 0, 0, 2.648566507246661], 離散行動：[1, 1], 連続行動：0.7391734272241592\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "61エピソード目の累積報酬：-24485.01443776352, 一つ保全の回数：6601, 二つ保全の回数：1436, 三つ保全の回数：155, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 1.5432e-01, -1.8741e+02, -7.5295e+02,  ...,  2.9482e+02,\n",
            "        -1.8972e+02, -3.7550e+02])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  29.0550,  161.2929,  106.3505,  ...,  -59.3365,  127.5516,\n",
            "        -199.7061])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -34.1535,  133.7008,  165.6848,  ..., -228.0179,   -5.0235,\n",
            "          96.0847])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -279.4031,   121.7928,    53.7134,  ..., -1413.2186,  -418.5937,\n",
            "           20.0487])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-298.2525,   -3.4473,   71.9471,  ...,  280.8419,   16.9476,\n",
            "        -139.8884])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -16.2254, -172.3427,   22.1542,  ...,  100.3943,  224.7946,\n",
            "        -493.3404])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  42.6044,  -88.2165,  110.2714,  ..., -391.1129,  215.1179,\n",
            "         -51.0549])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-140.6051, -182.7953,  166.6231,  ...,   92.5084, -258.6275,\n",
            "         268.0699])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  44.5718,  -93.8555, -229.7843,  ..., -730.4645,  131.1894,\n",
            "          35.1671])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -82.7212,   80.9435, -242.1561,  ..., -110.6412,  128.3721,\n",
            "        -140.3520])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 215.9478, -193.4874,  123.1983,  ...,   91.3271, -227.3714,\n",
            "         225.1457])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 188.7945,   55.4677, -212.1017,  ...,  -83.1562,  -26.1088,\n",
            "         106.2282])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -69.6127,  -97.8241,   -2.4608,  ...,  -92.4606,  105.5417,\n",
            "        -361.4278])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([293.1699, 178.2938, 177.4152,  ..., 139.0395, 100.4662, 215.0958])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -93.4967,  -85.5928, -307.6729,  ..., -740.4517, -415.0108,\n",
            "         211.2922])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-62.8083, 141.6434, 141.8615,  ..., 238.5278, 203.6178, 164.7323])\n",
            "actor loss: 2519.992649569722, critic loss: 3349631.578125, entropy: 24858.578735351562, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[24.023211392517794, 55.148145487753034, 0, 0, 1.1857873666241077], 離散行動：[1, 1], 連続行動：0.7974873483181\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "62エピソード目の累積報酬：-23790.902491217497, 一つ保全の回数：6621, 二つ保全の回数：1430, 三つ保全の回数：141, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -11.2894,  -88.5892, -199.5294,  ..., -287.9392,   89.6429,\n",
            "          93.8651])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  50.3522, -605.4929,   95.4276,  ..., -133.1682,  201.5677,\n",
            "         179.1747])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 162.8051,  154.4759, -369.3901,  ...,   21.3666,  269.6834,\n",
            "         -39.6484])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-263.8947,  -57.9551,  102.4371,  ...,  115.2913,  -32.8146,\n",
            "        -340.1603])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1471.4983,  -232.5059,   -27.5028,  ...,  -303.8730,  -107.1180,\n",
            "          173.4794])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-868.7740,  -51.0491,  227.0127,  ...,  102.1399,   88.3912,\n",
            "          80.9421])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -63.3611,    58.2433,   173.1864,  ..., -1792.6775,    -7.2290,\n",
            "         -370.6753])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -249.8616, -1747.0413,   162.2761,  ...,   -78.5434,    59.6274,\n",
            "           67.4601])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([168.7880, -53.6924, 179.2332,  ...,  35.2682, 195.2354, -99.7464])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -92.5996, -108.3436,  104.4400,  ...,  -93.0144, -289.3272,\n",
            "         -32.4551])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  78.2435, -424.2701, -100.5561,  ...,  236.1668, -261.4776,\n",
            "         122.3886])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  46.4342,  -97.8197,  118.2882,  ..., -145.9014, -492.3888,\n",
            "         131.7242])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-72.6301, 158.5520, -23.6215,  ...,  43.7713, 216.1037, 207.0490])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 162.1002,  178.9341, -256.9564,  ...,   66.4692,  148.5581,\n",
            "         177.2867])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-353.0173,  -31.2241,  331.8407,  ...,   73.4459,   43.3800,\n",
            "         -54.9613])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  110.4691, -1657.3505, -1737.8335,  ...,   774.7795,   -11.7067,\n",
            "            9.2848])\n",
            "actor loss: 2474.1415702761788, critic loss: 4157627.078125, entropy: 24613.572021484375, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[35.60379190984457, 7.201113526719074, 0, 0, 1.8123844760492314], 離散行動：[1, 1], 連続行動：0.2604329138994217\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "63エピソード目の累積報酬：-26186.14511997064, 一つ保全の回数：6643, 二つ保全の回数：1396, 三つ保全の回数：153, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-301.0912,  156.8273,  225.4540,  ..., -113.8934, -455.4801,\n",
            "        -106.8511])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  73.4430, -260.8740, -206.0388,  ...,  -20.1334, -206.7695,\n",
            "        -140.2774])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 36.5830, 100.3151, 156.1175,  ..., 436.3140, -85.0776,  54.1051])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -46.1918,  -252.2293,   114.8484,  ..., -1355.2673, -2134.2444,\n",
            "          158.8474])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 277.8854,  311.8114,    9.8570,  ...,  -29.7013,   85.7901,\n",
            "        -342.7499])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-513.3070,   84.3762, -166.3946,  ...,  124.2777,  187.4796,\n",
            "         -79.4310])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-46.1591, -71.2358, 243.6776,  ..., 120.8077,  51.2616, 239.7019])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   11.8832,   -13.5217,   161.7979,  ...,   -85.0258, -1418.0831,\n",
            "         -162.4645])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 187.7006,  102.0925,  105.7193,  ..., -143.9879, -339.1199,\n",
            "          13.6315])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -83.9005,   445.8685, -1636.0297,  ...,  -102.5887,   186.9881,\n",
            "          -44.4443])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   37.6522,    53.9157, -1360.0562,  ...,   215.4553,    73.8065,\n",
            "          -64.6897])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  136.3816,   178.6601, -1732.2332,  ...,    49.5217,  -149.1811,\n",
            "          -91.7120])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -58.0288,   67.0894,  -63.1265,  ...,  -82.2934, -163.8454,\n",
            "         127.3277])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 127.3274,  308.9034, -160.7872,  ...,   30.9585,   63.1881,\n",
            "         174.7883])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -202.3995,  -170.0401,  -120.1846,  ...,   -33.5202,    64.7833,\n",
            "        -1413.5775])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-391.4027,  144.6447, -227.6220,  ...,   99.1732,  201.7798,\n",
            "          46.7270])\n",
            "actor loss: 2696.006007724517, critic loss: 4279406.984375, entropy: 24710.685302734375, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[65.55023551353848, 9.022147094191055, 0, 0, 1.7193301229525637], 離散行動：[0, 1], 連続行動：0.42065607756376266\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "64エピソード目の累積報酬：-32570.78865616822, 一つ保全の回数：6605, 二つ保全の回数：1480, 三つ保全の回数：107, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-288.4929,  -81.3440,  209.7678,  ..., -489.5414, -197.2700,\n",
            "         -28.5951])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 177.2197, -800.0465,  -93.4312,  ...,   83.2654,  225.4392,\n",
            "         151.0657])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  28.6146,   79.4829,   -8.6070,  ...,  -50.6140,   -3.1911,\n",
            "        -184.7230])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -14.8889,  -90.0776,  238.1943,  ..., -145.4747, -290.1728,\n",
            "        -275.8525])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   88.5364,  -236.0146, -1431.3301,  ...,    89.6703,   192.9946,\n",
            "          136.7703])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 118.9060,   59.3982,  -44.8652,  ...,  -76.8182,  315.2977,\n",
            "        -193.5729])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  115.8898, -1630.2197,   267.2913,  ...,   174.2327,   239.6365,\n",
            "          -69.9912])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  173.1903,  -181.5507, -1666.0342,  ...,  -422.3048,   243.4325,\n",
            "          253.5734])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 274.9332,  206.3886,  -57.2801,  ...,  148.4478,   69.4186,\n",
            "        -152.5889])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 88.2951, 112.0071,  -1.6020,  ...,  26.0918,  -3.8913, -63.7881])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 152.0657,   84.6253, -497.1431,  ...,  -77.0901,  -39.3194,\n",
            "        -250.9252])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-670.1053,  191.7085, -458.2184,  ..., -149.1748,  -48.9912,\n",
            "         127.3063])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-163.9953,  -14.3351, -195.4039,  ..., -845.8495, -771.9035,\n",
            "        -378.0628])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-135.0805,  152.3940,  -39.1232,  ...,  -37.1825,  143.9246,\n",
            "         -26.1663])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 229.5221,   28.3848,  278.8272,  ...,  187.3920, -312.8890,\n",
            "        -114.0280])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -61.1564,  -87.6598, -389.8122,  ...,  -58.4419, -194.2972,\n",
            "          98.8798])\n",
            "actor loss: 2087.6924238299093, critic loss: 3580055.7890625, entropy: 24476.229858398438, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[46.880147902358374, 2.6307851402679745, 0, 0, 2.360355814170655], 離散行動：[1, 1], 連続行動：0.46172598376870155\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "65エピソード目の累積報酬：-25060.86525483221, 一つ保全の回数：6620, 二つ保全の回数：1462, 三つ保全の回数：110, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([152.9496,  16.3436, 143.6932,  ..., -87.2482, 628.5064,  30.8988])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -27.6342,   135.2364, -1792.9464,  ...,  -232.0949,  -124.1901,\n",
            "          275.7478])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-396.7933,  213.0161, -969.7801,  ...,  -46.2126,  -29.2624,\n",
            "         -13.3113])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  76.2605, -402.2046,   86.2522,  ...,  197.6993,  826.3281,\n",
            "        -383.3455])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  46.0299, -267.1672,  -94.5130,  ..., -406.8016,  118.9071,\n",
            "          35.7635])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 130.5351,  -77.0961,  180.3164,  ...,   52.0027, -398.0832,\n",
            "        -105.9277])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  98.1443,  561.4848,  -26.5991,  ..., -128.4277, -205.1805,\n",
            "          25.3549])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-251.8641,    8.4734, -465.7809,  ..., -129.7850,  -95.8079,\n",
            "         180.7921])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-624.0432, -133.6839,   10.4335,  ...,   97.9719, -671.1773,\n",
            "        -442.8562])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-364.7627, -457.1170,  158.3221,  ...,  187.3312,  331.6753,\n",
            "        -129.7850])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2083.7305,    -3.3973,   177.7200,  ..., -1888.7689,   169.5698,\n",
            "          -13.3020])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  13.4403,  101.4503,  -66.5426,  ...,  372.7634,  129.0042,\n",
            "        -969.7801])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -274.3887,  -201.5777,   -34.8839,  ...,   122.3194,  -237.6489,\n",
            "        -1988.4801])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   5.6740,  231.5695, -138.8528,  ..., -124.7821,  133.1790,\n",
            "          58.2810])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 291.0218, -370.5416, -100.1127,  ...,   51.8529,  130.2795,\n",
            "          80.4967])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([151.9954,  63.3819,  81.2585,  ...,   4.4218, -55.0301, -44.7968])\n",
            "actor loss: 2356.2287865110197, critic loss: 5396969.140625, entropy: 23275.425537109375, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[61.93834915094699, 50.28061686484787, 0, 0, 1.2666387688121505], 離散行動：[0, 1], 連続行動：0.6807074397802353\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "66エピソード目の累積報酬：-28311.354971928085, 一つ保全の回数：6631, 二つ保全の回数：1450, 三つ保全の回数：111, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -54.4345, -167.3658,  -49.3410,  ...,  214.8480,  164.3758,\n",
            "          65.7884])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-112.0150, -122.5428, -100.0558,  ...,  126.9024,  116.7640,\n",
            "        -351.0784])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1348.0701,  -186.3371, -1441.0186,  ..., -2128.8826,   218.4400,\n",
            "         -215.7515])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  37.1710,  -30.2733,  123.1336,  ...,  -39.3198, -442.2784,\n",
            "        -130.8113])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-187.5911,  187.6404,  193.5319,  ...,  -85.8277,   55.4591,\n",
            "          74.1909])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-205.2015,  128.9687,  112.1044,  ...,   84.3091, -147.4107,\n",
            "         -87.2868])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -17.4693,  -70.4466, -610.2435,  ...,  199.2734,  141.3732,\n",
            "        -117.9390])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([117.2695, -36.8572, -13.4583,  ...,  92.0404, -23.0918, 231.2703])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   94.6977, -1524.6162,  -242.3624,  ...,    44.4233,   231.2703,\n",
            "          -26.8179])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 112.2981, -127.2931, -227.6179,  ...,  -71.7308, -150.9828,\n",
            "         109.0726])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  49.1021,  -32.9580, -389.4157,  ...,  -59.0960,   20.1535,\n",
            "         118.1455])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([164.0447, 345.7381, 282.9136,  ..., -56.7345, -97.2663, 115.9262])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 347.8120,  214.9267,  -56.4416,  ..., -266.2944,   32.2071,\n",
            "        -302.0304])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  329.2506,  -539.1194,    58.7957,  ...,   210.5780,    69.7930,\n",
            "        -1367.9749])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-149.7431,  334.5797, -257.2714,  ...,  262.5704,  271.9056,\n",
            "          70.3869])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-204.2198,  -40.7696,   23.7240,  ...,  115.0581,  101.9629,\n",
            "        -338.3303])\n",
            "actor loss: 2037.9820179455248, critic loss: 3217974.6328125, entropy: 22241.44580078125, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[23.810921678364434, 10.792794477007094, 0, 0, 1.7078254732553897], 離散行動：[1, 1], 連続行動：0.3774355873465538\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "67エピソード目の累積報酬：-22347.553384205432, 一つ保全の回数：6653, 二つ保全の回数：1444, 三つ保全の回数：95, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -16.7896,  134.8176,  -20.4983,  ...,  -30.2654,  -12.2118,\n",
            "        -110.6755])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-124.3175,  138.0287,  346.2047,  ...,   57.2989,  -21.0826,\n",
            "         158.7186])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-156.4706, -405.8977,  353.2354,  ...,  -15.5921,   33.6732,\n",
            "        -255.8113])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 129.0927, -248.7343, -619.7279,  ...,  -87.9694,  167.3531,\n",
            "         319.1493])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 446.8954,   14.8429,  -85.3450,  ...,   95.0391, -343.5716,\n",
            "         -77.5122])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 146.9027,  -17.5952, -263.7510,  ...,   82.2762,  -30.4214,\n",
            "         104.3665])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 115.6140,  -25.6884,  178.4635,  ...,  148.3212, -355.3144,\n",
            "         153.7514])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-132.8259,    4.4299, -260.3824,  ...,  -84.3040,  116.9269,\n",
            "        -595.1282])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-460.4173,  175.3021,  201.9284,  ...,  109.0717, -184.8579,\n",
            "        -137.6557])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 126.4103, -286.5824, -332.6459,  ...,  -18.7268, -498.2560,\n",
            "        -223.7736])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 57.2947, 135.7148,  92.7411,  ...,  72.5361, 206.1835,  73.6480])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -295.9258,   203.6962,    55.7647,  ...,   -83.2170,   -86.6218,\n",
            "        -1067.3489])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 194.6034,  186.0352,  128.3419,  ..., -296.6974,  351.2866,\n",
            "          49.6585])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 172.5823,   13.7638, -306.0161,  ...,   99.4973, -117.5964,\n",
            "          98.8530])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-173.7226,   75.9311,  -67.7843,  ..., -382.6853,  206.1052,\n",
            "         -24.6148])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  94.4954,  -55.8230,  317.1933,  ..., -250.4519,   99.0700,\n",
            "         -62.1721])\n",
            "actor loss: 2071.454910037922, critic loss: 3206651.296875, entropy: 22146.708374023438, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[15.702006071475035, 0.51583595912887, 0, 0, 1.453488620377244], 離散行動：[1, 1], 連続行動：0.3509628027677536\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "68エピソード目の累積報酬：-22269.10225729036, 一つ保全の回数：6671, 二つ保全の回数：1443, 三つ保全の回数：78, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -13.8380,   74.7230,  -31.8807,  ..., -291.2089,  198.1235,\n",
            "         -47.9170])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-192.3355,   41.2193, -125.1268,  ...,   75.8807,  257.2912,\n",
            "         240.4150])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  17.2779,  286.9226,   55.4600,  ...,    4.5524, -247.8830,\n",
            "          56.3323])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-230.8849,  170.3741,  254.8547,  ...,   24.6841,    9.0787,\n",
            "         185.9367])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([137.9859,  62.7692,   3.8272,  ...,  31.6954, 103.8918, -81.9211])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 83.2400,  22.2281, -34.8041,  ...,  81.7361,  82.9260, 186.0423])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-301.6169,  145.0351, -171.4837,  ...,   87.2718,   71.7370,\n",
            "        -101.4141])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-90.8909, 226.8149,   8.2452,  ..., 542.3188,  -5.7712, 158.4850])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 113.5537, -197.2137,  -42.9399,  ..., -480.5657,  106.9587,\n",
            "         188.3232])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 139.1726,   42.4423,   81.0456,  ..., -187.2541,  -69.2488,\n",
            "         -52.5801])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-109.9803, -272.6911, -186.8491,  ...,   94.6491,  200.7778,\n",
            "        -788.4435])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   73.9532,    95.8690,  -112.2731,  ...,   -95.5470,    32.2543,\n",
            "        -1689.2039])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-146.7316,  114.1276,  -91.8452,  ...,   90.3153,   68.7583,\n",
            "         100.7345])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-300.7215,  -96.4443,  -27.8492,  ...,   60.8114, -164.7679,\n",
            "        -252.1597])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-208.3692, -170.5929,   67.0752,  ...,  -86.8709,  -43.4511,\n",
            "          75.1190])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([166.4790, 246.2050, -33.2521,  ...,  23.0026,  35.8134,  63.0208])\n",
            "actor loss: 2180.8241299993615, critic loss: 3965852.484375, entropy: 22513.873046875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[2.5263518623813175, 0, 0, 0, 2.8565295030605338], 離散行動：[1, 1], 連続行動：0.46657276153564453\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "69エピソード目の累積報酬：-21279.954743098933, 一つ保全の回数：6642, 二つ保全の回数：1486, 三つ保全の回数：64, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -39.0171,   20.1513,   57.2470,  ..., -382.1198,  -41.0485,\n",
            "        -137.4897])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 159.8880,   22.7117,  -21.0066,  ...,    5.4735, -214.7815,\n",
            "          26.4941])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([221.5744, 182.6484, 159.8388,  ..., 160.8924, 326.8786,   4.3690])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 145.1863,  -11.9755,  178.7517,  ..., -215.9175,   91.3553,\n",
            "          19.4489])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-126.6528,  284.1602, -209.5834,  ...,   67.3945,   47.4269,\n",
            "          28.8135])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1008.5302,  -225.5646,     4.9866,  ...,    21.3132,    11.8544,\n",
            "           48.2427])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 100.2756, -358.9071, -319.6653,  ...,  267.0428,   13.7337,\n",
            "        -139.8420])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  97.8861, -335.3224, -204.7672,  ...,  -82.2709,   87.4166,\n",
            "         232.3873])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 234.4149,   59.9394,  -58.5318,  ..., -113.5151,   -1.7134,\n",
            "        -118.4739])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-150.9720,  121.5080,    3.9870,  ..., -874.3776,  105.5427,\n",
            "          62.0057])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  50.1302,  112.4013,  226.9817,  ...,   41.0597, -128.7905,\n",
            "         -93.6490])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-482.3204, -458.8533,   26.5021,  ..., -246.6069,   16.0803,\n",
            "         461.8475])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 235.2836, -771.4473,  264.9180,  ...,  -18.9416,  286.7937,\n",
            "          90.3266])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 5.2957e+01,  9.8699e+01, -1.9213e+02,  ...,  1.2918e+02,\n",
            "        -6.1633e+01,  6.9219e-02])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  63.7087,   45.8413, -109.0016,  ...,   83.8356,  242.9744,\n",
            "          86.8114])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-255.0810,  101.9447, -490.7923,  ..., -174.7162,  193.6193,\n",
            "        -134.6495])\n",
            "actor loss: 1998.7138565381672, critic loss: 3775982.1875, entropy: 21986.328002929688, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[25.744375414697707, 0, 0, 0, 1.324029679708122], 離散行動：[1, 1], 連続行動：0.5630563572049141\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "70エピソード目の累積報酬：-24079.388394634014, 一つ保全の回数：6612, 二つ保全の回数：1513, 三つ保全の回数：67, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -83.7277,   26.2278, -119.0312,  ...,   89.9894,  100.7334,\n",
            "           5.8367])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 205.1820,  167.9817, -326.8437,  ..., -104.3316,   53.3639,\n",
            "          -8.0114])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   19.1782, -1097.7412,   135.0883,  ...,   127.7547,    24.6829,\n",
            "         -391.5994])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-300.0027,   43.9767,  -62.4434,  ...,   56.3351,   29.4926,\n",
            "          63.7510])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -73.8971,  -59.4469,  -26.8613,  ...,  180.6907,  330.1317,\n",
            "        -276.7070])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 317.8884, -242.5304,  205.8021,  ...,   77.4539,  102.7023,\n",
            "        -375.4018])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  106.6562,   180.0805, -1317.2600,  ...,  -137.8814,   194.0828,\n",
            "          162.4703])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -7.3385, -558.0040,  -18.1530,  ...,   95.1976,   50.8694,\n",
            "         177.5184])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  121.7216,   -74.1892,  -199.2331,  ..., -1258.7583,  -179.5075,\n",
            "          194.5565])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 56.0974, 251.7740, 179.8869,  ...,  56.3351,  89.9894,  31.5421])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([128.1512,  45.6809, 255.5652,  ..., 284.1115, 254.9790,  90.1268])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  182.2789, -1492.9552,  -334.2029,  ...,  -201.7430,   -55.3420,\n",
            "         -220.5693])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -1.3635, -132.1902,   86.9112,  ..., -436.3159,  -43.4099,\n",
            "        -464.4738])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([144.3242, 168.6832,  78.2178,  ..., 133.5836, -56.6285, 153.5890])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 492.1932,   -6.9147, -427.6537,  ...,  288.7652,  -26.0303,\n",
            "         154.3524])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  162.9104,  -268.3221, -1173.3109,  ...,    -8.1275,    88.2386,\n",
            "          152.1565])\n",
            "actor loss: 2008.0327186839459, critic loss: 2701682.2109375, entropy: 19960.36572265625, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[43.784291882076694, 38.67569053739941, 0, 0, 1.0979227475071833], 離散行動：[1, 1], 連続行動：0.5364899262785912\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "71エピソード目の累積報酬：-28411.19193444959, 一つ保全の回数：6663, 二つ保全の回数：1463, 三つ保全の回数：66, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 106.7695,  -10.3448,  -43.4624,  ..., -127.3041, -361.0804,\n",
            "         124.1930])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1737.6836,    52.9558,   -67.3133,  ...,   146.8161,   175.9086,\n",
            "          -31.9797])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 201.1744,  141.5386,  -47.9497,  ...,  211.1753,   84.6751,\n",
            "        -799.2758])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([162.5175, 122.7620,  99.8562,  ...,  41.9195, 191.8238,  37.9628])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  219.8721, -1433.1051,   211.7257,  ..., -1723.1881,   414.6786,\n",
            "          213.8684])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([137.9819, 162.4794, -53.6760,  ..., 111.2853,  97.2674,  52.0794])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 238.5788,  -46.9333, -212.5894,  ...,  -87.8235,  -63.4744,\n",
            "        -324.6359])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 41.4732,  88.7572, 108.4565,  ..., -13.3352, 168.6019, 154.1310])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-26.2570, 171.1454,  34.4283,  ...,  22.2863, -20.6840,  23.8371])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  44.0144, -481.3007, -222.5591,  ...,  152.3416, -264.7920,\n",
            "         -69.4559])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 119.0307,  -26.0936, -285.1198,  ...,  -41.2963, -343.0053,\n",
            "         161.1655])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  58.4665, -115.5150,   61.9223,  ..., -528.6094,  -97.7023,\n",
            "         501.8579])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-5.1284e+01,  9.0812e-01, -2.3156e+03,  ...,  1.6196e+02,\n",
            "         1.7821e+02,  1.4010e+02])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([194.1548,  36.7750, 194.6956,  ..., 334.3279, 171.2079,   5.0794])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -27.1042,   24.0933,  -14.0802,  ..., -233.9673,   80.2800,\n",
            "         -20.7023])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   4.4343,   47.6420,  -27.4325,  ...,   -6.1786,   85.7388,\n",
            "        -149.4568])\n",
            "actor loss: 2049.6326121318534, critic loss: 2917485.6015625, entropy: 18377.455078125, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[54.23596875744738, 4.5037997738181295, 0, 0, 1.0334505189180325], 離散行動：[1, 1], 連続行動：0.6912074387073517\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "72エピソード目の累積報酬：-21988.878208526854, 一つ保全の回数：6687, 二つ保全の回数：1452, 三つ保全の回数：53, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([138.3697,  37.3744, -95.5175,  ...,  82.6529, 117.9268,  42.5711])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -12.8650,  182.1394, -111.7703,  ...,   87.7966,   28.2502,\n",
            "          73.7793])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 483.2658, -131.6048,    8.0781,  ...,  128.4372,  206.7899,\n",
            "        -105.5046])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 1.1804e+02,  1.8280e+04,  6.6683e+00,  ..., -1.7994e+03,\n",
            "        -2.5581e+00, -3.9078e+02])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 133.0402,    2.9196,  191.5695,  ...,  137.3678, -265.9922,\n",
            "         -71.5225])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-118.1944, -149.3382,  152.3611,  ..., -109.2348,   78.0156,\n",
            "        -114.9038])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 149.4811, -219.0785,  110.1264,  ..., -104.2130,   73.0929,\n",
            "         134.1687])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2.1504e+02, -2.2258e+03, -1.4764e+02,  ...,  1.4725e+00,\n",
            "        -8.1368e+02, -3.4529e+01])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([139.7594, 146.3402, 185.9857,  ..., 148.2287, 141.1789,  27.8896])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -26.0975,    74.5002,  -371.0973,  ...,    83.6042,   207.6135,\n",
            "        -1666.6998])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([232.0792,  18.4910, 214.5716,  ..., -73.5122, -23.5391, 121.5465])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  90.1827, -291.0564,   15.6788,  ...,  390.0426, -155.1321,\n",
            "          71.5680])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 464.0192,  188.3020, -159.0161,  ...,  -82.9538,  146.8689,\n",
            "        -204.5183])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -14.7483,  101.5792,  168.9146,  ...,  124.6725, -135.8717,\n",
            "         122.3414])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  36.9548,   41.4177,  226.5949,  ..., -666.9830,  -51.9088,\n",
            "         188.1828])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-488.7415, -310.0271, -431.9489,  ...,  -22.6379,  185.3356,\n",
            "         197.8513])\n",
            "actor loss: 2111.525543431539, critic loss: 4096190.046875, entropy: 17584.600830078125, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[15.636704142613814, 24.33495674100725, 0, 0, 1.0974491012569196], 離散行動：[1, 1], 連続行動：0.6822075992822647\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "73エピソード目の累積報酬：-23448.372880117302, 一つ保全の回数：6710, 二つ保全の回数：1445, 三つ保全の回数：37, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([    2.0508,    72.4197,   -31.1870,  ...,   151.8669, -1826.4177,\n",
            "         -109.5739])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-125.4032,  146.8438, -103.7214,  ..., -208.0368,  153.6553,\n",
            "          68.0419])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -45.8793,  111.0406,  -23.1596,  ..., -327.6432,    1.5651,\n",
            "        -149.7949])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  40.5585,  114.3286,  372.9029,  ...,  146.8712, -580.2392,\n",
            "         356.9725])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 143.6712,  112.3381,   -9.7749,  ...,   82.5100, -646.7488,\n",
            "          91.8546])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 225.9351, -330.0799, -255.5333,  ...,  -74.4033,  113.2012,\n",
            "          71.6679])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-174.3709,  109.6952,   47.5892,  ...,  143.0332,  -79.9674,\n",
            "          54.4427])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  90.5115, -205.4652,  200.3427,  ..., -368.2286,   -4.7015,\n",
            "        -229.8858])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-108.0605,  120.6292,  336.9972,  ..., -695.7389,   95.6335,\n",
            "        -142.2960])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 156.1543, -136.0183,  533.3122,  ..., -507.0065,  162.7465,\n",
            "         128.6908])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 199.3291,  275.1587,  -93.2324,  ..., -397.2169,  242.8864,\n",
            "         136.2882])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -120.9847, -1987.3585,  -872.9391,  ...,   211.0071,   131.8119,\n",
            "         -119.0586])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-104.5843, -274.6409, -341.1504,  ...,   47.5681,   76.4253,\n",
            "         -32.4024])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-126.7467,   -7.1395,  -65.8609,  ...,  -71.3427,  428.5219,\n",
            "         -12.2856])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   40.6547, -1484.1102,    34.6261,  ...,   -51.0709,    10.9632,\n",
            "          439.2997])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-82.2513, 134.1649, -24.9397,  ..., 111.1611, 137.8123, -51.3915])\n",
            "actor loss: 2119.1570588488466, critic loss: 7282273.703125, entropy: 17247.545654296875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[20.911971912828506, 43.743290695055755, 0, 0, 2.42227277842886], 離散行動：[1, 1], 連続行動：0.3570856302976608\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "74エピソード目の累積報酬：-24188.114394790977, 一つ保全の回数：6700, 二つ保全の回数：1443, 三つ保全の回数：49, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 280.8006,  173.9123, -325.9268,  ...,   60.0216,  -53.7344,\n",
            "         160.3145])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -45.1762,  267.3807, -185.3249,  ..., -793.6393, -198.8263,\n",
            "         -43.7487])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-341.5907,  122.3924,  -16.5304,  ...,   41.5185,  -25.1626,\n",
            "        -175.3479])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   0.3931,  111.5038, -104.3116,  ...,   -6.3280, -124.2735,\n",
            "        -109.3081])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-416.4409, -158.6688, -493.0574,  ..., -518.0315, -335.5720,\n",
            "        -211.4151])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 253.7433,  292.6831,   44.0572,  ...,  236.2696, -434.2396,\n",
            "         -50.0880])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([205.0552, 253.3085,  23.2854,  ..., 296.3728, 198.4417, 136.9213])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -7.7252,  35.6362, 117.4119,  ..., -28.7707,  19.5857,  70.9309])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -17.2604, -392.1005,  -50.9316,  ..., -144.1272,  185.6767,\n",
            "         609.3015])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -63.1320, -112.0378,  222.5271,  ..., -201.2115,  121.1183,\n",
            "         434.7737])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   3.1377, -770.6409,  296.2549,  ..., -125.1851, -349.3587,\n",
            "        -337.5143])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -6.5547, 334.8838, 443.5599,  ..., -15.2531, 128.1223, 365.0437])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-100.6623,   86.7470,   74.0145,  ...,  -37.1870,   97.8614,\n",
            "        -180.7955])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-209.7524, -454.5191,  -61.0529,  ...,  174.0143,  106.9875,\n",
            "         269.2907])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 140.3834,   87.2652, -162.4534,  ..., -787.7436, -150.2372,\n",
            "        -125.8006])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  65.6363, -564.7515, -375.6936,  ...,  469.3647,  -35.8121,\n",
            "         -32.1143])\n",
            "actor loss: 1995.602749179571, critic loss: 4959311.71875, entropy: 15061.684692382812, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[74.48888147251806, 17.70524922403988, 0, 0, 2.2612952157271122], 離散行動：[1, 1], 連続行動：0.4819694459438324\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "75エピソード目の累積報酬：-20709.400175714072, 一つ保全の回数：6634, 二つ保全の回数：1512, 三つ保全の回数：46, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -75.2930,  106.1145,  -16.9918,  ...,  143.8835,   92.5908,\n",
            "        -441.4540])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 6.4165e+01,  1.0418e+02, -1.4205e+02,  ...,  9.6250e-02,\n",
            "         2.9597e+01,  2.7351e+02])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  405.9697,   426.7632,  -516.2477,  ...,  -219.3550,   165.3776,\n",
            "        -1769.2476])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  37.4354,  255.7654,   44.5277,  ..., -346.0764,  137.0133,\n",
            "        -271.5338])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 255.2648, -249.9016,  118.8317,  ...,  166.1233,  -27.5738,\n",
            "         319.8419])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -101.8906,    -2.2005,    68.3231,  ..., -1101.3196,  -223.8753,\n",
            "         -217.9969])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 100.3432,  340.9242,  146.5361,  ..., -185.6158,  197.1221,\n",
            "          65.1156])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 290.1422, -222.6525,  280.5413,  ...,   46.5680,    0.5772,\n",
            "         -59.7444])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -59.7444,  243.5562,   16.8476,  ..., -211.8981,  -51.4634,\n",
            "         108.2320])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -49.0546,  -16.6900, -469.8654,  ...,   98.0390,  -49.1200,\n",
            "         -43.2012])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 166.2333,  132.6121,  413.2087,  ...,  164.6648, -249.8558,\n",
            "          99.7673])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 221.5221,  -60.3175,  132.7199,  ..., -153.5671,  -12.1516,\n",
            "          43.8827])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -52.7262,  -74.8921,  371.3024,  ..., -880.7892, -148.9182,\n",
            "           8.3112])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1755.1382,  -329.5891,   299.1732,  ...,  -238.9856,   230.3114,\n",
            "          488.9789])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([230.6978, 109.9239,  57.2980,  ..., 133.3516,  80.1141, 188.2691])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  84.6376,  195.6328, -201.6404,  ..., -131.0592,  134.4041,\n",
            "        -158.6955])\n",
            "actor loss: 1816.548087463331, critic loss: 3403742.5, entropy: 12891.507385253906, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[68.91965866000466, 73.50019275229862, 0, 0, 1.4798468554475215], 離散行動：[1, 1], 連続行動：0.4378392659127712\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "76エピソード目の累積報酬：-24795.123115405844, 一つ保全の回数：6658, 二つ保全の回数：1496, 三つ保全の回数：38, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 245.7861,   11.2128,  276.7337,  ..., -123.2500,   93.2092,\n",
            "         -93.0811])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  88.5274,  138.9929,  286.9707,  ...,  -90.9073, -125.5785,\n",
            "          41.4799])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 138.6705, -142.6914,  273.2187,  ...,  174.4005,   56.5365,\n",
            "         183.2442])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  15.4903,  -33.2182, -441.3799,  ..., -238.0457, -146.9081,\n",
            "         172.5015])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -36.4886,   52.4550,  380.8298,  ...,  -10.3572, -126.1849,\n",
            "          81.2444])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -90.1651,   146.2520,  -488.8755,  ...,   -67.6557, -1200.9821,\n",
            "          208.3209])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1299.8771,   309.8607, -2471.9333,  ...,  -129.2800,   146.7165,\n",
            "         -103.8603])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 56.1288,  -2.7497, 248.7913,  ...,  -6.4688,  45.5302, -20.7638])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-222.5997,  -19.4907, -400.4647,  ...,  415.0901, -101.2567,\n",
            "          64.6131])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  60.2969,   99.2958, -270.0127,  ...,  373.2836, -121.0815,\n",
            "         -22.1523])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([308.3832, 234.9770,  77.3881,  ..., 397.8144,  48.0833, -30.3584])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   75.6793, -1354.9977,   280.5554,  ...,  -253.0849,   326.5035,\n",
            "        -1543.1317])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 241.3460,  122.9847,    7.1079,  ..., -466.4499,   57.3479,\n",
            "          65.6792])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -22.9238,  261.1136,  177.0624,  ...,  159.9221,   86.3477,\n",
            "        -293.0202])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 152.2443, -220.6051,  170.8094,  ...,  124.7649,   72.7112,\n",
            "         -35.4081])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-61.5783,  80.3592, 285.5815,  ..., 123.9607, 306.6183,  55.9822])\n",
            "actor loss: 1774.564342639342, critic loss: 2815329.2421875, entropy: 12053.911071777344, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[7.508354989615426, 4.299734340101509, 0, 0, 1.4826820493567674], 離散行動：[1, 1], 連続行動：0.25948338210582733\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "77エピソード目の累積報酬：-20168.743516991028, 一つ保全の回数：6671, 二つ保全の回数：1480, 三つ保全の回数：41, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-462.3184, -283.1331,  132.9918,  ...,   -8.7808, -104.8006,\n",
            "        -220.4354])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  174.2016,   140.4252,   247.2645,  ...,   188.2309, -3550.6138,\n",
            "          -37.7515])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   64.9381,   -95.5815,  -142.4158,  ..., -1110.4459,   -43.2549,\n",
            "           94.6652])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 84.2926,  48.6588, 242.3565,  ..., 112.1106, 112.3339, 205.5173])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 15.1316,  17.2799,  56.1897,  ..., -84.0690, -82.5978,  32.8892])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 369.5259,  153.3599,  188.5653,  ..., -722.7540,   10.4430,\n",
            "         217.7955])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 242.0810,  143.5585,   87.5241,  ...,  -45.8929, -981.2151,\n",
            "          11.3987])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-115.6188,  173.9056,   83.1179,  ...,  186.0576,  161.6657,\n",
            "        -331.8161])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   3.8492,   68.5545,  248.5932,  ..., -172.2643,  -16.2364,\n",
            "          63.4229])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  227.8649,  -377.7190,    93.2573,  ..., -1712.5225,    25.1233,\n",
            "         -499.7179])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([197.1541, 119.5075, 115.4768,  ..., -57.6793, 216.0770, 101.1408])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([144.2018, 110.3684,  94.8651,  ..., 134.9303,   0.4802,  68.1439])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1307.6101,   245.6090,     2.4628,  ...,   231.9741,    49.5376,\n",
            "          123.7213])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-249.7312,  177.7338,  140.3733,  ...,    5.5774,   26.3947,\n",
            "         100.4324])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   96.2156,   208.3689,   153.6562,  ...,  -422.2678, -1370.8381,\n",
            "          149.9610])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 180.2206, -244.9332, -138.0138,  ...,  262.0791,  -10.8319,\n",
            "          90.3997])\n",
            "actor loss: 2232.818553384434, critic loss: 2863279.453125, entropy: 12276.795654296875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0, 46.474834449610746, 0, 0, 1.4220709071392124], 離散行動：[0, 1], 連続行動：0.39013709872961044\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "78エピソード目の累積報酬：-22650.280529110474, 一つ保全の回数：6701, 二つ保全の回数：1450, 三つ保全の回数：41, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([176.2054, 117.2991, 136.6574,  ..., 162.9563, 117.4071,  14.1827])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -86.1166,   18.3689,  136.1352,  ..., -111.2196,   65.0698,\n",
            "         -49.3647])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-58.4121,  12.3641, 119.1501,  ...,  39.4490, 138.2822, 162.8838])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 74.5775, -72.2411, 178.5039,  ...,  31.0333, 179.4263, -71.4118])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-256.6808,  257.1895,  133.9678,  ...,  170.8215,   41.6088,\n",
            "          98.4325])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  29.7649, -241.1689,  161.8337,  ..., -624.0091,  425.4952,\n",
            "          91.2524])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 84.2623, -11.1042, 169.7718,  ...,  62.3454, 102.7203, 105.4264])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 245.3041,  176.1147,    4.2229,  ..., -132.0406, -209.9197,\n",
            "         111.3945])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-308.4604,  258.9411,  -58.3509,  ...,  134.5334,  189.1907,\n",
            "         -60.8437])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-21.0263, 113.1631,  26.0258,  ...,  58.4915, -41.5023, 179.6871])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([219.7451,  27.6207, 140.6861,  ...,  25.3387, 211.0889,  92.2559])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-146.2210,  119.6708,  -44.4860,  ...,  -21.8315, -116.2769,\n",
            "          -0.3306])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-272.7665, -227.2621,  167.0169,  ...,   53.8199, -190.2757,\n",
            "         128.0782])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  99.2294,  303.7584,  143.0038,  ..., -261.5321,   16.5804,\n",
            "         -22.1431])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1548.2949,  -613.2361,   -82.6784,  ...,   -55.9838,    60.1810,\n",
            "          139.3822])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -39.4720,   89.5493,   89.6021,  ...,  102.7203, -260.8545,\n",
            "          99.0663])\n",
            "actor loss: 1981.4429395001898, critic loss: 3302721.7109375, entropy: 12334.85546875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[43.53222705536738, 15.844373532586216, 0, 0, 1.1053457820617298], 離散行動：[1, 1], 連続行動：0.462539728730917\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "79エピソード目の累積報酬：-21692.97150260314, 一つ保全の回数：6746, 二つ保全の回数：1412, 三つ保全の回数：34, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  48.0585,   34.0980,  252.2686,  ...,  101.7033, -190.5418,\n",
            "         470.5631])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  82.3994,  203.5069,  -28.0919,  ...,  -55.0975, -125.8648,\n",
            "          22.3444])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([219.7491, 238.8227,  73.0126,  ..., -97.1711, 224.9686, 237.1374])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-53.6956, 184.8221, 213.5227,  ..., 326.4896,  18.7181, 231.9146])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  27.8553, -114.0104,  171.8457,  ...,  141.8972,  837.1435,\n",
            "         204.2078])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  32.0838, -228.0173, -150.8253,  ...,   16.0441,  150.1288,\n",
            "         -57.3770])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-283.1697, -248.2661,   53.5513,  ...,  260.6182,  148.3178,\n",
            "          98.7821])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 65.7424, -52.9774,  19.5187,  ..., 564.4041, -41.6517, 233.3154])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  46.1624, -147.5700,   41.3125,  ..., -222.7949, -273.2852,\n",
            "         -62.7193])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-237.9397,  -72.1679,   93.5925,  ...,   64.0564,  -49.8481,\n",
            "         505.9641])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -8.8856,  51.5083, 141.6427,  ..., -69.0113, 134.4200,  73.0420])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  52.8217,  -94.1647,  421.8492,  ...,  413.8630, -420.1675,\n",
            "         479.8031])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -71.4155,  232.0831,  162.1412,  ..., -126.9638,  -64.9208,\n",
            "         273.7336])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  53.4202, -109.6993,  -56.9585,  ..., -176.3313,  248.3560,\n",
            "          -6.4062])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -79.4610,   57.1770,   89.4348,  ...,  106.1846, -645.2870,\n",
            "         371.7432])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -29.8767,  109.6163, -108.2525,  ...,   29.9180,   -9.7403,\n",
            "         114.9575])\n",
            "actor loss: 2610.6147532857553, critic loss: 4586579.421875, entropy: 12226.56591796875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[13.412882928757456, 61.78500157440486, 0, 0, 1.6087626865530256], 離散行動：[1, 1], 連続行動：0.5071738348342478\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "80エピソード目の累積報酬：-20818.933843204413, 一つ保全の回数：6695, 二つ保全の回数：1456, 三つ保全の回数：41, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-132.9699,  174.9104,  132.9724,  ...,  112.6447, -106.0070,\n",
            "         115.9011])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 159.2866,  173.4526, -230.9454,  ...,  250.4089,   88.5775,\n",
            "          72.0901])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   81.9648,     2.1417,  -833.3057,  ...,  -279.1904, -1169.0419,\n",
            "         -517.6439])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 257.8778,  -17.1586,  -43.2212,  ...,   65.3770, -593.7583,\n",
            "          -3.8717])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 9.9270e+01,  2.2392e+02,  1.9623e-01,  ...,  1.8853e+02,\n",
            "        -4.1626e+02, -1.0969e+02])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 150.5963,  -48.2136, -590.9982,  ..., -248.4938, -217.9201,\n",
            "        -147.2464])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-160.9061, -549.0214, -135.9771,  ...,  119.6997, -316.1439,\n",
            "         135.2113])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -249.9043,     7.4725,   147.8768,  ..., -1215.5895,    27.6931,\n",
            "          209.3532])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 139.3618, -757.3039,  108.4579,  ...,  -18.1461, -109.8766,\n",
            "         -75.4933])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-423.7752, -367.7106,   51.1058,  ...,  -77.6406,  143.9191,\n",
            "         131.1640])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  100.8201,  -394.1562,  -157.7466,  ...,  -166.8522, -1885.0894,\n",
            "          193.1090])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   5.9500,  264.1676, -165.6483,  ...,    8.9752, -316.1461,\n",
            "         266.1468])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  79.2566, -529.2208,  218.6299,  ...,  150.8702, -365.4819,\n",
            "          66.7001])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 110.4480, -429.8889,  144.4621,  ...,  146.8709,  230.1000,\n",
            "         -60.0963])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  16.3720,  -70.2298, -328.1874,  ...,  114.3139,  -65.1129,\n",
            "         127.1514])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   33.4156,    -5.7711,   381.9854,  ...,    87.1563, -1663.1907,\n",
            "          186.7229])\n",
            "actor loss: 1844.3739279439799, critic loss: 3715197.640625, entropy: 11970.868896484375, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[63.73635181597955, 12.097755106844525, 0, 0, 1.3169456880016845], 離散行動：[1, 1], 連続行動：0.4785403832793236\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "81エピソード目の累積報酬：-22034.92771905254, 一つ保全の回数：6681, 二つ保全の回数：1485, 三つ保全の回数：26, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -210.8020, -1454.6393,    34.3431,  ...,   324.3502,   -31.4960,\n",
            "          -53.3285])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-429.2933,   98.8422, -139.3159,  ...,   27.5268,  117.8584,\n",
            "         186.8670])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 101.3536,  212.5815, -188.5921,  ...,   37.0885,  -32.9839,\n",
            "         -59.0943])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([174.4394,  83.7774, 261.0429,  ..., -53.0947, 359.9938,  65.0238])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  249.5004,    75.5486, -1635.6768,  ...,  -287.7678,   -72.7772,\n",
            "          164.6213])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 243.7207, -505.1982, -246.5368,  ...,   39.3890, -233.8644,\n",
            "        -435.2132])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -52.8632,   25.7183,  157.6177,  ..., -350.0734, -165.2633,\n",
            "        -116.5819])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 181.4305, -108.0243,  240.7874,  ...,  156.0465,  133.3582,\n",
            "         -29.5418])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -641.5976,  -188.0005, -1675.4282,  ...,    -4.3229,   212.6975,\n",
            "         -125.9884])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-377.3346,   93.1526,  380.2182,  ...,  191.4344,  -70.7328,\n",
            "        -442.4829])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   70.5725, -1522.8633,   204.7648,  ...,   179.6383,   302.0111,\n",
            "          -58.4350])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([132.3949,  54.4800,  67.5843,  ...,  85.2088, -83.9025, 234.9802])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-354.8220,  238.5208,  297.4580,  ...,  -31.8877,  169.9705,\n",
            "         248.8199])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 183.9406, -446.7850, -494.4610,  ...,  -59.8824, -264.4224,\n",
            "         171.2226])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-557.5967,  237.8353,  -34.3642,  ...,  159.0092,  333.5016,\n",
            "         186.2211])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -26.5634,  235.9868, -506.6448,  ...,   74.1205,  213.7514,\n",
            "         -27.6333])\n",
            "actor loss: 2035.671224701908, critic loss: 3131028.171875, entropy: 11848.453247070312, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[44.210671717875464, 34.87678160845034, 0, 0, 1.5116292488331151], 離散行動：[1, 1], 連続行動：0.2695576697587967\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "82エピソード目の累積報酬：-20372.56800648391, 一つ保全の回数：6736, 二つ保全の回数：1437, 三つ保全の回数：19, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-351.4217,   65.5706,   81.3486,  ...,   40.8022, -180.8976,\n",
            "        -415.8616])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-103.0634,   33.5826,  -44.7446,  ..., -196.2082, -130.5070,\n",
            "         244.4284])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 48.1534, 146.4363, 255.5557,  ..., 196.1018, 130.2176, -42.4194])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-57.1717, 108.3169, 105.5597,  ..., 344.7389, 234.9283, 248.5978])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1998.2889,   -62.8992,   214.0049,  ...,   117.3049,   173.6333,\n",
            "          -69.8337])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -320.1068,   -60.8691,  -400.0825,  ...,    66.7899,    26.8191,\n",
            "        -1593.5264])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  5.9587,  68.8273,  67.2186,  ..., 118.4424, -12.5662,   5.4049])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -25.4332, -149.5640,  122.0545,  ...,  199.0426,  102.8246,\n",
            "         131.8112])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-248.2694,  -88.8629, -290.9170,  ...,  -92.3214,  -28.5976,\n",
            "        -179.8539])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-312.3047,   85.1726,  212.7101,  ..., -266.4087,  150.3232,\n",
            "        -151.6166])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 170.3303, -216.9238,   97.8107,  ...,   38.5214,   44.5171,\n",
            "         -79.8585])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([280.3307, 240.2789,  86.7127,  ..., -60.8929, 325.7779,  76.1925])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-122.5669,  267.4815, -365.1406,  ..., -177.6951,  316.2827,\n",
            "         210.1459])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([280.1984, 115.0273,  29.5595,  ..., 183.5403,  74.9605, 213.2319])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -19.5837,    86.2650,   129.6855,  ...,   -68.4306,    90.1818,\n",
            "        -1721.7102])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([235.9729, 405.8777, 181.0271,  ..., 169.3412,  96.0266,  80.5559])\n",
            "actor loss: 1782.734682748507, critic loss: 3370870.921875, entropy: 11881.817321777344, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[8.55523824364619, 58.61370242679945, 0, 0, 1.6119458947761718], 離散行動：[0, 1], 連続行動：0.689496785402298\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "83エピソード目の累積報酬：-23215.39836971272, 一つ保全の回数：6752, 二つ保全の回数：1413, 三つ保全の回数：27, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-158.2815, -186.3936, -170.2721,  ..., -416.8773,  196.2254,\n",
            "         -22.7545])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-100.2120,  -73.5981,   68.5373,  ...,  -61.4100, -208.3460,\n",
            "         146.4409])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  120.8010,  -146.1938,   176.7728,  ...,   -93.3696, -2167.2727,\n",
            "         -329.4445])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 134.5148,  281.6098,  -34.0797,  ...,  263.5806,  -55.6476,\n",
            "        -156.5920])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -14.4802,  278.7999,  -60.2193,  ...,  308.2014,  -58.6489,\n",
            "        -170.1303])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  93.8676,  -65.2357,  -42.0943,  ...,  -11.1628,  103.0341,\n",
            "        -277.5392])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 181.9995,   57.3237,  -10.8967,  ...,  241.2615,  212.5090,\n",
            "        -436.8832])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-218.7708, -416.5841,   -1.4412,  ...,    4.3071,   15.3420,\n",
            "          -5.0487])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   98.0288,    28.6891, -1793.5033,  ...,   107.1703,   -61.5840,\n",
            "           65.7755])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  37.4474, -109.2123,  -14.5529,  ...,  251.1175,  326.7975,\n",
            "          61.0907])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -240.0212,   130.5484,   -83.7032,  ...,    51.6872,   185.9962,\n",
            "        -1953.5234])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  80.5208, -155.5424,  400.8696,  ...,  236.8807, -142.4267,\n",
            "          35.2382])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 188.5886, -292.2637,  -66.1579,  ...,  179.0761,  112.8108,\n",
            "         263.3256])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 106.7841, -466.8434, -101.1680,  ...,   82.2199, -183.4621,\n",
            "          75.2740])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   3.4133,  134.6818, -595.9286,  ..., -103.8296,  141.8816,\n",
            "         -18.6086])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   15.6614,  -140.8525, -1591.9834,  ...,   182.2311, -1863.4121,\n",
            "           23.2895])\n",
            "actor loss: 2011.5555958922514, critic loss: 3509436.671875, entropy: 11963.335510253906, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[43.60764905065397, 42.901172324990014, 0, 0, 2.234140459493221], 離散行動：[1, 1], 連続行動：0.6511023342609406\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "84エピソード目の累積報酬：-22932.524162067883, 一つ保全の回数：6712, 二つ保全の回数：1450, 三つ保全の回数：30, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 148.8135, -169.3224,  -54.1138,  ..., -182.2898,   69.3817,\n",
            "        -302.1842])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-464.0982,  -13.8521,  127.2362,  ...,  -60.7352, -254.0547,\n",
            "          26.1290])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 30.6363, -96.0233, -38.6427,  ...,  20.9404, 148.2385,  88.8879])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   24.7019,    24.1561,    57.9909,  ...,    45.0537,   124.3367,\n",
            "        -2012.6338])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 107.3210,  399.9182, -661.8593,  ..., -278.2946, -284.0226,\n",
            "        -341.2863])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-100.8464, -155.4516, -285.5396,  ...,  117.9080,  290.1621,\n",
            "          63.7028])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -16.5811,   36.3439, -187.3534,  ...,  144.7489,  319.9595,\n",
            "          33.4763])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 263.7780,   -5.3624,  166.6859,  ...,  205.6758,  480.8442,\n",
            "        -100.8336])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -311.4763,  -291.6914,  -195.4398,  ..., -1524.2109,  -306.4732,\n",
            "          275.7227])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 304.5728,   40.5992, -148.8194,  ..., -180.8444,   -7.2295,\n",
            "        -188.4741])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-284.7214,  102.4003,    7.0203,  ...,  -77.2337,  169.3244,\n",
            "        -232.9093])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([224.7130,  44.4905,  78.0324,  ..., 203.6441, 132.9078, 149.0448])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 107.4482, -279.2612,   29.3305,  ..., -206.7830,  -83.3985,\n",
            "          39.9608])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([556.6698, 102.8884,  96.8999,  ..., -76.4336, 123.3103, 155.5451])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 664.3755, -105.7697,  110.3172,  ...,  158.2029,  351.6707,\n",
            "        -264.0161])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  57.0799, -388.9297,   34.7358,  ...,  -39.4344,  174.6996,\n",
            "           6.9686])\n",
            "actor loss: 2047.5910304214822, critic loss: 3243811.984375, entropy: 11727.008911132812, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0.007244985600892452, 17.95596305337156, 0, 0, 1.0078501528765538], 離散行動：[1, 1], 連続行動：0.2466546595096588\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "85エピソード目の累積報酬：-21922.240233332013, 一つ保全の回数：6703, 二つ保全の回数：1469, 三つ保全の回数：20, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-481.1027,   75.6874,  176.2967,  ...,  148.9385, -265.7653,\n",
            "         -67.5563])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -80.9888,  137.7487,  -31.5888,  ..., -220.2591,   16.9151,\n",
            "          63.2467])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  129.7764, -1650.8694,   145.5697,  ...,    51.4455,   166.3996,\n",
            "          -76.3483])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  26.3757,   53.3740,   38.9683,  ...,  -59.3818, -409.0789,\n",
            "          17.1147])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 134.3049,  385.1473,   34.1274,  ..., -121.4450, -123.4248,\n",
            "         115.3384])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 101.7865,   -6.5747, -201.1389,  ...,   48.9688,  138.1493,\n",
            "         125.8731])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 216.1945,   14.6488,  -74.8729,  ...,  246.6568,  164.3235,\n",
            "        -350.4783])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-375.4758,  -69.0398,   68.1862,  ...,   83.0037, -111.9782,\n",
            "          32.6801])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  32.4027,  191.5951,  201.8459,  ..., -102.8795,  184.0130,\n",
            "         -16.7199])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -6.9665, 250.5211, 104.4716,  ..., 164.4684, 124.6302, 107.4116])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 183.5807, -789.8708, -176.6430,  ...,  -15.4646,   65.8230,\n",
            "         -79.3475])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   3.0598,   32.6585,   32.8779,  ...,  -64.0787, -181.2024,\n",
            "        -115.9038])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 256.4218,   82.1036, -135.2077,  ...,  172.3071,  155.9180,\n",
            "        -205.9727])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-74.1545, -69.3619, 152.2079,  ..., -11.3418,  18.8928, 172.6621])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -9.9668, -205.8708,  103.1727,  ..., -173.9311,  116.5866,\n",
            "          63.2422])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([101.0338,  95.3356, 308.1693,  ..., -16.2240, 105.8103, 279.3379])\n",
            "actor loss: 2022.5167458915564, critic loss: 3115609.234375, entropy: 11903.306823730469, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[1.0769135744748215, 18.91998336102893, 0, 0, 1.0663407821991373], 離散行動：[1, 1], 連続行動：0.8120797276496887\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "86エピソード目の累積報酬：-23792.052913272524, 一つ保全の回数：6727, 二つ保全の回数：1442, 三つ保全の回数：23, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-518.8937,  181.0425,  165.8236,  ..., -170.1249,   93.5455,\n",
            "        -141.9988])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 148.8568,  272.3450, -444.4096,  ...,   98.7551,  183.0019,\n",
            "          44.2688])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  12.3736,  231.2038,  588.6348,  ..., -177.8015,  204.0456,\n",
            "         316.0107])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1670.0378,   244.4855,     8.6929,  ...,   171.8688,   197.5271,\n",
            "          -58.9935])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   80.0626,    67.6935,   128.3972,  ..., -1938.7551,   469.7177,\n",
            "         -527.4341])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 371.7902, -116.0955, -308.0194,  ...,  132.9357, -407.2255,\n",
            "         -11.4819])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 187.5126,  235.9076, -121.0234,  ...,  -16.8598, -116.2613,\n",
            "         -67.9196])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([103.6764, 194.4372, 141.2696,  ..., 364.9931, -31.2247,  20.7864])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -68.9536,   97.7939,  -73.1499,  ..., -211.6922, -245.9751,\n",
            "         266.6857])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-206.2790,   76.9673,   53.1217,  ...,   -3.4890, -281.4522,\n",
            "         101.0644])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 194.5961,  -67.5008,  -99.3748,  ..., -317.4542,  -81.9930,\n",
            "        -285.0571])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   9.2415,   -1.9343, -371.0611,  ...,   66.1159,  170.3932,\n",
            "         104.4962])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -30.7438,  -194.4798,   217.0501,  ...,    81.6297, -2038.6128,\n",
            "           94.1976])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-27.2308, 176.4784, 130.4922,  ...,  12.3122, -28.6814, 183.4148])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1586.5714,    29.7648,    56.2992,  ...,  -174.9434,    93.7281,\n",
            "          133.5204])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -46.8535,  -111.1279,   111.5681,  ..., -1291.5820,   155.3426,\n",
            "          141.7274])\n",
            "actor loss: 1777.0245088871693, critic loss: 3225154.3828125, entropy: 11979.688171386719, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0.5448273509299777, 36.4414362150352, 0, 0, 1.0614412556001935], 離散行動：[1, 1], 連続行動：0.6187763288617134\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "87エピソード目の累積報酬：-24993.631255842418, 一つ保全の回数：6723, 二つ保全の回数：1440, 三つ保全の回数：29, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-206.2203,  -53.1291,  298.6632,  ..., -158.5364,  531.9445,\n",
            "          60.4296])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 429.9871, -306.9542, -166.7232,  ..., -195.9861,  229.8874,\n",
            "         526.7393])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -54.7700,  172.9977, -388.4768,  ...,  212.3318,   86.4114,\n",
            "         -37.8696])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-641.2378,  -14.5132,   60.7029,  ..., -145.0043,  234.2424,\n",
            "         190.1870])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([169.5647, 106.6591, -62.9552,  ..., 141.4553, 421.9346, -56.6538])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-87.9602, -29.2100,   4.7581,  ..., 314.2495, 149.3173,  61.6323])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([199.9141, -91.6895, -39.0561,  ...,  51.0502, 459.5332, 165.2976])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-249.8147,  -28.8440,   76.2733,  ...,  169.9443, -316.0848,\n",
            "         153.2738])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 195.5872,   42.0384,   93.9150,  ...,  116.9915,  280.7596,\n",
            "        -233.0942])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-168.4806, -247.8383,  293.3994,  ..., -152.4218,  -55.6369,\n",
            "         318.0576])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 304.6443,   75.5487,  -93.2452,  ...,   75.1188, -285.4960,\n",
            "        -290.0160])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -311.4442, -1763.3875,   107.0342,  ...,   -77.5049,  -276.7020,\n",
            "          -40.6181])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([203.3585, 225.3703, -48.1018,  ..., -32.8897, -53.1872, 147.0392])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([289.5424, 157.5880, -13.1691,  ..., 122.8429,  13.3390, 239.8098])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 190.9656,  161.3800, -174.7194,  ...,  214.5057,  -93.4681,\n",
            "         118.9025])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -69.4286,  -12.9212,   12.6443,  ...,   89.4791, -114.4322,\n",
            "        -121.2010])\n",
            "actor loss: 1550.8473097602705, critic loss: 2994546.546875, entropy: 11911.909545898438, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0, 50.345172538041844, 0, 0, 1.2388529411870945], 離散行動：[1, 1], 連続行動：0.6166520863771439\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "88エピソード目の累積報酬：-24135.2863696989, 一つ保全の回数：6701, 二つ保全の回数：1466, 三つ保全の回数：25, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -16.3472,  182.6001,  416.5252,  ..., -323.1992, -280.8986,\n",
            "         160.2242])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 246.6701,  410.5482,  311.9075,  ...,  414.1332, -110.2064,\n",
            "        -163.3313])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-289.1725,   97.9915, -303.3450,  ...,  179.1616, -415.0810,\n",
            "          95.7042])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  306.3993,   202.2399, -1401.3036,  ...,  -538.4609,   111.3156,\n",
            "          -83.0834])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -11.0610, -146.1979,   70.1147,  ...,  163.7365,  240.1788,\n",
            "          34.6285])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 244.0259,  -67.7573,   79.5877,  ...,  120.4712,  -58.0198,\n",
            "        -433.3736])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-261.4749, -404.3600,  175.8752,  ...,  141.2760,  727.0984,\n",
            "        -433.0473])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 461.7696, -234.5413, -190.0170,  ...,  185.6831,  -30.5593,\n",
            "         -76.5533])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([107.0325, 148.8768, 144.1381,  ...,  63.8228, -30.5593,   8.6757])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  22.8705,  -39.9853,  -90.5087,  ...,  231.1653, -115.3499,\n",
            "          21.8911])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  43.4671,  -60.0888, -114.1543,  ...,   93.9507, -221.7973,\n",
            "        -115.0424])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  76.3852,  295.5163, -167.7924,  ...,  119.3431, -118.2342,\n",
            "        -152.1132])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -7.7029, -121.1062,   45.1504,  ..., -384.1917,   27.6134,\n",
            "         -45.2448])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([    5.6148, -1684.5106,   240.0554,  ...,  -124.5634,  -277.8219,\n",
            "         -240.3560])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   3.9215, -169.5699, -289.1510,  ...,  188.1755,  120.1800,\n",
            "         202.1436])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -27.2024, -117.5522,  -39.7288,  ..., -726.0424, -144.3049,\n",
            "         387.3292])\n",
            "actor loss: 1444.7317760762564, critic loss: 3781220.875, entropy: 12264.00830078125, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[69.41114720134732, 53.398258155464674, 0, 0, 1.9587464827802026], 離散行動：[0, 1], 連続行動：0.5919384658336639\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "89エピソード目の累積報酬：-21796.53880548834, 一つ保全の回数：6685, 二つ保全の回数：1493, 三つ保全の回数：14, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-542.5896,  167.7578,   27.6381,  ...,  247.5870,  281.9345,\n",
            "         336.0114])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 389.6637,  278.9715,  -33.8381,  ...,  203.6861,  157.5870,\n",
            "        -325.7359])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -96.9884, -292.1809,  -98.9277,  ...,  181.0283,  117.1988,\n",
            "         285.8736])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-525.3699,  163.8336,   60.1371,  ..., -130.8146,  122.3028,\n",
            "         128.0252])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  40.3431, -110.9651,  -18.6544,  ...,   81.4780,   95.6208,\n",
            "         120.4664])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-355.1326, -211.3686,  -53.8131,  ...,  198.5703,   96.5336,\n",
            "          21.5771])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([392.1313,   3.2614, 185.0028,  ..., 261.2927,  76.2596, -73.4604])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-457.6216,  322.1472,  144.1378,  ...,  169.1826,  -36.4587,\n",
            "        -132.4380])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-681.4880,  -46.3766, -224.1395,  ...,  -60.9429,  -39.2247,\n",
            "        -237.5498])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 257.3324,  144.4481, -328.7787,  ..., -228.4280,  181.0283,\n",
            "         247.9830])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  59.5752,   37.9079, -150.7192,  ...,  -72.4119, -551.4851,\n",
            "         135.2529])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -47.6560, -199.0286, -150.3307,  ...,  -29.8174,  -27.1055,\n",
            "         118.5486])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -46.6285, -212.7896,  744.4266,  ..., -203.3636,   40.5827,\n",
            "         115.9564])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 159.6781, -154.4090,  167.2441,  ..., -855.9475,  356.5619,\n",
            "         -57.6840])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -41.2379, -193.8195,    3.1865,  ...,  425.7861, -222.7413,\n",
            "         145.7594])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 101.4765,   91.3510, -234.3454,  ...,  397.5035, -467.0450,\n",
            "         220.9173])\n",
            "actor loss: 1516.6021958120941, critic loss: 3203433.65625, entropy: 12052.449035644531, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[38.68190238067266, 11.693289237902171, 0, 0, 2.6730823599316436], 離散行動：[1, 1], 連続行動：0.4151255637407303\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "90エピソード目の累積報酬：-22331.937412803745, 一つ保全の回数：6626, 二つ保全の回数：1544, 三つ保全の回数：22, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  89.0960, -136.3394, -199.5118,  ...,  152.6480,   39.9580,\n",
            "         209.5921])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -94.2354,  166.5628,  122.4354,  ..., -470.4457, -345.8069,\n",
            "         228.2208])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 325.9784,  406.5111, -343.2494,  ...,   77.0786,  503.9495,\n",
            "         -54.2303])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-234.5343,  167.2108,   35.2002,  ..., -325.1871,   60.9676,\n",
            "          41.5217])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-360.1204,  118.0311,  356.6221,  ...,  182.2415,   82.5952,\n",
            "          16.3167])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 406.5111,  -56.2629, -133.0731,  ...,  -83.2642, -120.8275,\n",
            "         -75.7768])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  17.7910,   49.4906,  -61.2248,  ...,   25.4356, -134.8336,\n",
            "        -137.7599])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 155.3853,   63.9956,    7.0404,  ..., -604.2253,  116.7258,\n",
            "         102.6495])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-141.4603, -547.9073, -179.4189,  ...,  202.3513, -164.4890,\n",
            "         134.8961])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-213.3619,  125.6114, -349.2820,  ...,   99.8075,  151.3054,\n",
            "         -76.3275])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 471.9620, -194.2880, -125.5412,  ...,  -37.9304,  -93.6150,\n",
            "         184.0576])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-342.2276,   -3.7659,  -79.5429,  ..., -198.3845, -195.8407,\n",
            "         283.6412])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-317.9440,  -26.2017, -116.5773,  ..., -219.0614,  555.2081,\n",
            "         217.4460])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 108.4130,  122.8896,  230.3749,  ..., -440.7328, -458.1945,\n",
            "          -0.7947])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 257.5193, -176.3091,  -86.3742,  ...,   59.9696,  267.7487,\n",
            "         144.0451])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   1.2199,  292.1954, -106.2220,  ..., -276.2948, -292.9921,\n",
            "          35.9800])\n",
            "actor loss: 1562.220441626364, critic loss: 1927935.65625, entropy: 12310.445922851562, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[36.48642981876858, 12.432126751825034, 0, 0, 1.6722592048103726], 離散行動：[1, 1], 連続行動：0.6771257966756821\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "91エピソード目の累積報酬：-21734.823012493514, 一つ保全の回数：6555, 二つ保全の回数：1611, 三つ保全の回数：26, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -13.6249,  223.7689, -205.6945,  ...,  -79.0035, -275.4080,\n",
            "          86.8253])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  78.3489,   85.0323,   -4.1952,  ..., -391.4357, -229.0920,\n",
            "         -10.6914])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-630.6789, -152.5472,   52.2463,  ...,  124.5875,  178.9940,\n",
            "         151.6426])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -56.6152,  148.3069, -107.8791,  ...,  212.5511,   43.5696,\n",
            "          63.4231])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -377.7857,  -234.9517,   153.7501,  ..., -1063.5380,  -155.9681,\n",
            "         -267.7806])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  68.8172, -190.3062,  137.2623,  ..., -106.6513, -106.2249,\n",
            "         306.8698])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-183.5471,  -41.7314,  -43.0157,  ...,  -21.1303, -594.5765,\n",
            "        -172.2531])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  22.4946,  228.5238, -270.5210,  ...,   19.0869,  207.2326,\n",
            "        -237.1908])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  79.8731,  -30.1920, -325.3041,  ...,   41.3558,   -8.5460,\n",
            "         114.2995])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2.1247e+02,  4.2227e+01, -6.2710e+02,  ..., -1.1204e+02,\n",
            "         1.4174e+02, -2.5537e-01])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -34.8217, -346.0178,   22.7970,  ...,  127.2167,  159.9477,\n",
            "         184.8751])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-224.9846,  -85.5769, -105.1901,  ..., -164.0330,  140.4718,\n",
            "         341.1667])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -58.2291, -247.1124, -209.7160,  ..., -261.2684, -115.9993,\n",
            "          40.9349])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  60.0986,  -43.5895,  178.2881,  ...,  210.2365,  195.9818,\n",
            "        -265.1188])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   4.9698,   53.2796,  349.9005,  ...,  178.5299,  183.9773,\n",
            "        -504.0370])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  157.7045, -1305.1299,   140.4718,  ...,    98.1758,   314.3959,\n",
            "          -13.0271])\n",
            "actor loss: 1479.4058923936084, critic loss: 1787450.8515625, entropy: 12164.361145019531, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[14.281946079914043, 10.454663896679971, 0, 0, 1.6620391991652608], 離散行動：[1, 1], 連続行動：0.6382501274347305\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "92エピソード目の累積報酬：-21763.30963290552, 一つ保全の回数：6559, 二つ保全の回数：1615, 三つ保全の回数：18, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -106.6563,  -447.1342,   129.8288,  ...,  -269.1659, -1250.9698,\n",
            "          -56.9793])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   45.1749,  -570.5430,    30.9081,  ...,   107.1867, -1388.0493,\n",
            "           23.5656])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 63.5913,  33.5187,  98.1782,  ...,  65.2660, 275.6294,  77.3324])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([118.2467,  37.8800,  56.9210,  ..., -34.8047,  24.4347, -69.5632])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  71.4112,   35.3907,   90.0148,  ...,  107.6644, -269.4486,\n",
            "          66.0967])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 77.6031, 121.7033, -17.6473,  ...,  40.9572,  55.6741, 185.0130])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 151.0707,  262.1664, -187.4768,  ...,  144.7153, -579.7294,\n",
            "         -17.5260])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -69.9833, -121.9691,  144.1125,  ...,   79.2578,  229.3172,\n",
            "          38.7978])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  76.4113,   -4.2324,   91.5154,  ...,  -25.1539,  186.3616,\n",
            "        -272.4785])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 105.0820, -757.9631,  -23.1991,  ...,   90.8540, -565.4955,\n",
            "         291.8274])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 106.8994,   59.4774, -141.8148,  ...,  327.7943,   66.9920,\n",
            "          30.9747])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -63.2079,  104.3427, -108.7654,  ...,  228.4914,  190.2204,\n",
            "          36.2677])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 177.1615,  -79.8779,  -21.7270,  ..., -165.5101,   74.4209,\n",
            "        -158.4482])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 111.3874,   80.7224,  166.2012,  ..., -110.5836,  -22.8204,\n",
            "        -767.3104])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -0.8172, 110.0077, 124.0562,  ..., 155.4860,  48.6667, -38.1347])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 134.9465,  -98.4215, -192.5644,  ...,  161.5563,   -4.7011,\n",
            "         116.4246])\n",
            "actor loss: 1475.5765547373148, critic loss: 1882160.03515625, entropy: 11730.453308105469, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[65.34953214219968, 61.62657414238272, 0, 0, 1.4853949033307918], 離散行動：[0, 1], 連続行動：0.4631600119173527\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "93エピソード目の累積報酬：-22011.110351240208, 一つ保全の回数：6586, 二つ保全の回数：1586, 三つ保全の回数：20, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  95.3345,  232.5083, -255.9266,  ..., -104.7103, -209.1749,\n",
            "         227.3683])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([150.3258,   9.5511,  33.6735,  ..., 128.1566,  39.7919,  30.1431])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  67.2042, -269.4388,   68.0388,  ...,  142.9121,  109.6641,\n",
            "         -24.4009])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  83.4410,  217.9875,   75.8600,  ...,   85.1409, -248.3418,\n",
            "        -165.8328])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -13.4081, -396.4625,   46.1660,  ...,  -21.9249, -183.3136,\n",
            "          43.6039])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-110.0654,  -37.7845,  -49.6532,  ...,   68.1685,   36.6901,\n",
            "         -66.0596])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -54.8668,    11.7812,   198.8747,  ..., -1393.5104,  -406.4135,\n",
            "          153.9719])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-167.0738,   66.3968,  152.8220,  ..., -191.1985, -174.2589,\n",
            "          17.6320])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -270.3435,   -57.4998,    68.3026,  ...,   110.0692,   118.9015,\n",
            "        -1029.9622])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 160.8964, -375.2935,  -97.0472,  ...,  -23.1549,  257.8546,\n",
            "        -357.7992])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   82.2576,    27.8879, -1393.5104,  ...,   -30.1574,    95.8408,\n",
            "          -21.4410])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-129.4553,  -95.7058,  -74.1335,  ..., -371.1978, -162.5482,\n",
            "         165.5104])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-375.5879,  244.9495,  507.8315,  ...,  -29.5471,   30.8644,\n",
            "         126.8772])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-122.9987,  122.0835,   -7.8066,  ..., -115.2665, -132.7627,\n",
            "         -83.2199])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 396.2233, -160.0314, -422.0318,  ...,  167.1733, -306.1857,\n",
            "        -106.5826])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 226.9501,  -25.7078,  -75.3736,  ..., -114.9579,    8.6144,\n",
            "          65.9025])\n",
            "actor loss: 1276.3528987717314, critic loss: 1951805.0546875, entropy: 11655.759521484375, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[21.88198046765337, 2.9132161893899036, 0, 0, 1.5898978742496366], 離散行動：[1, 1], 連続行動：0.5774015486240387\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "94エピソード目の累積報酬：-21068.744354109906, 一つ保全の回数：6604, 二つ保全の回数：1552, 三つ保全の回数：36, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([314.9662, 195.7965, 188.9416,  ..., 296.0702, 214.5479,  97.5506])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-198.0262, -164.2595, -382.4257,  ...,   -7.3764,  -50.7929,\n",
            "         182.4284])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-544.0341,  139.9077, -228.2842,  ...,  230.7868,   30.5887,\n",
            "          54.4938])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 218.7734,  148.1295, -298.7773,  ...,   18.6905,  109.4494,\n",
            "          24.4618])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -69.1571,   67.8810,   70.8613,  ..., -210.7714,   41.3927,\n",
            "         -17.8865])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([222.6075, 141.1893,  75.7709,  ...,  -0.9981,  26.4728, -11.4930])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  223.4357,   187.3634, -1536.7512,  ...,   -82.3383,    46.3883,\n",
            "          303.7700])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 49.1100,  86.9130,  73.8057,  ..., 111.9476,  38.0579, 179.8857])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-128.2544,   52.4740,  -44.0697,  ...,  136.9843,  -79.3521,\n",
            "          69.9862])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-113.1837,  -33.8138,   81.8161,  ...,   82.1991,  249.3969,\n",
            "          12.6696])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 46.3737, -77.0007, -97.6685,  ..., 105.5188,  38.3204, 107.6122])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-473.6847,   16.4632, -556.2986,  ...,   -6.4260, -357.9373,\n",
            "          17.6815])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-176.1451,   56.9647,  475.9439,  ...,   55.7747, -749.6453,\n",
            "        -151.9591])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 156.1562, -139.2627,  236.4254,  ...,  185.5538,   64.9612,\n",
            "         128.3499])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1417.7531,   -11.6640,  -500.3076,  ...,   215.4225,   -77.8695,\n",
            "          252.0646])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 150.1514,   88.1622,   29.3974,  ...,  -35.6076,  404.7365,\n",
            "        -164.7744])\n",
            "actor loss: 1343.9872631230337, critic loss: 2519990.3046875, entropy: 11964.286682128906, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[15.913228293172262, 0, 0, 0, 1.1791771423706014], 離散行動：[1, 1], 連続行動：0.5843812674283981\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "95エピソード目の累積報酬：-24100.935997820976, 一つ保全の回数：6626, 二つ保全の回数：1545, 三つ保全の回数：21, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-110.1627,  141.2554,  208.6447,  ...,  359.4424,  -15.9318,\n",
            "          93.6205])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 20.0051,  57.4322, 211.9381,  ...,  -4.2882, 177.6743, 152.1537])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -9.0863,   84.0266,  121.8259,  ...,  140.7057,   73.3430,\n",
            "        -309.2239])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  96.7421,  -66.9278, -326.2555,  ..., -213.3801,   36.4465,\n",
            "         192.4843])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-431.2760,  243.1199,  153.3097,  ...,   47.6776,  -26.8390,\n",
            "         155.4423])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 174.8936,  178.5003, -149.1725,  ...,   95.1395,  -79.6221,\n",
            "         110.0967])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 112.5492, -208.7150,   39.9639,  ...,  -58.3360,  -44.6348,\n",
            "         189.5211])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -186.4235, -1412.9041,    36.6335,  ...,  -719.5538,     5.6780,\n",
            "         -145.2617])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-156.2883,  114.8432,  -14.7662,  ..., -218.9624,  -66.9182,\n",
            "        -111.5384])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   37.9679,    76.4742,   217.2115,  ...,  -503.6132, -1641.2141,\n",
            "          208.3300])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 100.7974,  338.6808,  -45.5790,  ..., -158.7390, -145.2245,\n",
            "          26.1431])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   1.6859,  191.3002, -483.7558,  ...,  -43.2041,  177.8725,\n",
            "        -145.1453])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -37.0797, -132.3751,  144.6763,  ...,  -17.6388,  159.6588,\n",
            "         107.4829])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -83.0640,  237.1859, -421.4196,  ...,  226.3395,  146.7170,\n",
            "          34.1855])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   13.5209,    25.6892,   -75.9478,  ..., -2329.1382,   173.8173,\n",
            "         -273.9152])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 132.5973, -222.0027,  139.1454,  ...,   34.6111,  140.3524,\n",
            "         -19.4757])\n",
            "actor loss: 1364.8466033173913, critic loss: 2125166.640625, entropy: 11852.0517578125, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[1.30039134483357, 0, 0, 0, 2.326225390738432], 離散行動：[1, 1], 連続行動：0.5481581948697567\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "96エピソード目の累積報酬：-23382.986008741238, 一つ保全の回数：6632, 二つ保全の回数：1540, 三つ保全の回数：20, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -14.6908, -254.9325,  201.5395,  ...,  113.9661,  117.5359,\n",
            "        -104.6579])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -44.6631,  235.5222, -373.7654,  ..., -127.6443,  -41.8411,\n",
            "        -352.8619])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-353.3030,   58.0004,  -23.8345,  ...,  134.7350,   -9.2770,\n",
            "         207.4544])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-468.3753,  203.2457, -100.3487,  ..., -158.7927,   72.4149,\n",
            "         121.5099])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 117.2564,  281.7867, -251.5006,  ...,  157.3761,  -25.4210,\n",
            "         157.8543])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 79.8711,  87.6395,  94.1167,  ..., -60.6623, 172.4708,  38.3790])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 118.2150,   99.7335, -252.4222,  ...,   45.9452,  122.5658,\n",
            "        -117.7825])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -78.3003,   71.5778,  334.1931,  ..., -127.4395, -213.6756,\n",
            "         109.2077])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([254.0107, -96.3256, 147.8499,  ..., -58.7171, 172.1498, 112.3042])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  80.8683,  216.7261, -392.5699,  ...,  195.2685,   99.9554,\n",
            "         101.5120])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-155.6625,    1.8562,  -12.8857,  ..., -123.5947, -138.6798,\n",
            "        -520.8406])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([148.5812, -37.8804,  65.9509,  ...,  96.9056, 171.0607, 237.2530])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -188.5866, -1633.9659,  -318.8933,  ...,   245.2736,    24.7600,\n",
            "            7.3608])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  465.0314,   143.7133,   -81.9598,  ...,  -175.2044,    69.3737,\n",
            "        -1379.8198])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -52.9329,  -80.3506,  -62.9737,  ...,  -17.3185, -175.9804,\n",
            "         258.8594])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 107.3294,   43.7574,  114.6421,  ..., -333.3372,  262.5854,\n",
            "         119.2426])\n",
            "actor loss: 1222.3502494305574, critic loss: 1982329.359375, entropy: 11582.703918457031, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[2.9626955141273243, 36.893154076677405, 0, 0, 1.2927198033101077], 離散行動：[1, 1], 連続行動：0.58396777510643\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "97エピソード目の累積報酬：-20522.396265494524, 一つ保全の回数：6646, 二つ保全の回数：1527, 三つ保全の回数：19, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 175.3221,   25.4030,    0.6302,  ..., -219.0025,  -20.0123,\n",
            "        -102.2294])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  43.5382,  -63.8012,  224.3635,  ...,  115.3515,  -44.8982,\n",
            "        -201.8856])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 22.8922,  27.4270, -35.2933,  ...,  54.5008, 150.4163, -18.7891])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([161.9422, 206.2591, 185.9733,  ...,  71.4497, 111.6310, 335.2113])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -16.6323, -108.5199,  -56.4183,  ...,   97.4369,  138.0166,\n",
            "          87.0521])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-276.2105,  -43.0728,  200.5613,  ...,  187.3204,  -32.5480,\n",
            "         -41.2877])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -77.4770, -1291.7074,   206.2591,  ...,  -307.0924,    30.6728,\n",
            "          -29.7374])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-307.3169,  124.7155,   44.8465,  ...,  113.9132,   65.7444,\n",
            "          45.0341])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 169.2724, -134.7271,  -14.8661,  ..., -503.4795, -126.4659,\n",
            "          80.9605])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  44.6769,   82.1215,  -48.1368,  ..., -241.7131,  -97.6132,\n",
            "        -509.2741])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  58.3340,  100.9461,  -78.3313,  ...,  -93.2322,  -14.5987,\n",
            "        -126.8645])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 112.1764, -197.1167,  146.2473,  ...,   39.5817, -282.4433,\n",
            "          -3.3721])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 148.6866, -209.4903,  174.3323,  ...,  119.7627,  -58.1766,\n",
            "         -28.8296])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 144.6449,   18.5024,  -35.9595,  ..., -442.5035,   51.3998,\n",
            "          26.4265])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 46.4653, -79.0994,  83.0703,  ..., 202.7296, -63.6838, -67.6696])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  89.1135,   18.1832,   23.9938,  ..., -439.8317,  -46.2488,\n",
            "         165.5493])\n",
            "actor loss: 1203.224380270576, critic loss: 2000946.8125, entropy: 11513.291809082031, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[40.536923230985636, 15.954818363442515, 0, 0, 1.9024965888838556], 離散行動：[1, 1], 連続行動：0.49412562046200037\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "98エピソード目の累積報酬：-22073.63794856227, 一つ保全の回数：6635, 二つ保全の回数：1543, 三つ保全の回数：14, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -64.1275, -462.4257,  -69.8891,  ...,   70.1112, -319.0984,\n",
            "         187.2697])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   86.0933,   162.1304,  -195.9745,  ...,   231.3144, -2224.9810,\n",
            "          -94.2137])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -99.6761,   70.5972,  -18.7095,  ...,  -94.0807,  123.0954,\n",
            "        -144.9530])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([194.2220,  76.4549, 128.0178,  ...,  80.8512, -97.3504,  26.3017])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-30.3437,  18.7476, 247.7323,  ...,  -5.9625, 131.6443, 216.7842])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  90.7397,  130.3420,  -38.6446,  ..., -258.5589,  -49.7696,\n",
            "         433.1397])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   20.6591, -1852.6445, -1914.9066,  ...,    74.7710,   204.3530,\n",
            "         -360.1523])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 328.0958,  -80.8073, -259.3403,  ...,  314.9166,  248.8136,\n",
            "         219.0018])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  140.4686,    19.6894,    58.7058,  ...,    33.2521,   -29.6241,\n",
            "        -1439.0568])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -29.1463, -337.3728,   -5.8209,  ...,   41.8836,   15.0327,\n",
            "        -262.7315])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  64.2418, -991.3121,  170.3996,  ..., -266.4496, -223.9568,\n",
            "          -6.1029])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -37.2090,  -54.2604,   -6.4740,  ...,  157.2773, -534.8928,\n",
            "         148.8449])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -0.7516,  -22.7953,  -86.6064,  ...,  -62.9633,  -42.7243,\n",
            "        -207.5861])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 28.4933, 217.1519, -64.2964,  ..., 225.3749, -23.0210, -91.6565])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-107.2937,   49.9086,  224.5203,  ..., -250.4914,  -23.3414,\n",
            "         -21.2096])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   35.1330,   117.0842,   -22.1032,  ...,  -106.8305,   110.3400,\n",
            "        -1208.4285])\n",
            "actor loss: 1188.326283248547, critic loss: 2624846.390625, entropy: 11660.310241699219, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[28.36598893132285, 16.133674637056046, 0, 0, 1.3727225410177535], 離散行動：[1, 1], 連続行動：0.471055107191205\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "99エピソード目の累積報酬：-18331.305951463717, 一つ保全の回数：6669, 二つ保全の回数：1499, 三つ保全の回数：24, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 286.8862, -185.6175,  303.2168,  ...,  -20.3732,  -52.4438,\n",
            "          47.6550])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -1.5240, 128.8739, 208.3906,  ..., 372.3228,  79.6868,  85.2757])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  25.1850, -115.6704,  -46.5511,  ...,  158.4969, -354.9353,\n",
            "         116.8829])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -77.4731,   84.6920,    8.5168,  ..., -414.8145,   84.9208,\n",
            "         -33.7858])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  97.5596, -212.2410,   78.2318,  ...,  348.1751, -339.0080,\n",
            "          95.6096])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 95.7237,  14.0319, 128.0710,  ...,  65.4693, 118.9347, -42.3045])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -61.7283, -132.7418, -217.0402,  ...,  -21.8943,   37.8696,\n",
            "         -80.2060])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-134.6629,  112.5571,  157.3403,  ..., -212.3332, -206.0593,\n",
            "         123.1187])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  20.4916,   96.3849, -205.7593,  ...,  237.4053,   18.1581,\n",
            "        -435.4393])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-322.8573, -175.5208, -132.3813,  ..., -630.3273,   96.3916,\n",
            "          39.3168])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-340.0473,  313.6837,  130.1360,  ...,  141.5723, -306.4207,\n",
            "          72.1824])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 36.4572, 198.1851, -46.9795,  ..., -61.1506, -14.8902, 173.6533])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -9.0390,  146.3461,  288.9698,  ..., -178.9390,  145.8966,\n",
            "         -63.5207])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -9.7343,   61.4539, -219.9157,  ...,  -85.1948,  139.5804,\n",
            "        -169.4256])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 131.1711, -186.6959,   68.8739,  ...,   27.9830,  154.2811,\n",
            "         379.7774])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([264.5117,  24.4344, 128.3004,  ..., 128.3573, -91.0429,  23.1080])\n",
            "actor loss: 1133.501298634724, critic loss: 2712270.8046875, entropy: 11399.162292480469, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[67.3025420502121, 42.19265338805968, 0, 0, 1.00651270728015], 離散行動：[1, 1], 連続行動：0.5106829022988677\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "100エピソード目の累積報酬：-21165.642844968886, 一つ保全の回数：6650, 二つ保全の回数：1527, 三つ保全の回数：15, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-218.6751,   33.1820,  118.1413,  ..., -150.2773,  107.4510,\n",
            "        -215.8832])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  44.1538,  150.6277,   83.1705,  ...,  -52.0423,    1.5738,\n",
            "        -597.1332])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-239.8002,  233.7958, -221.8970,  ..., -344.1281, -142.5893,\n",
            "         -26.4079])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-143.7200, -258.8094,  176.6998,  ...,  -72.3709, -270.5886,\n",
            "         142.6384])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -93.0459,  278.2885, -372.3126,  ...,  -56.9975,  391.0305,\n",
            "        -135.5214])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 47.4076,   5.3819, -19.7986,  ...,  13.0111, -23.9394,  17.2706])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 137.4701, -118.9099,  -69.0731,  ...,   82.3696,  107.8508,\n",
            "         187.6326])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  77.3587,   60.3399,   40.0722,  ..., -313.1045,  178.7360,\n",
            "           9.2327])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2224.7268,   -59.7760,    49.7545,  ...,    57.3857,   276.4027,\n",
            "          290.4643])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  99.1774,  273.9769,  -76.6503,  ...,  -14.6982, -258.2100,\n",
            "         181.1487])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   8.2566, -273.3397,  123.4494,  ...,  517.5797,  200.0559,\n",
            "         278.7694])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -49.3518,   -65.0847,    72.2058,  ...,    18.4724,  -190.6889,\n",
            "        -2402.0825])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -35.5483, -124.5667,    8.6399,  ...,  137.9348, -216.9120,\n",
            "         135.8098])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-10.6136,   6.1404, 180.7016,  ...,  94.4122,  11.8463,  61.4129])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  71.7566,  -18.9429,   67.7704,  ..., -372.5089,  -43.3789,\n",
            "        -247.7082])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([123.9626, 338.4403, 237.0966,  ..., -79.2259, 118.5222, -20.5144])\n",
            "actor loss: 1296.5735239648009, critic loss: 3173157.0078125, entropy: 11541.411193847656, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[35.32002205796018, 94.06387492944756, 0, 0, 1.4843920310801213], 離散行動：[0, 1], 連続行動：0.5493845343589783\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "101エピソード目の累積報酬：-21596.021974636278, 一つ保全の回数：6670, 二つ保全の回数：1506, 三つ保全の回数：16, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([188.3988, 187.9092, 180.4688,  ..., -96.7855, -69.8337, 423.7968])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 398.8722,  154.1990, -101.8827,  ...,  312.5610,  156.2832,\n",
            "         148.0239])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  3.4635,  82.4678,  -7.0808,  ...,  53.5911, 166.8801,  75.5119])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-340.0572,  -14.9103,  317.6698,  ..., -556.2823,  -75.9092,\n",
            "           2.5783])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-27.1709, -36.8734, 151.7072,  ..., -12.0308, 107.8407, 180.3261])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 255.7453,  -24.9632,  145.4327,  ..., -405.7592, -435.1126,\n",
            "        -657.1729])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([246.0572, 125.7037,  27.7470,  ..., -12.2588, 224.3656, 196.2814])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 112.8180, -176.0746, -257.6678,  ..., -183.6144,  -35.2221,\n",
            "          75.1677])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-125.5956,  101.9945,  185.5349,  ..., -114.4483,  328.3760,\n",
            "        -250.4030])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 222.5589, -125.0544,  139.9251,  ..., -405.7592, -179.6595,\n",
            "          92.9932])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 199.0354,   69.6956,  127.9477,  ..., -262.4077, -464.3797,\n",
            "          20.9901])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   81.8593, -1262.2511,  -736.7054,  ...,    54.4336,    44.3364,\n",
            "          164.3417])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-65.3720, 203.0350, -30.3423,  ...,  -4.3375,  17.5657, 171.4177])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -23.2563,  -97.6108,   65.1109,  ..., -291.0744,  278.9287,\n",
            "         -16.8226])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  13.0828,   52.8552, -402.0156,  ..., -415.2603,  -31.3901,\n",
            "          75.6176])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -182.4569,   233.3070,   304.9785,  ..., -2488.7832,   -90.5403,\n",
            "         -343.5960])\n",
            "actor loss: 959.2483423631911, critic loss: 2861732.7421875, entropy: 11532.14306640625, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0.9870777087060391, 61.878480471555235, 0, 0, 2.475196938327812], 離散行動：[1, 1], 連続行動：0.5457864999771118\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "102エピソード目の累積報酬：-22626.001181790907, 一つ保全の回数：6704, 二つ保全の回数：1475, 三つ保全の回数：13, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 100.1386,   -2.2933, -105.8444,  ..., -137.5522,   -9.6887,\n",
            "         123.3665])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([250.6730, -53.7047, -80.8954,  ..., 156.7002,  17.5368,  72.5054])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 233.8947, -218.3935, -362.9420,  ...,  146.1981,   88.3253,\n",
            "          59.3114])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-210.3891,  187.8555,  164.0704,  ...,   10.3249,   29.5912,\n",
            "         106.6008])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 135.6523,    8.3701,  138.5738,  ..., -102.8016,   49.8660,\n",
            "         165.6814])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  185.4968, -1593.3784,  -433.8812,  ...,   -66.0322,    48.5467,\n",
            "          177.0779])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -60.7421, -257.7403,  370.5179,  ..., -100.2545, -494.4890,\n",
            "        -228.2785])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 254.6952,  115.1019,   17.0104,  ..., -114.8074,   44.0565,\n",
            "        -232.0556])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-200.5558,   27.7347,  254.5217,  ...,   41.2197,  181.4036,\n",
            "         125.6203])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  52.1546,   60.4953,  126.8968,  ...,   54.1562, -438.5309,\n",
            "        -257.9579])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-134.3097,   50.8920, -246.7100,  ...,    7.2636,   36.1731,\n",
            "         246.6392])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  107.8735,    83.2709,  -471.4545,  ...,  -150.5294,    56.7337,\n",
            "        19426.0762])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-242.0184, -127.1883,  328.9152,  ..., -137.1691,  235.9259,\n",
            "        -234.0174])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -1.9132, 145.2092, 206.8162,  ..., 317.3915, 109.6333,  91.2254])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-111.5868,  -75.0846,  206.1270,  ...,  -91.3748,  162.6944,\n",
            "        -156.9757])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-232.5997, -102.8016,   17.3895,  ...,  124.1155,  224.9662,\n",
            "        -113.2657])\n",
            "actor loss: 1118.2608648489781, critic loss: 2287740.359375, entropy: 11124.873840332031, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[69.38702537831335, 40.155887896714724, 0, 0, 2.088967502090597], 離散行動：[1, 1], 連続行動：0.489950442686677\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "103エピソード目の累積報酬：-21652.43950781587, 一つ保全の回数：6691, 二つ保全の回数：1491, 三つ保全の回数：10, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-672.4235,   56.7096,   99.2176,  ...,   31.7124,  -29.8809,\n",
            "          83.2022])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -67.9350, -1719.7517,   121.3429,  ...,  -187.0091,  -164.2951,\n",
            "         -289.3193])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  22.5941,  281.5138,    9.1456,  ..., -116.8858,  175.2892,\n",
            "           6.4527])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([226.2225,   9.5357, 120.8523,  ..., -25.4081,  63.9792,  10.5297])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -24.8700,  247.4033,  305.1414,  ...,   28.4271, -152.7625,\n",
            "         357.8256])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([190.1824,  43.3362,  52.8816,  ..., 270.2849, 170.9836, 203.9888])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 160.0043,  -58.7461, -117.0108,  ...,   57.6945,   17.3910,\n",
            "          93.9368])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  30.2725,    3.9048,  -15.3357,  ..., -132.2004,  258.6058,\n",
            "         117.2941])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   86.3769,    68.4949, -1875.5424,  ...,   -47.4015,   126.5087,\n",
            "          -17.9269])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 114.0000, -207.7070,   12.6562,  ..., -160.9438, -184.9395,\n",
            "         -21.0296])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -33.9194,  -148.8631, -1389.9467,  ...,   122.5579,   -22.8523,\n",
            "          128.4199])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -84.6014,    16.5469,    67.4092,  ...,   -91.4164, -1315.9216,\n",
            "          192.5098])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-19.1993, 152.3089, 202.2556,  ..., -47.1786,  36.4243, -81.7917])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-15.0406, 252.7991,  61.6935,  ..., 278.2634,  39.9495, 139.3060])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([110.9866, -96.4868,  18.9952,  ..., 178.8212, 252.5110,  13.7398])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-133.8718,  126.4184,    2.2692,  ...,   80.2970,  -23.1154,\n",
            "         194.3088])\n",
            "actor loss: 1322.751861246118, critic loss: 2908379.1328125, entropy: 11306.74267578125, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0, 18.997105122947403, 0, 0, 2.028996554825742], 離散行動：[1, 1], 連続行動：0.5094003146514297\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "104エピソード目の累積報酬：-24044.075503382337, 一つ保全の回数：6722, 二つ保全の回数：1459, 三つ保全の回数：11, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-174.9413,  250.0106, -168.8569,  ...,  179.7175,  -84.4283,\n",
            "        -153.6809])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -64.9539,  132.4604,  165.8811,  ..., -106.0284, -950.2734,\n",
            "         108.3173])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 272.8542,  165.1986,   66.1880,  ...,   29.3061, -346.8876,\n",
            "         121.7376])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-38.1676, 340.2416, 165.9408,  ..., 172.8713,   2.7405,  89.7015])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 335.1343, -502.5172,  332.8542,  ...,  100.1336,   57.8970,\n",
            "        -253.6114])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  312.2812,    51.5468,   103.7260,  ...,  -211.1742,   146.1195,\n",
            "        -1468.1116])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -67.4049,  135.1223,  186.5079,  ..., -100.5151,  -27.4772,\n",
            "        -360.9161])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-211.4182,   84.6145,    6.6519,  ...,  117.5708,  247.1558,\n",
            "          62.1391])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([485.7459,  87.6562, 116.3187,  ..., -74.6941,  -3.7255, 122.3690])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  79.8026,  -12.6034,  -83.6108,  ...,  216.4326,  182.0560,\n",
            "        -114.4542])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 40.1791, 133.2715, -31.7612,  ..., 132.7014,  24.9079, -96.2630])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-96.0497, -64.9539, 222.3959,  ...,  35.7028,  18.4417, -16.2070])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   97.3179,   140.8479, -2064.6089,  ...,  -102.8595,   207.7347,\n",
            "         -131.3788])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 168.9008,  -52.5293,  146.0974,  ..., -212.2738, -228.0475,\n",
            "         238.9760])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 165.6851,  -37.2267,   79.5218,  ...,  -98.0591, -148.3147,\n",
            "         160.2257])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 100.5128,  -76.7009,  107.7683,  ..., -131.0300,   17.5557,\n",
            "         201.0779])\n",
            "actor loss: 1268.9379309892288, critic loss: 2418509.3515625, entropy: 11457.460571289062, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[71.50972922856276, 28.84927372143948, 0, 0, 1.3265907775772214], 離散行動：[1, 1], 連続行動：0.6453766077756882\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "105エピソード目の累積報酬：-20268.09561464038, 一つ保全の回数：6709, 二つ保全の回数：1461, 三つ保全の回数：22, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  245.6980,   -96.4896,    58.8086,  ...,   135.7730, -1480.8488,\n",
            "           33.3320])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  324.8390, -1137.8760,   157.2483,  ...,  -324.6912,  -133.3825,\n",
            "         -841.3806])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 135.0266,  216.5211, -153.3188,  ...,  -54.4652,  141.3485,\n",
            "         -38.6089])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -9.1428, -264.9419,   78.1455,  ...,  157.8943, -127.6867,\n",
            "         -36.2099])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-284.3740,   32.0439,  -37.8550,  ..., -143.1807, -100.1358,\n",
            "         112.3595])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-505.1599,   41.4141,  286.7962,  ...,  170.7513, -212.3465,\n",
            "         183.2633])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-395.7464, -113.9371, -119.0212,  ...,   69.8971,  -15.1199,\n",
            "         160.6988])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([315.1749, 168.4565, -19.5638,  ..., 148.1416, 164.2247, -81.3983])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-260.8481,  283.6727,   20.4291,  ...,  -15.6745,  376.4377,\n",
            "         -87.0934])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 390.4130,   95.4427,   27.5855,  ...,   96.2497,  138.9294,\n",
            "        -106.1670])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-341.5420,  264.9697,  116.1583,  ...,   53.6889,  -48.5595,\n",
            "         144.0245])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([148.6216,  67.9320,  71.3429,  ..., -74.2602, -36.5820, 121.3020])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1188.8713,    92.6445,   -37.4786,  ...,   116.1583,   -29.7884,\n",
            "         -726.1304])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-135.4211,  -44.1589,  120.6552,  ...,  -72.4227,  279.2979,\n",
            "         107.6848])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-432.6149,    8.9095, -325.0510,  ...,  323.5990,   81.3198,\n",
            "        -283.9114])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  39.5386,   71.9486, -404.8204,  ...,   77.4094,  215.9681,\n",
            "         382.8719])\n",
            "actor loss: 1066.5733904410015, critic loss: 1978312.9921875, entropy: 11370.540832519531, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[21.982290566430216, 0.6313844390507465, 0, 0, 2.176662622545998], 離散行動：[1, 1], 連続行動：0.48088704608380795\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "106エピソード目の累積報酬：-24591.952891970795, 一つ保全の回数：6699, 二つ保全の回数：1489, 三つ保全の回数：4, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  79.5100,  -90.4288,   42.5826,  ...,  297.7573,   41.0126,\n",
            "        -356.0686])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 76.4020, 156.3040, 114.8859,  ...,  19.7017,  79.6615,  40.6078])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([101.8207, -48.8367, 124.3899,  ..., -45.1348, 165.1020, 147.4525])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-198.1597, -113.3384,   78.7794,  ...,  180.3172, -306.2842,\n",
            "         263.0641])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 131.2819,  181.2485, -201.5007,  ...,   43.3895, -517.1870,\n",
            "         136.0212])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-61.0555,  29.8173, 278.0414,  ...,  -1.1322,  25.0769,  50.6631])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -383.3782,    67.7028,  -335.3936,  ...,  -772.0129, -1713.1654,\n",
            "           51.9001])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -69.1015,  131.8856, -438.1165,  ...,  -92.3558,   89.8386,\n",
            "         239.9592])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-189.0686,   -0.8342,   88.1584,  ..., -293.8353,   78.0196,\n",
            "        -215.8909])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 171.6303, -316.1167,  169.9268,  ...,   50.8405,   16.1520,\n",
            "         -99.6330])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([109.0145,  18.6408, -62.2405,  ...,  97.0559, 129.9388, 296.8893])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-17.5996, -66.6005, 168.9921,  ..., -12.6388, -75.0762, 167.2673])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 151.7207,   -2.9242,  244.3674,  ...,   86.7460,  164.3876,\n",
            "        -109.8001])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  56.8904, -263.5226,  -35.7723,  ...,    3.6547,  253.7085,\n",
            "          -5.2213])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 300.0341, -108.2997, -109.5862,  ...,  -40.8901,  202.5371,\n",
            "         -24.2201])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 102.5372, -193.8509,   66.1920,  ..., -157.8439,  -35.5521,\n",
            "         -90.9241])\n",
            "actor loss: 1103.9727114516863, critic loss: 2062774.3984375, entropy: 10995.361877441406, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[9.063029128828356, 28.928695440119505, 0, 0, 1.8271832267410215], 離散行動：[1, 1], 連続行動：0.5011462679831311\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "107エピソード目の累積報酬：-20815.70522910963, 一つ保全の回数：6695, 二つ保全の回数：1485, 三つ保全の回数：12, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 53.7409,  64.0012,  74.7067,  ...,  24.1029, -70.3515,  12.2858])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-75.6266, 121.6306,  35.1330,  ..., -23.5820, -50.7785, 129.7830])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -8.0475, -38.8708, 255.4625,  ..., 144.0353, 178.1753,   2.0961])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   9.6972,   77.8005,  -38.9451,  ..., -199.0748, -116.8118,\n",
            "         -14.0368])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-3.3863e+02,  3.3588e+01,  1.7110e+02,  ..., -1.1982e+01,\n",
            "         1.0812e+02, -1.4340e-01])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -16.8784,   206.9688,  -502.0450,  ...,     6.3392,    30.7852,\n",
            "        -1623.7731])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([122.0275, 135.0758, 164.3892,  ..., 186.3757,  95.3054, -80.5629])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-2.3056e+02,  1.3942e+02,  8.7281e+01,  ...,  1.7734e-01,\n",
            "         1.6783e+02,  9.2711e+01])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  72.1977, -232.1500,  -87.7833,  ...,   48.1412,  108.4725,\n",
            "         122.7202])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 64.7025,  39.6114, 266.8884,  ..., -90.2012, -17.6312,  65.3871])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-408.4464,  128.0561,  -47.8629,  ...,   75.0505,  183.6758,\n",
            "        -162.5678])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-38.1436, 207.5126, 231.6608,  ..., -60.1718, -28.4530,  37.5786])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -79.4402,  -20.0569,  140.2346,  ..., -105.1281, -125.2622,\n",
            "         194.8941])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 25.9418, 209.7850, 134.9403,  ..., 111.4164, 148.6068, 325.6308])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([101.5105,  -7.3604,  87.7142,  ..., 111.3150, 199.3743, 168.4594])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-226.5344,  138.0363,  145.5882,  ...,   56.2617,  173.0480,\n",
            "          80.8910])\n",
            "actor loss: 1289.3027456206607, critic loss: 2637919.5546875, entropy: 10773.908325195312, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[28.448464473359973, 76.10938520498935, 0, 0, 1.1854802126063102], 離散行動：[1, 1], 連続行動：0.40501923114061356\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "108エピソード目の累積報酬：-19727.658008047933, 一つ保全の回数：6726, 二つ保全の回数：1459, 三つ保全の回数：7, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -97.7366,  108.0882, -202.9096,  ...,  -81.6804,  -36.5421,\n",
            "         670.8128])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 70.0766, 178.6858, -43.7060,  ..., 201.0242, -42.6545, -18.6776])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 100.0306,  210.0756,  109.1682,  ..., -133.9803, -294.8646,\n",
            "         189.1115])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-163.7590,  155.8380,   46.0946,  ...,  128.3930,  -20.0307,\n",
            "        -104.8347])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  67.1179, -193.2169, -183.2370,  ...,  -62.0321,   34.6597,\n",
            "        -226.6566])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  62.3633, -362.1056, -100.5521,  ..., -266.0914,  232.2583,\n",
            "          71.1595])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-184.4010,   39.7411,  134.5380,  ...,  129.7637, -184.5726,\n",
            "         271.8605])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  190.0890,    -3.1897,   389.8169,  ...,    70.0334,   283.1743,\n",
            "        -2336.3816])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -23.7540,  146.8543,  122.6080,  ..., -123.8937,  -83.5193,\n",
            "         -10.5421])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -77.5373,   152.5563, -1510.2318,  ...,   389.2877,    86.8666,\n",
            "          383.3637])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  30.3609,  292.6948,  184.8561,  ...,  133.2164,   89.7697,\n",
            "        -250.8735])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([229.4126, 215.1013, 246.6562,  ..., 162.6407,  16.2832, 207.6762])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  95.1834,   74.2101,  -29.2940,  ...,  -93.3783, -160.4150,\n",
            "         104.7141])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 253.6813,   -4.9496, -131.3543,  ...,   25.9837, -232.8883,\n",
            "         -67.2761])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -48.1909, -1393.9138,  -180.9176,  ...,    67.3978,   -46.4478,\n",
            "           40.1625])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-422.2170,  -11.0016, -482.9085,  ...,  153.0522,   64.2996,\n",
            "         110.5097])\n",
            "actor loss: 1240.9650037522129, critic loss: 3066045.21875, entropy: 11078.843933105469, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[65.80360131063767, 28.84784408378064, 0, 0, 1.0746167854969104], 離散行動：[1, 1], 連続行動：0.396784745156765\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "109エピソード目の累積報酬：-19483.21144133925, 一つ保全の回数：6735, 二つ保全の回数：1441, 三つ保全の回数：16, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-287.4305, -214.1631, -299.9607,  ...,   46.0190,   27.3099,\n",
            "        -144.4830])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 243.7326,   50.5793,  120.2271,  ..., -182.2236,  171.9525,\n",
            "         -48.1116])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-116.7022,   29.8821,  172.7365,  ..., -180.4516, -253.5594,\n",
            "        -248.3754])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 284.1370,   75.8917,    7.9468,  ..., -125.2205,  235.9224,\n",
            "         300.5312])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-181.3898,  -51.9252,  -60.8114,  ...,  235.0830,   60.6879,\n",
            "          30.0228])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -14.4897,  644.1409, -180.4516,  ...,  223.0417, -417.6990,\n",
            "          26.1120])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-119.5101,  -38.9039,  187.0863,  ...,   89.1536,   37.8668,\n",
            "        -242.2799])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 2.0774e+00, -2.4164e+02, -3.9118e+02,  ..., -2.1835e+01,\n",
            "        -2.5939e+03,  8.1845e+01])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  31.6387,  269.3126,  132.8032,  ..., -174.3586, -156.3559,\n",
            "        -190.6494])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 189.3559,    7.5075,  -41.5722,  ...,  -16.0466,  367.2476,\n",
            "        -236.1838])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-552.6223, -274.7873,  402.0311,  ..., -120.2317,  173.5860,\n",
            "         201.1916])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 146.8958,  -98.1997, -127.7291,  ..., -440.2076,   59.9907,\n",
            "         197.8495])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  53.1524, -156.5390,  498.6900,  ...,   -1.1051, -352.7664,\n",
            "          79.8097])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -99.5406,  143.4948,  362.9803,  ...,   62.0939, -195.8873,\n",
            "         123.6628])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-204.6268,   31.6282,  -87.9404,  ...,  877.3784,  114.4397,\n",
            "         -24.1601])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  80.0030,  433.5567,   55.1266,  ...,   76.3406, -256.9143,\n",
            "        -259.4879])\n",
            "actor loss: 1158.0663601188169, critic loss: 3527658.65625, entropy: 11556.919677734375, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[33.48137460637375, 3.63668794049088, 0, 0, 2.737335834668377], 離散行動：[0, 1], 連続行動：0.5402153395116329\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "110エピソード目の累積報酬：-20820.038446643255, 一つ保全の回数：6728, 二つ保全の回数：1454, 三つ保全の回数：10, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  164.6507, -2820.8333,   -18.9127,  ...,   -90.2601,     7.8046,\n",
            "          -39.1077])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 350.6267, -386.9167,  241.6762,  ...,  -88.3872,  298.8106,\n",
            "         516.5930])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 153.6542,  153.4399, -417.0957,  ...,  218.5441, -103.5606,\n",
            "         204.5829])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-395.3015, -137.8233,  -53.2751,  ...,  187.1618,  230.9304,\n",
            "        -230.9241])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 362.4901,  581.1273,  153.6542,  ...,  101.7010, -103.2418,\n",
            "         -56.4298])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 242.0451, -109.4986,  -57.8408,  ...,  -93.9038,    1.1864,\n",
            "         277.6048])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 225.1250,  328.1885, -266.0359,  ...,  264.5320, -326.9361,\n",
            "        -260.7064])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 133.2158, -421.1493,  143.6818,  ..., -132.3618,   34.5302,\n",
            "         -37.2265])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  84.8888,  891.7095, -639.1934,  ...,  -64.4877,  635.8938,\n",
            "        -121.9781])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 441.2226, -338.5944,   78.3791,  ..., -172.9969,   27.1396,\n",
            "        -227.7992])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 186.8542,  379.7629, -136.4950,  ...,  187.3901, -128.6168,\n",
            "          73.9715])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -468.9145,  -119.2741, -1747.0052,  ...,  -162.5121,    59.1297,\n",
            "         -224.4726])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-94.6485,  55.4500, -16.1304,  ...,  19.5691,  87.0242, -48.5598])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 124.9321, -272.9031, -395.7152,  ...,  133.7092,  180.2705,\n",
            "         635.6917])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   75.1414,   -76.3315, -1771.7887,  ...,   -77.7296,  -397.9700,\n",
            "          345.9671])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  98.6111,   62.2762,  138.0127,  ...,  -43.0031, -126.7870,\n",
            "         503.3267])\n",
            "actor loss: 1263.0710426335258, critic loss: 3629035.03125, entropy: 11856.593688964844, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[87.59691208223212, 17.16457089564509, 0, 0, 1.8891173881050125], 離散行動：[0, 1], 連続行動：0.4391523264348507\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "111エピソード目の累積報酬：-23643.79787284231, 一つ保全の回数：6644, 二つ保全の回数：1538, 三つ保全の回数：10, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-259.0756,  -17.1392,  109.8958,  ...,  372.2220,  -18.0470,\n",
            "          45.3687])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-119.6936,  -21.5294,    3.2702,  ...,   98.8704,   -0.4508,\n",
            "         -26.5287])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-289.2645, -207.1009, -204.9187,  ..., -423.0384,    7.2793,\n",
            "        -180.2704])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-132.5258,  -83.8152,  -93.0597,  ...,  512.5922, -138.0211,\n",
            "         153.2603])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 237.2951,   14.6292,  106.1230,  ..., -140.8044,  448.2154,\n",
            "         -42.4287])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  46.7992, -181.1484, -185.8774,  ...,  -55.4084,  114.6328,\n",
            "          42.5209])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-252.2243, -250.2500,  -50.5637,  ...,  431.6669,   64.7461,\n",
            "          65.7897])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -0.7394, -129.1927, -249.2647,  ..., -167.6781,   25.1737,\n",
            "        -172.8124])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-262.7454, -215.9866,  -92.2428,  ..., -274.5770,  -31.5453,\n",
            "         131.7727])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 406.3113,   96.6871,  133.6041,  ...,  -99.2141,  -43.6283,\n",
            "        -215.6612])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-167.8161, -199.6968,  181.6986,  ...,  176.1925, -252.4390,\n",
            "        -321.5316])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 133.5172,  145.6175,   96.4705,  ..., -157.4274, -596.0054,\n",
            "         154.8407])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 301.6304,   26.5433, -210.1070,  ...,  169.5751,   21.9160,\n",
            "         138.8793])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-181.2515,  280.3271,  329.1382,  ...,   81.1515,  -57.9896,\n",
            "         285.0694])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -41.5420,  370.2669,  158.9194,  ...,   57.6147,  119.0828,\n",
            "        -155.4566])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  68.0906, -225.0113,  142.0266,  ..., -591.4572, -213.9013,\n",
            "         -16.1085])\n",
            "actor loss: 1097.5345823160503, critic loss: 2027920.0546875, entropy: 11649.55029296875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[74.40254252867399, 2.4379072405551914, 0, 0, 2.360483879630567], 離散行動：[1, 1], 連続行動：0.4681190177798271\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "112エピソード目の累積報酬：-18695.023454573267, 一つ保全の回数：6625, 二つ保全の回数：1554, 三つ保全の回数：13, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-123.7368, -201.8195,  234.7727,  ...,   11.3056,   84.6505,\n",
            "          96.5650])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  26.6458, -204.2716,  585.6441,  ...,   24.5596,  453.3687,\n",
            "          43.6389])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 187.4797, -274.3074,   65.3979,  ...,  129.1536,   17.4306,\n",
            "         -22.8453])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -32.6902,  -29.5904, -366.1953,  ...,   70.2400, -298.3023,\n",
            "          -2.6719])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -20.4648, -363.2545,   95.1223,  ...,   67.9103, -287.6439,\n",
            "        -161.5160])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-25.5930, 170.2774,  25.1958,  ...,  59.6996, 266.5199, -97.8079])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-230.5305, -181.7900,  318.1102,  ...,  135.8602,  260.0903,\n",
            "        -511.6786])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-388.8651, -277.1913,  -31.6847,  ...,  195.8991,   12.2026,\n",
            "        -494.5743])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   21.9952,  -152.1167,   216.2128,  ..., -1440.6665,   116.9162,\n",
            "            5.0892])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-353.8723, -145.6244, -211.8268,  ..., -119.8860, -265.6865,\n",
            "         111.2441])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-83.3274,  45.3854,  64.9201,  ..., 120.7630, 236.7225, -93.0818])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 103.9991,  151.0486, -157.9201,  ..., -340.3922,  -40.0473,\n",
            "          22.5383])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -18.3093, -319.3019,   18.8391,  ...,   19.6249, -174.9642,\n",
            "         300.7018])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -11.9451, -240.3366,   24.9090,  ...,   -2.0830,   56.8506,\n",
            "          47.3400])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 88.6939,  45.9966,  83.7871,  ..., 126.3933,  29.0971, 156.7818])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 125.2628, -254.5173,    4.2508,  ...,  180.4113,  -49.0151,\n",
            "         -90.9246])\n",
            "actor loss: 998.731893854349, critic loss: 1823991.15625, entropy: 11054.217590332031, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[47.85358978175667, 57.364676394844935, 0, 0, 1.5627498444022514], 離散行動：[1, 1], 連続行動：0.481588589027524\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "113エピソード目の累積報酬：-20540.62676286351, 一つ保全の回数：6616, 二つ保全の回数：1560, 三つ保全の回数：16, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-138.3084,   28.5422, -116.3655,  ...,   75.8727, -194.1236,\n",
            "        -131.0171])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 102.6942, -154.9857,   79.3108,  ..., -207.6223,  139.8029,\n",
            "          68.6422])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   63.9480,  -573.4988,  -246.9321,  ...,   128.2794, -1622.2137,\n",
            "          -23.2182])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-117.8145,   33.5867,  154.8603,  ..., -262.2957,  -81.2999,\n",
            "        -129.5993])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 163.9369,   84.4130,    5.4358,  ...,   71.8787,  -78.3718,\n",
            "        -439.8486])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -234.7282,   138.5244, -1516.7976,  ...,  -227.8977,    82.3935,\n",
            "          163.8571])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([116.4666, 155.3978,   1.5185,  ..., 236.3017,  34.1321,  83.7377])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([263.8903, -61.0246, 233.3854,  ...,  28.2132, 211.8855,   4.1375])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-287.9708,  -34.9349,   95.2050,  ...,  123.9230,  -58.5217,\n",
            "          38.2316])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  65.0544,  186.3979,  -55.2593,  ...,   14.7630,   54.6521,\n",
            "        -202.2354])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 214.1816,  114.7601,  103.4349,  ..., -295.5740,   11.4226,\n",
            "         195.8584])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-117.2997,    1.1737,   49.5216,  ...,  108.5400, -192.8179,\n",
            "           2.7424])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  11.0911,   78.1087, -142.3675,  ...,  108.2471,   20.0180,\n",
            "         198.0073])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 268.1096,  228.3036,   -3.7957,  ..., -194.1236, -103.1786,\n",
            "         -58.6378])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 247.9217,   66.3932,  149.7317,  ...,  109.5134,  187.6510,\n",
            "        -105.2330])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 396.8191,  201.9142,   76.9424,  ..., -454.2431, -111.4660,\n",
            "         -13.5755])\n",
            "actor loss: 914.9317966450742, critic loss: 1984167.5703125, entropy: 11078.924133300781, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[41.233337255655925, 22.561229612961235, 0, 0, 2.0447537657241943], 離散行動：[1, 1], 連続行動：0.5676207989454269\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "114エピソード目の累積報酬：-20301.084219231027, 一つ保全の回数：6658, 二つ保全の回数：1525, 三つ保全の回数：9, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 232.3328, -138.2692,  -89.8443,  ...,  183.7222,  174.4776,\n",
            "         275.9086])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  76.9336,  -31.4665,   81.5692,  ..., -172.2503,   77.2052,\n",
            "          17.2216])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -52.9882,  135.0696, -119.1343,  ...,  131.5279,  -80.4544,\n",
            "          18.0462])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-320.8425,  100.5368, -139.3530,  ...,   35.8469,   29.3899,\n",
            "           7.9960])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -10.0872,  -28.6570,   32.7166,  ...,  146.5230, -156.8475,\n",
            "         147.8173])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  206.9281,  -389.2612,   164.0307,  ...,   169.1068, -1296.1180,\n",
            "         -371.1415])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  60.7305, -152.2418,  -64.1373,  ...,  -93.5338, -140.3675,\n",
            "          84.9392])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 10.8619, 148.1273,  47.4263,  ...,  22.3033, 213.5739,  45.1529])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  93.6352,  292.1354, -109.2763,  ...,   75.4813,  155.0364,\n",
            "        -388.4582])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  69.2754,  279.3358,  334.8320,  ...,  136.7712,   88.1855,\n",
            "        -112.9799])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-133.1470,  189.1765, -112.4667,  ...,  -78.8778,  334.2850,\n",
            "         114.3131])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 290.3667,  -34.4951, -185.2261,  ..., -241.8279,   -4.8925,\n",
            "         -13.4807])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 21.3352, 122.1740, -14.3237,  ..., 348.4375, 172.8713, 145.0498])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 197.3876,  -98.8610,  -40.2963,  ..., -133.4391,   89.4972,\n",
            "          38.6977])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 142.5553,   58.5554, -238.7869,  ...,   61.8984,   56.8568,\n",
            "         -92.1793])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -35.3990,  151.2707,  -54.5213,  ..., -276.2113,   52.2335,\n",
            "         153.8187])\n",
            "actor loss: 873.6911483266761, critic loss: 1993754.0390625, entropy: 11105.153259277344, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[0, 1.1129215181395744, 0, 0, 1.6315547012246427], 離散行動：[1, 1], 連続行動：0.4014907553792\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "115エピソード目の累積報酬：-22532.329858038283, 一つ保全の回数：6698, 二つ保全の回数：1487, 三つ保全の回数：7, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027, -22532.329858038283]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-218.5947, -218.3390,  -10.8387,  ...,  166.0551, -203.3539,\n",
            "         168.4037])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  35.4943,   44.4925,  188.7032,  ..., -624.8375,   62.3364,\n",
            "          32.4995])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1332.4014,  -126.3387,    42.8854,  ...,   113.8633,    94.7576,\n",
            "         -247.2334])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  23.6166, -150.8233,   65.7894,  ...,  -36.3986,   23.3583,\n",
            "        -155.5951])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 45.6323, -29.6063,  36.3527,  ..., 249.7369, 128.0008,  96.1388])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([109.2716, 239.5762,  17.9323,  ..., 213.8447,   4.4245,  70.7205])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  43.8862, -122.3580,  402.9641,  ...,  -20.6335,  709.9139,\n",
            "         -10.5646])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([    6.7894, -1469.0372,    15.4111,  ...,  -147.2538,   160.9657,\n",
            "        -1725.9232])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  48.3732,  209.0157,   19.1732,  ...,   10.0033, -128.0302,\n",
            "         -18.0040])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 185.7882, -142.4264,  -12.2621,  ..., -211.5976,   58.2482,\n",
            "         -99.9324])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([168.8172, 177.4958, 114.4966,  ..., -58.4195, 151.8952, 157.6840])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 213.5880,   58.6035,  -48.3293,  ...,  -92.2750,   28.8589,\n",
            "        -172.2730])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 125.5712, -103.1673,   -7.1081,  ...,  180.6977,   -4.1704,\n",
            "         256.8941])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -217.6678,   284.4959,   149.0226,  ...,    70.7080, -1427.5681,\n",
            "         -495.5237])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-52.2629,  42.3987,  65.1028,  ..., 159.6425, 171.2119, 161.4846])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-231.2786, -105.5753, -206.9951,  ..., -418.2774,   -8.6240,\n",
            "        -204.7250])\n",
            "actor loss: 929.4401768030016, critic loss: 2324320.296875, entropy: 11224.65771484375, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[54.943202369669976, 27.125503289473606, 0, 0, 1.7170506101994452], 離散行動：[1, 1], 連続行動：0.5078251659870148\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "116エピソード目の累積報酬：-17901.558681027713, 一つ保全の回数：6711, 二つ保全の回数：1467, 三つ保全の回数：14, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027, -22532.329858038283, -17901.558681027713]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 157.0063,  168.0318,   95.4671,  ..., -269.8849,  270.4311,\n",
            "         106.2436])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-448.6828, -279.6591,   19.8759,  ..., -150.9511, -356.9940,\n",
            "         134.2118])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 179.6628,   50.5593,  300.2541,  ...,   24.9146, -650.6428,\n",
            "          63.2010])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 15.8094, -31.8856,  17.3853,  ..., -65.9677,  86.5580, -49.1705])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  73.9320, -394.6133,  166.3534,  ..., -105.7410,  310.8804,\n",
            "          20.4913])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -1.8078,   3.9046, 143.7863,  ..., -72.2241,  69.6828,  92.3367])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  48.0222, -104.5129,  259.4832,  ...,   87.7478, -337.8615,\n",
            "          29.3195])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -31.2920,  212.4601, -334.9888,  ...,  200.8743,   85.0172,\n",
            "         359.4234])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 83.4873, -19.1647,  44.8859,  ...,  20.7867, 100.4918,   3.1328])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 190.5984,   32.0587,   41.3371,  ..., -102.0516,  236.7553,\n",
            "         132.4507])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-146.3572,  138.2381,   98.7459,  ...,  287.9076, -188.1093,\n",
            "           1.7923])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1066.7195,   257.8134,  -550.5818,  ...,   108.4935,  -169.1676,\n",
            "          102.4758])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  40.4757,   21.7435,   86.5127,  ...,  -26.4660,  -66.8265,\n",
            "        -374.6080])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-107.1060, -229.4539,  -72.7398,  ...,  135.3578,  -51.8683,\n",
            "          32.2248])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-79.2710,  62.6432, -33.5377,  ..., 149.1716,  92.3367, 274.0791])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([202.3418, 314.4297, -79.7424,  ..., 154.4480, 129.5434,  -9.8318])\n",
            "actor loss: 1132.1269195078155, critic loss: 2761470.03125, entropy: 10586.844848632812, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[41.301713624104025, 0.10827267214883021, 0, 0, 1.251987080150187], 離散行動：[1, 1], 連続行動：0.4645397290587425\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "117エピソード目の累積報酬：-19892.169833086413, 一つ保全の回数：6668, 二つ保全の回数：1514, 三つ保全の回数：10, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027, -22532.329858038283, -17901.558681027713, -19892.169833086413]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  54.6635, -170.7075,  197.6481,  ...,   59.1162, -106.6338,\n",
            "        -889.3974])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 14.7150, 202.9991, -19.9215,  ..., 385.6500,  43.0886,  22.1207])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 170.2832, -737.6043,   57.2806,  ...,  123.6047,   27.6996,\n",
            "        -173.8829])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  237.5462,    48.0387,   244.5459,  ...,   153.2924, -1566.4554,\n",
            "          186.1625])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 64.2089, 130.2307, 263.2788,  ...,  88.3498, -24.7976,  99.7653])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([181.5918, -96.0828,  62.1082,  ...,  55.5113, 162.8967, 449.1440])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -8.4469,  129.7337,   18.4147,  ..., -302.2385,  154.5115,\n",
            "          22.5537])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-515.1936, -205.0579, -327.4860,  ...,   26.5101,   38.8462,\n",
            "          23.6038])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 367.2433, -506.2108,   80.0017,  ..., -354.6242,   62.7400,\n",
            "        -143.7773])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-111.5639,   28.9258,  203.0040,  ...,   46.5224, -159.2980,\n",
            "         139.8904])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([216.0346, -38.2384, 128.5023,  ..., 125.8423, -38.7309,  11.9679])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 73.0663, 178.0558,  78.3158,  ...,  13.3591,  58.7460, -86.4978])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 160.4328,  226.2577,   98.0546,  ...,   31.3327, -113.4589,\n",
            "         134.2772])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-314.5835,  -99.6897,  -16.9179,  ...,   10.5427, -449.9412,\n",
            "         -16.1511])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 100.2079,   14.9159,   80.3286,  ..., -300.1580,  214.6966,\n",
            "        -426.1357])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 151.7200,   37.9828,    5.2739,  ...,  181.8585, -487.6974,\n",
            "         -61.5661])\n",
            "actor loss: 1047.495113423523, critic loss: 4969948.375, entropy: 10443.676513671875, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[4.301168774190516, 29.381048584864025, 0, 0, 1.61860162177241], 離散行動：[1, 1], 連続行動：0.569716565310955\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "118エピソード目の累積報酬：-20352.118895372725, 一つ保全の回数：6732, 二つ保全の回数：1449, 三つ保全の回数：11, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027, -22532.329858038283, -17901.558681027713, -19892.169833086413, -20352.118895372725]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -20.5369,  136.3442, -439.3409,  ...,  376.0240, -513.3770,\n",
            "         147.0741])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  90.8349,  148.6609, -545.0344,  ...,  155.6395,   46.4630,\n",
            "         172.1300])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 153.4977,   64.6920,  237.5941,  ..., -397.7215,  134.0471,\n",
            "         356.2018])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-694.2291, -244.2052,  189.6898,  ...,  283.8628,  127.6283,\n",
            "         491.8189])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -0.3842, 183.3108, 224.6429,  ..., 229.5956,  11.9097,  32.2381])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -48.8059,  223.0849,    4.9482,  ...,  -84.4916,   54.1412,\n",
            "        -424.4394])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 198.0414,  163.7368,   98.9604,  ..., -437.6023,  -91.2916,\n",
            "         346.0110])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-523.1100,  195.7675,  313.5261,  ...,  140.4090, -749.1306,\n",
            "         151.5815])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 164.6841, -113.7115,   -1.6333,  ...,   20.5610, -373.1419,\n",
            "         199.9320])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -34.9137,  121.6891, -548.6042,  ...,  274.9878,   20.1807,\n",
            "          98.5459])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 184.7941,   81.6978, -454.6584,  ...,  107.4577,  153.3619,\n",
            "        -505.6143])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([195.1347, 242.8133,  68.5819,  ..., 154.1822,  74.6730, -72.3386])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 266.3918,  178.7360, -534.2609,  ..., -560.3713,  113.6781,\n",
            "         103.8043])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([359.1438, 147.2980, -37.8672,  ..., 261.7590,  35.9398, -58.2867])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -231.4327, -1317.5654,    51.8866,  ...,   297.7751,   169.4142,\n",
            "         -516.6768])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  37.9810,   97.7350, -520.0721,  ...,   89.5708,  121.6384,\n",
            "          52.7346])\n",
            "actor loss: 1451.8477476895318, critic loss: 3572145.5703125, entropy: 10509.094787597656, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[29.726941599319954, 40.42877502256235, 0, 0, 1.5270827816302202], 離散行動：[1, 1], 連続行動：0.6062922775745392\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "119エピソード目の累積報酬：-17639.394030412084, 一つ保全の回数：6765, 二つ保全の回数：1420, 三つ保全の回数：7, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027, -22532.329858038283, -17901.558681027713, -19892.169833086413, -20352.118895372725, -17639.394030412084]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   72.3132,   129.3140, -1715.2231,  ...,  -234.9238,   600.0791,\n",
            "          -31.1736])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-441.2172,  173.4895, -240.2928,  ...,  199.9634,  133.2692,\n",
            "         209.7115])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-609.5921,  -82.0260, -346.2113,  ...,  -47.9577,  100.5787,\n",
            "         -18.8587])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-657.8023,  268.9505,    2.2788,  ...,  -29.4926,  141.7063,\n",
            "          84.1267])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 164.7561, -273.9606,  131.3789,  ..., -403.1447,  -64.8678,\n",
            "          96.0855])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([143.3667, 114.6201, 118.8635,  ..., -47.6814,  74.0500,  93.3165])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 282.8565,  181.9769, -476.0983,  ...,   23.7934,  -65.7244,\n",
            "         134.3692])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-142.3442, -438.6829,  217.2220,  ..., -161.4027,   54.4898,\n",
            "         355.4472])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 148.0029,   98.3605,   -2.0447,  ...,    6.1503,   61.5501,\n",
            "        -277.5599])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   41.6935,    48.1890,  -326.0288,  ...,  -310.7656,   -20.7898,\n",
            "        -1617.4886])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  41.6186,  119.4493,   79.9116,  ...,   56.9129, -273.9606,\n",
            "        -132.4790])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -47.9286,  150.6278,  227.7261,  ..., -343.3949,  174.1384,\n",
            "         188.8004])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  210.1709, -2576.0969,    57.1098,  ...,    18.7741,    66.5423,\n",
            "         -392.4524])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 198.0683,  169.8367, -103.2809,  ...,   70.2972,  327.5083,\n",
            "         163.3216])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([331.8362,  84.1267, 293.2070,  ...,  19.5448,   3.3415, -38.2574])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -15.4429,  115.3672,  244.6941,  ...,   92.3477, -241.8478,\n",
            "         221.0566])\n",
            "actor loss: 1341.0569415115096, critic loss: 4442855.921875, entropy: 10610.505310058594, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[47.773527172654106, 43.16897318464671, 0, 0, 1.5726257147108278], 離散行動：[1, 1], 連続行動：0.5257405191659927\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "120エピソード目の累積報酬：-19306.721021187353, 一つ保全の回数：6800, 二つ保全の回数：1387, 三つ保全の回数：5, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027, -22532.329858038283, -17901.558681027713, -19892.169833086413, -20352.118895372725, -17639.394030412084, -19306.721021187353]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 199.1345,  197.5725,  169.5412,  ..., -161.7079,   31.7906,\n",
            "        -614.5647])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([225.6209, -14.0946, 146.0872,  ..., 223.9970,   6.7137,  29.8773])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([110.0448, -78.4486,  47.2444,  ...,  77.9123,  53.6091, 191.2168])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 279.3394, -289.2658,  144.7648,  ...,  210.6298,  370.8761,\n",
            "          92.1819])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 329.5609,   92.5829,  314.6433,  ..., -450.8557,  428.6130,\n",
            "         -51.2103])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -23.3745, -505.8752,   52.3495,  ...,   32.8721,  165.3744,\n",
            "        -206.0004])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-367.5976,  269.5169,  182.8148,  ...,  160.7747,   34.8652,\n",
            "         100.8610])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  95.7987, -542.0514, -352.2800,  ...,  139.6270,  -36.3857,\n",
            "         129.9955])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-52.2845,  13.1162, 119.7682,  ..., 170.7043, -78.0208,  30.3374])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-588.5228,   31.8344, -693.8364,  ...,  251.9906,  -45.7082,\n",
            "         -75.4163])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([130.7582,  53.8412,  94.1412,  ..., 138.3036,  62.7832, 266.7260])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([371.1938, -33.6659, -41.5317,  ..., -36.0862, -27.2014, 114.0865])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -636.5375,   -85.8188,   127.2598,  ..., -1683.8956,   140.8468,\n",
            "          100.1768])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 269.9836, -170.7823,  197.5917,  ...,  232.8873, -117.6612,\n",
            "         154.1607])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 139.3076, -440.9809,  -91.6953,  ...,  133.4876,  119.5757,\n",
            "        -101.4879])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-368.6906,  177.6537,   18.8939,  ...,  250.5369,  160.9478,\n",
            "         173.6658])\n",
            "actor loss: 1458.8898460783262, critic loss: 5510819.234375, entropy: 10582.184692382812, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[55.77916259990989, 56.782923014891566, 0, 0, 1.424915250330963], 離散行動：[1, 1], 連続行動：0.4384124055504799\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "121エピソード目の累積報酬：-22515.270389352147, 一つ保全の回数：6803, 二つ保全の回数：1383, 三つ保全の回数：6, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027, -22532.329858038283, -17901.558681027713, -19892.169833086413, -20352.118895372725, -17639.394030412084, -19306.721021187353, -22515.270389352147]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  62.4159,  335.1069, -402.6817,  ...,  307.2602,  148.8155,\n",
            "         244.3396])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-311.2719,   72.8640, -301.7888,  ...,  124.2676, -132.2582,\n",
            "         -33.2123])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 174.0453,  -99.7524,   98.1971,  ..., -230.1666,   82.1758,\n",
            "         248.7879])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 148.8618,  -27.9435,  168.3808,  ...,   92.7519, -418.9143,\n",
            "         104.4756])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -20.5186,  -91.9759,  -21.3667,  ..., -206.1578, -198.2146,\n",
            "         154.4325])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 174.2481,  105.9220, -645.7896,  ...,   94.6154,  445.9070,\n",
            "         316.0115])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([158.9833, 317.7152, 160.2750,  ...,  69.7108,  98.6883, -64.1707])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-134.0447,  -16.0969, -239.6715,  ...,  -95.1079,   50.9790,\n",
            "         330.5492])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-104.2772,  103.2789,    0.7380,  ...,  -33.0935, -576.5995,\n",
            "          93.6746])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([207.7070, -63.3545, 232.5384,  ..., 266.6589, -56.3178, 248.3372])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 139.5429,  122.4844,  256.7988,  ...,  138.6777, -308.2821,\n",
            "         133.2805])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-404.5828, -386.3197,  498.4734,  ..., -117.2404,  112.9165,\n",
            "         -62.5523])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  67.0796, -306.1156,  -14.9968,  ...,  -15.8028,  214.7003,\n",
            "        -341.3340])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-79.8583, 113.2681, 218.6314,  ..., 205.3151,  70.1013, -32.4261])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  151.5675,    67.9854,  -491.2389,  ...,   -97.5230,    46.6992,\n",
            "        -1383.4166])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-156.7590,   56.7592,  135.3176,  ...,  220.7835, -133.9034,\n",
            "          43.6364])\n",
            "actor loss: 1480.6897714333732, critic loss: 3730926.515625, entropy: 10347.351867675781, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[17.877610979971795, 94.45403400277381, 0, 0, 1.7547222205843533], 離散行動：[0, 1], 連続行動：0.41733311861753464\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "122エピソード目の累積報酬：-23237.02892280519, 一つ保全の回数：6833, 二つ保全の回数：1350, 三つ保全の回数：9, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027, -22532.329858038283, -17901.558681027713, -19892.169833086413, -20352.118895372725, -17639.394030412084, -19306.721021187353, -22515.270389352147, -23237.02892280519]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  29.2265, -295.5255,  360.5561,  ...,   84.9845,  236.7812,\n",
            "         187.1534])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -374.0628,   132.5943, -2259.2192,  ...,   187.1059,   -59.0756,\n",
            "         -119.8448])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -36.1089,  133.4690, -148.6649,  ..., -123.4137,  -67.8898,\n",
            "          75.8331])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   -4.2869, -1809.8524,    62.9303,  ...,  -189.0226,   -94.8821,\n",
            "           20.8087])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-284.5307,  160.0349,  118.4910,  ..., -104.8228,  129.6750,\n",
            "        -154.4504])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-1695.6234,   -13.4199,   -79.8828,  ...,    -4.4273,   -70.3681,\n",
            "          117.4579])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 55.3867, -18.0440, 127.1501,  ..., -92.1144, 140.0053, 113.4785])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  104.1264,   172.9765,   145.7098,  ...,   124.9158, -1686.5083,\n",
            "          204.9190])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -101.2465,   200.8406, 18974.8203,  ...,   317.1430,   545.5693,\n",
            "          145.7997])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([280.5785, 175.1587, 201.7065,  ..., 178.2028, -57.3304,  82.9167])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 58.7807, 156.0476,  98.2344,  ..., 245.2389,  68.4254, -46.0391])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([315.7182, -98.3258, -80.3961,  ..., 100.0667,  72.4032,  74.8457])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 142.3778, -157.3752, -203.0781,  ...,   49.3922,  206.7779,\n",
            "          59.0793])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  69.3825,  148.9871,  -79.8617,  ..., -136.2701,  -59.8639,\n",
            "          71.6447])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-84.9400, 298.4886, -51.5110,  ..., 193.8115,  30.9444,  -1.7986])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  30.2921,   97.7902,   40.7017,  ..., -167.6249,  -46.4073,\n",
            "         -80.7414])\n",
            "actor loss: 1946.447313215381, critic loss: 7907483.3125, entropy: 11179.870727539062, KL divergence: 1.2430401218835632\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[84.8988398749041, 18.734355950673468, 0, 0, 1.5616442222560916], 離散行動：[1, 1], 連続行動：0.3864593654870987\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "123エピソード目の累積報酬：-24743.92036466665, 一つ保全の回数：6843, 二つ保全の回数：1345, 三つ保全の回数：4, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027, -22532.329858038283, -17901.558681027713, -19892.169833086413, -20352.118895372725, -17639.394030412084, -19306.721021187353, -22515.270389352147, -23237.02892280519, -24743.92036466665]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-386.6026, -328.8050, -278.5697,  ...,   63.9362,  -90.8816,\n",
            "        -368.5126])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  95.7058, 1346.2610,  299.4484,  ...,  -10.3838,  -38.2093,\n",
            "          76.0159])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 174.6078, -206.8882,   52.9379,  ..., -331.8530,  -86.9056,\n",
            "         -33.9680])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 481.3305,  139.0489,   17.2850,  ...,  769.8574,   26.5183,\n",
            "        -170.9859])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -525.4952,   426.9201, -2211.6025,  ...,   115.9362,  -224.4433,\n",
            "          268.2018])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -578.8036,   -96.5074, -2002.2788,  ...,    19.9981,   466.8008,\n",
            "          308.1503])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-531.3632,  225.8501,   11.5241,  ..., -289.7011,  293.7170,\n",
            "         187.6292])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-277.6460,   36.7414, -236.8657,  ...,  377.3061,   21.1038,\n",
            "         315.1069])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 187.3353,  140.0627,  635.5002,  ...,   34.0541,  166.6033,\n",
            "        -120.1224])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 239.0000, -185.1254,  291.0477,  ..., -422.1360,  -30.7858,\n",
            "         115.6390])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 182.4030, -274.0470,   80.0842,  ..., -255.2058, -181.5711,\n",
            "          64.6369])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -152.0136,  -642.1263, -1971.8168,  ...,    40.6419,  -124.3940,\n",
            "          128.4836])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-199.6652, -135.4994,  128.1009,  ...,  -63.0982, -187.1592,\n",
            "         214.5515])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -90.8102,  385.5318,   94.7444,  ...,  -95.2400, -308.1152,\n",
            "         315.2810])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 257.1918,  -37.7944,  144.6388,  ...,  274.5471,  194.0162,\n",
            "        -140.4544])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   49.6806,    84.1591,    12.5904,  ...,    99.0891, -1853.7052,\n",
            "           93.1597])\n",
            "actor loss: 1265.3415266086342, critic loss: 6445926.609375, entropy: 11383.185485839844, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[115.51177391219957, 9.91832997741676, 1, 0, 2.462248304614147], 離散行動：[0, 1], 連続行動：0.581436961889267\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "124エピソード目の累積報酬：-24284.116214054644, 一つ保全の回数：6787, 二つ保全の回数：1400, 三つ保全の回数：5, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027, -22532.329858038283, -17901.558681027713, -19892.169833086413, -20352.118895372725, -17639.394030412084, -19306.721021187353, -22515.270389352147, -23237.02892280519, -24743.92036466665, -24284.116214054644]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -69.5753,  -89.8100, -172.7718,  ...,   90.9480,  -27.5056,\n",
            "         339.6183])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -184.8025, -1490.2766, -1349.3372,  ...,  -254.3684,   230.3204,\n",
            "          175.0371])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-121.2745,  641.9336,  265.6215,  ..., -235.6782,   57.8646,\n",
            "        -129.2664])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 115.1745, -438.0008, -250.3363,  ...,  -91.8957, -250.1184,\n",
            "        -233.0930])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   3.6970, -204.9770,   43.9132,  ...,  -26.7123,  163.2288,\n",
            "          59.9908])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 299.1189,  185.3710, -100.7716,  ..., -313.1109,  311.8146,\n",
            "         263.4015])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-160.8289,   12.8223,  272.3778,  ...,  501.1725,  177.5811,\n",
            "        -193.0323])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 100.2244,  -93.8778, -102.4531,  ...,   91.3952,  572.0834,\n",
            "          39.7629])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 285.8654,   64.3043,   53.3738,  ...,  112.1329, -134.2321,\n",
            "        -106.2153])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 143.3262,  254.5601, -163.1124,  ...,   78.7684,  268.9580,\n",
            "          -3.8344])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -48.0424, -345.1552, -108.2238,  ...,   88.4619,  385.5389,\n",
            "        -221.9098])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 263.6923,   -0.6822,   92.6326,  ...,   93.3537, -280.0458,\n",
            "         159.8340])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([383.2004,  40.5505, 116.5690,  ...,  36.7652,  40.1089, 141.0518])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 182.2781,    7.1862,  635.6406,  ..., -671.5206, -135.7008,\n",
            "         -21.8064])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-441.4487,  -10.5565,  358.7465,  ..., -168.6406,  230.2234,\n",
            "         184.5186])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  254.2139, -1515.3900,  -436.6629,  ...,    52.8927,   262.5940,\n",
            "         -183.6509])\n",
            "actor loss: 1139.5080380355796, critic loss: 3571430.796875, entropy: 11134.664978027344, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[28.116726428496108, 8.330615839139396, 0, 0, 1.9646793730079044], 離散行動：[1, 1], 連続行動：0.4812122732400894\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "125エピソード目の累積報酬：-21617.10679167899, 一つ保全の回数：6703, 二つ保全の回数：1481, 三つ保全の回数：8, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027, -22532.329858038283, -17901.558681027713, -19892.169833086413, -20352.118895372725, -17639.394030412084, -19306.721021187353, -22515.270389352147, -23237.02892280519, -24743.92036466665, -24284.116214054644, -21617.10679167899]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -54.4173, -184.1797,  414.2413,  ..., -466.0304, -296.1791,\n",
            "         485.7425])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 136.3295,  281.0068, -101.6416,  ..., -536.6267,  -85.4134,\n",
            "         583.9539])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-394.1707, -271.3026, -116.3015,  ..., -439.6369, -400.8459,\n",
            "           1.4286])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-670.9832, -145.3670,   68.1592,  ...,  -83.2567, -200.8118,\n",
            "         221.0747])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -98.2253,  297.7070,  498.0900,  ..., -572.3569,  120.0189,\n",
            "         117.8239])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([391.8578, -67.6164, 256.2442,  ..., 232.6136, 388.9135, -49.4421])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 404.5747,  -33.4546,  -50.4386,  ..., -608.7913,    0.9220,\n",
            "         126.5963])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-163.4937,   66.4597,  -80.8930,  ..., -119.9174, -180.9665,\n",
            "          42.5546])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  75.0953,  235.2395, -670.9240,  ...,    6.5206,   48.6413,\n",
            "          73.3913])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([   2.6744,  214.5625, -167.3972,  ...,  201.8635, -149.5495,\n",
            "         417.2643])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-100.2922,   42.8908,  446.4613,  ...,  -39.1354,   67.5673,\n",
            "         390.9773])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([125.3295, 264.6844,  35.4489,  ..., -20.7308,  69.7792, 442.5844])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  208.4913,   126.5546, -2073.9836,  ...,   321.8265,  -127.6621,\n",
            "           91.8727])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 147.7024, -100.5345,   90.6373,  ..., -476.0466, -910.1296,\n",
            "        -137.3747])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  83.9456,  -56.8481,  213.7131,  ...,  -12.9657, -243.7686,\n",
            "         -55.4407])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  95.6932, -171.6246,  629.8560,  ...,  164.0889, -420.3025,\n",
            "         -37.4410])\n",
            "actor loss: 1031.39425164807, critic loss: 2982300.9375, entropy: 11378.143981933594, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[15.603578303257898, 33.50237176014485, 0, 0, 2.0718224600760573], 離散行動：[1, 1], 連続行動：0.5234914608299732\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "126エピソード目の累積報酬：-17184.444987305364, 一つ保全の回数：6681, 二つ保全の回数：1505, 三つ保全の回数：6, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027, -22532.329858038283, -17901.558681027713, -19892.169833086413, -20352.118895372725, -17639.394030412084, -19306.721021187353, -22515.270389352147, -23237.02892280519, -24743.92036466665, -24284.116214054644, -21617.10679167899, -17184.444987305364]\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-339.4216,  -17.0395,  177.7347,  ..., -127.5596,  134.2882,\n",
            "        -183.2486])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([295.2674, -75.3297,  -7.0539,  ..., 220.7850, 144.2970,  74.3609])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-126.6845,    0.9906,  216.9593,  ...,  124.2367, -289.6116,\n",
            "         264.2256])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-166.7404, -193.4263,   27.4886,  ...,  264.0381,  -18.3877,\n",
            "          43.2058])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([162.0036, -71.7572, -97.0269,  ...,  62.8134, -42.2191,  58.8288])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  -3.6677,   74.9107,  169.0323,  ..., -100.2367,  121.6942,\n",
            "          91.2383])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-173.5675,  198.5588, -201.4156,  ...,   -1.8654,  146.8277,\n",
            "         -42.3728])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([  89.8891,  186.8499,   57.1104,  ..., -817.4185,  -21.0792,\n",
            "         140.2180])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 170.5141, -277.5420,  113.4074,  ...,  164.1009,  194.3371,\n",
            "          93.6425])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 180.9770, -174.1113,   64.1288,  ...,  155.1317,   43.8432,\n",
            "         245.8236])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([166.4360,  27.4886, 197.4084,  ..., 150.7115, 130.6144,  -2.8330])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 113.3205,  173.1016,  122.8554,  ...,  -34.3123, -180.9557,\n",
            "         283.6609])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 141.2488, -102.2473, -526.0838,  ...,  147.2593,  102.4005,\n",
            "         113.3665])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ -33.3566,  222.6626,  317.4920,  ...,  224.9741,  153.6632,\n",
            "        -253.2731])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([-28.5429, -57.1681, 277.1376,  ...,  64.1294,  77.4961,  15.7616])\n",
            "FLAG\n",
            "advantage[batch].size(),advantage[batch]: torch.Size([2048]) tensor([ 107.7314,  120.7161, -416.7800,  ..., -513.1321,   49.8307,\n",
            "        -115.5514])\n",
            "actor loss: 1110.3308290572168, critic loss: 1825493.62890625, entropy: 11157.248596191406, KL divergence: inf\n",
            "... loading models ...\n",
            "... saving models ...\n",
            "状態[10.403462638789257, 7.288285305834721, 0, 0, 1.2249492314504873], 離散行動：[1, 1], 連続行動：0.45128826424479485\n",
            "[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [0, 0, 0, 0]\n",
            "127エピソード目の累積報酬：-23388.792696690256, 一つ保全の回数：6630, 二つ保全の回数：1556, 三つ保全の回数：6, 違反回数：0,episode_reward_history：[-424131.63446220686, -340464.372321981, -321996.347681344, -282709.1254283362, -246754.853478048, -232008.53351150412, -159476.38627970015, -140851.99378857182, -111551.1344843698, -102941.17891721817, -69202.61186772131, -66381.57768579849, -45069.280903162165, -55403.8392526335, -55462.78536354346, -45541.945147806524, -43655.71108482313, -39235.56229148684, -48780.938435145756, -38055.59035839627, -33081.34053374719, -36611.21136484806, -39672.36784071029, -39034.12035504293, -34039.42912318882, -35459.05955783035, -37274.80481091052, -32239.251168395054, -27764.496223290473, -29844.947972048565, -27970.68903265544, -40793.60409964634, -30738.497974633683, -41515.47372239095, -24607.603346491414, -38135.681688042074, -32355.02832136693, -36647.148505796664, -34290.15603842583, -31712.777109955623, -32592.191967588562, -24698.39955578173, -24344.87882615109, -31222.72346644917, -27799.181043978075, -35677.4076327358, -26795.163735319074, -28350.54887778851, -27987.390708409726, -25957.368770391484, -28597.84502397488, -29063.005302638492, -25933.514388994052, -25131.520886451133, -26864.082786618008, -26663.368338251643, -24689.653316803906, -21407.294571222526, -27821.24598153389, -24230.122184200784, -24100.123458682312, -24485.01443776352, -23790.902491217497, -26186.14511997064, -32570.78865616822, -25060.86525483221, -28311.354971928085, -22347.553384205432, -22269.10225729036, -21279.954743098933, -24079.388394634014, -28411.19193444959, -21988.878208526854, -23448.372880117302, -24188.114394790977, -20709.400175714072, -24795.123115405844, -20168.743516991028, -22650.280529110474, -21692.97150260314, -20818.933843204413, -22034.92771905254, -20372.56800648391, -23215.39836971272, -22932.524162067883, -21922.240233332013, -23792.052913272524, -24993.631255842418, -24135.2863696989, -21796.53880548834, -22331.937412803745, -21734.823012493514, -21763.30963290552, -22011.110351240208, -21068.744354109906, -24100.935997820976, -23382.986008741238, -20522.396265494524, -22073.63794856227, -18331.305951463717, -21165.642844968886, -21596.021974636278, -22626.001181790907, -21652.43950781587, -24044.075503382337, -20268.09561464038, -24591.952891970795, -20815.70522910963, -19727.658008047933, -19483.21144133925, -20820.038446643255, -23643.79787284231, -18695.023454573267, -20540.62676286351, -20301.084219231027, -22532.329858038283, -17901.558681027713, -19892.169833086413, -20352.118895372725, -17639.394030412084, -19306.721021187353, -22515.270389352147, -23237.02892280519, -24743.92036466665, -24284.116214054644, -21617.10679167899, -17184.444987305364, -23388.792696690256]\n"
          ]
        }
      ],
      "source": [
        "num_episode =128#8*16*4で90分\n",
        "threshold = 0 #cnt学習を開始するエピソード\n",
        "best_reward = -np.inf\n",
        "episode_reward_history = []\n",
        "avg_cost = 0\n",
        "critic_value0_history=[]\n",
        "\n",
        "for episode in range(num_episode):\n",
        "    episode_reward = 0\n",
        "    operation_time = 0\n",
        "    one_action = 0\n",
        "    two_action = 0\n",
        "    three_action = 0\n",
        "    penalty_action = 0\n",
        "    #level_ohe, load_total = env.init_random()\n",
        "    levels, flags, load_total = env.init_random()\n",
        "    if episode % 100 == 0:\n",
        "        interval_time_episode = time.time()\n",
        "    interval_time_episode = time.time()\n",
        "    for _ in range(1024*8):#1024*8\n",
        "        #state = level_ohe + list([inventory,demand])\n",
        "        #print(levels,\"levels\")\n",
        "        state = levels + flags + list([load_total])\n",
        "        #print(state)\n",
        "        act_dsc, act_cnt, log_prob_dsc, log_prob_cnt, val = agent.choose_action(state)\n",
        "        act_dsc_list = [int(bit) for bit in format(act_dsc.item(), f'0{env.n_units}b')]\n",
        "        if sum(act_dsc_list) == 2:\n",
        "            one_action += 1\n",
        "        elif sum(act_dsc_list) == 1:\n",
        "            two_action += 1\n",
        "        elif sum(act_dsc_list) == 0:\n",
        "            three_action += 1\n",
        "        act_cnt_np = act_cnt.squeeze().cpu().numpy().copy()\n",
        "        act_cnt_np = act_cnt_np * 0.5 + 0.5 #補正\n",
        "\n",
        "        if act_cnt_np<0.5:\n",
        "          env.cntCount[0]+=1\n",
        "        else:\n",
        "          env.cntCount[1]+=1\n",
        "        #print(act_dsc_list,act_cnt_np)\n",
        "        #reward, level_ohe_next, load_total_next= env.operation(act_dsc_list,act_cnt_np)\n",
        "        reward, levels_next, flags_next, load_total_next= env.operation(act_dsc_list,act_cnt_np)\n",
        "\n",
        "        episode_reward = episode_reward *0.99 + reward\n",
        "        #penalty_action += flag\n",
        "        #if remain_interval > remain_interval_next:\n",
        "            #operation_time += (remain_interval+1)/2*interval - (remain_interval_next+1)/2*interval\n",
        "        #else:\n",
        "            #operation_time += (remain_interval_next + 1) / 2 * interval\n",
        "        agent.remember(state, act_dsc.item(), act_cnt.squeeze().cpu().numpy().copy(), log_prob_dsc, log_prob_cnt, val, reward, operation_time)\n",
        "        levels = levels_next\n",
        "        flags = flags_next\n",
        "        #mstatus_ohe = mstatus_ohe_next\n",
        "        #inventory = inventory_next\n",
        "        #demand = demand_next\n",
        "        #remain_interval = remain_interval_next\n",
        "        load_total = load_total_next\n",
        "    #print(f'{episode}エピソード目の時間：{time.time()-interval_time_episode}')\n",
        "    interval_time_episode = time.time()\n",
        "    agent.learn(episode, threshold)\n",
        "\n",
        "    old_agent = Agent(n_units=n_units,\n",
        "                        input_dims=input_size,\n",
        "                        n_states=n_states,\n",
        "                        MAX_maintenance_time=MAX_maintenance_time,\n",
        "                        beta=beta,\n",
        "                        interval=interval,\n",
        "                        alpha_actor=alpha_actor,\n",
        "                        alpha_critic=alpha_critic,\n",
        "                        policy_clip=policy_clip,\n",
        "                        batch_size=batch_size,\n",
        "                        n_epochs=n_epochs)\n",
        "    if episode != 0:\n",
        "        old_agent.load_models()\n",
        "\n",
        "    #if Check_convergence(agent, old_agent, n_units, n_states, MAX_maintenance_time):\n",
        "    #    break\n",
        "\n",
        "\n",
        "\n",
        "    agent.save_models()\n",
        "    print(f'状態{state}, 離散行動：{act_dsc_list}, 連続行動：{act_cnt_np}')\n",
        "    print(f'[保全を選択できた回数,1個故障で保全を選ばない回数, 2個故障で保全を選ばない回数, 3個故障で保全を選ばない回数] = [{env.replace_chance}, {env.failure_keep1}, {env.failure_keep2}, {env.failure_keep3}]')\n",
        "    env.replace_chance = 0\n",
        "    env.failure_keep1 = 0\n",
        "    env.failure_keep2 = 0\n",
        "    env.failure_keep3 = 0\n",
        "    #print(f'{episode}エピソード目の学習時間：{time.time()-interval_time_episode}')\n",
        "    episode_reward_history.append(episode_reward)\n",
        "    print(f'{episode}エピソード目の累積報酬：{episode_reward}, 一つ保全の回数：{one_action}, 二つ保全の回数：{two_action}, 三つ保全の回数：{three_action}, 違反回数：{penalty_action},episode_reward_history：{episode_reward_history}')\n",
        "\n",
        "    critic_value0_history.append(float(agent.critic(state0)[0][0]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ncPGOL29TYPd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b4a196cb-53b5-4f75-ef0a-e90eb64f56fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AHLLAogeTYPe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9a74c33-60c7-4662-cbb1-2af6d0390cf0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def plot_learning_curve(rewards, title=\"Learning Curve\", label=\"Total reward\"):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(rewards, label='Episode Reward')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel(label)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# エージェントの学習\n",
        "# (agent.train()の呼び出しなど)\n",
        "\n",
        "# 学習後のエージェントの評価\n",
        "#evaluate_agent(agent, env, num_episodes=10)\n",
        "\n",
        "# 学習曲線のプロット\n",
        "plot_learning_curve(episode_reward_history, title=\"PPO Learning Curve\", label=\"Total reward\")\n",
        "plot_learning_curve(agent.loss_history_detail, title=\"loss curve\", label=\"Total loss (actor loss +  critic loss) \")\n",
        "plot_learning_curve(agent.actor_loss_history, title=\"actor loss curve\", label=\"actor loss\")\n",
        "plot_learning_curve(agent.critic_loss_history, title=\"critic loss curve\", label=\"critic loss\")\n",
        "plot_learning_curve(agent.entropy_history, title=\"entropy curve\", label=\"entropy\")\n",
        "plot_learning_curve(agent.kl_divergence_history, title=\"kl divergence curve\", label=\"kl divergence\")\n",
        "plot_learning_curve(critic_value0_history, title=\"PPO Learning Curve\", label=\"critic_value0\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "U3bLWs2RTYPe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "433beaea-66ca-4a1a-aebd-7ae115bf2722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state: tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.2000]]) dist_dsc.probs: tensor([[0.0045, 0.0066, 0.0046, 0.9843]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0009]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3845]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00088205247\n",
            "-0.00088205247 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 10.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0040, 0.0133, 0.0033, 0.9795]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0009]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.3927]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0008732809\n",
            "-0.0008732809 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 20.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0032, 0.0282, 0.0020, 0.9666]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.3658]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0006175675\n",
            "-0.0006175675 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 30.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0025, 0.0583, 0.0012, 0.9380]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.3383]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00033046075\n",
            "-0.00033046075 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 40.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.8047e-03, 1.1477e-01, 7.2277e-04, 8.8271e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[3.5804e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.3108]], grad_fn=<ExpBackward0>)\n",
            "3 3.5804318e-05\n",
            "3.5804318e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 50.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.2398e-03, 2.1097e-01, 3.9003e-04, 7.8740e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2844]], grad_fn=<ExpBackward0>)\n",
            "3 0.00039435184\n",
            "0.00039435184 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 60.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[7.8044e-04, 3.5540e-01, 1.9287e-04, 6.4363e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0008]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2603]], grad_fn=<ExpBackward0>)\n",
            "3 0.00075290573\n",
            "0.00075290573 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 70.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[4.3536e-04, 5.3120e-01, 8.4568e-05, 4.6828e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0011]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2357]], grad_fn=<ExpBackward0>)\n",
            "1 0.0010957896\n",
            "state: tensor([[ 0.0000, 80.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[2.1316e-04, 6.9848e-01, 3.2576e-05, 3.0127e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0014]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2111]], grad_fn=<ExpBackward0>)\n",
            "1 0.001400593\n",
            "state: tensor([[ 0.0000, 90.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[9.3336e-05, 8.2481e-01, 1.1237e-05, 1.7508e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0016]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1867]], grad_fn=<ExpBackward0>)\n",
            "1 0.0015861914\n",
            "state: tensor([[  0.0000, 100.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[4.0920e-05, 9.0625e-01, 3.9076e-06, 9.3703e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1865]], grad_fn=<ExpBackward0>)\n",
            "1 0.00058853027\n",
            "state: tensor([[  0.0000, 110.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[1.5882e-05, 9.5121e-01, 1.1966e-06, 4.8769e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0009]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1612]], grad_fn=<ExpBackward0>)\n",
            "1 0.0008538598\n",
            "state: tensor([[10.0000,  0.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0040, 0.0133, 0.0033, 0.9795]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0009]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3927]], grad_fn=<ExpBackward0>)\n",
            "3 0.0008732809\n",
            "0.0008732809 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 10.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0044, 0.0168, 0.0033, 0.9755]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-1.8502e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.4249]], grad_fn=<ExpBackward0>)\n",
            "3 -1.8502324e-05\n",
            "-1.8502324e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 20.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0036, 0.0320, 0.0022, 0.9623]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.3910]], grad_fn=<ExpBackward0>)\n",
            "3 0.00021009284\n",
            "0.00021009284 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 30.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0028, 0.0646, 0.0014, 0.9312]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.3543]], grad_fn=<ExpBackward0>)\n",
            "3 0.00048462994\n",
            "0.00048462994 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 40.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[2.1220e-03, 1.2954e-01, 8.0875e-04, 8.6753e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0008]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.3341]], grad_fn=<ExpBackward0>)\n",
            "3 0.0007954045\n",
            "0.0007954045 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 50.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.4986e-03, 2.4199e-01, 4.4794e-04, 7.5606e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.3145]], grad_fn=<ExpBackward0>)\n",
            "3 0.00073035737\n",
            "0.00073035737 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 60.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[9.4404e-04, 4.0458e-01, 2.2174e-04, 5.9425e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2931]], grad_fn=<ExpBackward0>)\n",
            "3 0.00052345515\n",
            "0.00052345515 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 70.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[5.1595e-04, 5.8906e-01, 9.5291e-05, 4.1033e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2729]], grad_fn=<ExpBackward0>)\n",
            "1 0.0003316553\n",
            "state: tensor([[10.0000, 80.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[2.4659e-04, 7.5110e-01, 3.5825e-05, 2.4862e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2528]], grad_fn=<ExpBackward0>)\n",
            "1 0.0002716103\n",
            "state: tensor([[10.0000, 90.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.0562e-04, 8.6304e-01, 1.2096e-05, 1.3685e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2294]], grad_fn=<ExpBackward0>)\n",
            "1 0.00071923947\n",
            "state: tensor([[ 10.0000, 100.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[4.5623e-05, 9.3011e-01, 4.1485e-06, 6.9839e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[7.5404e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2333]], grad_fn=<ExpBackward0>)\n",
            "1 7.5404154e-05\n",
            "state: tensor([[ 10.0000, 110.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[1.7474e-05, 9.6457e-01, 1.2564e-06, 3.5415e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2037]], grad_fn=<ExpBackward0>)\n",
            "1 0.0003397801\n",
            "state: tensor([[20.0000,  0.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0032, 0.0282, 0.0020, 0.9666]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3658]], grad_fn=<ExpBackward0>)\n",
            "3 0.0006175675\n",
            "0.0006175675 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 10.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0036, 0.0320, 0.0022, 0.9623]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3910]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00021009284\n",
            "-0.00021009284 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 20.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0030, 0.0380, 0.0017, 0.9574]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[1.5718e-06]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3935]], grad_fn=<ExpBackward0>)\n",
            "3 1.5717524e-06\n",
            "1.5717524e-06 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 30.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0025, 0.0689, 0.0011, 0.9274]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[8.8003e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.3624]], grad_fn=<ExpBackward0>)\n",
            "3 8.800285e-05\n",
            "8.800285e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 40.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.8895e-03, 1.3001e-01, 6.9113e-04, 8.6741e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.3195]], grad_fn=<ExpBackward0>)\n",
            "3 -0.000206125\n",
            "-0.000206125 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 50.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.3391e-03, 2.3305e-01, 3.8889e-04, 7.6522e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-6.9123e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2869]], grad_fn=<ExpBackward0>)\n",
            "3 -6.9122674e-05\n",
            "-6.9122674e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 60.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[8.6192e-04, 3.9203e-01, 1.9727e-04, 6.0691e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2594]], grad_fn=<ExpBackward0>)\n",
            "3 0.00027535632\n",
            "0.00027535632 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 70.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[4.8714e-04, 5.8259e-01, 8.7319e-05, 4.1684e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0011]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2443]], grad_fn=<ExpBackward0>)\n",
            "1 0.0010779524\n",
            "state: tensor([[20.0000, 80.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[2.3825e-04, 7.5046e-01, 3.3476e-05, 2.4927e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0015]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2286]], grad_fn=<ExpBackward0>)\n",
            "1 0.0014950593\n",
            "state: tensor([[20.0000, 90.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.0432e-04, 8.6602e-01, 1.1495e-05, 1.3386e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0017]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2125]], grad_fn=<ExpBackward0>)\n",
            "1 0.0017204994\n",
            "state: tensor([[ 20.0000, 100.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[4.6069e-05, 9.3394e-01, 4.0039e-06, 6.6014e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2321]], grad_fn=<ExpBackward0>)\n",
            "1 0.00049824285\n",
            "state: tensor([[ 20.0000, 110.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[1.7926e-05, 9.6746e-01, 1.2261e-06, 3.2524e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2080]], grad_fn=<ExpBackward0>)\n",
            "1 0.00069795956\n",
            "state: tensor([[30.0000,  0.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0025, 0.0583, 0.0012, 0.9380]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3383]], grad_fn=<ExpBackward0>)\n",
            "3 0.00033046075\n",
            "0.00033046075 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 10.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0028, 0.0646, 0.0014, 0.9312]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3543]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00048462994\n",
            "-0.00048462994 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 20.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[0.0025, 0.0689, 0.0011, 0.9274]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-8.8003e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3624]], grad_fn=<ExpBackward0>)\n",
            "3 -8.800285e-05\n",
            "-8.800285e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 30.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.9841e-03, 8.3608e-02, 8.0861e-04, 9.1360e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3598]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00031368397\n",
            "-0.00031368397 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 40.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.6548e-03, 1.4263e-01, 5.6516e-04, 8.5515e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[3.0561e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.3291]], grad_fn=<ExpBackward0>)\n",
            "3 3.056074e-05\n",
            "3.056074e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 50.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.1690e-03, 2.4970e-01, 3.1851e-04, 7.4881e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0001]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2977]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00010495834\n",
            "-0.00010495834 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 60.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[7.5614e-04, 3.9925e-01, 1.6440e-04, 5.9983e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2611]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0006343008\n",
            "-0.0006343008 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 70.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[4.3014e-04, 5.7395e-01, 7.4371e-05, 4.2555e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2345]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00049476797\n",
            "state: tensor([[30.0000, 80.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[2.1520e-04, 7.3585e-01, 2.9437e-05, 2.6390e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0009]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2070]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0008605892\n",
            "state: tensor([[30.0000, 90.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[9.5621e-05, 8.5686e-01, 1.0304e-05, 1.4303e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[4.7058e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1879]], grad_fn=<ExpBackward0>)\n",
            "1 4.7058187e-05\n",
            "state: tensor([[ 30.0000, 100.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[4.2543e-05, 9.2815e-01, 3.6211e-06, 7.1806e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2121]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00060905056\n",
            "state: tensor([[ 30.0000, 110.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[1.6776e-05, 9.6525e-01, 1.1202e-06, 3.4735e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1940]], grad_fn=<ExpBackward0>)\n",
            "1 0.00031271702\n",
            "state: tensor([[40.0000,  0.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.8047e-03, 1.1477e-01, 7.2277e-04, 8.8271e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-3.5804e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3108]], grad_fn=<ExpBackward0>)\n",
            "3 -3.5804318e-05\n",
            "-3.5804318e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 10.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[2.1220e-03, 1.2954e-01, 8.0875e-04, 8.6753e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0008]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3341]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0007954045\n",
            "-0.0007954045 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 20.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.8895e-03, 1.3001e-01, 6.9113e-04, 8.6741e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3195]], grad_fn=<ExpBackward0>)\n",
            "3 0.000206125\n",
            "0.000206125 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 30.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.6548e-03, 1.4263e-01, 5.6516e-04, 8.5515e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-3.0561e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3291]], grad_fn=<ExpBackward0>)\n",
            "3 -3.056074e-05\n",
            "-3.056074e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 40.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.2479e-03, 1.7399e-01, 3.7248e-04, 8.2439e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0014]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3126]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0014496804\n",
            "-0.0014496804 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 50.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[9.9834e-04, 2.7241e-01, 2.5276e-04, 7.2634e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0021]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2949]], grad_fn=<ExpBackward0>)\n",
            "3 0.0021102738\n",
            "0.0021102738 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 60.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[6.4626e-04, 4.2634e-01, 1.3118e-04, 5.7288e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0021]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2694]], grad_fn=<ExpBackward0>)\n",
            "3 0.0020715056\n",
            "0.0020715056 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 70.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[3.5914e-04, 5.9081e-01, 5.8174e-05, 4.0877e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0011]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2415]], grad_fn=<ExpBackward0>)\n",
            "1 0.0010541384\n",
            "state: tensor([[40.0000, 80.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.8295e-04, 7.4223e-01, 2.3665e-05, 2.5757e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2110]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00021237406\n",
            "state: tensor([[40.0000, 90.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[8.3174e-05, 8.5288e-01, 8.5746e-06, 1.4703e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1882]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0006785118\n",
            "state: tensor([[ 40.0000, 100.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[3.8630e-05, 9.2224e-01, 3.1788e-06, 7.7717e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2056]], grad_fn=<ExpBackward0>)\n",
            "1 0.00070386566\n",
            "state: tensor([[ 40.0000, 110.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[1.5430e-05, 9.6116e-01, 1.0043e-06, 3.8826e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0009]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1765]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00093502953\n",
            "state: tensor([[50.0000,  0.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.2398e-03, 2.1097e-01, 3.9003e-04, 7.8740e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2844]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00039435184\n",
            "-0.00039435184 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 10.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.4986e-03, 2.4199e-01, 4.4794e-04, 7.5606e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.3145]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00073035737\n",
            "-0.00073035737 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 20.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.3391e-03, 2.3305e-01, 3.8889e-04, 7.6522e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[6.9123e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2869]], grad_fn=<ExpBackward0>)\n",
            "3 6.9122674e-05\n",
            "6.9122674e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 30.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.1690e-03, 2.4970e-01, 3.1851e-04, 7.4881e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2977]], grad_fn=<ExpBackward0>)\n",
            "3 0.00010495834\n",
            "0.00010495834 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 40.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[9.9834e-04, 2.7241e-01, 2.5276e-04, 7.2634e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0021]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2949]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0021102738\n",
            "-0.0021102738 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 50.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[7.0910e-04, 3.2711e-01, 1.5500e-04, 6.7203e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0034]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2698]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0033746832\n",
            "-0.0033746832 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 60.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[5.2378e-04, 4.5851e-01, 9.7917e-05, 5.4087e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0041]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2552]], grad_fn=<ExpBackward0>)\n",
            "3 0.0040598125\n",
            "0.0040598125 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 70.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[3.0546e-04, 6.2265e-01, 4.6217e-05, 3.7700e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0047]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2421]], grad_fn=<ExpBackward0>)\n",
            "1 0.004689009\n",
            "state: tensor([[50.0000, 80.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.4890e-04, 7.6058e-01, 1.7991e-05, 2.3925e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0039]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2156]], grad_fn=<ExpBackward0>)\n",
            "1 0.003917506\n",
            "state: tensor([[50.0000, 90.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[6.8117e-05, 8.6152e-01, 6.5716e-06, 1.3840e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0024]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1911]], grad_fn=<ExpBackward0>)\n",
            "1 0.002415605\n",
            "state: tensor([[ 50.0000, 100.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[3.2312e-05, 9.2569e-01, 2.5046e-06, 7.4276e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0030]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2056]], grad_fn=<ExpBackward0>)\n",
            "1 0.002986611\n",
            "state: tensor([[ 50.0000, 110.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[1.3287e-05, 9.6156e-01, 8.2181e-07, 3.8429e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0025]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1834]], grad_fn=<ExpBackward0>)\n",
            "1 0.0025045245\n",
            "state: tensor([[60.0000,  0.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[7.8044e-04, 3.5540e-01, 1.9287e-04, 6.4363e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0008]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2603]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00075290573\n",
            "-0.00075290573 <class 'numpy.ndarray'>\n",
            "state: tensor([[60.0000, 10.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[9.4404e-04, 4.0458e-01, 2.2174e-04, 5.9425e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2931]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00052345515\n",
            "-0.00052345515 <class 'numpy.ndarray'>\n",
            "state: tensor([[60.0000, 20.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[8.6192e-04, 3.9203e-01, 1.9727e-04, 6.0691e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2594]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00027535632\n",
            "-0.00027535632 <class 'numpy.ndarray'>\n",
            "state: tensor([[60.0000, 30.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[7.5614e-04, 3.9925e-01, 1.6440e-04, 5.9983e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2611]], grad_fn=<ExpBackward0>)\n",
            "3 0.0006343008\n",
            "0.0006343008 <class 'numpy.ndarray'>\n",
            "state: tensor([[60.0000, 40.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[6.4626e-04, 4.2634e-01, 1.3118e-04, 5.7288e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0021]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2694]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0020715056\n",
            "-0.0020715056 <class 'numpy.ndarray'>\n",
            "state: tensor([[60.0000, 50.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[5.2378e-04, 4.5851e-01, 9.7917e-05, 5.4087e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0041]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2552]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0040598125\n",
            "-0.0040598125 <class 'numpy.ndarray'>\n",
            "state: tensor([[60.0000, 60.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[3.4627e-04, 5.2857e-01, 5.5439e-05, 4.7103e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0053]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2328]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0052909325\n",
            "state: tensor([[60.0000, 70.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[2.3339e-04, 6.5620e-01, 3.2236e-05, 3.4354e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0059]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2182]], grad_fn=<ExpBackward0>)\n",
            "1 0.005859415\n",
            "state: tensor([[60.0000, 80.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.2428e-04, 7.8491e-01, 1.4023e-05, 2.1495e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0065]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2075]], grad_fn=<ExpBackward0>)\n",
            "1 0.0064903568\n",
            "state: tensor([[60.0000, 90.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[5.5416e-05, 8.7543e-01, 4.9944e-06, 1.2451e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0065]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1921]], grad_fn=<ExpBackward0>)\n",
            "1 0.0064970255\n",
            "state: tensor([[ 60.0000, 100.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[2.5943e-05, 9.3189e-01, 1.8780e-06, 6.8087e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0072]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2077]], grad_fn=<ExpBackward0>)\n",
            "1 0.0071936734\n",
            "state: tensor([[ 60.0000, 110.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[1.0867e-05, 9.6414e-01, 6.2809e-07, 3.5850e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0056]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1839]], grad_fn=<ExpBackward0>)\n",
            "1 0.005570837\n",
            "state: tensor([[70.0000,  0.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[4.3536e-04, 5.3120e-01, 8.4568e-05, 4.6828e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0011]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2357]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0010957896\n",
            "state: tensor([[70.0000, 10.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[5.1595e-04, 5.8906e-01, 9.5291e-05, 4.1033e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2729]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0003316553\n",
            "state: tensor([[70.0000, 20.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[4.8714e-04, 5.8259e-01, 8.7319e-05, 4.1684e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0011]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2443]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0010779524\n",
            "state: tensor([[70.0000, 30.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[4.3014e-04, 5.7395e-01, 7.4371e-05, 4.2555e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2345]], grad_fn=<ExpBackward0>)\n",
            "1 0.00049476797\n",
            "state: tensor([[70.0000, 40.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[3.5914e-04, 5.9081e-01, 5.8174e-05, 4.0877e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0011]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2415]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0010541384\n",
            "state: tensor([[70.0000, 50.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[3.0546e-04, 6.2265e-01, 4.6217e-05, 3.7700e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0047]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2421]], grad_fn=<ExpBackward0>)\n",
            "1 -0.004689009\n",
            "state: tensor([[70.0000, 60.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[2.3339e-04, 6.5620e-01, 3.2236e-05, 3.4354e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0059]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2182]], grad_fn=<ExpBackward0>)\n",
            "1 -0.005859415\n",
            "state: tensor([[70.0000, 70.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.4240e-04, 7.2021e-01, 1.6715e-05, 2.7964e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0071]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1983]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0070757167\n",
            "state: tensor([[70.0000, 80.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[8.8996e-05, 8.1244e-01, 9.0667e-06, 1.8746e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0075]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1844]], grad_fn=<ExpBackward0>)\n",
            "1 0.007525181\n",
            "state: tensor([[70.0000, 90.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[4.4816e-05, 8.8970e-01, 3.7617e-06, 1.1025e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0080]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1757]], grad_fn=<ExpBackward0>)\n",
            "1 0.007978044\n",
            "state: tensor([[ 70.0000, 100.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[2.1208e-05, 9.4019e-01, 1.4340e-06, 5.9786e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0096]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1950]], grad_fn=<ExpBackward0>)\n",
            "1 0.009587127\n",
            "state: tensor([[ 70.0000, 110.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[8.7136e-06, 9.6801e-01, 4.7050e-07, 3.1979e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0096]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1830]], grad_fn=<ExpBackward0>)\n",
            "1 0.00960451\n",
            "state: tensor([[80.0000,  0.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[2.1316e-04, 6.9848e-01, 3.2576e-05, 3.0127e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0014]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2111]], grad_fn=<ExpBackward0>)\n",
            "1 -0.001400593\n",
            "state: tensor([[80.0000, 10.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[2.4659e-04, 7.5110e-01, 3.5825e-05, 2.4862e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2528]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0002716103\n",
            "state: tensor([[80.0000, 20.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[2.3825e-04, 7.5046e-01, 3.3476e-05, 2.4927e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0015]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2286]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0014950593\n",
            "state: tensor([[80.0000, 30.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[2.1520e-04, 7.3585e-01, 2.9437e-05, 2.6390e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0009]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2070]], grad_fn=<ExpBackward0>)\n",
            "1 0.0008605892\n",
            "state: tensor([[80.0000, 40.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.8295e-04, 7.4223e-01, 2.3665e-05, 2.5757e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2110]], grad_fn=<ExpBackward0>)\n",
            "1 0.00021237406\n",
            "state: tensor([[80.0000, 50.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.4890e-04, 7.6058e-01, 1.7991e-05, 2.3925e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0039]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2156]], grad_fn=<ExpBackward0>)\n",
            "1 -0.003917506\n",
            "state: tensor([[80.0000, 60.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.2428e-04, 7.8491e-01, 1.4023e-05, 2.1495e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0065]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2075]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0064903568\n",
            "state: tensor([[80.0000, 70.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[8.8996e-05, 8.1244e-01, 9.0667e-06, 1.8746e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0075]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1844]], grad_fn=<ExpBackward0>)\n",
            "1 -0.007525181\n",
            "state: tensor([[80.0000, 80.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[5.1039e-05, 8.5526e-01, 4.3923e-06, 1.4468e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0087]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1670]], grad_fn=<ExpBackward0>)\n",
            "1 -0.008727187\n",
            "state: tensor([[80.0000, 90.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[3.0228e-05, 9.0814e-01, 2.2660e-06, 9.1826e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0091]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1544]], grad_fn=<ExpBackward0>)\n",
            "1 0.009140346\n",
            "state: tensor([[ 80.0000, 100.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[1.6414e-05, 9.4774e-01, 1.0259e-06, 5.2241e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0100]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1684]], grad_fn=<ExpBackward0>)\n",
            "1 0.010004526\n",
            "state: tensor([[ 80.0000, 110.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[7.0895e-06, 9.7204e-01, 3.5758e-07, 2.7948e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0114]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1665]], grad_fn=<ExpBackward0>)\n",
            "1 0.011353857\n",
            "state: tensor([[90.0000,  0.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[9.3336e-05, 8.2481e-01, 1.1237e-05, 1.7508e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0016]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1867]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0015861914\n",
            "state: tensor([[90.0000, 10.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.0562e-04, 8.6304e-01, 1.2096e-05, 1.3685e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2294]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00071923947\n",
            "state: tensor([[90.0000, 20.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.0432e-04, 8.6602e-01, 1.1495e-05, 1.3386e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0017]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2125]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0017204994\n",
            "state: tensor([[90.0000, 30.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[9.5621e-05, 8.5686e-01, 1.0304e-05, 1.4303e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-4.7058e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1879]], grad_fn=<ExpBackward0>)\n",
            "1 -4.7058187e-05\n",
            "state: tensor([[90.0000, 40.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[8.3174e-05, 8.5288e-01, 8.5746e-06, 1.4703e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1882]], grad_fn=<ExpBackward0>)\n",
            "1 0.0006785118\n",
            "state: tensor([[90.0000, 50.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[6.8117e-05, 8.6152e-01, 6.5716e-06, 1.3840e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0024]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1911]], grad_fn=<ExpBackward0>)\n",
            "1 -0.002415605\n",
            "state: tensor([[90.0000, 60.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[5.5416e-05, 8.7543e-01, 4.9944e-06, 1.2451e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0065]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1921]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0064970255\n",
            "state: tensor([[90.0000, 70.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[4.4816e-05, 8.8970e-01, 3.7617e-06, 1.1025e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0080]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1757]], grad_fn=<ExpBackward0>)\n",
            "1 -0.007978044\n",
            "state: tensor([[90.0000, 80.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[3.0228e-05, 9.0814e-01, 2.2660e-06, 9.1826e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0091]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1544]], grad_fn=<ExpBackward0>)\n",
            "1 -0.009140346\n",
            "state: tensor([[90.0000, 90.0000,  0.0000,  0.0000,  0.2000]]) dist_dsc.probs: tensor([[1.6775e-05, 9.3134e-01, 1.0584e-06, 6.8646e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0104]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1407]], grad_fn=<ExpBackward0>)\n",
            "1 -0.010375943\n",
            "state: tensor([[ 90.0000, 100.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[1.0627e-05, 9.5767e-01, 5.8976e-07, 4.2322e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0110]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1443]], grad_fn=<ExpBackward0>)\n",
            "1 0.011043615\n",
            "state: tensor([[ 90.0000, 110.0000,   0.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[5.2601e-06, 9.7592e-01, 2.4305e-07, 2.4071e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0115]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1406]], grad_fn=<ExpBackward0>)\n",
            "1 0.011531968\n",
            "state: tensor([[100.0000,   0.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[4.0920e-05, 9.0625e-01, 3.9076e-06, 9.3703e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1865]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00058853027\n",
            "state: tensor([[100.0000,  10.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[4.5623e-05, 9.3011e-01, 4.1485e-06, 6.9839e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-7.5404e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2333]], grad_fn=<ExpBackward0>)\n",
            "1 -7.5404154e-05\n",
            "state: tensor([[100.0000,  20.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[4.6069e-05, 9.3394e-01, 4.0039e-06, 6.6014e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2321]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00049824285\n",
            "state: tensor([[100.0000,  30.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[4.2543e-05, 9.2815e-01, 3.6211e-06, 7.1806e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2121]], grad_fn=<ExpBackward0>)\n",
            "1 0.00060905056\n",
            "state: tensor([[100.0000,  40.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[3.8630e-05, 9.2224e-01, 3.1788e-06, 7.7717e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2056]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00070386566\n",
            "state: tensor([[100.0000,  50.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[3.2312e-05, 9.2569e-01, 2.5046e-06, 7.4276e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0030]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2056]], grad_fn=<ExpBackward0>)\n",
            "1 -0.002986611\n",
            "state: tensor([[100.0000,  60.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[2.5943e-05, 9.3189e-01, 1.8780e-06, 6.8087e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0072]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2077]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0071936734\n",
            "state: tensor([[100.0000,  70.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[2.1208e-05, 9.4019e-01, 1.4340e-06, 5.9786e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0096]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1950]], grad_fn=<ExpBackward0>)\n",
            "1 -0.009587127\n",
            "state: tensor([[100.0000,  80.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[1.6414e-05, 9.4774e-01, 1.0259e-06, 5.2241e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0100]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1684]], grad_fn=<ExpBackward0>)\n",
            "1 -0.010004526\n",
            "state: tensor([[100.0000,  90.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[1.0627e-05, 9.5767e-01, 5.8976e-07, 4.2322e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0110]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1443]], grad_fn=<ExpBackward0>)\n",
            "1 -0.011043615\n",
            "state: tensor([[100.0000, 100.0000,   1.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[6.5382e-06, 9.7350e-01, 3.0070e-07, 2.6491e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0103]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1640]], grad_fn=<ExpBackward0>)\n",
            "1 -0.010287269\n",
            "state: tensor([[100.0000, 110.0000,   1.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[3.6839e-06, 9.8276e-01, 1.4839e-07, 1.7233e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0122]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1503]], grad_fn=<ExpBackward0>)\n",
            "1 0.012185282\n",
            "state: tensor([[110.0000,   0.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[1.5882e-05, 9.5121e-01, 1.1966e-06, 4.8769e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0009]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1612]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0008538598\n",
            "state: tensor([[110.0000,  10.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[1.7474e-05, 9.6457e-01, 1.2564e-06, 3.5415e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2037]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0003397801\n",
            "state: tensor([[110.0000,  20.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[1.7926e-05, 9.6746e-01, 1.2261e-06, 3.2524e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2080]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00069795956\n",
            "state: tensor([[110.0000,  30.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[1.6776e-05, 9.6525e-01, 1.1202e-06, 3.4735e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1940]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00031271702\n",
            "state: tensor([[110.0000,  40.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[1.5430e-05, 9.6116e-01, 1.0043e-06, 3.8826e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0009]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1765]], grad_fn=<ExpBackward0>)\n",
            "1 0.00093502953\n",
            "state: tensor([[110.0000,  50.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[1.3287e-05, 9.6156e-01, 8.2181e-07, 3.8429e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0025]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1834]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0025045245\n",
            "state: tensor([[110.0000,  60.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[1.0867e-05, 9.6414e-01, 6.2809e-07, 3.5850e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0056]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1839]], grad_fn=<ExpBackward0>)\n",
            "1 -0.005570837\n",
            "state: tensor([[110.0000,  70.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[8.7136e-06, 9.6801e-01, 4.7050e-07, 3.1979e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0096]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1830]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00960451\n",
            "state: tensor([[110.0000,  80.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[7.0895e-06, 9.7204e-01, 3.5758e-07, 2.7948e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0114]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1665]], grad_fn=<ExpBackward0>)\n",
            "1 -0.011353857\n",
            "state: tensor([[110.0000,  90.0000,   1.0000,   0.0000,   0.2000]]) dist_dsc.probs: tensor([[5.2601e-06, 9.7592e-01, 2.4305e-07, 2.4071e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0115]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1406]], grad_fn=<ExpBackward0>)\n",
            "1 -0.011531968\n",
            "state: tensor([[110.0000, 100.0000,   1.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[3.6839e-06, 9.8276e-01, 1.4839e-07, 1.7233e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0122]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1503]], grad_fn=<ExpBackward0>)\n",
            "1 -0.012185282\n",
            "state: tensor([[110.0000, 110.0000,   1.0000,   1.0000,   0.2000]]) dist_dsc.probs: tensor([[2.0026e-06, 9.8829e-01, 6.7517e-08, 1.1707e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0113]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1373]], grad_fn=<ExpBackward0>)\n",
            "1 -0.011338605\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state: tensor([[0., 0., 0., 0., 1.]]) dist_dsc.probs: tensor([[0.0027, 0.0050, 0.0027, 0.9896]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0017]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2222]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0016572997\n",
            "-0.0016572997 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0026, 0.0100, 0.0022, 0.9853]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0020]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2350]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0019560014\n",
            "-0.0019560014 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0021, 0.0213, 0.0014, 0.9752]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0017]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2207]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0016815402\n",
            "-0.0016815402 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.6661e-03, 4.5299e-02, 8.7993e-04, 9.5215e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0015]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2072]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0014631548\n",
            "-0.0014631548 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.2902e-03, 9.3198e-02, 5.3477e-04, 9.0498e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0012]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1940]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0012320937\n",
            "-0.0012320937 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.3764e-04, 1.8046e-01, 3.0528e-04, 8.1830e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0010]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1806]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0009915214\n",
            "-0.0009915214 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[6.1344e-04, 3.1483e-01, 1.5657e-04, 6.8440e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1670]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00070440513\n",
            "-0.00070440513 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[3.5702e-04, 4.8867e-01, 7.1431e-05, 5.1090e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1545]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00041729526\n",
            "-0.00041729526 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.8225e-04, 6.6528e-01, 2.8583e-05, 3.3451e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0001]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1429]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00013018065\n",
            "state: tensor([[ 0., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[8.2621e-05, 8.0489e-01, 1.0163e-05, 1.9502e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1318]], grad_fn=<ExpBackward0>)\n",
            "1 0.00019081854\n",
            "state: tensor([[  0., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[3.7377e-05, 8.9706e-01, 3.6239e-06, 1.0290e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1440]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0006959557\n",
            "state: tensor([[  0., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.4689e-05, 9.4691e-01, 1.1203e-06, 5.3073e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1289]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0003878452\n",
            "state: tensor([[10.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0026, 0.0100, 0.0022, 0.9853]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0020]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2350]], grad_fn=<ExpBackward0>)\n",
            "3 0.0019560014\n",
            "0.0019560014 <class 'numpy.ndarray'>\n",
            "state: tensor([[10., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0033, 0.0142, 0.0026, 0.9799]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[8.2964e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2617]], grad_fn=<ExpBackward0>)\n",
            "3 8.2963525e-05\n",
            "8.2963525e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[10., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0028, 0.0273, 0.0018, 0.9681]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[8.1292e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2478]], grad_fn=<ExpBackward0>)\n",
            "3 8.129244e-05\n",
            "8.129244e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[10., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0022, 0.0558, 0.0011, 0.9409]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0010]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2326]], grad_fn=<ExpBackward0>)\n",
            "3 0.0010475898\n",
            "0.0010475898 <class 'numpy.ndarray'>\n",
            "state: tensor([[10., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.6767e-03, 1.1242e-01, 6.5403e-04, 8.8525e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0008]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2182]], grad_fn=<ExpBackward0>)\n",
            "3 0.00080198765\n",
            "0.00080198765 <class 'numpy.ndarray'>\n",
            "state: tensor([[10., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.1929e-03, 2.1271e-01, 3.6537e-04, 7.8573e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2048]], grad_fn=<ExpBackward0>)\n",
            "3 0.0005072124\n",
            "0.0005072124 <class 'numpy.ndarray'>\n",
            "state: tensor([[10., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.6811e-04, 3.6435e-01, 1.8471e-04, 6.3469e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1921]], grad_fn=<ExpBackward0>)\n",
            "3 0.00021244257\n",
            "0.00021244257 <class 'numpy.ndarray'>\n",
            "state: tensor([[10., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.3484e-04, 5.4872e-01, 8.2104e-05, 4.5077e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-8.2357e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1803]], grad_fn=<ExpBackward0>)\n",
            "1 -8.235677e-05\n",
            "state: tensor([[10., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.1388e-04, 7.2002e-01, 3.1741e-05, 2.7974e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-8.8327e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1684]], grad_fn=<ExpBackward0>)\n",
            "1 -8.832748e-05\n",
            "state: tensor([[10., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.3762e-05, 8.4433e-01, 1.0948e-05, 1.5557e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1564]], grad_fn=<ExpBackward0>)\n",
            "1 0.0001546597\n",
            "state: tensor([[ 10., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[4.1716e-05, 9.2258e-01, 3.8405e-06, 7.7378e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0008]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1761]], grad_fn=<ExpBackward0>)\n",
            "1 -0.000834612\n",
            "state: tensor([[ 10., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.6189e-05, 9.6134e-01, 1.1751e-06, 3.8638e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1588]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00043669646\n",
            "state: tensor([[20.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0021, 0.0213, 0.0014, 0.9752]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0017]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2207]], grad_fn=<ExpBackward0>)\n",
            "3 0.0016815402\n",
            "0.0016815402 <class 'numpy.ndarray'>\n",
            "state: tensor([[20., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0028, 0.0273, 0.0018, 0.9681]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-8.1292e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2478]], grad_fn=<ExpBackward0>)\n",
            "3 -8.129244e-05\n",
            "-8.129244e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[20., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0023, 0.0328, 0.0013, 0.9635]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[4.1614e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2423]], grad_fn=<ExpBackward0>)\n",
            "3 4.1613734e-05\n",
            "4.1613734e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[20., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.9620e-03, 5.9487e-02, 9.2274e-04, 9.3763e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0001]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2278]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00010260186\n",
            "-0.00010260186 <class 'numpy.ndarray'>\n",
            "state: tensor([[20., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.5199e-03, 1.1365e-01, 5.6955e-04, 8.8426e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2025]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00028918558\n",
            "-0.00028918558 <class 'numpy.ndarray'>\n",
            "state: tensor([[20., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.0958e-03, 2.0766e-01, 3.2546e-04, 7.9092e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-5.4726e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1828]], grad_fn=<ExpBackward0>)\n",
            "3 -5.472559e-05\n",
            "-5.472559e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[20., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.2717e-04, 3.5940e-01, 1.6993e-04, 6.3970e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0011]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1703]], grad_fn=<ExpBackward0>)\n",
            "3 0.0010746209\n",
            "0.0010746209 <class 'numpy.ndarray'>\n",
            "state: tensor([[20., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.2201e-04, 5.4861e-01, 7.7197e-05, 4.5089e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0018]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1606]], grad_fn=<ExpBackward0>)\n",
            "1 0.0017614345\n",
            "state: tensor([[20., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.1195e-04, 7.2473e-01, 3.0350e-05, 2.7503e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0019]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1514]], grad_fn=<ExpBackward0>)\n",
            "1 0.0018827158\n",
            "state: tensor([[20., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.3925e-05, 8.4958e-01, 1.0549e-05, 1.5032e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0017]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1422]], grad_fn=<ExpBackward0>)\n",
            "1 0.0016784366\n",
            "state: tensor([[ 20., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[4.2170e-05, 9.2643e-01, 3.7189e-06, 7.3529e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-8.3183e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1666]], grad_fn=<ExpBackward0>)\n",
            "1 -8.318343e-05\n",
            "state: tensor([[ 20., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.6559e-05, 9.6419e-01, 1.1461e-06, 3.5796e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1561]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00036869862\n",
            "state: tensor([[30.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.6661e-03, 4.5299e-02, 8.7993e-04, 9.5215e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0015]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2072]], grad_fn=<ExpBackward0>)\n",
            "3 0.0014631548\n",
            "0.0014631548 <class 'numpy.ndarray'>\n",
            "state: tensor([[30., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0022, 0.0558, 0.0011, 0.9409]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0010]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2326]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0010475898\n",
            "-0.0010475898 <class 'numpy.ndarray'>\n",
            "state: tensor([[30., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.9620e-03, 5.9487e-02, 9.2274e-04, 9.3763e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2278]], grad_fn=<ExpBackward0>)\n",
            "3 0.00010260186\n",
            "0.00010260186 <class 'numpy.ndarray'>\n",
            "state: tensor([[30., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.5617e-03, 7.2680e-02, 6.5063e-04, 9.2511e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2244]], grad_fn=<ExpBackward0>)\n",
            "3 0.00010636277\n",
            "0.00010636277 <class 'numpy.ndarray'>\n",
            "state: tensor([[30., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.3070e-03, 1.2434e-01, 4.5688e-04, 8.7389e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2080]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00057400396\n",
            "-0.00057400396 <class 'numpy.ndarray'>\n",
            "state: tensor([[30., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.5273e-04, 2.2141e-01, 2.6620e-04, 7.7737e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0001]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1890]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00014972678\n",
            "-0.00014972678 <class 'numpy.ndarray'>\n",
            "state: tensor([[30., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[6.3910e-04, 3.6672e-01, 1.4226e-04, 6.3249e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1655]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0007053986\n",
            "-0.0007053986 <class 'numpy.ndarray'>\n",
            "state: tensor([[30., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[3.7242e-04, 5.4042e-01, 6.5845e-05, 4.5914e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1486]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00056838087\n",
            "state: tensor([[30., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.9115e-04, 7.0892e-01, 2.6719e-05, 2.9086e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1342]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0004713015\n",
            "state: tensor([[30., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[8.6362e-05, 8.3925e-01, 9.5018e-06, 1.6065e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0010]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1245]], grad_fn=<ExpBackward0>)\n",
            "1 0.0009589557\n",
            "state: tensor([[ 30., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[3.9061e-05, 9.2101e-01, 3.3738e-06, 7.8947e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1458]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00024330794\n",
            "state: tensor([[ 30., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.5510e-05, 9.6191e-01, 1.0487e-06, 3.8072e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1375]], grad_fn=<ExpBackward0>)\n",
            "1 0.00044353615\n",
            "state: tensor([[40.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.2902e-03, 9.3198e-02, 5.3477e-04, 9.0498e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0012]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1940]], grad_fn=<ExpBackward0>)\n",
            "3 0.0012320937\n",
            "0.0012320937 <class 'numpy.ndarray'>\n",
            "state: tensor([[40., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.6767e-03, 1.1242e-01, 6.5403e-04, 8.8525e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0008]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2182]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00080198765\n",
            "-0.00080198765 <class 'numpy.ndarray'>\n",
            "state: tensor([[40., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.5199e-03, 1.1365e-01, 5.6955e-04, 8.8426e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2025]], grad_fn=<ExpBackward0>)\n",
            "3 0.00028918558\n",
            "0.00028918558 <class 'numpy.ndarray'>\n",
            "state: tensor([[40., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.3070e-03, 1.2434e-01, 4.5688e-04, 8.7389e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2080]], grad_fn=<ExpBackward0>)\n",
            "3 0.00057400396\n",
            "0.00057400396 <class 'numpy.ndarray'>\n",
            "state: tensor([[40., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.9491e-04, 1.5319e-01, 3.0356e-04, 8.4551e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-6.5913e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2062]], grad_fn=<ExpBackward0>)\n",
            "3 -6.591281e-05\n",
            "-6.591281e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[40., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[8.0721e-04, 2.4212e-01, 2.0934e-04, 7.5687e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0008]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1887]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0007849121\n",
            "-0.0007849121 <class 'numpy.ndarray'>\n",
            "state: tensor([[40., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[5.4316e-04, 3.8983e-01, 1.1303e-04, 6.0951e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0001]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1748]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00014442267\n",
            "-0.00014442267 <class 'numpy.ndarray'>\n",
            "state: tensor([[40., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[3.1502e-04, 5.6234e-01, 5.2238e-05, 4.3730e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1545]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0005694759\n",
            "state: tensor([[40., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.6354e-04, 7.2011e-01, 2.1639e-05, 2.7970e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0011]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1352]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0011477642\n",
            "state: tensor([[40., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.5408e-05, 8.3896e-01, 7.9376e-06, 1.6095e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0010]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1214]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0010082487\n",
            "state: tensor([[ 40., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[3.5411e-05, 9.1483e-01, 2.9687e-06, 8.5128e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0022]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1364]], grad_fn=<ExpBackward0>)\n",
            "1 -0.002150174\n",
            "state: tensor([[ 40., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.4239e-05, 9.5767e-01, 9.4142e-07, 4.2311e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0026]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1216]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0025769358\n",
            "state: tensor([[50.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.3764e-04, 1.8046e-01, 3.0528e-04, 8.1830e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0010]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1806]], grad_fn=<ExpBackward0>)\n",
            "3 0.0009915214\n",
            "0.0009915214 <class 'numpy.ndarray'>\n",
            "state: tensor([[50., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.1929e-03, 2.1271e-01, 3.6537e-04, 7.8573e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2048]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0005072124\n",
            "-0.0005072124 <class 'numpy.ndarray'>\n",
            "state: tensor([[50., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.0958e-03, 2.0766e-01, 3.2546e-04, 7.9092e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[5.4726e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1828]], grad_fn=<ExpBackward0>)\n",
            "3 5.472559e-05\n",
            "5.472559e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[50., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.5273e-04, 2.2141e-01, 2.6620e-04, 7.7737e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1890]], grad_fn=<ExpBackward0>)\n",
            "3 0.00014972678\n",
            "0.00014972678 <class 'numpy.ndarray'>\n",
            "state: tensor([[50., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[8.0721e-04, 2.4212e-01, 2.0934e-04, 7.5687e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0008]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1887]], grad_fn=<ExpBackward0>)\n",
            "3 0.0007849121\n",
            "0.0007849121 <class 'numpy.ndarray'>\n",
            "state: tensor([[50., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[5.7807e-04, 2.9451e-01, 1.2917e-04, 7.0479e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1872]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0003877979\n",
            "-0.0003877979 <class 'numpy.ndarray'>\n",
            "state: tensor([[50., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.3558e-04, 4.1836e-01, 8.3565e-05, 5.8112e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1713]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00026830952\n",
            "-0.00026830952 <class 'numpy.ndarray'>\n",
            "state: tensor([[50., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.6578e-04, 5.8933e-01, 4.1189e-05, 4.1036e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1591]], grad_fn=<ExpBackward0>)\n",
            "1 0.00022574313\n",
            "state: tensor([[50., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.3319e-04, 7.3908e-01, 1.6457e-05, 2.6077e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0001]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1427]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00014402732\n",
            "state: tensor([[50., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[6.1937e-05, 8.4813e-01, 6.1065e-06, 1.5180e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0010]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1261]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0010497377\n",
            "state: tensor([[ 50., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[2.9632e-05, 9.1840e-01, 2.3442e-06, 8.1567e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0025]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1380]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0025091344\n",
            "state: tensor([[ 50., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.2239e-05, 9.5784e-01, 7.7131e-07, 4.2146e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0027]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1241]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0027440286\n",
            "state: tensor([[60.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[6.1344e-04, 3.1483e-01, 1.5657e-04, 6.8440e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1670]], grad_fn=<ExpBackward0>)\n",
            "3 0.00070440513\n",
            "0.00070440513 <class 'numpy.ndarray'>\n",
            "state: tensor([[60., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.6811e-04, 3.6435e-01, 1.8471e-04, 6.3469e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1921]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00021244257\n",
            "-0.00021244257 <class 'numpy.ndarray'>\n",
            "state: tensor([[60., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.2717e-04, 3.5940e-01, 1.6993e-04, 6.3970e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0011]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1703]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0010746209\n",
            "-0.0010746209 <class 'numpy.ndarray'>\n",
            "state: tensor([[60., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[6.3910e-04, 3.6672e-01, 1.4226e-04, 6.3249e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1655]], grad_fn=<ExpBackward0>)\n",
            "3 0.0007053986\n",
            "0.0007053986 <class 'numpy.ndarray'>\n",
            "state: tensor([[60., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[5.4316e-04, 3.8983e-01, 1.1303e-04, 6.0951e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1748]], grad_fn=<ExpBackward0>)\n",
            "3 0.00014442267\n",
            "0.00014442267 <class 'numpy.ndarray'>\n",
            "state: tensor([[60., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.3558e-04, 4.1836e-01, 8.3565e-05, 5.8112e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1713]], grad_fn=<ExpBackward0>)\n",
            "3 0.00026830952\n",
            "0.00026830952 <class 'numpy.ndarray'>\n",
            "state: tensor([[60., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.9104e-04, 4.9059e-01, 4.7630e-05, 5.0907e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-5.8036e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1628]], grad_fn=<ExpBackward0>)\n",
            "3 -5.8036152e-05\n",
            "-5.8036152e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[60., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.0096e-04, 6.1931e-01, 2.8462e-05, 3.8046e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1552]], grad_fn=<ExpBackward0>)\n",
            "1 0.0005165509\n",
            "state: tensor([[60., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.0966e-04, 7.6298e-01, 1.2632e-05, 2.3689e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1425]], grad_fn=<ExpBackward0>)\n",
            "1 0.0005876169\n",
            "state: tensor([[60., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[5.0357e-05, 8.6297e-01, 4.6362e-06, 1.3697e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1297]], grad_fn=<ExpBackward0>)\n",
            "1 0.0004018427\n",
            "state: tensor([[ 60., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[2.3782e-05, 9.2503e-01, 1.7561e-06, 7.4944e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0013]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1426]], grad_fn=<ExpBackward0>)\n",
            "1 0.0012945133\n",
            "state: tensor([[ 60., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.0033e-05, 9.6065e-01, 5.9113e-07, 3.9343e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1268]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00024145297\n",
            "state: tensor([[70.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[3.5702e-04, 4.8867e-01, 7.1431e-05, 5.1090e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1545]], grad_fn=<ExpBackward0>)\n",
            "3 0.00041729526\n",
            "0.00041729526 <class 'numpy.ndarray'>\n",
            "state: tensor([[70., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.3484e-04, 5.4872e-01, 8.2104e-05, 4.5077e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[8.2357e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1803]], grad_fn=<ExpBackward0>)\n",
            "1 8.235677e-05\n",
            "state: tensor([[70., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.2201e-04, 5.4861e-01, 7.7197e-05, 4.5089e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0018]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1606]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0017614345\n",
            "state: tensor([[70., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[3.7242e-04, 5.4042e-01, 6.5845e-05, 4.5914e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1486]], grad_fn=<ExpBackward0>)\n",
            "1 0.00056838087\n",
            "state: tensor([[70., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[3.1502e-04, 5.6234e-01, 5.2238e-05, 4.3730e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1545]], grad_fn=<ExpBackward0>)\n",
            "1 0.0005694759\n",
            "state: tensor([[70., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.6578e-04, 5.8933e-01, 4.1189e-05, 4.1036e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1591]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00022574313\n",
            "state: tensor([[70., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.0096e-04, 6.1931e-01, 2.8462e-05, 3.8046e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1552]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0005165509\n",
            "state: tensor([[70., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.2364e-04, 6.8959e-01, 1.4819e-05, 3.1027e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0019]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1406]], grad_fn=<ExpBackward0>)\n",
            "1 -0.001862283\n",
            "state: tensor([[70., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.8935e-05, 7.8749e-01, 8.2396e-06, 2.1243e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0024]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1337]], grad_fn=<ExpBackward0>)\n",
            "1 0.002392912\n",
            "state: tensor([[70., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.0224e-05, 8.7844e-01, 3.4414e-06, 1.2152e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0028]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1268]], grad_fn=<ExpBackward0>)\n",
            "1 0.0028039457\n",
            "state: tensor([[ 70., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.9471e-05, 9.3423e-01, 1.3425e-06, 6.5749e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0047]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1434]], grad_fn=<ExpBackward0>)\n",
            "1 0.004732991\n",
            "state: tensor([[ 70., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[8.0287e-06, 9.6479e-01, 4.4187e-07, 3.5203e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0040]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1284]], grad_fn=<ExpBackward0>)\n",
            "1 0.003977311\n",
            "state: tensor([[80.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.8225e-04, 6.6528e-01, 2.8583e-05, 3.3451e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1429]], grad_fn=<ExpBackward0>)\n",
            "1 0.00013018065\n",
            "state: tensor([[80., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.1388e-04, 7.2002e-01, 3.1741e-05, 2.7974e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[8.8327e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1684]], grad_fn=<ExpBackward0>)\n",
            "1 8.832748e-05\n",
            "state: tensor([[80., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.1195e-04, 7.2473e-01, 3.0350e-05, 2.7503e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0019]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1514]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0018827158\n",
            "state: tensor([[80., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.9115e-04, 7.0892e-01, 2.6719e-05, 2.9086e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1342]], grad_fn=<ExpBackward0>)\n",
            "1 0.0004713015\n",
            "state: tensor([[80., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.6354e-04, 7.2011e-01, 2.1639e-05, 2.7970e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0011]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1352]], grad_fn=<ExpBackward0>)\n",
            "1 0.0011477642\n",
            "state: tensor([[80., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.3319e-04, 7.3908e-01, 1.6457e-05, 2.6077e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1427]], grad_fn=<ExpBackward0>)\n",
            "1 0.00014402732\n",
            "state: tensor([[80., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.0966e-04, 7.6298e-01, 1.2632e-05, 2.3689e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1425]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0005876169\n",
            "state: tensor([[80., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.8935e-05, 7.8749e-01, 8.2396e-06, 2.1243e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0024]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1337]], grad_fn=<ExpBackward0>)\n",
            "1 -0.002392912\n",
            "state: tensor([[80., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.5343e-05, 8.3671e-01, 3.9801e-06, 1.6324e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0038]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1214]], grad_fn=<ExpBackward0>)\n",
            "1 -0.003787271\n",
            "state: tensor([[80., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.7342e-05, 8.9488e-01, 2.0982e-06, 1.0509e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0043]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1152]], grad_fn=<ExpBackward0>)\n",
            "1 0.004295111\n",
            "state: tensor([[ 80., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.4957e-05, 9.4218e-01, 9.5361e-07, 5.7807e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0054]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1282]], grad_fn=<ExpBackward0>)\n",
            "1 0.005400424\n",
            "state: tensor([[ 80., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[6.5271e-06, 9.6921e-01, 3.3551e-07, 3.0784e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0067]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1236]], grad_fn=<ExpBackward0>)\n",
            "1 0.0066528055\n",
            "state: tensor([[90.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[8.2621e-05, 8.0489e-01, 1.0163e-05, 1.9502e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1318]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00019081854\n",
            "state: tensor([[90., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.3762e-05, 8.4433e-01, 1.0948e-05, 1.5557e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1564]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0001546597\n",
            "state: tensor([[90., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.3925e-05, 8.4958e-01, 1.0549e-05, 1.5032e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0017]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1422]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0016784366\n",
            "state: tensor([[90., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[8.6362e-05, 8.3925e-01, 9.5018e-06, 1.6065e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0010]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1245]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0009589557\n",
            "state: tensor([[90., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.5408e-05, 8.3896e-01, 7.9376e-06, 1.6095e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0010]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1214]], grad_fn=<ExpBackward0>)\n",
            "1 0.0010082487\n",
            "state: tensor([[90., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[6.1937e-05, 8.4813e-01, 6.1065e-06, 1.5180e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0010]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1261]], grad_fn=<ExpBackward0>)\n",
            "1 0.0010497377\n",
            "state: tensor([[90., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[5.0357e-05, 8.6297e-01, 4.6362e-06, 1.3697e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1297]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0004018427\n",
            "state: tensor([[90., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.0224e-05, 8.7844e-01, 3.4414e-06, 1.2152e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0028]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1268]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0028039457\n",
            "state: tensor([[90., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.7342e-05, 8.9488e-01, 2.0982e-06, 1.0509e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0043]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1152]], grad_fn=<ExpBackward0>)\n",
            "1 -0.004295111\n",
            "state: tensor([[90., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.5101e-05, 9.2199e-01, 9.7078e-07, 7.7994e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0057]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1048]], grad_fn=<ExpBackward0>)\n",
            "1 -0.005712233\n",
            "state: tensor([[ 90., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[9.7181e-06, 9.5253e-01, 5.5071e-07, 4.7464e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0069]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1142]], grad_fn=<ExpBackward0>)\n",
            "1 0.0068581314\n",
            "state: tensor([[ 90., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[4.8086e-06, 9.7328e-01, 2.2665e-07, 2.6716e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0072]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1093]], grad_fn=<ExpBackward0>)\n",
            "1 0.0071705263\n",
            "state: tensor([[100.,   0.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[3.7377e-05, 8.9706e-01, 3.6239e-06, 1.0290e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1440]], grad_fn=<ExpBackward0>)\n",
            "1 0.0006959557\n",
            "state: tensor([[100.,  10.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[4.1716e-05, 9.2258e-01, 3.8405e-06, 7.7378e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0008]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1761]], grad_fn=<ExpBackward0>)\n",
            "1 0.000834612\n",
            "state: tensor([[100.,  20.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[4.2170e-05, 9.2643e-01, 3.7189e-06, 7.3529e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[8.3183e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1666]], grad_fn=<ExpBackward0>)\n",
            "1 8.318343e-05\n",
            "state: tensor([[100.,  30.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[3.9061e-05, 9.2101e-01, 3.3738e-06, 7.8947e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1458]], grad_fn=<ExpBackward0>)\n",
            "1 0.00024330794\n",
            "state: tensor([[100.,  40.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[3.5411e-05, 9.1483e-01, 2.9687e-06, 8.5128e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0022]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1364]], grad_fn=<ExpBackward0>)\n",
            "1 0.002150174\n",
            "state: tensor([[100.,  50.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[2.9632e-05, 9.1840e-01, 2.3442e-06, 8.1567e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0025]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1380]], grad_fn=<ExpBackward0>)\n",
            "1 0.0025091344\n",
            "state: tensor([[100.,  60.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[2.3782e-05, 9.2503e-01, 1.7561e-06, 7.4944e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0013]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1426]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0012945133\n",
            "state: tensor([[100.,  70.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.9471e-05, 9.3423e-01, 1.3425e-06, 6.5749e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0047]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1434]], grad_fn=<ExpBackward0>)\n",
            "1 -0.004732991\n",
            "state: tensor([[100.,  80.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.4957e-05, 9.4218e-01, 9.5361e-07, 5.7807e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0054]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1282]], grad_fn=<ExpBackward0>)\n",
            "1 -0.005400424\n",
            "state: tensor([[100.,  90.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[9.7181e-06, 9.5253e-01, 5.5071e-07, 4.7464e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0069]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1142]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0068581314\n",
            "state: tensor([[100., 100.,   1.,   1.,   1.]]) dist_dsc.probs: tensor([[5.9634e-06, 9.6955e-01, 2.7996e-07, 3.0441e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0113]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1340]], grad_fn=<ExpBackward0>)\n",
            "1 -0.011340325\n",
            "state: tensor([[100., 110.,   1.,   1.,   1.]]) dist_dsc.probs: tensor([[3.3815e-06, 9.8084e-01, 1.3905e-07, 1.9160e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0123]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1235]], grad_fn=<ExpBackward0>)\n",
            "1 0.012320618\n",
            "state: tensor([[110.,   0.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.4689e-05, 9.4691e-01, 1.1203e-06, 5.3073e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1289]], grad_fn=<ExpBackward0>)\n",
            "1 0.0003878452\n",
            "state: tensor([[110.,  10.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.6189e-05, 9.6134e-01, 1.1751e-06, 3.8638e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1588]], grad_fn=<ExpBackward0>)\n",
            "1 0.00043669646\n",
            "state: tensor([[110.,  20.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.6559e-05, 9.6419e-01, 1.1461e-06, 3.5796e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1561]], grad_fn=<ExpBackward0>)\n",
            "1 0.00036869862\n",
            "state: tensor([[110.,  30.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.5510e-05, 9.6191e-01, 1.0487e-06, 3.8072e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1375]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00044353615\n",
            "state: tensor([[110.,  40.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.4239e-05, 9.5767e-01, 9.4142e-07, 4.2311e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0026]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1216]], grad_fn=<ExpBackward0>)\n",
            "1 0.0025769358\n",
            "state: tensor([[110.,  50.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.2239e-05, 9.5784e-01, 7.7131e-07, 4.2146e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0027]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1241]], grad_fn=<ExpBackward0>)\n",
            "1 0.0027440286\n",
            "state: tensor([[110.,  60.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.0033e-05, 9.6065e-01, 5.9113e-07, 3.9343e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1268]], grad_fn=<ExpBackward0>)\n",
            "1 0.00024145297\n",
            "state: tensor([[110.,  70.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[8.0287e-06, 9.6479e-01, 4.4187e-07, 3.5203e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0040]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1284]], grad_fn=<ExpBackward0>)\n",
            "1 -0.003977311\n",
            "state: tensor([[110.,  80.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[6.5271e-06, 9.6921e-01, 3.3551e-07, 3.0784e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0067]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1236]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0066528055\n",
            "state: tensor([[110.,  90.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[4.8086e-06, 9.7328e-01, 2.2665e-07, 2.6716e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0072]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1093]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0071705263\n",
            "state: tensor([[110., 100.,   1.,   1.,   1.]]) dist_dsc.probs: tensor([[3.3815e-06, 9.8084e-01, 1.3905e-07, 1.9160e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0123]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1235]], grad_fn=<ExpBackward0>)\n",
            "1 -0.012320618\n",
            "state: tensor([[110., 110.,   1.,   1.,   1.]]) dist_dsc.probs: tensor([[1.8343e-06, 9.8657e-01, 6.3069e-08, 1.3427e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0124]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1132]], grad_fn=<ExpBackward0>)\n",
            "1 -0.012361348\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state: tensor([[0.0000, 0.0000, 0.0000, 0.0000, 1.8000]]) dist_dsc.probs: tensor([[0.0016, 0.0039, 0.0016, 0.9929]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0018]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1284]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0017517845\n",
            "-0.0017517845 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 10.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[0.0017, 0.0076, 0.0015, 0.9893]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0030]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1409]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0030328913\n",
            "-0.0030328913 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 20.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.3469e-03, 1.5966e-02, 9.4431e-04, 9.8174e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0027]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1321]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00274843\n",
            "-0.00274843 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 30.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.0843e-03, 3.4074e-02, 5.9621e-04, 9.6425e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0025]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1241]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0024880378\n",
            "-0.0024880378 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 40.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[8.5547e-04, 7.1277e-02, 3.6881e-04, 9.2750e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0023]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1165]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0022785496\n",
            "-0.0022785496 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 50.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.4760e-04, 1.4307e-01, 2.1891e-04, 8.5606e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0021]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1093]], grad_fn=<ExpBackward0>)\n",
            "3 -0.002053023\n",
            "-0.002053023 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 60.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[4.5315e-04, 2.6581e-01, 1.2018e-04, 7.3362e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0018]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1025]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0018160196\n",
            "-0.0018160196 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 70.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[2.7911e-04, 4.3553e-01, 5.8057e-05, 5.6414e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0016]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0956]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0015943426\n",
            "-0.0015943426 <class 'numpy.ndarray'>\n",
            "state: tensor([[ 0.0000, 80.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.4895e-04, 6.1807e-01, 2.4260e-05, 3.8176e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0014]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0892]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0013654407\n",
            "state: tensor([[ 0.0000, 90.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.9662e-05, 7.7091e-01, 8.8941e-06, 2.2901e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0011]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0825]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0010783343\n",
            "state: tensor([[  0.0000, 100.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[3.2639e-05, 8.7957e-01, 3.2653e-06, 1.2040e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0020]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0943]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0019730951\n",
            "state: tensor([[  0.0000, 110.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[1.3033e-05, 9.3807e-01, 1.0226e-06, 6.1919e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0017]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0870]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0017407303\n",
            "state: tensor([[10.0000,  0.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[0.0017, 0.0076, 0.0015, 0.9893]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0030]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1409]], grad_fn=<ExpBackward0>)\n",
            "3 0.0030328913\n",
            "0.0030328913 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 10.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[0.0025, 0.0120, 0.0020, 0.9835]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1602]], grad_fn=<ExpBackward0>)\n",
            "3 0.00039396563\n",
            "0.00039396563 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 20.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[0.0021, 0.0231, 0.0014, 0.9734]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1572]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0005370557\n",
            "-0.0005370557 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 30.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.6754e-03, 4.6868e-02, 8.5313e-04, 9.5060e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0009]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1514]], grad_fn=<ExpBackward0>)\n",
            "3 0.0008533442\n",
            "0.0008533442 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 40.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.2777e-03, 9.5057e-02, 5.1089e-04, 9.0315e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1421]], grad_fn=<ExpBackward0>)\n",
            "3 0.0005788346\n",
            "0.0005788346 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 50.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[9.2614e-04, 1.8324e-01, 2.9077e-04, 8.1554e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1333]], grad_fn=<ExpBackward0>)\n",
            "3 0.00028406628\n",
            "0.00028406628 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 60.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.1559e-04, 3.2391e-01, 1.5176e-04, 6.7532e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-1.0716e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1251]], grad_fn=<ExpBackward0>)\n",
            "3 -1.071571e-05\n",
            "-1.071571e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[10.0000, 70.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[3.6056e-04, 5.0463e-01, 6.9793e-05, 4.9494e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1174]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0003054913\n",
            "state: tensor([[10.0000, 80.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.8247e-04, 6.8258e-01, 2.7781e-05, 3.1721e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0001]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1093]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00012384521\n",
            "state: tensor([[10.0000, 90.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[8.1826e-05, 8.1921e-01, 9.8032e-06, 1.8070e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1012]], grad_fn=<ExpBackward0>)\n",
            "1 0.000108004635\n",
            "state: tensor([[ 10.0000, 100.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[3.6985e-05, 9.0887e-01, 3.4921e-06, 9.1085e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0009]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1146]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0009487402\n",
            "state: tensor([[ 10.0000, 110.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[1.4498e-05, 9.5450e-01, 1.0775e-06, 4.5485e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1054]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00073934277\n",
            "state: tensor([[20.0000,  0.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.3469e-03, 1.5966e-02, 9.4431e-04, 9.8174e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0027]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1321]], grad_fn=<ExpBackward0>)\n",
            "3 0.00274843\n",
            "0.00274843 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 10.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[0.0021, 0.0231, 0.0014, 0.9734]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1572]], grad_fn=<ExpBackward0>)\n",
            "3 0.0005370557\n",
            "0.0005370557 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 20.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[0.0018, 0.0285, 0.0011, 0.9686]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1492]], grad_fn=<ExpBackward0>)\n",
            "3 0.00015992721\n",
            "0.00015992721 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 30.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.5308e-03, 5.1230e-02, 7.3686e-04, 9.4650e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1422]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00045722106\n",
            "-0.00045722106 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 40.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.2190e-03, 9.9071e-02, 4.6794e-04, 8.9924e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1284]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00037224486\n",
            "-0.00037224486 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 50.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[8.9037e-04, 1.8432e-01, 2.7009e-04, 8.1452e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1181]], grad_fn=<ExpBackward0>)\n",
            "3 0.0002352361\n",
            "0.0002352361 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 60.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.0802e-04, 3.2675e-01, 1.4499e-04, 6.7249e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0018]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1119]], grad_fn=<ExpBackward0>)\n",
            "3 0.0017581343\n",
            "0.0017581343 <class 'numpy.ndarray'>\n",
            "state: tensor([[20.0000, 70.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[3.6275e-04, 5.1353e-01, 6.7763e-05, 4.8604e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0020]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1052]], grad_fn=<ExpBackward0>)\n",
            "1 0.0020448419\n",
            "state: tensor([[20.0000, 80.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.8514e-04, 6.9362e-01, 2.7131e-05, 3.0617e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0018]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0987]], grad_fn=<ExpBackward0>)\n",
            "1 0.0017500579\n",
            "state: tensor([[20.0000, 90.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[8.3467e-05, 8.2879e-01, 9.5996e-06, 1.7112e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0015]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0926]], grad_fn=<ExpBackward0>)\n",
            "1 0.001455288\n",
            "state: tensor([[ 20.0000, 100.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[3.7949e-05, 9.1519e-01, 3.4271e-06, 8.4764e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1085]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00030633665\n",
            "state: tensor([[ 20.0000, 110.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[1.4995e-05, 9.5846e-01, 1.0628e-06, 4.1524e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1018]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0006011086\n",
            "state: tensor([[30.0000,  0.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.0843e-03, 3.4074e-02, 5.9621e-04, 9.6425e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0025]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1241]], grad_fn=<ExpBackward0>)\n",
            "3 0.0024880378\n",
            "0.0024880378 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 10.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.6754e-03, 4.6868e-02, 8.5313e-04, 9.5060e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0009]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1514]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0008533442\n",
            "-0.0008533442 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 20.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.5308e-03, 5.1230e-02, 7.3686e-04, 9.4650e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1422]], grad_fn=<ExpBackward0>)\n",
            "3 0.00045722106\n",
            "0.00045722106 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 30.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.2272e-03, 6.3073e-02, 5.2263e-04, 9.3518e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1382]], grad_fn=<ExpBackward0>)\n",
            "3 0.00014819126\n",
            "0.00014819126 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 40.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.0293e-03, 1.0809e-01, 3.6829e-04, 8.9051e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0009]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1298]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0009153121\n",
            "-0.0009153121 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 50.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[7.7459e-04, 1.9563e-01, 2.2193e-04, 8.0337e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1198]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00022069612\n",
            "-0.00022069612 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 60.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[5.3217e-04, 3.3188e-01, 1.2136e-04, 6.6747e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0008]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1049]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00078846136\n",
            "-0.00078846136 <class 'numpy.ndarray'>\n",
            "state: tensor([[30.0000, 70.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[3.1868e-04, 5.0293e-01, 5.7651e-05, 4.9670e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0942]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0006514343\n",
            "state: tensor([[30.0000, 80.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.6858e-04, 6.7892e-01, 2.4085e-05, 3.2089e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0878]], grad_fn=<ExpBackward0>)\n",
            "1 0.0004949058\n",
            "state: tensor([[30.0000, 90.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[7.7597e-05, 8.1966e-01, 8.7132e-06, 1.8025e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0017]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0818]], grad_fn=<ExpBackward0>)\n",
            "1 0.0016646152\n",
            "state: tensor([[ 30.0000, 100.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[3.5517e-05, 9.1033e-01, 3.1306e-06, 8.9632e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0958]], grad_fn=<ExpBackward0>)\n",
            "1 0.00044021948\n",
            "state: tensor([[ 30.0000, 110.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[1.4188e-05, 9.5650e-01, 9.7896e-07, 4.3486e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0010]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0904]], grad_fn=<ExpBackward0>)\n",
            "1 0.0009959294\n",
            "state: tensor([[40.0000,  0.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[8.5547e-04, 7.1277e-02, 3.6881e-04, 9.2750e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0023]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1165]], grad_fn=<ExpBackward0>)\n",
            "3 0.0022785496\n",
            "0.0022785496 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 10.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.2777e-03, 9.5057e-02, 5.1089e-04, 9.0315e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1421]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0005788346\n",
            "-0.0005788346 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 20.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.2190e-03, 9.9071e-02, 4.6794e-04, 8.9924e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1284]], grad_fn=<ExpBackward0>)\n",
            "3 0.00037224486\n",
            "0.00037224486 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 30.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.0293e-03, 1.0809e-01, 3.6829e-04, 8.9051e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0009]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1298]], grad_fn=<ExpBackward0>)\n",
            "3 0.0009153121\n",
            "0.0009153121 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 40.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[7.9074e-04, 1.3447e-01, 2.4663e-04, 8.6449e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1280]], grad_fn=<ExpBackward0>)\n",
            "3 0.00021243343\n",
            "0.00021243343 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 50.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.4962e-04, 2.1419e-01, 1.7257e-04, 7.8499e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0015]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1186]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0014790259\n",
            "-0.0014790259 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 60.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[4.5221e-04, 3.5309e-01, 9.6496e-05, 6.4636e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1115]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00032790765\n",
            "-0.00032790765 <class 'numpy.ndarray'>\n",
            "state: tensor([[40.0000, 70.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[2.7043e-04, 5.2388e-01, 4.5986e-05, 4.7580e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0978]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0006626202\n",
            "state: tensor([[40.0000, 80.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.4451e-04, 6.9153e-01, 1.9576e-05, 3.0831e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0012]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0857]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0012069186\n",
            "state: tensor([[40.0000, 90.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.7750e-05, 8.1973e-01, 7.2924e-06, 1.8020e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0011]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0770]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0010676605\n",
            "state: tensor([[ 40.0000, 100.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[3.2207e-05, 9.0516e-01, 2.7586e-06, 9.4810e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0022]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0866]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0021810713\n",
            "state: tensor([[ 40.0000, 110.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[1.3050e-05, 9.5298e-01, 8.8060e-07, 4.7008e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0016]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0796]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0016076249\n",
            "state: tensor([[50.0000,  0.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.4760e-04, 1.4307e-01, 2.1891e-04, 8.5606e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0021]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1093]], grad_fn=<ExpBackward0>)\n",
            "3 0.002053023\n",
            "0.002053023 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 10.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[9.2614e-04, 1.8324e-01, 2.9077e-04, 8.1554e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1333]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00028406628\n",
            "-0.00028406628 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 20.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[8.9037e-04, 1.8432e-01, 2.7009e-04, 8.1452e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1181]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0002352361\n",
            "-0.0002352361 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 30.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[7.7459e-04, 1.9563e-01, 2.2193e-04, 8.0337e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1198]], grad_fn=<ExpBackward0>)\n",
            "3 0.00022069612\n",
            "0.00022069612 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 40.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.4962e-04, 2.1419e-01, 1.7257e-04, 7.8499e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0015]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1186]], grad_fn=<ExpBackward0>)\n",
            "3 0.0014790259\n",
            "0.0014790259 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 50.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[4.6897e-04, 2.6386e-01, 1.0713e-04, 7.3556e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1181]], grad_fn=<ExpBackward0>)\n",
            "3 0.00018183715\n",
            "0.00018183715 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 60.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[3.6016e-04, 3.8020e-01, 7.0786e-05, 6.1937e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0013]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1089]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0013067512\n",
            "-0.0013067512 <class 'numpy.ndarray'>\n",
            "state: tensor([[50.0000, 70.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[2.2490e-04, 5.5046e-01, 3.5674e-05, 4.4928e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1013]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00062248396\n",
            "state: tensor([[50.0000, 80.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.1763e-04, 7.1010e-01, 1.4896e-05, 2.8976e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0916]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00053781\n",
            "state: tensor([[50.0000, 90.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[5.6032e-05, 8.3257e-01, 5.6552e-06, 1.6737e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0011]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0799]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0011413387\n",
            "state: tensor([[ 50.0000, 100.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[2.7010e-05, 9.0928e-01, 2.1874e-06, 9.0689e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0029]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0876]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0029427179\n",
            "state: tensor([[ 50.0000, 110.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[1.1206e-05, 9.5301e-01, 7.2211e-07, 4.6976e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0028]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0786]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0028031787\n",
            "state: tensor([[60.0000,  0.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[4.5315e-04, 2.6581e-01, 1.2018e-04, 7.3362e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0018]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1025]], grad_fn=<ExpBackward0>)\n",
            "3 0.0018160196\n",
            "0.0018160196 <class 'numpy.ndarray'>\n",
            "state: tensor([[60.0000, 10.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.1559e-04, 3.2391e-01, 1.5176e-04, 6.7532e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[1.0716e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1251]], grad_fn=<ExpBackward0>)\n",
            "3 1.071571e-05\n",
            "1.071571e-05 <class 'numpy.ndarray'>\n",
            "state: tensor([[60.0000, 20.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.0802e-04, 3.2675e-01, 1.4499e-04, 6.7249e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0018]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1119]], grad_fn=<ExpBackward0>)\n",
            "3 -0.0017581343\n",
            "-0.0017581343 <class 'numpy.ndarray'>\n",
            "state: tensor([[60.0000, 30.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[5.3217e-04, 3.3188e-01, 1.2136e-04, 6.6747e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0008]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1049]], grad_fn=<ExpBackward0>)\n",
            "3 0.00078846136\n",
            "0.00078846136 <class 'numpy.ndarray'>\n",
            "state: tensor([[60.0000, 40.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[4.5221e-04, 3.5309e-01, 9.6496e-05, 6.4636e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1115]], grad_fn=<ExpBackward0>)\n",
            "3 0.00032790765\n",
            "0.00032790765 <class 'numpy.ndarray'>\n",
            "state: tensor([[60.0000, 50.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[3.6016e-04, 3.8020e-01, 7.0786e-05, 6.1937e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0013]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1089]], grad_fn=<ExpBackward0>)\n",
            "3 0.0013067512\n",
            "0.0013067512 <class 'numpy.ndarray'>\n",
            "state: tensor([[60.0000, 60.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[2.4313e-04, 4.5262e-01, 4.0675e-05, 5.4710e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1077]], grad_fn=<ExpBackward0>)\n",
            "3 -0.00021074465\n",
            "-0.00021074465 <class 'numpy.ndarray'>\n",
            "state: tensor([[60.0000, 70.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.7157e-04, 5.8014e-01, 2.4938e-05, 4.1966e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0008]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0989]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00080289127\n",
            "state: tensor([[60.0000, 80.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[9.5453e-05, 7.3309e-01, 1.1254e-05, 2.6680e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0910]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0007275045\n",
            "state: tensor([[60.0000, 90.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[4.5389e-05, 8.4618e-01, 4.2809e-06, 1.5377e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0838]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00026703175\n",
            "state: tensor([[ 60.0000, 100.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[2.1655e-05, 9.1630e-01, 1.6371e-06, 8.3676e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0024]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0930]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0023512212\n",
            "state: tensor([[ 60.0000, 110.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[9.2012e-06, 9.5602e-01, 5.5499e-07, 4.3975e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0031]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0810]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0030907237\n",
            "state: tensor([[70.0000,  0.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[2.7911e-04, 4.3553e-01, 5.8057e-05, 5.6414e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0016]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0956]], grad_fn=<ExpBackward0>)\n",
            "3 0.0015943426\n",
            "0.0015943426 <class 'numpy.ndarray'>\n",
            "state: tensor([[70.0000, 10.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[3.6056e-04, 5.0463e-01, 6.9793e-05, 4.9494e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1174]], grad_fn=<ExpBackward0>)\n",
            "1 0.0003054913\n",
            "state: tensor([[70.0000, 20.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[3.6275e-04, 5.1353e-01, 6.7763e-05, 4.8604e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0020]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1052]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0020448419\n",
            "state: tensor([[70.0000, 30.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[3.1868e-04, 5.0293e-01, 5.7651e-05, 4.9670e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0942]], grad_fn=<ExpBackward0>)\n",
            "1 0.0006514343\n",
            "state: tensor([[70.0000, 40.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[2.7043e-04, 5.2388e-01, 4.5986e-05, 4.7580e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0978]], grad_fn=<ExpBackward0>)\n",
            "1 0.0006626202\n",
            "state: tensor([[70.0000, 50.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[2.2490e-04, 5.5046e-01, 3.5674e-05, 4.4928e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1013]], grad_fn=<ExpBackward0>)\n",
            "1 0.00062248396\n",
            "state: tensor([[70.0000, 60.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.7157e-04, 5.8014e-01, 2.4938e-05, 4.1966e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0008]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0989]], grad_fn=<ExpBackward0>)\n",
            "1 0.00080289127\n",
            "state: tensor([[70.0000, 70.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.0651e-04, 6.5604e-01, 1.3050e-05, 3.4384e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0971]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00041067303\n",
            "state: tensor([[70.0000, 80.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.9432e-05, 7.5860e-01, 7.4404e-06, 2.4132e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0898]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0002697973\n",
            "state: tensor([[70.0000, 90.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[3.5699e-05, 8.6054e-01, 3.1262e-06, 1.3942e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0008]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0816]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0008035008\n",
            "state: tensor([[ 70.0000, 100.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[1.7751e-05, 9.2649e-01, 1.2529e-06, 7.3495e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0015]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0944]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0015324297\n",
            "state: tensor([[ 70.0000, 110.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[7.3504e-06, 9.6053e-01, 4.1404e-07, 3.9459e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0019]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0846]], grad_fn=<ExpBackward0>)\n",
            "1 -0.001946352\n",
            "state: tensor([[80.0000,  0.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.4895e-04, 6.1807e-01, 2.4260e-05, 3.8176e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0014]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0892]], grad_fn=<ExpBackward0>)\n",
            "1 0.0013654407\n",
            "state: tensor([[80.0000, 10.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.8247e-04, 6.8258e-01, 2.7781e-05, 3.1721e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1093]], grad_fn=<ExpBackward0>)\n",
            "1 0.00012384521\n",
            "state: tensor([[80.0000, 20.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.8514e-04, 6.9362e-01, 2.7131e-05, 3.0617e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0018]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0987]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0017500579\n",
            "state: tensor([[80.0000, 30.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.6858e-04, 6.7892e-01, 2.4085e-05, 3.2089e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0878]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0004949058\n",
            "state: tensor([[80.0000, 40.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.4451e-04, 6.9153e-01, 1.9576e-05, 3.0831e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0012]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0857]], grad_fn=<ExpBackward0>)\n",
            "1 0.0012069186\n",
            "state: tensor([[80.0000, 50.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.1763e-04, 7.1010e-01, 1.4896e-05, 2.8976e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0916]], grad_fn=<ExpBackward0>)\n",
            "1 0.00053781\n",
            "state: tensor([[80.0000, 60.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[9.5453e-05, 7.3309e-01, 1.1254e-05, 2.6680e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0910]], grad_fn=<ExpBackward0>)\n",
            "1 0.0007275045\n",
            "state: tensor([[80.0000, 70.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.9432e-05, 7.5860e-01, 7.4404e-06, 2.4132e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0898]], grad_fn=<ExpBackward0>)\n",
            "1 0.0002697973\n",
            "state: tensor([[80.0000, 80.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[3.9981e-05, 8.1479e-01, 3.5875e-06, 1.8516e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-8.0868e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0844]], grad_fn=<ExpBackward0>)\n",
            "1 -8.0867525e-05\n",
            "state: tensor([[80.0000, 90.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[2.4542e-05, 8.7844e-01, 1.9339e-06, 1.2153e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0809]], grad_fn=<ExpBackward0>)\n",
            "1 0.000174458\n",
            "state: tensor([[ 80.0000, 100.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[1.3505e-05, 9.3484e-01, 8.8095e-07, 6.5149e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0892]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00025313828\n",
            "state: tensor([[ 80.0000, 110.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[5.8959e-06, 9.6546e-01, 3.0949e-07, 3.4537e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0841]], grad_fn=<ExpBackward0>)\n",
            "1 0.0006372005\n",
            "state: tensor([[90.0000,  0.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.9662e-05, 7.7091e-01, 8.8941e-06, 2.2901e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0011]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0825]], grad_fn=<ExpBackward0>)\n",
            "1 0.0010783343\n",
            "state: tensor([[90.0000, 10.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[8.1826e-05, 8.1921e-01, 9.8032e-06, 1.8070e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1012]], grad_fn=<ExpBackward0>)\n",
            "1 -0.000108004635\n",
            "state: tensor([[90.0000, 20.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[8.3467e-05, 8.2879e-01, 9.5996e-06, 1.7112e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0015]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0926]], grad_fn=<ExpBackward0>)\n",
            "1 -0.001455288\n",
            "state: tensor([[90.0000, 30.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[7.7597e-05, 8.1966e-01, 8.7132e-06, 1.8025e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0017]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0818]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0016646152\n",
            "state: tensor([[90.0000, 40.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[6.7750e-05, 8.1973e-01, 7.2924e-06, 1.8020e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0011]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0770]], grad_fn=<ExpBackward0>)\n",
            "1 0.0010676605\n",
            "state: tensor([[90.0000, 50.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[5.6032e-05, 8.3257e-01, 5.6552e-06, 1.6737e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0011]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0799]], grad_fn=<ExpBackward0>)\n",
            "1 0.0011413387\n",
            "state: tensor([[90.0000, 60.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[4.5389e-05, 8.4618e-01, 4.2809e-06, 1.5377e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0838]], grad_fn=<ExpBackward0>)\n",
            "1 0.00026703175\n",
            "state: tensor([[90.0000, 70.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[3.5699e-05, 8.6054e-01, 3.1262e-06, 1.3942e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0008]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0816]], grad_fn=<ExpBackward0>)\n",
            "1 0.0008035008\n",
            "state: tensor([[90.0000, 80.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[2.4542e-05, 8.7844e-01, 1.9339e-06, 1.2153e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0809]], grad_fn=<ExpBackward0>)\n",
            "1 -0.000174458\n",
            "state: tensor([[90.0000, 90.0000,  0.0000,  0.0000,  1.8000]]) dist_dsc.probs: tensor([[1.3500e-05, 9.1029e-01, 8.8717e-07, 8.9698e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0733]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0003498633\n",
            "state: tensor([[ 90.0000, 100.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[8.8190e-06, 9.4468e-01, 5.1287e-07, 5.5310e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0016]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0821]], grad_fn=<ExpBackward0>)\n",
            "1 0.0015748236\n",
            "state: tensor([[ 90.0000, 110.0000,   0.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[4.3740e-06, 9.6990e-01, 2.1100e-07, 3.0093e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0019]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0780]], grad_fn=<ExpBackward0>)\n",
            "1 0.0018571723\n",
            "state: tensor([[100.0000,   0.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[3.2639e-05, 8.7957e-01, 3.2653e-06, 1.2040e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0020]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0943]], grad_fn=<ExpBackward0>)\n",
            "1 0.0019730951\n",
            "state: tensor([[100.0000,  10.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[3.6985e-05, 9.0887e-01, 3.4921e-06, 9.1085e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0009]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1146]], grad_fn=<ExpBackward0>)\n",
            "1 0.0009487402\n",
            "state: tensor([[100.0000,  20.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[3.7949e-05, 9.1519e-01, 3.4271e-06, 8.4764e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1085]], grad_fn=<ExpBackward0>)\n",
            "1 0.00030633665\n",
            "state: tensor([[100.0000,  30.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[3.5517e-05, 9.1033e-01, 3.1306e-06, 8.9632e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0958]], grad_fn=<ExpBackward0>)\n",
            "1 -0.00044021948\n",
            "state: tensor([[100.0000,  40.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[3.2207e-05, 9.0516e-01, 2.7586e-06, 9.4810e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0022]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0866]], grad_fn=<ExpBackward0>)\n",
            "1 0.0021810713\n",
            "state: tensor([[100.0000,  50.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[2.7010e-05, 9.0928e-01, 2.1874e-06, 9.0689e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0029]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0876]], grad_fn=<ExpBackward0>)\n",
            "1 0.0029427179\n",
            "state: tensor([[100.0000,  60.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[2.1655e-05, 9.1630e-01, 1.6371e-06, 8.3676e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0024]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0930]], grad_fn=<ExpBackward0>)\n",
            "1 0.0023512212\n",
            "state: tensor([[100.0000,  70.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[1.7751e-05, 9.2649e-01, 1.2529e-06, 7.3495e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0015]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0944]], grad_fn=<ExpBackward0>)\n",
            "1 0.0015324297\n",
            "state: tensor([[100.0000,  80.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[1.3505e-05, 9.3484e-01, 8.8095e-07, 6.5149e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0892]], grad_fn=<ExpBackward0>)\n",
            "1 0.00025313828\n",
            "state: tensor([[100.0000,  90.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[8.8190e-06, 9.4468e-01, 5.1287e-07, 5.5310e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0016]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0821]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0015748236\n",
            "state: tensor([[100.0000, 100.0000,   1.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[5.3826e-06, 9.6483e-01, 2.5826e-07, 3.5161e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0071]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1014]], grad_fn=<ExpBackward0>)\n",
            "1 -0.007117586\n",
            "state: tensor([[100.0000, 110.0000,   1.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[3.0915e-06, 9.7816e-01, 1.3023e-07, 2.1833e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0078]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.0944]], grad_fn=<ExpBackward0>)\n",
            "1 0.0077710077\n",
            "state: tensor([[110.0000,   0.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[1.3033e-05, 9.3807e-01, 1.0226e-06, 6.1919e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0017]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0870]], grad_fn=<ExpBackward0>)\n",
            "1 0.0017407303\n",
            "state: tensor([[110.0000,  10.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[1.4498e-05, 9.5450e-01, 1.0775e-06, 4.5485e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1054]], grad_fn=<ExpBackward0>)\n",
            "1 0.00073934277\n",
            "state: tensor([[110.0000,  20.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[1.4995e-05, 9.5846e-01, 1.0628e-06, 4.1524e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1018]], grad_fn=<ExpBackward0>)\n",
            "1 0.0006011086\n",
            "state: tensor([[110.0000,  30.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[1.4188e-05, 9.5650e-01, 9.7896e-07, 4.3486e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0010]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0904]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0009959294\n",
            "state: tensor([[110.0000,  40.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[1.3050e-05, 9.5298e-01, 8.8060e-07, 4.7008e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0016]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0796]], grad_fn=<ExpBackward0>)\n",
            "1 0.0016076249\n",
            "state: tensor([[110.0000,  50.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[1.1206e-05, 9.5301e-01, 7.2211e-07, 4.6976e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0028]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0786]], grad_fn=<ExpBackward0>)\n",
            "1 0.0028031787\n",
            "state: tensor([[110.0000,  60.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[9.2012e-06, 9.5602e-01, 5.5499e-07, 4.3975e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0031]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0810]], grad_fn=<ExpBackward0>)\n",
            "1 0.0030907237\n",
            "state: tensor([[110.0000,  70.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[7.3504e-06, 9.6053e-01, 4.1404e-07, 3.9459e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0019]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0846]], grad_fn=<ExpBackward0>)\n",
            "1 0.001946352\n",
            "state: tensor([[110.0000,  80.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[5.8959e-06, 9.6546e-01, 3.0949e-07, 3.4537e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0841]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0006372005\n",
            "state: tensor([[110.0000,  90.0000,   1.0000,   0.0000,   1.8000]]) dist_dsc.probs: tensor([[4.3740e-06, 9.6990e-01, 2.1100e-07, 3.0093e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0019]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0780]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0018571723\n",
            "state: tensor([[110.0000, 100.0000,   1.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[3.0915e-06, 9.7816e-01, 1.3023e-07, 2.1833e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0078]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0944]], grad_fn=<ExpBackward0>)\n",
            "1 -0.0077710077\n",
            "state: tensor([[110.0000, 110.0000,   1.0000,   1.0000,   1.8000]]) dist_dsc.probs: tensor([[1.6600e-06, 9.8444e-01, 5.8337e-08, 1.5559e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0089]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.0863]], grad_fn=<ExpBackward0>)\n",
            "1 -0.008879223\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state: tensor([[0., 0., 0., 0., 1.]]) dist_dsc.probs: tensor([[0.0027, 0.0050, 0.0027, 0.9896]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0017]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2222]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 0., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0026, 0.0100, 0.0022, 0.9853]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0020]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2350]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 0., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0021, 0.0213, 0.0014, 0.9752]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0017]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2207]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 0., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.6661e-03, 4.5299e-02, 8.7993e-04, 9.5215e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0015]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2072]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 0., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.2902e-03, 9.3198e-02, 5.3477e-04, 9.0498e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0012]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1940]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 0., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.3764e-04, 1.8046e-01, 3.0528e-04, 8.1830e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0010]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1806]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 0., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[6.1344e-04, 3.1483e-01, 1.5657e-04, 6.8440e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1670]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 0., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[3.5702e-04, 4.8867e-01, 7.1431e-05, 5.1090e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1545]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 0., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.8225e-04, 6.6528e-01, 2.8583e-05, 3.3451e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0001]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1429]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 0., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[8.2621e-05, 8.0489e-01, 1.0163e-05, 1.9502e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1318]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[  0., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[3.7377e-05, 8.9706e-01, 3.6239e-06, 1.0290e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1440]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[  0., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.4689e-05, 9.4691e-01, 1.1203e-06, 5.3073e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1289]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[10.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0026, 0.0100, 0.0022, 0.9853]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0020]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2350]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[10., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0033, 0.0142, 0.0026, 0.9799]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[8.2964e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2617]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[10., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0028, 0.0273, 0.0018, 0.9681]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[8.1292e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2478]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[10., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0022, 0.0558, 0.0011, 0.9409]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0010]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2326]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[10., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.6767e-03, 1.1242e-01, 6.5403e-04, 8.8525e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0008]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2182]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[10., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.1929e-03, 2.1271e-01, 3.6537e-04, 7.8573e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2048]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[10., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.6811e-04, 3.6435e-01, 1.8471e-04, 6.3469e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1921]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[10., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.3484e-04, 5.4872e-01, 8.2104e-05, 4.5077e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-8.2357e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1803]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[10., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.1388e-04, 7.2002e-01, 3.1741e-05, 2.7974e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-8.8327e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1684]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[10., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.3762e-05, 8.4433e-01, 1.0948e-05, 1.5557e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1564]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 10., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[4.1716e-05, 9.2258e-01, 3.8405e-06, 7.7378e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0008]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1761]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 10., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.6189e-05, 9.6134e-01, 1.1751e-06, 3.8638e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1588]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[20.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0021, 0.0213, 0.0014, 0.9752]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0017]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2207]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[20., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0028, 0.0273, 0.0018, 0.9681]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-8.1292e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2478]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[20., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0023, 0.0328, 0.0013, 0.9635]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[4.1614e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2423]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[20., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.9620e-03, 5.9487e-02, 9.2274e-04, 9.3763e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0001]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2278]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[20., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.5199e-03, 1.1365e-01, 5.6955e-04, 8.8426e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2025]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[20., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.0958e-03, 2.0766e-01, 3.2546e-04, 7.9092e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-5.4726e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1828]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[20., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.2717e-04, 3.5940e-01, 1.6993e-04, 6.3970e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0011]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1703]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[20., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.2201e-04, 5.4861e-01, 7.7197e-05, 4.5089e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0018]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1606]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[20., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.1195e-04, 7.2473e-01, 3.0350e-05, 2.7503e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0019]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1514]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[20., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.3925e-05, 8.4958e-01, 1.0549e-05, 1.5032e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0017]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1422]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 20., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[4.2170e-05, 9.2643e-01, 3.7189e-06, 7.3529e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-8.3183e-05]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1666]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 20., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.6559e-05, 9.6419e-01, 1.1461e-06, 3.5796e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1561]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[30.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.6661e-03, 4.5299e-02, 8.7993e-04, 9.5215e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0015]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2072]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[30., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[0.0022, 0.0558, 0.0011, 0.9409]], grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0010]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2326]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[30., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.9620e-03, 5.9487e-02, 9.2274e-04, 9.3763e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2278]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[30., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.5617e-03, 7.2680e-02, 6.5063e-04, 9.2511e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2244]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[30., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.3070e-03, 1.2434e-01, 4.5688e-04, 8.7389e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.2080]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[30., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.5273e-04, 2.2141e-01, 2.6620e-04, 7.7737e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0001]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1890]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[30., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[6.3910e-04, 3.6672e-01, 1.4226e-04, 6.3249e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0007]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1655]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[30., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[3.7242e-04, 5.4042e-01, 6.5845e-05, 4.5914e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1486]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[30., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.9115e-04, 7.0892e-01, 2.6719e-05, 2.9086e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1342]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[30., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[8.6362e-05, 8.3925e-01, 9.5018e-06, 1.6065e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0010]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1245]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 30., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[3.9061e-05, 9.2101e-01, 3.3738e-06, 7.8947e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1458]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 30., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.5510e-05, 9.6191e-01, 1.0487e-06, 3.8072e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1375]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[40.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.2902e-03, 9.3198e-02, 5.3477e-04, 9.0498e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0012]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1940]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[40., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.6767e-03, 1.1242e-01, 6.5403e-04, 8.8525e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0008]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2182]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[40., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.5199e-03, 1.1365e-01, 5.6955e-04, 8.8426e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2025]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[40., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.3070e-03, 1.2434e-01, 4.5688e-04, 8.7389e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2080]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[40., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.9491e-04, 1.5319e-01, 3.0356e-04, 8.4551e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-6.5913e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2062]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[40., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[8.0721e-04, 2.4212e-01, 2.0934e-04, 7.5687e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0008]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1887]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[40., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[5.4316e-04, 3.8983e-01, 1.1303e-04, 6.0951e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0001]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1748]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[40., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[3.1502e-04, 5.6234e-01, 5.2238e-05, 4.3730e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1545]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[40., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.6354e-04, 7.2011e-01, 2.1639e-05, 2.7970e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0011]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1352]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[40., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.5408e-05, 8.3896e-01, 7.9376e-06, 1.6095e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0010]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1214]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 40., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[3.5411e-05, 9.1483e-01, 2.9687e-06, 8.5128e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0022]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1364]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 40., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.4239e-05, 9.5767e-01, 9.4142e-07, 4.2311e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0026]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1216]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[50.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.3764e-04, 1.8046e-01, 3.0528e-04, 8.1830e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0010]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1806]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[50., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.1929e-03, 2.1271e-01, 3.6537e-04, 7.8573e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.2048]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[50., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.0958e-03, 2.0766e-01, 3.2546e-04, 7.9092e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[5.4726e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1828]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[50., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.5273e-04, 2.2141e-01, 2.6620e-04, 7.7737e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1890]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[50., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[8.0721e-04, 2.4212e-01, 2.0934e-04, 7.5687e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0008]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1887]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[50., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[5.7807e-04, 2.9451e-01, 1.2917e-04, 7.0479e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1872]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[50., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.3558e-04, 4.1836e-01, 8.3565e-05, 5.8112e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0003]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1713]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[50., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.6578e-04, 5.8933e-01, 4.1189e-05, 4.1036e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1591]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[50., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.3319e-04, 7.3908e-01, 1.6457e-05, 2.6077e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0001]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1427]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[50., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[6.1937e-05, 8.4813e-01, 6.1065e-06, 1.5180e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0010]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1261]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 50., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[2.9632e-05, 9.1840e-01, 2.3442e-06, 8.1567e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0025]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1380]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 50., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.2239e-05, 9.5784e-01, 7.7131e-07, 4.2146e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0027]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1241]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[60.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[6.1344e-04, 3.1483e-01, 1.5657e-04, 6.8440e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1670]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[60., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.6811e-04, 3.6435e-01, 1.8471e-04, 6.3469e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1921]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[60., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.2717e-04, 3.5940e-01, 1.6993e-04, 6.3970e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0011]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1703]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[60., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[6.3910e-04, 3.6672e-01, 1.4226e-04, 6.3249e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1655]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[60., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[5.4316e-04, 3.8983e-01, 1.1303e-04, 6.0951e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1748]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[60., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.3558e-04, 4.1836e-01, 8.3565e-05, 5.8112e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0003]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1713]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[60., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.9104e-04, 4.9059e-01, 4.7630e-05, 5.0907e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-5.8036e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1628]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[60., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.0096e-04, 6.1931e-01, 2.8462e-05, 3.8046e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1552]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[60., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.0966e-04, 7.6298e-01, 1.2632e-05, 2.3689e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1425]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[60., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[5.0357e-05, 8.6297e-01, 4.6362e-06, 1.3697e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1297]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 60., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[2.3782e-05, 9.2503e-01, 1.7561e-06, 7.4944e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0013]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1426]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 60., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.0033e-05, 9.6065e-01, 5.9113e-07, 3.9343e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1268]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[70.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[3.5702e-04, 4.8867e-01, 7.1431e-05, 5.1090e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1545]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[70., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.3484e-04, 5.4872e-01, 8.2104e-05, 4.5077e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[8.2357e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1803]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[70., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.2201e-04, 5.4861e-01, 7.7197e-05, 4.5089e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0018]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1606]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[70., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[3.7242e-04, 5.4042e-01, 6.5845e-05, 4.5914e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1486]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[70., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[3.1502e-04, 5.6234e-01, 5.2238e-05, 4.3730e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1545]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[70., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.6578e-04, 5.8933e-01, 4.1189e-05, 4.1036e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1591]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[70., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.0096e-04, 6.1931e-01, 2.8462e-05, 3.8046e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1552]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[70., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.2364e-04, 6.8959e-01, 1.4819e-05, 3.1027e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0019]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1406]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[70., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.8935e-05, 7.8749e-01, 8.2396e-06, 2.1243e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0024]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1337]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[70., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.0224e-05, 8.7844e-01, 3.4414e-06, 1.2152e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0028]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1268]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 70., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.9471e-05, 9.3423e-01, 1.3425e-06, 6.5749e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0047]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1434]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 70., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[8.0287e-06, 9.6479e-01, 4.4187e-07, 3.5203e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0040]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1284]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[80.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.8225e-04, 6.6528e-01, 2.8583e-05, 3.3451e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1429]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[80., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.1388e-04, 7.2002e-01, 3.1741e-05, 2.7974e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[8.8327e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1684]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[80., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.1195e-04, 7.2473e-01, 3.0350e-05, 2.7503e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0019]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1514]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[80., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.9115e-04, 7.0892e-01, 2.6719e-05, 2.9086e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0005]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1342]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[80., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.6354e-04, 7.2011e-01, 2.1639e-05, 2.7970e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0011]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1352]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[80., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.3319e-04, 7.3908e-01, 1.6457e-05, 2.6077e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0001]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1427]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[80., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.0966e-04, 7.6298e-01, 1.2632e-05, 2.3689e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0006]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1425]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[80., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.8935e-05, 7.8749e-01, 8.2396e-06, 2.1243e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0024]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1337]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[80., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.5343e-05, 8.3671e-01, 3.9801e-06, 1.6324e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0038]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1214]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[80., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.7342e-05, 8.9488e-01, 2.0982e-06, 1.0509e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0043]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1152]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 80., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[1.4957e-05, 9.4218e-01, 9.5361e-07, 5.7807e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0054]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1282]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 80., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[6.5271e-06, 9.6921e-01, 3.3551e-07, 3.0784e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0067]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1236]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[90.,  0.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[8.2621e-05, 8.0489e-01, 1.0163e-05, 1.9502e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1318]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[90., 10.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.3762e-05, 8.4433e-01, 1.0948e-05, 1.5557e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1564]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[90., 20.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[9.3925e-05, 8.4958e-01, 1.0549e-05, 1.5032e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0017]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1422]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[90., 30.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[8.6362e-05, 8.3925e-01, 9.5018e-06, 1.6065e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0010]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1245]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[90., 40.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[7.5408e-05, 8.3896e-01, 7.9376e-06, 1.6095e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0010]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1214]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[90., 50.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[6.1937e-05, 8.4813e-01, 6.1065e-06, 1.5180e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0010]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1261]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[90., 60.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[5.0357e-05, 8.6297e-01, 4.6362e-06, 1.3697e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1297]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[90., 70.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[4.0224e-05, 8.7844e-01, 3.4414e-06, 1.2152e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0028]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1268]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[90., 80.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[2.7342e-05, 8.9488e-01, 2.0982e-06, 1.0509e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0043]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1152]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[90., 90.,  0.,  0.,  1.]]) dist_dsc.probs: tensor([[1.5101e-05, 9.2199e-01, 9.7078e-07, 7.7994e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0057]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1048]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 90., 100.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[9.7181e-06, 9.5253e-01, 5.5071e-07, 4.7464e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0069]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1142]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[ 90., 110.,   0.,   1.,   1.]]) dist_dsc.probs: tensor([[4.8086e-06, 9.7328e-01, 2.2665e-07, 2.6716e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0072]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1093]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[100.,   0.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[3.7377e-05, 8.9706e-01, 3.6239e-06, 1.0290e-01]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0007]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1440]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[100.,  10.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[4.1716e-05, 9.2258e-01, 3.8405e-06, 7.7378e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0008]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1761]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[100.,  20.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[4.2170e-05, 9.2643e-01, 3.7189e-06, 7.3529e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[8.3183e-05]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1666]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[100.,  30.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[3.9061e-05, 9.2101e-01, 3.3738e-06, 7.8947e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1458]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[100.,  40.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[3.5411e-05, 9.1483e-01, 2.9687e-06, 8.5128e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0022]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1364]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[100.,  50.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[2.9632e-05, 9.1840e-01, 2.3442e-06, 8.1567e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0025]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1380]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[100.,  60.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[2.3782e-05, 9.2503e-01, 1.7561e-06, 7.4944e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0013]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1426]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[100.,  70.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.9471e-05, 9.3423e-01, 1.3425e-06, 6.5749e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0047]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1434]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[100.,  80.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.4957e-05, 9.4218e-01, 9.5361e-07, 5.7807e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0054]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1282]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[100.,  90.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[9.7181e-06, 9.5253e-01, 5.5071e-07, 4.7464e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0069]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1142]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[100., 100.,   1.,   1.,   1.]]) dist_dsc.probs: tensor([[5.9634e-06, 9.6955e-01, 2.7996e-07, 3.0441e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0113]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1340]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[100., 110.,   1.,   1.,   1.]]) dist_dsc.probs: tensor([[3.3815e-06, 9.8084e-01, 1.3905e-07, 1.9160e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0123]], grad_fn=<TanhBackward0>) dist_cnt.scale tensor([[0.1235]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[110.,   0.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.4689e-05, 9.4691e-01, 1.1203e-06, 5.3073e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1289]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[110.,  10.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.6189e-05, 9.6134e-01, 1.1751e-06, 3.8638e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1588]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[110.,  20.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.6559e-05, 9.6419e-01, 1.1461e-06, 3.5796e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1561]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[110.,  30.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.5510e-05, 9.6191e-01, 1.0487e-06, 3.8072e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0004]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1375]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[110.,  40.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.4239e-05, 9.5767e-01, 9.4142e-07, 4.2311e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0026]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1216]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[110.,  50.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.2239e-05, 9.5784e-01, 7.7131e-07, 4.2146e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0027]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1241]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[110.,  60.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[1.0033e-05, 9.6065e-01, 5.9113e-07, 3.9343e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[0.0002]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1268]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[110.,  70.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[8.0287e-06, 9.6479e-01, 4.4187e-07, 3.5203e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0040]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1284]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[110.,  80.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[6.5271e-06, 9.6921e-01, 3.3551e-07, 3.0784e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0067]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1236]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[110.,  90.,   1.,   0.,   1.]]) dist_dsc.probs: tensor([[4.8086e-06, 9.7328e-01, 2.2665e-07, 2.6716e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0072]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1093]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[110., 100.,   1.,   1.,   1.]]) dist_dsc.probs: tensor([[3.3815e-06, 9.8084e-01, 1.3905e-07, 1.9160e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0123]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1235]], grad_fn=<ExpBackward0>)\n",
            "state: tensor([[110., 110.,   1.,   1.,   1.]]) dist_dsc.probs: tensor([[1.8343e-06, 9.8657e-01, 6.3069e-08, 1.3427e-02]],\n",
            "       grad_fn=<DivBackward0>) dist_cnt.mean: tensor([[-0.0124]], grad_fn=<NegBackward0>) dist_cnt.scale tensor([[0.1132]], grad_fn=<ExpBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
            "[523298, 525278]\n"
          ]
        }
      ],
      "source": [
        "def one_hot_encoding(levels, n_units=2,n_states=5, MAX_maintenance_time=0):\n",
        "    level_ohe = []\n",
        "    #mstatus_ohe = []\n",
        "    for unit_idx in range(n_units):\n",
        "        l = [0] * n_states\n",
        "        #m = [0] * (MAX_maintenance_time + 1)\n",
        "        l[levels[unit_idx]] = 1\n",
        "        #m[maintenance_status[unit_idx]] = 1\n",
        "        level_ohe = level_ohe + l\n",
        "        #mstatus_ohe = mstatus_ohe + m\n",
        "    return level_ohe #, mstatus_ohe\n",
        "\n",
        "\n",
        "def get_color(action):\n",
        "    if action < 0:\n",
        "        print(action)\n",
        "        return \"white\"\n",
        "    #cmap = [\"red\",\"sandybrown\",\"orange\",\"lawngreen\",\"darkorange\",\"lightgreen\",\"green\",\"lightblue\"]\n",
        "    cmap = [\"red\",\"orange\",\"orange\",\"lightgreen\",\"orange\",\"lightgreen\",\"lightgreen\",\"lightblue\"]\n",
        "    return cmap[action]\n",
        "\n",
        "def plot_action(ax, center_x, center_y, act_dsc, act_cnt, load_total):\n",
        "    size = 1\n",
        "    opt_action = patches.Rectangle(\n",
        "        (center_x-size/2, center_y-size/2),\n",
        "        1,\n",
        "        1,\n",
        "        linewidth = 0,\n",
        "        facecolor = get_color(act_dsc)\n",
        "    )\n",
        "    ax.add_patch(opt_action)\n",
        "    #print(act_dsc)\n",
        "    if act_dsc==0:\n",
        "        ax.text(center_x,center_y,f'M12',ha='center', va='center')\n",
        "    elif act_dsc==1:\n",
        "        if center_x<center_y:\n",
        "          ax.text(center_x,center_y,f'M1',ha='center', va='center')\n",
        "        else:\n",
        "          ax.text(center_x,center_y,f'M2',ha='center', va='center')\n",
        "    elif act_dsc==2:\n",
        "        if center_x<center_y:\n",
        "          ax.text(center_x,center_y,f'M2',ha='center', va='center')\n",
        "        else:\n",
        "          ax.text(center_x,center_y,f'M1',ha='center', va='center')\n",
        "    else: #稼働継続\n",
        "        print(act_cnt, type(act_cnt))\n",
        "        act_cnt = act_cnt * 0.5 + 0.5\n",
        "        #ax.text(center_x, center_y,f'{(round(act_cnt[0],2),round(1-act_cnt[0],2))}',ha='center', va='center',fontsize=5)\n",
        "        ax.text(center_x, center_y, f'{(round(act_cnt, 2))}', ha='center', va='center', fontsize=5)\n",
        "\n",
        "def plot_state_value(ax, center_x, center_y, val):\n",
        "    size = 1\n",
        "    opt_action = patches.Rectangle(\n",
        "        (center_x-size/2, center_y-size/2),\n",
        "        1,\n",
        "        1,\n",
        "        linewidth = 0,\n",
        "        facecolor = get_color(act_dsc)\n",
        "    )\n",
        "    ax.add_patch(opt_action)\n",
        "    #print(act_dsc)\n",
        "\n",
        "    ax.text(center_x, center_y, f'{round(float(val), 0)}', ha='center', va='center', fontsize=5)\n",
        "\n",
        "\n",
        "def optimal_policy(load_total):\n",
        "    fig, ax = plt.subplots()\n",
        "    x = 10\n",
        "    for s1 in range(x+2):\n",
        "        for s2 in range(x+2):\n",
        "            a =env.L/(x)\n",
        "            x1 =s1*a\n",
        "            x2 =s2*a\n",
        "            flag1=0\n",
        "            flag2=0\n",
        "            if s1>=x:\n",
        "              flag1=1\n",
        "            if s2>=x:\n",
        "              flag2=1\n",
        "            #level_ohe = one_hot_encoding(levels=[s2,s3])\n",
        "            state = [x1,x2] +[flag1,flag2] +list([load_total])\n",
        "            #print(state)\n",
        "            act_dsc, act_cnt, log_prob_dsc, log_prob_cnt, val = agent.choose_action_max_prob(state)\n",
        "            act_dsc = act_dsc.item()\n",
        "            act_cnt = act_cnt.squeeze().cpu().detach().numpy().copy()\n",
        "            print(act_dsc,act_cnt)\n",
        "            #print(\"val:\",val)\n",
        "\n",
        "            plot_action(ax, s1, s2, act_dsc, act_cnt, load_total)\n",
        "    ax.set_xlim(-0.5,x+1.5)\n",
        "    ax.set_ylim(-0.5,x+1.5)\n",
        "    #cbar = plt.colorbar(scatter, cax=cax, ticks=np.arange(0.5, 8.5, 1))\n",
        "    #cbar.ax.set_yticklabels([f'{i:b}' for i in range(8)])\n",
        "    ax.set_aspect('equal', adjustable='box')  # アスペクト比を保持\n",
        "    ax.set_xlabel(\"s1\") #変更\n",
        "    ax.set_ylabel(\"s2\") #変更\n",
        "    # グラフを表示\n",
        "    ax.set_title(\"load_total=\"+str(load_total))\n",
        "\n",
        "    # 軸のラベルを設定\n",
        "    ax.set_xticks(range(x+2))  # 目盛りの位置を設定\n",
        "    ax.set_xticklabels([f\"{int(label * a)}\" for label in ax.get_xticks()])  # X倍の値でラベルを整数で更新\n",
        "    ax.set_yticks(range(x+2))\n",
        "    ax.set_yticklabels([f\"{int(label * a)}\" for label in ax.get_yticks()])\n",
        "    plt.show()\n",
        "\n",
        "def state_value(load_total):\n",
        "    fig, ax = plt.subplots()\n",
        "    x = 10\n",
        "    for s1 in range(x+2):\n",
        "        for s2 in range(x+2):\n",
        "            a =env.L/(x)\n",
        "            x1 =s1*a\n",
        "            x2 =s2*a\n",
        "            flag1=0\n",
        "            flag2=0\n",
        "            if s1>=x:\n",
        "              flag1=1\n",
        "            if s2>=x:\n",
        "              flag2=1\n",
        "            #level_ohe = one_hot_encoding(levels=[s2,s3])\n",
        "            state = [x1,x2] + [flag1,flag2] + list([load_total])\n",
        "            act_dsc, act_cnt, log_prob_dsc, log_prob_cnt, val = agent.choose_action_max_prob(state)\n",
        "            act_dsc = act_dsc.item()\n",
        "            act_cnt = act_cnt.squeeze().cpu().detach().numpy().copy()\n",
        "            #print(act_dsc,act_cnt)\n",
        "            #print(\"val:\",val)\n",
        "            #status = np.array([(cs1<env.failures[0])*1,(cs2<env.failures[1])*1,(cs3<env.failures[2])*1])\n",
        "            plot_state_value(ax, s1, s2, val)\n",
        "    # 軸の範囲と目盛りを設定\n",
        "    ax.set_xlim(-0.5,x+1.5)\n",
        "    ax.set_ylim(-0.5,x+1.5)\n",
        "    #cbar = plt.colorbar(scatter, cax=cax, ticks=np.arange(0.5, 8.5, 1))\n",
        "    #cbar.ax.set_yticklabels([f'{i:b}' for i in range(8)])\n",
        "    ax.set_aspect('equal', adjustable='box')  # アスペクト比を保持\n",
        "    ax.set_xlabel(\"s1\") #変更\n",
        "    ax.set_ylabel(\"s2\") #変更\n",
        "    # グラフを表示\n",
        "    ax.set_title(\"load_total=\"+str(load_total))\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "optimal_policy(load_total=0.2)\n",
        "optimal_policy(load_total=1.0)\n",
        "optimal_policy(load_total=1.8)\n",
        "\n",
        "\n",
        "state_value(load_total=1)\n",
        "\n",
        "#optimal_policy(s1=0,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=1,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=2,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=3,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=4,m1=0,m2=0,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=4,m1=0,m2=0,m3=0,b=0,d=0,t=1)\n",
        "#optimal_policy(s1=0,m1=1,m2=1,m3=0,b=1,d=0,t=1)\n",
        "#optimal_policy(s1=0,m1=0,m2=0,m3=0,b=1,d=0,t=0.5)\n",
        "#optimal_policy(s1=0,m1=0,m2=0,m3=0,b=-1,d=0,t=1)\n",
        "#optimal_policy(s1=1,m1=0,m2=0,m3=0,b=-1,d=0,t=1)\n",
        "#optimal_policy(s1=2,m1=0,m2=0,m3=0,b=-1,d=0,t=1)\n",
        "#optimal_policy(s1=3,m1=0,m2=0,m3=0,b=-1,d=0,t=1)\n",
        "#optimal_policy(s1=4,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=0,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=1,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=2,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=3,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "#optimal_policy(s1=4,m1=0,m2=0,m3=0,b=-1,d=-1,t=0.3)\n",
        "s1 = 4\n",
        "s2 = 4\n",
        "s3 = 4\n",
        "m1 = 0\n",
        "m2 = 0\n",
        "m3 = 0\n",
        "inventory = 0\n",
        "#demand = 0\n",
        "remain_interval = 1\n",
        "#level_ohe, mstatus_ohe = one_hot_encoding(levels=[s1,s2,s3],maintenance_status=[m1,m2,m3])\n",
        "#state = level_ohe + mstatus_ohe + list([inventory,demand,remain_interval])\n",
        "#act_dsc, act_cnt, log_prob, val = agent.choose_action_max_prob(state)\n",
        "#act_dsc = act_dsc.item()\n",
        "#act_dsc\n",
        "print(env.Visit)\n",
        "print(env.cntCount)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def get_color(action):\n",
        "    if action < 0:\n",
        "        return \"white\"\n",
        "    #cmap = [\"red\",\"sandybrown\",\"orange\",\"lawngreen\",\"darkorange\",\"lightgreen\",\"green\",\"blue\"]\n",
        "    cmap = [\"red\",\"orange\",\"orange\",\"lightgreen\",\"orange\",\"lightgreen\",\"lightgreen\",\"lightblue\"]\n",
        "    return cmap[action]\n",
        "\n",
        "def plot_action(ax, center_x, center_y, size, action):\n",
        "    opt_action = patches.Rectangle(\n",
        "        (center_x-size/2, center_y-size/2),\n",
        "        size,\n",
        "        size,\n",
        "        linewidth = 0,\n",
        "        facecolor = get_color(action)\n",
        "    )\n",
        "    ax.add_patch(opt_action)\n",
        "    if action >= 0:\n",
        "        r = list(map(int, bin(action)[2:].zfill(env.num_targets)))\n",
        "        #ax.text(center_x,center_y,f'({r[0]},{r[1]},{r[2]})',ha='center', va='center')\n",
        "        ax.text(center_x,center_y,f'{action}',ha='center', va='center')\n",
        "\n",
        "def optimal_policy(load_total):\n",
        "    fig, ax = plt.subplots()\n",
        "    x = 26\n",
        "    for s1 in range(x):\n",
        "        for s2 in range(x):\n",
        "            state = [s1,s2] + list([load_total])\n",
        "            act_dsc, act_cnt, log_prob_dsc, log_prob_cnt, val = agent.choose_action_max_prob(state)\n",
        "            act_dsc = act_dsc.item()\n",
        "            act_cnt = act_cnt.squeeze().cpu().detach().numpy().copy()\n",
        "            #print(act_dsc,act_cnt)\n",
        "            print(\"val:\",val)\n",
        "            #status = np.array([(cs1<env.failures[0])*1,(cs2<env.failures[1])*1,(cs3<env.failures[2])*1])\n",
        "            plot_action(ax, s1, s2, act_dsc, act_cnt, load_total)\n",
        "            plot_action(ax,cs2,cs3,size=1,action=action)\n",
        "    ax.set_xlim(-0.5,x-1+0.5)\n",
        "    ax.set_ylim(-0.5,x-1+0.5)\n",
        "    #cbar = plt.colorbar(scatter, cax=cax, ticks=np.arange(0.5, 8.5, 1))\n",
        "    #cbar.ax.set_yticklabels([f'{i:b}' for i in range(8)])\n",
        "    ax.set_aspect('equal', adjustable='box')  # アスペクト比を保持\n",
        "    ax.set_xlabel(\"s2\")\n",
        "    ax.set_ylabel(\"s3\")\n",
        "    # グラフを表示\n",
        "    ax.set_title(\"(s1=\"+str(cs1)+\", s2, s3, z1=\"+str(cz1)+\", z2=\"+str(cz2)+\", z3=\"+str(cz3)+\")\")\n",
        "    plt.show()\n",
        "\n",
        "optimal_policy(load_total=0.2)\n",
        "optimal_policy(load_total=1)\n",
        "optimal_policy(load_total=1.8)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qBPaE5n89aZQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1a401ca5-e30d-4b76-ca46-5f2e2d0ed01c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef get_color(action):\\n    if action < 0:\\n        return \"white\"\\n    #cmap = [\"red\",\"sandybrown\",\"orange\",\"lawngreen\",\"darkorange\",\"lightgreen\",\"green\",\"blue\"]\\n    cmap = [\"red\",\"orange\",\"orange\",\"lightgreen\",\"orange\",\"lightgreen\",\"lightgreen\",\"lightblue\"]\\n    return cmap[action]\\n\\ndef plot_action(ax, center_x, center_y, size, action):\\n    opt_action = patches.Rectangle(\\n        (center_x-size/2, center_y-size/2),\\n        size,\\n        size,\\n        linewidth = 0,\\n        facecolor = get_color(action)\\n    )\\n    ax.add_patch(opt_action)\\n    if action >= 0:\\n        r = list(map(int, bin(action)[2:].zfill(env.num_targets)))\\n        #ax.text(center_x,center_y,f\\'({r[0]},{r[1]},{r[2]})\\',ha=\\'center\\', va=\\'center\\')\\n        ax.text(center_x,center_y,f\\'{action}\\',ha=\\'center\\', va=\\'center\\')\\n\\ndef optimal_policy(load_total):\\n    fig, ax = plt.subplots()\\n    x = 26\\n    for s1 in range(x):\\n        for s2 in range(x):\\n            state = [s1,s2] + list([load_total])\\n            act_dsc, act_cnt, log_prob_dsc, log_prob_cnt, val = agent.choose_action_max_prob(state)\\n            act_dsc = act_dsc.item()\\n            act_cnt = act_cnt.squeeze().cpu().detach().numpy().copy()\\n            #print(act_dsc,act_cnt)\\n            print(\"val:\",val)\\n            #status = np.array([(cs1<env.failures[0])*1,(cs2<env.failures[1])*1,(cs3<env.failures[2])*1])\\n            plot_action(ax, s1, s2, act_dsc, act_cnt, load_total)\\n            plot_action(ax,cs2,cs3,size=1,action=action)\\n    ax.set_xlim(-0.5,x-1+0.5)\\n    ax.set_ylim(-0.5,x-1+0.5)\\n    #cbar = plt.colorbar(scatter, cax=cax, ticks=np.arange(0.5, 8.5, 1))\\n    #cbar.ax.set_yticklabels([f\\'{i:b}\\' for i in range(8)])\\n    ax.set_aspect(\\'equal\\', adjustable=\\'box\\')  # アスペクト比を保持\\n    ax.set_xlabel(\"s2\")\\n    ax.set_ylabel(\"s3\")\\n    # グラフを表示\\n    ax.set_title(\"(s1=\"+str(cs1)+\", s2, s3, z1=\"+str(cz1)+\", z2=\"+str(cz2)+\", z3=\"+str(cz3)+\")\")\\n    plt.show()\\n\\noptimal_policy(load_total=0.2)\\noptimal_policy(load_total=1)\\noptimal_policy(load_total=1.8)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "DRL",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.1.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}